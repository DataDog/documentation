重複排除 (deduplicate) プロセッサーは、ボリュームとノイズを削減するためにデータの重複を削除します。一度に 5,000 件のメッセージをキャッシュし、そこに対して受信ログを比較します。たとえば、複数の同一の警告ログが連続で送信される場合に、ユニークな警告ログのみを保持したいときに使用できます。

Deduplicate プロセッサーの設定方法
1. **フィルタークエリ**を定義します。指定した[フィルタークエリ](#filter-query-syntax)に一致するログだけが処理されます。重複排除されたログと、フィルタークエリに一致しないログはパイプラインの次のステップに送られます。
1. **Type of deduplication** ドロップダウンメニューで、下記のフィールドについて `Match` するか、または `Ignore` するかを選択します。
    - `Match` を選択した場合、ログが通過した後、下記で指定するすべてのフィールドの値が同一である将来のログが削除されます。
    - `Ignore` を選択した場合、ログが通過した後、下記で指定するフィールドを除いたすべてのフィールドの値が同一である将来のログが削除されます。
1.  Match する、または Ignore するフィールドを入力します。最低 1 つのフィールドが必要で、最大 3 つのフィールドを指定できます。
    - サブフィールドを指定する場合は、`<OUTER_FIELD>.<INNER_FIELD>` のようなパス表記を使用します。詳細は、[パス表記の例](#path-notation-example)を参照してください。
1. **Add field** をクリックして、フィルターの対象にしたいフィールドを追加します。

##### パス表記の例

 以下のようなメッセージ構造があった場合、`double_inner_value` という値を持つキーを指すには、`outer_key.inner_key.double_inner_key` のように記述します:
```json
{
    "outer_key": {
        "inner_key": "inner_value",
        "a": {
            "double_inner_key": "double_inner_value",
            "b": "b value"
        },
        "c": "c value"
    },
    "d": "d value"
}
```
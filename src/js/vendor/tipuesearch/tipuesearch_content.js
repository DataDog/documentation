
var tipuesearch = {"pages": [{"title":"API Reference","text":"\n  \n    API Reference \n    \n      \n        Auth\n        Errors\n        Rate Limiting\n        Metrics\n        Events\n        Checks\n        Monitors\n        Downtimes\n        Timeboards\n        Screenboards\n        Hosts\n        Tags\n        Search\n        Comments\n        Users\n        Graphs\n        Embeds\n      \n      \n      \n      \n        Shell\n        Python\n        Ruby\n      \n      \n        Troubleshooting\n      \n    \n  \n\n  \n\n    \n\n    \nOverview\n    \n      \n        This section details Datadog's HTTP API. It makes it easy to get data in and\n        out of Datadog.\n\n        The Datadog API uses resource-oriented URLs, uses status codes to indicate the\n        success or failure of requests and returns JSON from all requests. Let's dive\n        in and see how it works.\n      \n      \n        Libraries\n        There are many client libraries that wrap the Datadog API. Check them out.\n\n        API Endpoint\n        https://app.datadoghq.com/api/\n      \n    \n\n    \n    \nAuthentication\n    \n      \n        \n          All requests to Datadog's API must be authenticated. Requests that write data require\n          reporting access and require an API key. Requests that read data\n          require full access and also require an application key.\n        \n\n        You can manage your account's API and application keys here.\n      \n      \n        Example\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\ncurl \"https://app.datadoghq.com/api/v1/validate?api_key=9775a026f1ca7d1c6c5af9d94d9595a4\"\n\n\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\ndog = Dogapi::Client.new('9775a026f1ca7d1c6c5af9d94d9595a4', '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff')\n      \n    \n\n    \n\n    \nSuccess and Errors\n    \n      \n        \n        The Datadog API uses HTTP status codes to indicate the success or failure\n        of a request.\n        \n\n        \n        An error indicates that the service did not successfully handle your request. In addition to the status code, the response may contain a JSON object with an errors array containing more detailed error messages. Note: When using libraries, some errors may throw exceptions rather than return JSON objects.\n        \n\n        \n  If the service is able to handle your request, but some issues are present (e.g. using a deprecated API or API version), the HTTP status code will indicate success and the response body will contain the expected result with the addition of a warnings array containing detailed warning messages.\n        \n\n\n\n      \n      \n        Status Codes\n        \n        \n           200 OK \n\n        \n           201 Created \n\n        \n           202 Accepted \n\n        \n           204 No Content \n\n        \n           301 Moved Permanently \n\n        \n           304 Not Modified \n\n        \n           401 Unauthorized \n\n        \n           403 Forbidden \n\n        \n           404 Not Found \n\n        \n           409 Conflict \n\n        \n           422 Unprocessable Entity \n\n        \n           500 Server Error \n\n        \n        \n        Example Error Response\n        { 'errors': [\n    'Something bad happened to the server.',\n    'Your query made the server very sad.'\n  ]\n}\n\n        Example Warning Response\n        { 'some_thing': ...,\n  'some_other_thing': ...,\n  'warnings': [\n      'This is a deprecated API.'\n  ]\n}\n\n      \n    \n\n\n\n    \n\n    \nRate Limiting\n    \n      \n        \n        Some of our API endpoints are rate limited.  Once you exceed a certain number of requests in a certain time period we return an error.\n        \n        \n        For rate limited API endpoints we return headers so you can know how close you are to your limit.  If you exceed your limit, you can review these headers to determine when you will be able to try again.\n        \n        \n        Rate limits can be increased from defaults by contacting the Datadog Support team.\n        \n      \n      \n        Rate Limit Headers\n        \n          \nX-RateLimit-Limitnumber of requests allowed in a time period\n          \nX-RateLimit-Periodlength of time in seconds for resets (calendar aligned)\n          \nX-RateLimit-Remainingnumber of allowed requests left in current time period\n          \nX-RateLimit-Resettime in seconds until next reset\n        \n      \n    \n\n\n    \n\n    \nMetrics\n    \n      \n        \n          The metrics end-point allows you to:\n        \n        \n          Post metrics data so it can be graphed on Datadog's dashboards\n          Query metrics from any time period\n        \n        \n          As occurs within the Datadog UI, a graph can only contain a set number of points and as the timeframe over which a metric is viewed increases, aggregation between points will occur to stay below that set number.\n        \n        \n          Thus, if you are querying for larger timeframes of data, the points returned will be more aggregated. The max granularity within Datadog is one point per second, so if you had submitted points at that interval and requested a very small interval from the query API (in this case, probably less than 100 seconds), you could end up getting all of those points back. Otherwise, our algorithm tries to return about 150 points per any given time window, so you'll see coarser and coarser granularity as the amount of time requested increases. We do this time aggregation via averages.\n        \n      \n    \n\n    \n    \nGet list of active metrics\n    \n      \n        \n          Get the list of actively reporting metrics from a given time until now. This endpoint is not available in the Python and Ruby libraries.\n        \n\n        Arguments\n        \n              \n      from [required]\n      seconds since the unix epoch\n    \n\n        \n\n      \n      \n        Signature\n        GET https://app.datadoghq.com/api/v1/metrics\n        Example Request\n          #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\nfrom_time=$(date -v -1d +%s)\n\ncurl -G \\\n    \"https://app.datadoghq.com/api/v1/metrics\" \\\n    -d \"api_key=${api_key}\" \\\n    -d \"application_key=${app_key}\" \\\n    -d \"from=${from_time}\"\n\n        Example Response\n        {\n \"metrics\": [\n   \"system.load.1\",\n   \"system.load.15\",\n   \"system.load.5\",\n   \"system.load.norm.1\",\n   \"system.load.norm.15\",\n   \"system.load.norm.5\",\n   \"system.mem.buffered\",\n   \"system.mem.cached\",\n   \"system.mem.committed\",\n   \"system.mem.free\"\n ],\n \"from\": 1467815773\n}\n\n      \n    \n    \n\n    \nPost time series points\n    \n      \n        \n          The metrics end-point allows you to post time-series data that can be\n          graphed on Datadog's dashboards.\n        \n        Arguments\n        \n              \n      series [required]\n      A JSON array of metrics where each item in the array contains the following arguments:\n    \n\n              \n      series [optional, default=None]\n      To submit multiple metrics, you may pass a JSON array where each item in the array contains the following arguments. To submit a single metric, you may pass the following arguments as separate arguments.\n    \n\n              \n      metric [required]\n      The name of the time series\n    \n\n          \n            points [required]\n            A JSON array of points. Each point is of the form:\n              \n                [[POSIX_timestamp, numeric_value], ...]\n              \n              Note that the timestamp should be in seconds, must be current, and the numeric value is a 32bit float gauge-type value.\n              Current is defined as not more than 10 minutes in the future or more than 1 hour in the past.\n            \n          \n              \n      host [optional, default=None]\n      The name of the host that produced the metric.\n    \n\n              \n      tags [optional, default=None]\n      A list of tags associated with the metric.\n    \n\n        \n      \n      \n        Signature\n        POST https://app.datadoghq.com/api/v1/series\n        Example Request\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\nimport time\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\nnow = time.time()\nfuture_10s = now + 10\n\n# Submit a single point with a timestamp of `now`\napi.Metric.send(metric='page.views', points=1000)\n\n# Submit a point with a timestamp (must be ~current)\napi.Metric.send(metric='my.pair', points=(now, 15))\n\n# Submit multiple points.\napi.Metric.send(metric='my.series', points=[(now, 15), (future_10s, 16)])\n\n# Submit a point with a host and tags.\napi.Metric.send(metric='my.series', points=100, host=\"myhost.example.com\", tags=[\"version:1\"])\n\n# Submit multiple metrics\napi.Metric.send([{'metric':'my.series', 'points':15}, {'metric':'my1.series', 'points':16}])\n        \n          #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n\ncurrenttime=$(date +%s)\ncurl  -X POST -H \"Content-type: application/json\" \\\n-d \"{ \\\"series\\\" :\n         [{\\\"metric\\\":\\\"test.metric\\\",\n          \\\"points\\\":[[$currenttime, 20]],\n          \\\"type\\\":\\\"gauge\\\",\n          \\\"host\\\":\\\"test.example.com\\\",\n          \\\"tags\\\":[\\\"environment:test\\\"]}\n        ]\n    }\" \\\n'https://app.datadoghq.com/api/v1/series?api_key=9775a026f1ca7d1c6c5af9d94d9595a4'\n\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key = \"9775a026f1ca7d1c6c5af9d94d9595a4\"\n\ndog = Dogapi::Client.new(api_key)\n\n# Submit one metric value.\ndog.emit_point('some.metric.name', 50.0, :host => \"my_host.example.com\")\n\n# Submit multiple metric values\npoints = [[Time.now, 0], [Time.now + 10, 10.0], [Time.now + 20, 20.0]]\ndog.emit_points('some.metric.name', points, :tags => [\"version:1\"])\n        \n      \n    \n\n    \nQuery time series points\n    \n      \n        \n          This end point allows you to query for metrics from any time period.\n        \n\n        Arguments\n        \n              \n      from [required]\n      seconds since the unix epoch\n    \n\n              \n      to [required]\n      seconds since the unix epoch\n    \n\n              \n      start [required]\n      seconds since the unix epoch\n    \n\n              \n      end [required]\n      seconds since the unix epoch\n    \n\n              \n      query [required]\n      The query string\n    \n\n        \n        Query Language\n        \n          Any query used for a graph can be used here. See here for more details. The time between from and to should be less than 24 hours. If it is longer, you will receive points with less granularity.\n        \n\n      \n      \n        Signature\n        GET https://app.datadoghq.com/api/v1/query\n        Example Request\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\nimport time\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\nnow = int(time.time())\nquery = 'system.cpu.idle{*}by{host}'\nprint api.Metric.query(start=now - 3600, end=now, query=query)\n        \n          #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nto_time=$(date +%s)\nfrom_time=$(date -v -1d +%s)\n\ncurl -G \\\n    \"https://app.datadoghq.com/api/v1/query\" \\\n    -d \"api_key=${api_key}\" \\\n    -d \"application_key=${app_key}\" \\\n    -d \"from=${from_time}\" \\\n    -d \"to=${to_time}\" \\\n    -d \"query=system.cpu.idle{*}by{host}\"\n\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key = \"9775a026f1ca7d1c6c5af9d94d9595a4\"\napplication_key = \"87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\"\n\ndog = Dogapi::Client.new(api_key, application_key)\n\n# Get points from the last hour\nfrom = Time.now - 3600\nto = Time.now\nquery = 'system.cpu.idle{*}by{host}'\n\ndog.get_points(query, from, to)\n        \n        Example Response\n        \n          {\n  'status': 'ok',\n  'res_type': 'time_series',\n  'series': [{\n    'end': 1430313599000,\n    'metric': 'system.cpu.idle',\n    'interval': 30,\n    'start': 1430312070000,\n    'length': 10,\n    'aggr': None,\n    'attributes': {},\n    'pointlist': [\n      [1430312070000.0, 75.08000183105469],\n      [1430312100000.0, 99.33000183105469],\n      [1430312130000.0, 99.83499908447266],\n      [1430312160000.0, 100.0],\n      [1430312190000.0, 99.66999816894531],\n      [1430312220000.0, 100.0],\n      [1430312250000.0, 99.83499908447266],\n      [1430312280000.0, 99.66999816894531],\n      [1430312310000.0, 99.83499908447266],\n      [1430312340000.0, 99.66999816894531]\n    ],\n    'expression': 'system.cpu.idle{host:vagrant-ubuntu-trusty-64}',\n    'scope': 'host:vagrant-ubuntu-trusty-64',\n    'unit': None,\n    'display_name':\n    'system.cpu.idle'\n  }],\n  'from_date': 1430309983000,\n  'group_by': ['host'],\n  'to_date': 1430313583000,\n  'query': 'system.cpu.idle{*}by{host}',\n  'message': u''\n}\n        \n          {\n  \"status\": \"ok\",\n  \"res_type\": \"time_series\",\n  \"series\": [\n    {\n      \"metric\": \"system.cpu.idle\",\n      \"attributes\": {},\n      \"display_name\": \"system.cpu.idle\",\n      \"unit\": null,\n      \"pointlist\": [\n        [\n          1430311800000,\n          98.19375610351562\n        ],\n        [\n          1430312400000,\n          99.85856628417969\n        ]\n      ],\n      \"end\": 1430312999000,\n      \"interval\": 600,\n      \"start\": 1430311800000,\n      \"length\": 2,\n      \"aggr\": null,\n      \"scope\": \"host:vagrant-ubuntu-trusty-64\",\n      \"expression\": \"system.cpu.idle{host:vagrant-ubuntu-trusty-64}\"\n    }\n  ],\n  \"from_date\": 1430226140000,\n  \"group_by\": [\n    \"host\"\n  ],\n  \"to_date\": 1430312540000,\n  \"query\": \"system.cpu.idle{*}by{host}\",\n  \"message\": \"\"\n}\n\n        \n          {\n  'status'=>'ok',\n  'res_type'=>'time_series',\n  'series'=>[{\n    'end'=>1430313599000,\n    'metric'=>'system.cpu.idle',\n    'interval'=>30,\n    'start'=>1430312070000,\n    'length'=>10,\n    'aggr'=>nil,\n    'attributes'=>{},\n    'pointlist'=>[\n      [1430312070000.0, 75.08000183105469],\n      [1430312100000.0, 99.33000183105469],\n      [1430312130000.0, 99.83499908447266],\n      [1430312160000.0, 100.0],\n      [1430312190000.0, 99.66999816894531],\n      [1430312220000.0, 100.0],\n      [1430312250000.0, 99.83499908447266],\n      [1430312280000.0, 99.66999816894531],\n      [1430312310000.0, 99.83499908447266],\n      [1430312340000.0, 99.66999816894531]\n    ],\n    'expression'=>'system.cpu.idle{host:vagrant-ubuntu-trusty-64}',\n    'scope'=>'host:vagrant-ubuntu-trusty-64',\n    'unit'=>nil,\n    'display_name'=>'system.cpu.idle'\n  }],\n  'from_date'=>1430309983000,\n  'group_by'=>['host'],\n  'to_date'=>1430313583000,\n  'query'=>'system.cpu.idle{*}by{host}',\n  'message'=>''\n}\n        \n      \n    \n\n    \nView metric metadata\n    \n      \n        \n          The metrics metadata endpoint allows you to get metadata about a specific metric.\n        \n\n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        GET /api/v1/metrics/:metric_name\n        Example Request\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\nmetric = 'system.cpu.idle'\n\napi.Metadata.get(metric_name=metric)\n        \n          #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nmetric_name=\"system.net.bytes_sent\"\n\ncurl \"https://app.datadoghq.com/api/v1/metrics/${metric_name}?api_key=${api_key}&application_key=${app_key}\"\n\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key = \"9775a026f1ca7d1c6c5af9d94d9595a4\"\n\ndog = Dogapi::Client.new(api_key)\n\n# Get metadata on metric\nresult = dog.get_metadata('system.net.bytes_sent')\n        \n        Example Response\n        \n          {'description': 'Percent of time the CPU spent in an idle state.',\n 'short_name': 'cpu idle',\n 'integration': 'system',\n 'statsd_interval': None,\n 'per_unit': None,\n 'type': 'gauge',\n 'unit': 'percent'}\n        \n          {\n  \"description\": \"My custom description\",\"short_name\":\"bytes sent\",\n  \"integration\": null,\n  \"statsd_interval\": null,\n  \"per_unit\": \"second\",\n  \"type\": \"gauge\",\n  \"unit\": \"byte\"\n}\n\n        \n          {\n \"description\" => \"Percent of time the CPU spent in an idle state.\",\n \"short_name\" => \"cpu idle\",\n \"integration\" => \"system\",\n \"statsd_interval\" => nil,\n \"per_unit\" => nil,\n \"type\" => \"gauge\",\n \"unit\" => \"percent\"\n}\n        \n      \n    \n\n    \nEdit metric metadata\n    \n      \n        \n          The metrics metadata endpoint allows you to edit fields of a metric's metadata.\n        \n\n        Arguments\n        \n              \n      type [optional, default=None]\n      metric type such as 'gauge' or 'rate'\n    \n\n              \n      description [optional, default=None]\n      string description of the metric\n    \n\n              \n      short_name [optional, default=None]\n      short name string of the metric\n    \n\n              \n      unit [optional, default=None]\n      primary unit of the metric such as 'byte' or 'operation'\n    \n\n              \n      per_unit [optional, default=None]\n      'per' unit of the metric such as 'second' in 'bytes per second'\n    \n\n              \n      statsd_interval [optional, default=None]\n      if applicable, statds flush interval in seconds for the metric\n    \n\n        \n      \n      \n        Signature\n        PUT /api/v1/metrics/:metric_name\n        Example Request\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\nmetric = 'system.net.bytes_sent'\nparams = {\n    'description': 'My custom description',\n    'short_name': 'bytes sent',\n    'type': 'gauge',\n    'unit': 'byte',\n    'per_unit': 'second'\n}\n\napi.Metadata.update(metric_name=metric, **params)\n        \n          #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nmetric_name=\"system.net.bytes_sent\"\n\ncurl -X PUT -H \"Content-type: application/json\" \\\n-d '{\n      \"type\": \"gauge\",\n      \"description\": \"my custom description\",\n      \"short_name\": \"bytes sent\",\n      \"unit\": \"byte\",\n      \"per_unit\": \"second\"\n    }' \\\n    \"https://app.datadoghq.com/api/v1/metrics/${metric_name}?api_key=${api_key}&application_key=${app_key}\"\n\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key = \"9775a026f1ca7d1c6c5af9d94d9595a4\"\n\ndog = Dogapi::Client.new(api_key)\n\nupdates = {\n    \"type\" => \"gauge\",\n    \"description\" => \"my custom description\",\n    \"short_name\" => \"bytes sent\",\n    \"unit\" => \"byte\",\n    \"per_unit\" => \"second\"\n}\n\n# Submit updates for metric\nresult = dog.update_metadata('system.net.bytes_sent', updates)\n        \n        Example Response\n        \n          {'description': 'My custom description',\n 'short_name': 'bytes sent',\n 'integration': None,\n 'statsd_interval': None,\n 'per_unit': 'second',\n 'type': 'gauge',\n 'unit': 'byte'}\n        \n          {\n  \"description\": \"my custom description\",\n  \"short_name\": \"bytes sent\",\n  \"integration\": null,\n  \"statsd_interval\": null,\n  \"per_unit\": \"second\",\n  \"type\": \"gauge\",\n  \"unit\": \"byte\"\n}\n\n        \n          {\n \"description\" => \"My custom description\",\n \"short_name\" => \"bytes sent\",\n \"integration\" => nil,\n \"statsd_interval\" => nil,\n \"per_unit\" => \"second\",\n \"type\" => \"gauge\",\n \"unit\" => \"byte\"\n}\n        \n      \n    \n\n    \n\n    \nEvents\n    \n      \n        \n          The events service allows you to programatically post events to the\n          stream and fetch events from the stream.\n        \n      \n    \n    \nPost an Event\n    \n      \n        \n          This end point allows you to post events to the stream. You can tag them, set priority and event aggregate them with other events.\n        \n        Arguments\n        \n        \n          \n                \n      title [required]\n      The event title. Limited to 100 characters.\n    \n\n                \n      text [required]\n      The body of the event. Limited to 4000 characters. The text supports markdown.\n    \n\n          \n                \n      title [required]\n      The event title. Limited to 100 characters.\n    \n\n                \n      text [required]\n      The body of the event. Limited to 4000 characters. The text supports markdown.\n    \n\n          \n              \n      msg_text [required]\n      The text for the message. Limited to 4000 characters. The text supports markdown.\n    \n\n              \n      msg_title [optional, default='']\n      The event title. Limited to 100 characters.\n    \n\n              \n      date_happened [optional, default=now]\n      POSIX timestamp of the event.\n    \n\n              \n      priority [optional, default='normal']\n      The priority of the event ('normal' or 'low').\n    \n\n              \n      host [optional, default=None]\n      Host name to associate with the event. Any tags associated with the host will also be applied to this event.\n    \n\n              \n      tags [optional, default=None]\n      A list of tags to apply to the event.\n    \n\n              \n      alert_type [optional, default='info']\n      \"error\", \"warning\", \"info\" or \"success\".\n    \n\n              \n      aggregation_key [optional, default=None]\n      An arbitrary string to use for aggregation, max length of 100 characters. If you specify a key, all events using that key will be grouped together in the Event Stream.\n    \n\n              \n      source_type_name [optional, default=None]\n      The type of event being posted. Options: nagios, hudson, jenkins, my apps, feed, chef, puppet, git, bitbucket, fabric, capistrano\n\n    \n\n        \n      \n      \n        Signature\n        POST /api/v1/events\n        Example Request\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\ntitle = \"Something big happened!\"\ntext = 'And let me tell you all about it here!'\ntags = ['version:1', 'application:web']\n\napi.Event.create(title=title, text=text, tags=tags)\n\n# If you are programmatically adding a comment to this new event\n# you might want to insert a pause of .5 - 1 second to allow the\n# event to be available.\n        \n          #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\ncurl  -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"title\": \"Did you hear the news today?\",\n      \"text\": \"Oh boy!\",\n      \"priority\": \"normal\",\n      \"tags\": [\"environment:test\"],\n      \"alert_type\": \"info\"\n  }' \\\n'https://app.datadoghq.com/api/v1/events?api_key=9775a026f1ca7d1c6c5af9d94d9595a4'\n\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# submitting events doesn't require an application_key, so we don't bother\n# setting it\ndog = Dogapi::Client.new(api_key)\n\ndog.emit_event(Dogapi::Event.new('msg_text', :msg_title => 'Title'))\n\n# If you are programmatically adding a comment to this new event\n# you might want to insert a pause of .5 - 1 second to allow the\n# event to be available.\n        \n        Example Response\n        \n          {'event': {'date_happened': 1419436860,\n  'handle': None,\n  'id': 2603387619536318140,\n  'priority': None,\n  'related_event_id': None,\n  'tags': ['version:1', 'application:web'],\n  'text': 'And let me tell you all about it here!',\n  'title': 'Something big happened!',\n  'url': 'https://app.datadoghq.com/event/jump_to?event_id=2603387619536318140'},\n 'status': 'ok'}\n        \n          {\n    \"event\": {\n        \"date_happened\": 1346449298, \n        \"handle\": null, \n        \"id\": 1378859526682864843, \n        \"priority\": \"normal\", \n        \"related_event_id\": null, \n        \"tags\": [\n            \"environment:test\"\n        ], \n        \"text\": null, \n        \"title\": \"Did you hear the news today?\", \n        \"url\": \"https://app.datadoghq.com/event/jump_to?event_id=1378859526682864843\"\n    }, \n    \"status\": \"ok\"\n}\n\n        \n          [\"202\",\n {\"status\"=>\"ok\",\n  \"event\"=>\n   {\"priority\"=>\"normal\",\n    \"date_happened\"=>1346452418,\n    \"title\"=>\"Title\",\n    \"url\"=>\n     \"https://app.datadoghq.com/event/jump_to?event_id=1378911893708573827\",\n    \"text\"=>\"msg_text\",\n    \"tags\"=>[],\n    \"related_event_id\"=>nil,\n    \"id\"=>1378911893708573827}}]\n        \n      \n    \n    \nGet an Event\n    \n      \n        \n          This end point allows you to query for event details.\n        \n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        GET /api/v1/events/:event_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\napi.Event.get(2603387619536318140)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nevent_id=1377281704830403917\n\n# Create an event to get\nevent_id=$(curl  -X POST -H \"Content-type: application/json\" -d \"{\\\"title\\\": \\\"Did you hear the news today?\\\"}\" \"https://app.datadoghq.com/api/v1/events?api_key=9775a026f1ca7d1c6c5af9d94d9595a4\" | jq -r '.event.url|ltrimstr(\"https://app.datadoghq.com/event/event?id=\")')\nsleep 5\n\ncurl \"https://app.datadoghq.com/api/v1/events/${event_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nevent_id = '1375909614428331251'\ndog.get_event(event_id)\n        Example Response\n        {'event': {'alert_type': 'info',\n  'date_happened': 1419436860,\n  'device_name': None,\n  'host': None,\n  'id': 2603387619536318140,\n  'payload': '{}',\n  'priority': 'normal',\n  'resource': '/api/v1/events/2603387619536318140',\n  'tags': ['application:web', 'version:1'],\n  'text': 'And let me tell you all about it here!',\n  'title': 'Something big happened!',\n  'url': '/event/jump_to?event_id=2603387619536318140'}}\n        {\n    \"event\": {\n        \"alert_type\": \"info\", \n        \"date_happened\": 1346355252, \n        \"device_name\": null, \n        \"host\": null, \n        \"id\": 1377281704830403917, \n        \"payload\": \"{}\", \n        \"priority\": \"normal\", \n        \"resource\": \"/api/v1/events/1377281704830403917\", \n        \"tags\": [\n            \"environment:test\"\n        ], \n        \"text\": \"Oh boy!\", \n        \"title\": \"Did you hear the news today?\", \n        \"url\": \"/event/jump_to?event_id=1377281704830403917\"\n    }\n}\n\n        [\"200\",\n {\"event\"=>\n   {\"date_happened\"=>1346273469,\n    \"alert_type\"=>\"info\",\n    \"resource\"=>\"/api/v1/events/1375909614428331251\",\n    \"title\"=>\"Something big happened!\",\n    \"url\"=>\"/event/jump_to?event_id=1375909614428331251\",\n    \"text\"=>\"And let me tell you all about it here!\",\n    \"tags\"=>[\"application:web\", \"version:1\"],\n    \"id\"=>1375909614428331251,\n    \"priority\"=>\"normal\",\n    \"host\"=>nil,\n    \"device_name\"=>nil,\n    \"payload\"=>\"{}\"}}]\n      \n    \n\n    \nDelete an Event\n    \n      \n        \n          This end point allows you to delete an event.\n        \n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        DELETE /api/v1/events/:event_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\napi.Event.delete(2603387619536318140)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nevent_id=1377281704830403917\n\ncurl -X DELETE \"https://app.datadoghq.com/api/v1/events/${event_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndog.delete_event(1375909614428331251)\n        Example Response\n        {\"deleted_event_id\": \"2603387619536318140\"}\n        {\"deleted_event_id\": \"1377281704830403917\"}\n\n        [\"200\", {\"deleted_event_id\"=>\"1375909614428331251\"}]\n      \n    \n\n    \nQuery the Event Stream\n    \n      \n        \n          The event stream can be queried and filtered by time, priority, sources and tags.\n        \n        Arguments\n        \n              \n      start [required]\n      POSIX timestamp\n    \n\n              \n      end [required]\n      POSIX timestamp\n    \n\n              \n      priority [optional, default=None]\n      'low' or 'normal'\n    \n\n              \n      sources [optional, default=None]\n      A comma separated string of sources\n    \n\n              \n      tags [optional, default=None]\n      A comma separated string of tags\n    \n\n        \n\n      \n      \n        Signature\n        GET /api/v1/events\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\nimport time\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n\nend_time = time.time()\nstart_time = end_time - 100\n\napi.Event.query(start=start_time, end=end_time, priority=\"normal\", tags=[\"application:web\"])\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nend_time = Time.now.to_i\nstart_time = end_time - 100\n\ndog.stream(start_time, end_time, :priority=>\"normal\", :tags=>[\"application:web\"])\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n# Note: this end point only accepts form-encoded requests.\ncurrenttime=$(date +%s)\ncurrenttime2=$(date --date='1 day ago' +%s)\ncurl -G -H \"Content-type: application/json\" \\\n    -d \"start=${currenttime2}\" \\\n    -d \"end=${currenttime}\" \\\n    -d \"api_key=9775a026f1ca7d1c6c5af9d94d9595a4\" \\\n    -d \"application_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\" \\\n    'https://app.datadoghq.com/api/v1/events'\n\n        Example Response\n        [{'alert_type': 'info',\n  'comments': [],\n  'date_happened': 1419436860,\n  'device_name': None,\n  'host': None,\n  'id': 2603387619536318140,\n  'is_aggregate': False,\n  'priority': 'normal',\n  'resource': '/api/v1/events/2603387619536318140',\n  'source': 'My Apps',\n  'tags': ['application:web', 'version:1'],\n  'text': 'And let me tell you all about it here!',\n  'title': 'Something big happened!',\n  'url': '/event/jump_to?event_id=2603387619536318140'},\n  {'alert_type': 'info',\n  'comments': [],\n  'date_happened': 1419436865,\n  'device_name': None,\n  'host': None,\n  'id': 2603387619536318141,\n  'is_aggregate': False,\n  'priority': 'normal',\n  'resource': '/api/v1/events/2603387619536318141',\n  'source': 'My Apps',\n  'tags': ['application:web', 'version:1'],\n  'text': 'And let me tell you all about it here!',\n  'title': 'Something big happened!',\n  'url': '/event/jump_to?event_id=2603387619536318141'}]\n        [\"200\", {\"events\"=>[]}]\n        {\n    \"events\": [\n        {\n            \"alert_type\": \"info\",\n            \"comments\": [],\n            \"date_happened\": 1346273496,\n            \"device_name\": null,\n            \"host\": null,\n            \"id\": 1375910067732769979,\n            \"is_aggregate\": false,\n            \"priority\": \"normal\",\n            \"resource\": \"/api/v1/events/1375910067732769979\",\n            \"source\": \"My Apps\",\n            \"tags\": [\n                \"application:web\",\n                \"version:1\"\n            ],\n            \"text\": \"And let me tell you all about it here!\",\n            \"title\": \"Something big happened!\",\n            \"url\": \"/event/jump_to?event_id=1375910067732769979\"\n        },\n        {\n            \"alert_type\": \"info\",\n            \"comments\": [],\n            \"date_happened\": 1346273469,\n            \"device_name\": null,\n            \"host\": null,\n            \"id\": 1375909614428331251,\n            \"is_aggregate\": false,\n            \"priority\": \"normal\",\n            \"resource\": \"/api/v1/events/1375909614428331251\",\n            \"source\": \"My Apps\",\n            \"tags\": [\n                \"application:web\",\n                \"version:1\"\n            ],\n            \"text\": \"And let me tell you all about it here!\",\n            \"title\": \"Something big happened!\",\n            \"url\": \"/event/jump_to?event_id=1375909614428331251\"\n        }\n    ]\n}\n\n      \n    \n\n\n    \n\n    \nService Checks\n    \n      \n        \n          The service check endpoint allows you to post check statuses for use with\n          monitors.\n        \n      \n    \n    \nPost a Check Run\n    \n      \n        Arguments\n        \n          \n              \n      check [required]\n      The text for the message\n    \n\n              \n      host_name [required]\n      The name of the host submitting the check\n    \n\n              \n      status [required]\n      An integer for the status of the check. Options: '0': OK, '1': WARNING, '2': CRITICAL, '3': UNKNOWN\n\n    \n\n              \n      timestamp [optional, default=now]\n      POSIX timestamp of the event.\n    \n\n              \n      message [optional, default=None]\n      A description of why this status occurred\n    \n\n              \n      tags [optional, default=None]\n      A list of key:val tags for this check\n    \n\n        \n      \n      \n        Signature\n        POST /api/v1/check_run\n        Example Request\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\nfrom datadog.api.constants import CheckStatus\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\ncheck = 'app.ok'\nhost = 'app1'\nstatus = CheckStatus.OK # equals 0\n\napi.ServiceCheck.check(check=check, host_name=host, status=status, message='Response: 200 OK')\n        \n          #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\ncurrenttime=$(date +%s)\ncurl  -X POST -H \"Content-type: application/json\" \\\n-d \"{\n      \\\"check\\\": \\\"app.is_ok\\\",\n      \\\"host_name\\\": \\\"app1\\\",\n      \\\"timestamp\\\": $currenttime,\n      \\\"status\\\": 0\n  }\" \\\n'https://app.datadoghq.com/api/v1/check_run?api_key=9775a026f1ca7d1c6c5af9d94d9595a4'\n\n        \n          # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# submitting events doesn't require an application_key, so we don't bother\n# setting it\ndog = Dogapi::Client.new(api_key)\n\ndog.service_check('app.is_ok', 'app1', 0, :message => 'Response: 200 OK')\n        \n        Example Response\n        \n          {'status': 'ok'}\n        \n          {\n    \"status\": \"ok\"\n}\n\n        \n          [\"202\", {\"status\"=>\"ok\"}]\n        \n      \n    \n\n    \n\n    \nMonitors\n    \n      \n        Monitors allow you to watch a metric or check that you care about,\n        notifying your team when some defined threshold is exceeded. Please\n        refer to the Guide to Monitors for more\n        information on creating monitors.\n      \n    \n\n    \n    \nCreate a monitor\n    \n      \n        Arguments\n        \n          \n            type [required]\n            The type of the monitor, chosen from:\n              \n                metric alert\n                service check\n                event alert\n                composite\n              \n            \n          \n          \n            query [required]\n            The query defines when the monitor will trigger. Query syntax depends\n            on what type of monitor you are creating:\n\n            Metric Alert Query\n\n            time_aggr(time_window):space_aggr:metric{tags} [by {key}] operator #\n            \n              \ntime_aggr avg, sum, max, min, change, or pct_change\n              \ntime_window last_#m (5, 10, 15, or 30),\n              last_#h (1, 2, or 4), or last_1d\n              \nspace_aggr avg, sum, min, or max\n              \ntags one or more tags (comma-separated), or *\n              \nkey a 'key' in key:value tag syntax; defines a\n              separate alert for each tag in the group (multi-alert)\n              \noperator <, <=, >, >=, ==, or !=\n              \n# an integer or decimal number used to set the\n              threshold\n            \n            If you are using the change or pct_change\n             time aggregator, you can instead use\n             change_aggr(time_aggr(time_window), timeshift):space_aggr:metric{tags} [by {key}] operator #\n             with:\n             \n              \nchange_aggr change, pct_change\n              \ntime_aggr avg, sum, max, min\n              \ntime_window last_#m (1, 5, 10, 15, or 30),\n              last_#h (1, 2, or 4), or last_#d (1 or 2)\n              \ntimeshift #m_ago (5, 10, 15, or 30),\n              #h_ago (1, 2, or 4), or 1d_ago\n             \n            \n            You can also use this to create an outlier monitor using the following query: avg(last_30m):outliers(avg:system.cpu.user{role:es-events-data} by {host}, 'dbscan', 7) > 0\n\n\n            Service Check Query\n            \"check\".over(tags).last(count).count_by_status()\n            \n              \ncheck name of the check, e.g. datadog.agent.up\n              \ntags one or more quoted tags (comma-separated),\n              or \"*\". e.g.: .over(\"env:prod\", \"role:db\")\n\n              \ncount must be at >= your max threshold (defined\n              in the options). e.g. if you want to notify on 1\n              critical, 3 ok and 2 warn statuses count should be 3.\n            \n\n            Event Alert Query\n            events('sources:nagios status:error,warning priority:normal tags: \"string query\"').rollup(\"count\").last(\"1h\")\"\n            \n              \nevent, the event query string:\n                \n                  \nstring_query free text query to match against event title and text.\n                  \nsources event sources (comma-separated).\n                  \nstatus event statuses (comma-separated). Valid options: error, warn, and info.\n                  \npriority event priorities (comma-separated). Valid options: low, normal, all.\n                  \nhost event reporting host (comma-separated).\n                  \ntags event tags (comma-separated).\n                  \nexcluded_tags exluded event tags (comma-separated).\n                \n              \n              \nrollup the stats rollup method. count is the only supported method now.\n              \nlast the timeframe to roll up the counts. Examples: 60s, 4h. Supported timeframes: s, m, h and d.\n            \n\n            Composite Query\n            \n12345 && 67890, where 12345 and 67890 are the IDs of non-composite monitors\n\n          \n              \n      name [optional, default=dynamic, based on query]\n      The name of the alert.\n    \n\n              \n      message [optional, default=dynamic, based on query]\n      A message to include with notifications for\n              this monitor. Email notifications can be sent to specific users by\n              using the same '@username' notation as events.\n    \n\n              \n      tags [optional, default=empty list]\n      A list of tags to associate with your monitor.\n              When getting all monitor details via the API, you can use the monitor_tags argument to filter results by these tags.\n              Tags using the \"service\" key (e.g. service:my-app) will be visible in the corresponding \"service\" field when editing the monitor in the Datadog UI. Tags without the \"service\" key will only be available via the API and will not be visible or editable in the Datadog UI.\n    \n\n\n          \n            options [optional]\n            A dictionary of options for the monitor. There are options that\n            are common to all types as well as options that are specific to\n            certain monitor types.\n\n            Common Options\n\n            \n              \nsilenced dictionary of scopes to timestamps or\n              None. Each scope will be muted until the given POSIX\n              timestamp or forever if the value is None.\n              Default: None\n              Examples:\n\n                \n\n                  To mute the alert completely:\n                      {'*': None}\n\n                  To mute role:db for a short time:\n                      {'role:db': 1412798116}\n\n                \n              \n              \n\n              \nnotify_no_data a boolean indicating whether this\n              monitor will notify when data stops reporting.\n              Default: false\n\n\n              \nnew_host_delay Time (in seconds) to allow a host\n              to boot and applications to fully start before starting the\n              evaluation of monitor results. Should be a non negative integer.\n              Default: 300\n\n\n              \nno_data_timeframe the number of minutes before a\n              monitor will notify when data stops reporting. Must be at least\n              1x the monitor timeframe for metric alerts or 2 minutes for\n              service checks.\n              Default: 1x timeframe for metric alerts, 2 minutes for\n              service checks\n\n\n              \ntimeout_h the number of hours of the monitor not\n              reporting data before it will automatically resolve from a\n              triggered state.\n              Default: None\n\n\n              \nrequire_full_window a boolean indicating whether\n              this monitor needs a full window of data before it's evaluated. We\n              highly recommend you set this to False for sparse\n              metrics, otherwise some evaluations will be skipped.\n              Default: True for \"on average\", \"at all times\" and\n              \"in total\" aggregation. False otherwise.\n\n\n              \nrenotify_interval the number of minutes after\n              the last notification before a monitor will re-notify on the\n              current status. It will only re-notify if it's not resolved.\n              Default: None\n\n\n              \nescalation_message a message to include with a\n              re-notification. Supports the '@username' notification we allow\n              elsewhere. Not applicable if renotify_interval is\n              None.\n              Default: None\n\n\n              \nnotify_audit a boolean indicating whether tagged\n              users will be notified on changes to this monitor.\n              Default: False\n\n\n              \nlocked a boolean indicating whether changes to\n              to this monitor should be restricted to the creator or admins.\n              Default: False\n\n\n              \ninclude_tags a boolean indicating whether\n              notifications from this monitor will automatically insert its\n              triggering tags into the title.\n              Default: True\n              Examples:\n\n                \n\n                  True:\n                      [Triggered on {host:h1}] Monitor Title\n\n                  False:\n                      [Triggered] Monitor Title\n\n                \n              \n              \n\n\n            \n\n            Metric Alert Options\n\n            These options only apply to metric alerts.\n\n            \n              \nthresholds a dictionary of thresholds by threshold\n              type. Currently we have two threshold types for metric alerts:\n              critical and warning. Critical is defined in the query, but can\n              also be specified in this option. Warning threshold can only be\n              specified using the thresholds option.\n              Example: {'critical': 90, 'warning': 80}\n              \n              \nevaluation_delay Time (in seconds) to delay\n              evaluation, as a non-negative integer. For example, if the value\n              is set to 300 (5min), the timeframe is set to last_5m and the\n              time is 7:00, the monitor will evaluate data from 6:50 to 6:55.\n              This is useful for AWS CloudWatch and other backfilled metrics to\n              ensure the monitor will always have data during evaluation.\n              \n            \n\n            Service Check Options\n\n            These options only apply to service checks and will be ignored\n            for other monitor types.\n\n            \n              \nthresholds a dictionary of thresholds by status.\n              Because service checks can have multiple thresholds, we don't\n              define them directly in the query.\n              Default: {'ok': 1, 'critical': 1, 'warning': 1}\n              \n            \n\n          \n        \n        \n      \n        Signature\n        POST /api/v1/monitor\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Create a new monitor\noptions = {\n    \"notify_no_data\": True,\n    \"no_data_timeframe\": 20\n}\ntags = [\"app:webserver\", \"frontend\"]\napi.Monitor.create(type=\"metric alert\", query=\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\", name=\"Bytes received on host0\", message=\"We may need to add web hosts if this is consistently high.\", tags=tags, options=options)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Create a new monitor\noptions = {\n  'notify_no_data' => true,\n  'no_data_timeframe' => 20\n}\ntags = ['app:webserver', 'frontend']\ndog.monitor(\"metric alert\", \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\", :name => \"Bytes received on host0\", :message => \"We may need to add web hosts if this is consistently high.\", :tags => tags, :options => options)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nalert_id=512\n\ncurl -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"type\": \"metric alert\",\n      \"query\": \"avg(last_5m):sum:system.net.bytes_rcvd{host:host0} > 100\",\n      \"name\": \"Bytes received on host0\",\n      \"message\": \"We may need to add web hosts if this is consistently high.\",\n      \"tags\": [\"app:webserver\", \"frontend\"],\n      \"options\": {\n      \t\"notify_no_data\": true,\n      \t\"no_data_timeframe\": 20\n      }\n    }' \\\n    \"https://app.datadoghq.com/api/v1/monitor?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'creator': {'email': 'matt@example.com',\n  'handle': 'matt@example.com',\n  'id': 1896,\n  'name': u'Matt'},\n 'id': 2081,\n 'message': 'We may need to add web hosts if this is consistently high.',\n 'name': 'Bytes received on host0',\n 'tags': ['app:webserver', 'frontend'],\n 'options': {'no_data_timeframe': 20,\n  'notify_audit': False,\n  'notify_no_data': True,\n  'silenced': {}},\n 'org_id': 2,\n 'overall_state': 'No Data',\n 'query': 'avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100',\n 'type': 'metric alert',\n 'multi': False,\n 'created': '2015-12-18T16:34:14.014039+00:00',\n 'modified': '2015-12-18T16:34:14.014039+00:00'\n }\n        [\"200\",\n {\"name\"=>\"Bytes received on host0\",\n  \"org_id\"=>1499,\n  \"tags\"=>[\"app:webserver\", \"frontend\"],\n  \"options\"=>\n   {\"notify_no_data\"=>true,\n    \"no_data_timeframe\"=>20,\n    \"notify_audit\"=>false,\n    \"silenced\"=>{}},\n  \"state\"=>{},\n  \"query\"=>\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\",\n  \"message\"=>\"We may need to add web hosts if this is consistently high.\",\n  \"type\"=>\"metric alert\",\n  \"id\"=>92089,\n  \"multi\"=>false,\n  \"created\"=>\"2015-12-18T16:34:14.014039+00:00\",\n  \"modified\"=>\"2015-12-18T16:34:14.014039+00:00\"}]\n        {\n    \"id\": 92090,\n    \"message\": \"We may need to add web hosts if this is consistently high.\",\n    \"name\": \"Bytes received on host0\",\n    \"tags\": [\"app:webserver\", \"frontend\"],\n    \"options\": {\n        \"no_data_timeframe\": 20,\n        \"notify_audit\": false,\n        \"notify_no_data\": true,\n        \"silenced\": {}\n    },\n    \"org_id\": 1499,\n    \"query\": \"avg(last_5m):sum:system.net.bytes_rcvd{host:host0} > 100\",\n    \"state\": {},\n    \"type\": \"metric alert\",\n    \"multi\": false,\n    \"created\": \"2015-12-18T16:34:14.014039+00:00\",\n    \"modified\": \"2015-12-18T16:34:14.014039+00:00\"\n}\n\n        \n      \n\n\n    \n    \nGet a monitor's details\n    \n      \n        Arguments\n        \n              \n      group_states [optional, default=None]\n      If this argument is\n          set, the returned data will include additional information (if\n          available) regarding the specified group states, including the\n          last notification timestamp, last resolution timestamp and\n          details about the last time the monitor was triggered. The\n          argument should include a string list indicating what, if any,\n          group states to include. Choose one or more from 'all', 'alert',\n          'warn', or 'no data'. Example: 'alert,warn'\n    \n\n        \n      \n      \n        Signature\n        GET /api/v1/monitor/:monitor_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Get a monitor's details\napi.Monitor.get(2081, group_states='all')\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Get a monitors's details\ndog.get_monitor(91879, :group_states => 'all')\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nmonitor_id=91879\n\n# Create a monitor to show\nmonitor_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"type\": \"metric alert\",\n      \"query\": \"avg(last_5m):sum:system.net.bytes_rcvd{host:host0} > 100\",\n      \"name\": \"Bytes received on host0\",\n      \"message\": \"We may need to add web hosts if this is consistently high.\"\n    }' \\\n    \"https://app.datadoghq.com/api/v1/monitor?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\ncurl -G \"https://app.datadoghq.com/api/v1/monitor/${monitor_id}\" \\\n     -d \"api_key=${api_key}\" \\\n     -d \"application_key=${app_key}\" \\\n     -d \"group_states=all\"\n\n        Example Response\n        {\n  'id': 2081,\n  'message': 'We may need to add web hosts if this is consistently high.',\n  'name': 'Bytes received on host0',\n  'options': {\n    'no_data_timeframe': 20,\n    'notify_audit': False,\n    'notify_no_data': True,\n    'silenced': {}\n  },\n  'org_id': 2,\n  'overall_state': 'No Data',\n  'query': 'avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100',\n  'type': 'metric alert',\n  'multi': False,\n  'created': '2015-12-18T16:34:14.014039+00:00',\n  'modified': '2015-12-18T16:34:14.014039+00:00',\n  \"state\": {\n    \"groups\": {\n      \"host:host0\": {\n        \"last_nodata_ts\": null,\n        \"last_notified_ts\": 1481909160,\n        \"last_resolved_ts\": 1481908200,\n        \"last_triggered_ts\": 1481909160,\n        \"name\": \"host:host0\",\n        \"status\": \"Alert\",\n        \"triggering_value\": {\n          \"from_ts\": 1481909037,\n          \"to_ts\": 1481909097,\n          \"value\": 1000\n        }\n      }\n    }\n  }\n}\n        [\"200\",\n  {\n    \"name\"=>\"Bytes received on host0\",\n    \"org_id\"=>1499,\n    \"options\"=>{\n      \"no_data_timeframe\"=>20,\n      \"notify_no_data\"=>false,\n      \"notify_audit\"=>false,\n      \"silenced\"=>{}\n    },\n    \"query\"=>\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\",\n    \"message\"=>\"We may need to add web hosts if this is consistently high.\",\n    \"type\"=>\"metric alert\",\n    \"id\"=>91879,\n    \"multi\"=>false,\n    \"created\"=>\"2015-12-18T16:34:14.014039+00:00\",\n    \"modified\"=>\"2015-12-18T16:34:14.014039+00:00\",\n    \"state\"=>{\n      \"groups\"=>{\n        \"host:host0\"=>{\n          \"last_nodata_ts\"=>null,\n          \"last_notified_ts\"=>1481909160,\n          \"last_resolved_ts\"=>1481908200,\n          \"last_triggered_ts\"=>1481909160,\n          \"name\"=>\"host:host0\",\n          \"status\"=>\"Alert\",\n          \"triggering_value\"=>{\n            \"from_ts\"=>1481909037,\n            \"to_ts\"=>1481909097,\n            \"value\"=>1000\n          }\n        }\n      }\n    }\n  }\n]\n        {\n  \"id\": 91879,\n  \"message\": \"We may need to add web hosts if this is consistently high.\",\n  \"name\": \"Bytes received on host0\",\n  \"options\": {\n    'no_data_timeframe': 20,\n    \"notify_audit\": false,\n    \"notify_no_data\": false,\n    \"silenced\": {}\n  },\n  \"org_id\": 1499,\n  \"query\": \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\",\n  \"type\": \"metric alert\",\n  \"multi\": false,\n  \"created\": \"2015-12-18T16:34:14.014039+00:00\",\n  \"modified\": \"2015-12-18T16:34:14.014039+00:00\",\n  \"state\": {\n    \"groups\": {\n      \"host:host0\": {\n        \"last_nodata_ts\": null,\n        \"last_notified_ts\": 1481909160,\n        \"last_resolved_ts\": 1481908200,\n        \"last_triggered_ts\": 1481909160,\n        \"name\": \"host:host0\",\n        \"status\": \"Alert\",\n        \"triggering_value\": {\n          \"from_ts\": 1481909037,\n          \"to_ts\": 1481909097,\n          \"value\": 1000\n        }\n      }\n    }\n  }\n}\n\n      \n    \n\n    \n    \nEdit a monitor\n    \n      \n        Arguments\n        \n              \n      query [required]\n      The metric query to alert on.\n    \n\n              \n      name [optional, default=dynamic, based on query]\n      The name of the monitor.\n    \n\n              \n      message [optional, default=dynamic, based on query]\n      A message to include with notifications for\n              this monitor. Email notifications can be sent to specific users by\n              using the same '@username' notation as events.\n    \n\n              \n      options [optional, default=None]\n      Refer to the create monitor documentation for\n              details on the available options.\n    \n\n              \n      tags [optional, default=empty list]\n      A list of tags to associate with your monitor.\n              This can help you categorize and filter monitors.\n    \n\n        \n      \n      \n        Signature\n        PUT /api/v1/monitor/:monitor_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize,  api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Edit an existing monitor\napi.Monitor.update(2081, query=\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\", name=\"Bytes received on host0\", message=\"We may need to add web hosts if this is consistently high.\")\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Edit an existing monitor\ndog.update_monitor(91879, \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\", :message => \"Bytes received on host0\", :name => \"We may need to add web hosts if this is consistently high.\")\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nmonitor_id=91879\n\n# Create a monitor to edit\nmonitor_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"type\": \"metric alert\",\n      \"query\": \"avg(last_5m):sum:system.net.bytes_rcvd{host:host0} > 100\",\n      \"name\": \"Bytes received on host0\",\n      \"message\": \"We may need to add web hosts if this is consistently high.\"\n    }' \\\n    \"https://app.datadoghq.com/api/v1/monitor?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\ncurl -X PUT -H \"Content-type: application/json\" \\\n-d '{\n      \"query\": \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\",\n      \"name\": \"Bytes received on host0\",\n      \"message\": \"We may need to add web hosts if this is consistently high.\"\n    }' \\\n    \"https://app.datadoghq.com/api/v1/monitor/${monitor_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'id': 2081,\n 'message': 'We may need to add web hosts if this is consistently high.',\n 'name': 'Bytes received on host0',\n 'options': {'notify_audit': False, 'notify_no_data': False, 'silenced': {}},\n 'org_id': 2,\n 'overall_state': 'No Data',\n 'query': 'avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100',\n 'type': 'metric alert',\n 'multi': False,\n 'created': '2015-12-18T16:34:14.014039+00:00',\n 'modified': '2015-12-18T18:39:24.391207+00:00'}\n        [\"200\",\n {\"name\"=>\"We may need to add web hosts if this is consistently high.\",\n  \"org_id\"=>1499,\n  \"options\"=>{\"notify_no_data\"=>false, \"notify_audit\"=>false, \"silenced\"=>{}},\n  \"state\"=>{},\n  \"query\"=>\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\",\n  \"message\"=>\"Bytes received on host0\",\n  \"type\"=>\"metric alert\",\n  \"id\"=>91879,\n  \"multi\"=>false,\n  \"created\"=>\"2015-12-18T16:34:14.014039+00:00\",\n  \"modified\"=>\"2015-12-18T18:39:24.391207+00:00\"}]\n        {\n    \"id\": 91879,\n    \"message\": \"We may need to add web hosts if this is consistently high.\",\n    \"name\": \"Bytes received on host0\",\n    \"options\": {\n        \"notify_audit\": false,\n        \"notify_no_data\": false,\n        \"silenced\": {}\n    },\n    \"org_id\": 1499,\n    \"query\": \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\",\n    \"state\": {},\n    \"type\": \"metric alert\",\n    \"multi\": false,\n    \"created\": \"2015-12-18T16:34:14.014039+00:00\",\n    \"modified\": \"2015-12-18T18:39:24.391207+00:00\"\n}\n\n      \n    \n\n    \n    \nDelete a monitor\n    \n      \n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        DELETE /api/v1/monitor/:monitor_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Delete a monitor\napi.Monitor.delete(2081)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Delete a monitor\ndog.delete_monitor(62625)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nmonitor_id=59409\n\n# Create a monitor to delete\nmonitor_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"type\": \"metric alert\",\n      \"query\": \"avg(last_5m):sum:system.net.bytes_rcvd{host:host0} > 100\",\n      \"name\": \"Bytes received on host0\",\n      \"message\": \"We may need to add web hosts if this is consistently high.\"\n    }' \\\n    \"https://app.datadoghq.com/api/v1/monitor?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\ncurl -X DELETE \"https://app.datadoghq.com/api/v1/monitor/${monitor_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'deleted_monitor_id': 2081}\n        [\"200\", {\"deleted_monitor_id\"=>62625}]\n        {\n    \"deleted_monitor_id\": 59409\n}\n\n      \n    \n\n    \n    \nGet all monitor details\n    \n      \n        Arguments\n        \n              \n      group_states [optional, default=None]\n      If this argument is\n          set, the returned data will include additional information (if\n          available) regarding the specified group states, including the\n          last notification timestamp, last resolution timestamp and\n          details about the last time the monitor was triggered. The\n          argument should include a string list indicating what, if any,\n          group states to include. Choose one or more from 'all', 'alert',\n          'warn', or 'no data'. Example: 'alert,warn'\n    \n\n              \n      name [optional, default=None]\n      A string to filter monitors by name\n    \n\n              \n      tags [optional, default=None]\n      A comma separated list indicating\n          what tags, if any, should be used to filter the list of monitors\n          by scope, e.g. host:host0. For more information, see the tags parameter for the appropriate query argument in the Create a monitor section above.\n    \n\n              \n      monitor_tags [optional, default=None]\n      A comma separated list indicating\n          what service and/or custom tags, if any, should be used to filter the list of monitors. Tags created in the Datadog UI will automatically have the \"service\" key prepended (e.g. service:my-app)\n    \n\n              \n      with_downtimes [optional, default=true]\n      If this argument is set to true, then the returned data will include all current downtimes for each monitor.\n    \n\n        \n      \n      \n        Signature\n        GET /api/v1/monitor\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Get all monitor details\nprint api.Monitor.get_all()\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Get all monitor details\ndog.get_all_monitors()\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -G \"https://app.datadoghq.com/api/v1/monitor\" \\\n     -d \"api_key=${api_key}\" \\\n     -d \"application_key=${app_key}\"\n\n        Example Response\n        [ {'creator': {'email': 'matt@example.com',\n   'handle': 'matt@example.com',\n   'id': 1896,\n   'name': u'Matt'},\n  'id': 2085,\n  'message': u'',\n  'name': '**system.net.bytes_rcvd** over **host:host0** was **> 100** on average during the **last 1h**.',\n  'options': {'notify_audit': False, 'notify_no_data': False, 'silenced': {}},\n  'org_id': 2,\n  'overall_state': 'No Data',\n  'query': 'avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100',\n  'type': 'metric alert',\n  'multi': False,\n  'created': '2015-12-18T16:34:14.014039+00:00',\n  'modified': '2015-12-18T18:39:24.391207+00:00'},\n {'creator': {'email': 'matt@example.com',\n   'handle': 'matt@example.com',\n   'id': 1896,\n   'name': u'Matt'},\n  'id': 2083,\n  'message': 'We may need to add web hosts if this is consistently high.',\n  'name': 'Bytes received on host0',\n  'options': {'no_data_timeframe': 20,\n   'notify_audit': False,\n   'notify_no_data': True,\n   'silenced': {}},\n  'org_id': 2,\n  'overall_state': 'No Data',\n  'query': 'avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100',\n  'type': 'metric alert',\n  'multi': False,\n  'created': '2015-12-18T16:34:14.014039+00:00',\n  'modified': '2015-12-18T18:39:24.391207+00:00'}]\n        [\"200\",\n [{\"name\"=>\"Bytes received on host0\",\n   \"org_id\"=>1499,\n   \"options\"=>{\"notify_no_data\"=>false, \"notify_audit\"=>false, \"silenced\"=>{}},\n   \"query\"=>\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\",\n   \"message\"=>\"We may need to add web hosts if this is consistently high.\",\n   \"type\"=>\"metric alert\",\n   \"multi\"=>false,\n   \"id\"=>91879,\n   \"created\"=>\"2015-12-18T16:34:14.014039+00:00\",\n   \"modified\"=>\"2015-12-18T16:34:14.014039+00:00\"},\n  {\"name\"=>\n    \"**system.net.bytes_rcvd** over **host:host0** was **> 100** on average during the **last 1h**.\",\n   \"org_id\"=>1499,\n   \"options\"=>\n    {\"notify_audit\"=>true,\n     \"timeout_h\"=>nil,\n     \"silenced\"=>{},\n     \"no_data_timeframe\"=>false,\n     \"notify_no_data\"=>false,\n     \"renotify_interval\"=>nil,\n     \"escalation_message\"=>\"\"},\n   \"query\"=>\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\",\n   \"message\"=>\"\",\n   \"type\"=>\"metric alert\",\n   \"multi\"=>false,\n   \"id\"=>91875,\n   \"created\"=>\"2015-12-18T16:34:14.014039+00:00\",\n   \"modified\"=>\"2015-12-18T16:34:14.014039+00:00\"}]]\n        [\n    {\n        \"id\": 91879,\n        \"message\": \"We may need to add web hosts if this is consistently high.\",\n        \"name\": \"Bytes received on host0\",\n        \"options\": {\n            \"notify_audit\": false,\n            \"notify_no_data\": false,\n            \"silenced\": {}\n        },\n        \"org_id\": 1499,\n        \"query\": \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\",\n        \"type\": \"metric alert\",\n        \"multi\": false,\n        \"created\": \"2015-12-18T16:34:14.014039+00:00\",\n        \"modified\": \"2015-12-18T16:34:14.014039+00:00\"\n    },\n    {\n        \"id\": 91875,\n        \"message\": \"\",\n        \"name\": \"**system.net.bytes_rcvd** over **host:host0** was **> 100** on average during the **last 1h**.\",\n        \"options\": {\n            \"escalation_message\": \"\",\n            \"no_data_timeframe\": false,\n            \"notify_audit\": true,\n            \"notify_no_data\": false,\n            \"renotify_interval\": null,\n            \"silenced\": {},\n            \"timeout_h\": null\n        },\n        \"org_id\": 1499,\n        \"query\": \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100\",\n        \"type\": \"metric alert\",\n        \"multi\": false,\n        \"created\": \"2015-12-18T16:34:14.014039+00:00\",\n        \"modified\": \"2015-12-18T16:34:14.014039+00:00\"\n    }\n]\n\n      \n    \n\n    \n    \nMute all monitors\n    \n      \n        \n        Muting will prevent all monitors from notifying through email and posts\n        to the event stream. State changes will only be visible by checking\n        the alert page.\n        \n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        POST /api/v1/monitor/mute_all\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Mute all monitors\napi.Monitor.mute_all()\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Mute all alerts\ndog.mute_monitors()\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -X POST \"https://app.datadoghq.com/api/v1/monitor/mute_all?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'active': True,\n 'disabled': False,\n 'end': None,\n 'id': 2728,\n 'message': None,\n 'scope': ['*'],\n 'start': 1419440110}\n        [\"200\",\n {\"end\"=>nil,\n  \"disabled\"=>false,\n  \"start\"=>1412805855,\n  \"active\"=>true,\n  \"scope\"=>[\"*\"],\n  \"id\"=>1647}]\n        {\n    \"active\": true,\n    \"disabled\": false,\n    \"end\": null,\n    \"id\": 1648,\n    \"scope\": [\n        \"*\"\n    ],\n    \"start\": 1412805856\n}\n\n      \n    \n\n    \n    \nUnmute all monitors\n    \n      \n        \n        Disables muting all monitors. Throws an error if mute all was\n        not enabled previously.\n        \n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        POST /api/v1/monitor/unmute_all\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Unmute all alerts\napi.Monitor.unmute_all()\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Unmute all alerts\ndog.unmute_monitors()\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -X POST \"https://app.datadoghq.com/api/v1/monitor/unmute_all?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        This end point does not return JSON on successful requests.\n      \n    \n\n    \n    \nMute a monitor\n    \n      \n        Arguments\n              \n      scope [optional, default=None]\n      The scope to apply the mute to, e.g. role:db\n    \n\n              \n      end [optional, default=None]\n      A POSIX timestamp for when the mute should end\n    \n\n      \n      \n        Signature\n        POST /api/v1/monitor/:monitor_id/mute\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Mute a monitor\napi.Monitor.mute(2088)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Mute a monitor\ndog.mute_monitor(62628)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nmonitor_id=62628\n\n# Create a monitor to mute\nmonitor_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"type\": \"metric alert\",\n      \"query\": \"avg(last_5m):sum:system.net.bytes_rcvd{host:host0} > 100\",\n      \"name\": \"Bytes received on host0\",\n      \"message\": \"We may need to add web hosts if this is consistently high.\"\n    }' \\\n    \"https://app.datadoghq.com/api/v1/monitor?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\n\ncurl -X POST \"https://app.datadoghq.com/api/v1/monitor/${monitor_id}/mute?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'id': 2088,\n 'message': 'We may need to add web hosts if this is consistently high.',\n 'name': 'Bytes received on host0',\n 'options': {'notify_audit': False,\n  'notify_no_data': False,\n  'silenced': {'*': None}},\n 'org_id': 2,\n 'overall_state': 'No Data',\n 'query': 'avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100',\n 'type': 'metric alert',\n 'created': '2015-12-18T16:34:14.014039+00:00',\n 'modified': '2015-12-18T18:39:24.391207+00:00'\n }\n        [\"200\",\n {\"name\"=>\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 200\",\n  \"org_id\"=>1499,\n  \"options\"=>\n   {\"notify_no_data\"=>false,\n    \"notify_audit\"=>true,\n    \"timeout_h\"=>nil,\n    \"silenced\"=>{\"*\"=>nil},\n    \"is_data_sparse\"=>false,\n    \"renotify_interval\"=>nil},\n  \"state\"=>{},\n  \"query\"=>\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 200\",\n  \"message\"=>\"\",\n  \"type\"=>\"metric alert\",\n  \"id\"=>62628,\n  \"created\"=>\"2015-12-18T16:34:14.014039+00:00\",\n  \"modified\"=>\"2015-12-18T18:39:24.391207+00:00\"}]\n        {\n    \"id\": 62628,\n    \"message\": \"\",\n    \"name\": \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 200\",\n    \"options\": {\n        \"is_data_sparse\": false,\n        \"notify_audit\": true,\n        \"notify_no_data\": false,\n        \"renotify_interval\": null,\n        \"silenced\": {\n            \"*\": null\n        },\n        \"timeout_h\": null\n    },\n    \"org_id\": 1499,\n    \"query\": \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 200\",\n    \"state\": {},\n    \"type\": \"metric alert\",\n    \"created\": \"2015-12-18T16:34:14.014039+00:00\",\n    \"modified\": \"2015-12-18T18:39:24.391207+00:00\"\n}\n\n      \n    \n\n    \n    \nUnmute a monitor\n    \n      \n        Arguments\n              \n      scope [optional, default=None]\n      The scope to apply the mute to. For example,\n          if your alert is grouped by {host}, you might mute 'host:app1'\n    \n\n              \n      all_scopes [optional, default=False]\n      Clear muting across all scopes\n    \n\n      \n      \n        Signature\n        POST /api/v1/monitor/:monitor_id/unmute\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Unmute all alerts\napi.Monitor.unmute(2088)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Unmute all alerts\ndog.unmute_monitor(62628)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nmonitor_id=62628\n\n# Create a monitor to unmute\nmonitor_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"type\": \"metric alert\",\n      \"query\": \"avg(last_5m):sum:system.net.bytes_rcvd{host:host0} > 100\",\n      \"name\": \"Bytes received on host0\",\n      \"message\": \"We may need to add web hosts if this is consistently high.\"\n    }' \\\n    \"https://app.datadoghq.com/api/v1/monitor?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\ncurl -X POST \"https://app.datadoghq.com/api/v1/monitor/${monitor_id}/unmute?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'id': 2088,\n 'message': 'We may need to add web hosts if this is consistently high.',\n 'name': 'Bytes received on host0',\n 'options': {'notify_audit': False,\n  'notify_no_data': False,\n  'silenced': {}},\n 'org_id': 2,\n 'overall_state': 'No Data',\n 'query': 'avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 100',\n 'type': 'metric alert',\n 'created': '2015-12-18T16:34:14.014039+00:00',\n 'modified': '2015-12-18T18:39:24.391207+00:00'}\n        [\"200\",\n {\"name\"=>\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 200\",\n  \"org_id\"=>1499,\n  \"options\"=>\n   {\"notify_no_data\"=>false,\n    \"notify_audit\"=>true,\n    \"timeout_h\"=>nil,\n    \"silenced\"=>{},\n    \"is_data_sparse\"=>false,\n    \"renotify_interval\"=>nil},\n  \"state\"=>{},\n  \"query\"=>\"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 200\",\n  \"message\"=>\"\",\n  \"type\"=>\"metric alert\",\n  \"id\"=>62628,\n  \"created\"=>\"2015-12-18T16:34:14.014039+00:00\",\n  \"modified\"=>\"2015-12-18T18:39:24.391207+00:00\"}]\n        {\n    \"id\": 62628,\n    \"message\": \"\",\n    \"name\": \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 200\",\n    \"options\": {\n        \"is_data_sparse\": false,\n        \"notify_audit\": true,\n        \"notify_no_data\": false,\n        \"renotify_interval\": null,\n        \"silenced\": {\n            \"*\": null\n        },\n        \"timeout_h\": null\n    },\n    \"org_id\": 1499,\n    \"query\": \"avg(last_1h):sum:system.net.bytes_rcvd{host:host0} > 200\",\n    \"state\": {},\n    \"type\": \"metric alert\",\n    \"created\": \"2015-12-18T16:34:14.014039+00:00\",\n    \"modified\": \"2015-12-18T18:39:24.391207+00:00\"\n}\n\n      \n    \n\n    \n\n    \nDowntimes\n    \n      \n        Downtiming gives you greater control over monitor notifications by allowing you\n        to globally exclude scopes from alerting. Downtime settings, which can be\n        scheduled with start and end times, prevent all alerting related to specified Datadog tags.\n      \n    \n\n    \n    \nSchedule monitor downtime\n    \n      \n        Arguments\n              \n      scope [required]\n      The scope(s) to which the downtime will apply, e.g.\n          'host:app2'. Provide multiple scopes as a comma-separated list, e.g. 'env:dev,env:prod'. The resulting downtime\n          applies to sources that matches ALL provided scopes (i.e. env:dev AND env:prod), NOT any of them.\n    \n\n              \n      monitor_id [optional, default=None]\n      A single monitor to which the downtime will apply. If not provided,\n          the downtime will apply to all monitors.\n    \n\n              \n      start [optional, default=None]\n      POSIX timestamp to start the downtime. If not provided, the downtime starts the moment\n          it is created.\n    \n\n              \n      end [optional, default=None]\n      POSIX timestamp to end the downtime. If not provided, the downtime will be in effect indefinitely\n          (i.e. until you cancel it).\n    \n\n              \n      message [optional, default=None]\n      A message to include with notifications for this downtime. Email notifications can be sent to specific users by using the same '@username' notation as events\n    \n\n              \n      monitor_id [optional, default=None]\n      The id of a specific monitor to apply the downtime to.\n    \n\n          \n            recurrence [optional, default=None]\n            An object defining the recurrence of the downtime with a variety of parameters:\n            \n              \n                type the type of recurrence. Choose from: days, weeks,\n              months, years.\n              \n              \n                period how often to repeat as an integer. For example to repeat every 3 days, select\n                a type of days and a period of 3.\n              \n              \n                week_days (optional) a list of week days to repeat on. Choose from: Mon, Tue, Wed, Thu, Fri, Sat or Sun. Only applicable when type is weeks. First letter must be capitalized.\n              \n              \n                until_occurrences (optional) how many times the downtime will be rescheduled.\n                until_occurences and until_date are mutually exclusive\n              \n              \n                until_date (optional) the date at which the recurrence should end as a POSIX timestmap.\n                until_occurences and until_date are mutually exclusive\n              \n            \n          \n              \n      timezone [optional, default=UTC]\n      The timezone for the downtime.\n    \n\n      \n      \n        Signature\n        POST /api/v1/downtime\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\nimport time\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Repeat for 3 hours (starting now) on every week day for 4 weeks.\nstart_ts = int(time.time())\nend_ts = start_ts + (3 * 60 * 60)\nend_reccurrence_ts = start_ts + (4* 7 * 24 * 60 * 60) # 4 weeks from now\n\nrecurrence = {\n    'type': 'weeks',\n    'period': 1,\n    'week_days': ['Mon', 'Tue', 'Wed', 'Thu', 'Fri'],\n    'until_date': end_reccurrence_ts\n}\n\n# Schedule downtime\napi.Downtime.create(scope='env:staging', start=start_ts, end=end_ts, recurrence=recurrence)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Repeat for 3 hours (starting now) on every week day for 4 weeks.\nstart_ts = Time.now.to_i\nend_ts = start_ts + (3 * 60 * 60)\nend_reccurrence_ts = start_ts + (4* 7 * 24 * 60 * 60) # 4 weeks from now\n\nrecurrence = {\n  'type' => 'weeks',\n  'period' => 1,\n  'week_days' => ['Mon', 'Tue', 'Wed', 'Thu', 'Fri'],\n  'until_date' => end_reccurrence_ts\n}\n\n# Schedule downtime\ndog.schedule_downtime('env:testing', :start => start_ts, :end => end_ts, :recurrence => recurrence)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\nstart=$(date +%s)\nend=$(date -v+3H +%s)\nend_recurrence=$(date -v+21d +%s)\n\ncurl -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"scope\": \"env:prod\",\n      \"start\": '\"${start}\"',\n      \"end\": '\"${end}\"',\n      \"recurrence\": {\n        \"type\": \"weeks\",\n        \"period\": 1,\n        \"week_days\": [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"],\n        \"until_date\": '\"${end_recurrence}\"'\n      }\n    }' \\\n    \"https://app.datadoghq.com/api/v1/downtime?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'active': True,\n 'canceled': None,\n 'creator_id': 3658,\n 'disabled': False,\n 'end': 1445978817,\n 'id': 169267576,\n 'message': None,\n 'monitor_id': None,\n 'parent_id': None,\n 'recurrence': {'period': 1,\n                'type': 'weeks',\n                'until_date': 1448387217,\n                'until_occurrences': None,\n                'week_days': ['Mon', 'Tue', 'Wed', 'Thu', 'Fri']},\n 'scope': ['env:staging'],\n 'start': 1445968017,\n 'updater_id': None}\n        [\"200\",\n {\"disabled\"=>false,\n  \"canceled\"=>nil,\n  \"active\"=>true,\n  \"message\"=>nil,\n  \"id\"=>169267581,\n  \"end\"=>1445978819,\n  \"parent_id\"=>nil,\n  \"monitor_id\"=>nil,\n  \"recurrence\"=>\n   {\"until_date\"=>1448387219,\n    \"until_occurrences\"=>nil,\n    \"week_days\"=>[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"],\n    \"type\"=>\"weeks\",\n    \"period\"=>1},\n  \"start\"=>1445968019,\n  \"creator_id\"=>3658,\n  \"scope\"=>[\"env:testing\"],\n  \"updater_id\"=>nil}]\n        {\n    \"active\": true,\n    \"canceled\": null,\n    \"creator_id\": 3658,\n    \"disabled\": false,\n    \"end\": 1445979093,\n    \"id\": 169267786,\n    \"message\": null,\n    \"monitor_id\": null,\n    \"parent_id\": null,\n    \"recurrence\": {\n        \"period\": 1,\n        \"type\": \"weeks\",\n        \"until_date\": 1447786293,\n        \"until_occurrences\": null,\n        \"week_days\": [\n            \"Mon\",\n            \"Tue\",\n            \"Wed\",\n            \"Thu\",\n            \"Fri\"\n        ]\n    },\n    \"scope\": [\n        \"env:prod\"\n    ],\n    \"start\": 1445968293,\n    \"updater_id\": null\n}\n\n      \n    \n\n    \n    \nUpdate monitor downtime\n    \n      \n        Arguments\n              \n      id [required]\n      The integer id of the downtime to be updated\n    \n\n              \n      scope [optional, default=original scope]\n      The scope to which the downtime will apply, e.g.\n          'host:app2'. Provide multiple scopes as a comma-separated list, e.g. 'env:dev,env:prod'. The resulting downtime\n          applies to sources that matches ALL provided scopes (i.e. env:dev AND env:prod), NOT any of them.\n    \n\n              \n      monitor_id [optional, default=original monitor_id]\n      A single monitor to which the downtime will apply. If not provided,\n          the downtime will apply to all monitors.\n    \n\n              \n      start [optional, default=original start]\n      POSIX timestamp to start the downtime.\n    \n\n              \n      end [optional, default=original end]\n      POSIX timestamp to end the downtime. If not provided, the downtime will be in effect indefinitely\n          (i.e. until you cancel it).\n    \n\n              \n      message [optional, default=original message]\n      A message to include with notifications for this downtime. Email notifications can be sent to specific users by using the same '@username' notation as events\n    \n\n          \n            recurrence [optional, default=original recurrence]\n            An object defining the recurrence of the downtime with a variety of parameters:\n            \n              \n                type the type of recurrence. Choose from: days, weeks,\n              months, years.\n              \n              \n                period how often to repeat as an integer. For example to repeat every 3 days, select\n                a type of days and a period of 3.\n              \n              \n                week_days (optional) a list of week days to repeat on. Choose from: Mon, Tue, Wed, Thu, Fri, Sat or Sun. Only applicable when type is weeks. First letter must be capitalized.\n              \n              \n                until_occurrences (optional) how many times the downtime will be rescheduled.\n                until_occurences and until_date are mutually exclusive\n              \n              \n                until_date (optional) the date at which the recurrence should end as a POSIX timestmap.\n                until_occurences and until_date are mutually exclusive\n              \n            \n          \n              \n      timezone [optional, default=original timezone]\n      The timezone for the downtime.\n    \n\n      \n      \n        Signature\n        PUT /api/v1/downtime/:downtime_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\nimport time\n\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Get an existing downtime\nstagingDowntimes = []\ndowntimes = api.Downtime.get_all()\n\nfor item in downtimes:\n  if item['scope'] == ['env:staging']:\n    stagingDowntimes.append(item)\n\n\n\n# Update that downtime\napi.Downtime.update(stagingDowntimes[0]['id'], scope='env:staging', end=int(time.time()) + 60000, message=\"Doing some testing on staging.\")\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Update downtime\nstagingDowntimes = []\ndowntimes = dog.get_all_downtimes()\ndowntimes[1].each do |item|\n  print item['scope']\n  if item['scope'] == ['env:staging']\n    stagingDowntimes.push item\n  end\n\nend\n\ndog.update_downtime(stagingDowntimes[0]['id'], :scope => 'env:testing', :end => Time.now.to_i + 60000, :message => \"Doing some testing on staging.\")\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\ndowntime_id=4336\n\n# Create a downtime to update\ncurrenttime=$(date +%s)\ndowntime_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d \"{\n      \\\"scope\\\": \\\"env:prod\\\",\n      \\\"start\\\": \\\"${currenttime}\\\"\n    }\" \\\n    \"https://app.datadoghq.com/api/v1/downtime?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\ncurl -X PUT -H \"Content-type: application/json\" \\\n-d '{\n      \"scope\": \"env:staging\",\n      \"message\": \"Doing some testing on staging\"\n    }' \\\n    \"https://app.datadoghq.com/api/v1/downtime/${downtime_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'active': True,\n 'disabled': False,\n 'end': 1420447087,\n 'id': 2910,\n 'message': 'Doing some testing on staging.',\n 'scope': ['env:staging'],\n 'start': 1420387032}\n        [\"200\",\n {\"end\"=>1418303372,\n  \"disabled\"=>false,\n  \"start\"=>1418224729,\n  \"active\"=>true,\n  \"scope\"=>[\"env:testing\"],\n  \"message\"=>\"Doing some testing on staging.\",\n  \"id\"=>4336}]\n        {\n    \"active\": true, \n    \"disabled\": false, \n    \"end\": 1418303372, \n    \"id\": 4336, \n    \"message\": \"Doing some testing on staging\", \n    \"scope\": [\n        \"env:staging\"\n    ], \n    \"start\": 1418224729\n}\n\n      \n    \n\n    \n    \nCancel monitor downtime\n    \n      \n        Arguments\n            \n      id [required]\n      The integer id of the downtime to be canceled\n    \n\n      \n      \n        Signature\n        DELETE /api/v1/downtime/:downtime_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Cancel downtime\napi.Downtime.delete(1654)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Cancel downtime\ndog.cancel_downtime(1655)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\ndowntime_id=1656\n\n# Create a downtime to delete\ncurrenttime=$(date +%s)\ndowntime_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d \"{\n      \\\"scope\\\": \\\"env:prod\\\",\n      \\\"start\\\": \\\"${currenttime}\\\"\n    }\" \\\n    \"https://app.datadoghq.com/api/v1/downtime?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\ncurl -X DELETE -H \"Content-type: application/json\" \"https://app.datadoghq.com/api/v1/downtime/${downtime_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        This end point does not return JSON on successful requests.\n      \n    \n\n    \n    \nCancel monitor downtimes by scope\n    \n      \n        Arguments\n            \n      scope [required]\n      Cancel all downtimes with the given scope(s), e.g. 'env:prod', 'role:db,role:db-slave'.\n    \n\n      \n      \n        Signature\n        POST /api/v1/downtime/cancel/by_scope\n        Example Request\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n#!/bin/bash\n\napi_key=\"9775a026f1ca7d1c6c5af9d94d9595a4\"\napp_key=\"87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\"\n\ncurl -X POST -H \"Content-type: application/json\" -H \"Accept: application/json\" \\\n-d \"{\n      \\\"scope\\\": \\\"host:i-123\\\"\n   }\" \\\n   \"https://app.datadoghq.com/api/v1/downtime/cancel/by_scope?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {\"cancelled_ids\":[123456789,123456790]}\n      \n    \n\n    \n    \nGet a monitor downtime\n    \n      \n        Arguments\n          This end point takes no JSON arguments.\n      \n      \n        Signature\n        GET /api/v1/downtime/:downtime_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Get a downtime\napi.Downtime.get(2910)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\ndowntime_id=2473\n\ncurl \"https://app.datadoghq.com/api/v1/downtime/${downtime_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'active': True,\n 'disabled': False,\n 'end': 1420447087,\n 'id': 2910,\n 'message': 'Doing some testing on staging.',\n 'scope': ['env:staging'],\n 'start': 1420387032}\n        {'active': True,\n 'disabled': False,\n 'end': 1420447087,\n 'id': 2910,\n 'message': 'Doing some testing on staging.',\n 'scope': ['env:staging'],\n 'start': 1420387032}\n\n      \n    \n\n    \n    \nGet all monitor downtimes\n    \n      \n        Arguments\n              \n      current_only [optional, default=false]\n      Only return downtimes that are active\n          when the request is made.\n    \n\n      \n      \n        Signature\n        GET /api/v1/downtime\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Get all downtimes\nprint api.Downtime.get_all()\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Get all downtimes\nprint(dog.get_all_downtimes())\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -G \"https://app.datadoghq.com/api/v1/downtime\" \\\n     -d \"api_key=${api_key}\" \\\n     -d \"application_key=${app_key}\"\n\n        Example Response\n        [{'active': False,\n  'disabled': True,\n  'end': 1412793983,\n  'id': 1625,\n  'scope': ['env:staging'],\n  'start': 1412792983},\n {'active': False,\n  'disabled': True,\n  'end': None,\n  'id': 1626,\n  'scope': ['*'],\n  'start': 1412792985}]\n        [\"200\",\n [{\"end\"=>1412793983,\n   \"disabled\"=>true,\n   \"start\"=>1412792983,\n   \"active\"=>false,\n   \"scope\"=>[\"env:staging\"],\n   \"id\"=>1625},\n  {\"end\"=>nil,\n   \"disabled\"=>true,\n   \"start\"=>1412792985,\n   \"active\"=>false,\n   \"scope\"=>[\"*\"],\n   \"id\"=>1626}]]\n        [\n    {\n        \"active\": false,\n        \"disabled\": true,\n        \"end\": 1412793983,\n        \"id\": 1625,\n        \"scope\": [\n            \"env:staging\"\n        ],\n        \"start\": 1412792983\n    },\n    {\n        \"active\": false,\n        \"disabled\": true,\n        \"end\": null,\n        \"id\": 1626,\n        \"scope\": [\n            \"*\"\n        ],\n        \"start\": 1412792985\n    }\n]\n\n      \n    \n\n    \n\n    \nTimeboards\n    \n      \n        \n          This endpoint allows you to programmatically create, update\n          delete and query timeboards.\n        \n      \n    \n    \nCreate a Timeboard\n    \n      \n        Arguments\n        \n              \n      title [required]\n      The name of the dashboard.\n    \n\n              \n      description [required]\n      A description of the dashboard's content.\n    \n\n              \n      graphs [required]\n      A list of graph definitions. Graph definitions follow this form:\n    \n\n          \n            \n              title [required]\n              The name of the graph.\n            \n            \n              definition [required]\n              \n                The graph definition. Example:\n                \n                  \n                    {\"requests\": [{\"q\": \"system.cpu.idle{*} by {host}\"}\n                  \n                \n              \n            \n          \n              \n      template_variables [optional, default=None]\n      A list of template variables for using Dashboard templating. Template variable definitions follow this form:\n    \n\n           \n             \n               name [required]\n               The name of the variable.\n             \n             \n               prefix [optional, default=None]\n               \n                 The tag prefix associated with the variable.  Only tags with this prefix will appear in the variable dropdown.\n               \n             \n             \n               default [optional, default=None]\n               The default value for the template variable on dashboard load\n             \n      \n\n\n      \n        Signature\n        POST /api/v1/dash\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\ntitle = \"My Timeboard\"\ndescription = \"An informative timeboard.\"\ngraphs = [{\n    \"definition\": {\n        \"events\": [],\n        \"requests\": [\n            {\"q\": \"avg:system.mem.free{*}\"}\n        ],\n    \"viz\": \"timeseries\"\n    },\n    \"title\": \"Average Memory Free\"\n}]\n\ntemplate_variables = [{\n    \"name\": \"host1\",\n    \"prefix\": \"host\",\n    \"default\": \"host:my-host\"\n}]\n\nread_only = True\n\napi.Timeboard.create(title=title, description=description, graphs=graphs, template_variables=template_variables, read_only=read_only)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Create a timeboard.\ntitle = 'My First Metrics'\ndescription = 'And they are marvelous.'\ngraphs = [{\n  \"definition\" => {\n    \"events\" => [],\n    \"requests\"=> [\n      {\"q\" => \"avg:system.mem.free{*}\"}\n    ],\n  \"viz\" => \"timeseries\"\n  },\n  \"title\" => \"Average Memory Free\"\n}]\ntemplate_variables = [{\n\t\"name\" => \"host1\",\n\t\"prefix\" => \"host\",\n\t\"default\" => \"host:my-host\"\n}]\n\ndog.create_dashboard(title, description, graphs, template_variables)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl  -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"graphs\" : [{\n          \"title\": \"Average Memory Free\",\n          \"definition\": {\n              \"events\": [],\n              \"requests\": [\n                  {\"q\": \"avg:system.mem.free{*}\"}\n              ]\n          },\n          \"viz\": \"timeseries\"\n      }],\n      \"title\" : \"Average Memory Free Shell\",\n      \"description\" : \"A dashboard with memory info.\",\n      \"template_variables\": [{\n          \"name\": \"host1\",\n          \"prefix\": \"host\",\n          \"default\": \"host:my-host\"\n      }],\n      \"read_only\": \"True\"\n    }' \\\n\"https://app.datadoghq.com/api/v1/dash?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'dash': {'description': 'An informative timeboard.',\n  'created': '2015-12-17T21:29:40.890824+00:00',\n  'modified': '2015-12-17T21:29:40.890824+00:00',\n  'read_only': 'True',\n  'graphs': [{'definition': {'events': [],\n     'requests': [{'q': 'avg:system.mem.free{*}'}],\n     'viz': 'timeseries'},\n    'title': 'Average Memory Free'}],\n  'id': 4952,\n  'template_variables': [{'default': 'host:my-host',\n    'name': 'host1',\n    'prefix': 'host'}],\n  'title': 'My Timeboard'},\n 'resource': '/api/v1/dash/4952',\n 'url': '/dash/dash/4952'}\n        [\"200\",\n {\"dash\"=>\n   {\"graphs\"=>\n     [{\"definition\"=>\n        {\"viz\"=>\"timeseries\",\n         \"events\"=>[],\n         \"requests \"=>[{\"q\"=>\"avg:system.mem.free{*}\"}]},\n       \"title\"=>\"Average Memory Free\"}],\n    \"description\"=>\"And they are marvelous.\",\n    \"id\"=>2552,\n    \"title\"=>\"My First Metrics\"},\n  \"url\"=>\"/dash/dash/2552\",\n  \"resource\"=>\"/api/v1/dash/2552\",\n  \"created\"=>\"2015-12-17T21:29:40.890824+00:00\",\n  \"modified\"=>\"2015-12-17T21:29:40.890824+00:00\"}]\n        {\n    \"dash\": {\n        \"description\": \"A dashboard with memory info.\",\n        \"graphs\": [\n            {\n                \"definition\": {\n                    \"events\": [],\n                    \"requests\": [\n                        {\n                            \"q\": \"avg:system.mem.free{*}\"\n                        }\n                    ]\n                },\n                \"title\": \"Average Memory Free\"\n            }\n        ],\n        \"id\": 2532,\n        \"title\": \"Average Memory Free Shell\"\n    },\n    \"resource\": \"/api/v1/dash/2532\",\n    \"url\": \"/dash/dash/2532\",\n    \"created\": \"2015-12-17T23:06:06.703087+00:00\",\n    \"modified\": \"2015-12-17T23:06:06.726234+00:00\",\n    \"read_only\": \"true\"\n}\n\n      \n    \n\n    \n    \nUpdate a Timeboard\n    \n      \n        Arguments\n        \n          \n            title [required]\n            The name of the dashboard.\n          \n          \n            description [required]\n            A description of the dashboard's contents.\n          \n          \n            graphs [required]\n            A list of graph definitions. Graph definitions follow this form:\n          \n          \n            \n              title [required]\n              The name of the graph.\n            \n            \n              definition [required]\n              \n                The graph definition. Read the Graph\n                Guide for more on graphs. Example:\n                \n                  \n                    {\"requests\": [{\"q\": \"system.cpu.idle{*} by {host}\"}\n                  \n                \n              \n            \n          \n            \n      template_variables [optional, default=None]\n      A list of template variables for using Dashboard templating. Template variable definitions follow this form:\n    \n\n           \n             \n               name [required]\n               The name of the variable.\n             \n             \n               prefix [optional, default=None]\n               \n                 The tag prefix associated with the variable.  Only tags with this prefix will appear in the variable dropdown.\n               \n             \n             \n               default [optional, default=None]\n               The default value for the template variable on dashboard load\n             \n      \n\n\n      \n        Signature\n        PUT /api/v1/dash/:dash_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\ntitle = \"My Timeboard\"\ndescription = \"A new and improved timeboard!\"\ngraphs =  [{\n    \"definition\": {\n        \"events\": [],\n        \"requests\": [\n            {\"q\": \"avg:system.mem.free{*} by {host}\"}\n        ],\n    \"viz\": \"timeseries\"\n    },\n    \"title\": \"Average Memory Free By Host\"\n}]\ntemplate_variables = [{\n\t\"name\": \"host1\",\n\t\"prefix\": \"host\",\n\t\"default\": \"host:my-host\"\n}]\nread_only = True\n\napi.Timeboard.update(4952, title=title, description=description, graphs=graphs, template_variables=template_variables, read_only=read_only)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndash_id = '2551'\ntitle = 'New and Improved Timeboard'\ndescription = 'This has all the new hotness.'\ngraphs =  [{\n  \"definition\" => {\n    \"events\" => [],\n    \"requests\"=> [\n      {\"q\" => \"avg:system.mem.free{*}\"}\n    ],\n  \"viz\" => \"timeseries\"\n  },\n  \"title\" => \"Average Memory Free\"\n}]\ntemplate_variables = [{\n\t\"name\" => \"host1\",\n\t\"prefix\" => \"host\",\n\t\"default\" => \"host:my-host\"\n}]\n\ndog.update_dashboard(dash_id, title, description, graphs, template_variables)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\ndash_id=2532\n\n# Create a dashboard to get. Use jq (http://stedolan.github.io/jq/download/) to get the dash id.\ndash_id=$(curl  -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"graphs\" : [{\n          \"title\": \"Average Memory Free\",\n          \"definition\": {\n              \"events\": [],\n              \"requests\": [\n                  {\"q\": \"avg:system.mem.free{*}\"}\n              ]\n          },\n          \"viz\": \"timeseries\"\n      }],\n      \"title\" : \"Average Memory Free Shell\",\n      \"description\" : \"A dashboard with memory info.\",\n      \"template_variables\": [{\n          \"name\": \"host1\",\n          \"prefix\": \"host\",\n          \"default\": \"host:my-host\"\n      }]\n    }' \\\n\"https://app.datadoghq.com/api/v1/dash?api_key=${api_key}&application_key=${app_key}\" | jq '.dash.id')\n\ncurl  -X PUT -H \"Content-type: application/json\" \\\n-d '{\n      \"graphs\" : [{\n          \"title\": \"Sum of Memory Free\",\n          \"definition\": {\n              \"events\": [],\n              \"requests\": [\n                  {\"q\": \"sum:system.mem.free{*}\"}\n              ]\n          },\n          \"viz\": \"timeseries\"\n      }],\n      \"title\" : \"Sum Memory Free Shell\",\n      \"description\" : \"An updated dashboard with memory info.\",\n      \"template_variables\": [{\n          \"name\": \"host1\",\n          \"prefix\": \"host\",\n          \"default\": \"host:my-host\"\n      }]\n    }' \\\n\"https://app.datadoghq.com/api/v1/dash/${dash_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'dash': {'description': 'A new and improved timeboard!',\n  'created': '2015-12-17T21:29:40.890824+00:00',\n  'modified': '2015-12-17T21:39:20.770834+00:00',\n  'read_only': True,\n  'graphs': [{'definition': {'events': [],\n     'requests': [{'q': 'avg:system.mem.free{*} by {host}'}],\n     'viz': 'timeseries'},\n    'title': 'Average Memory Free By Host'}],\n  'id': 4952,\n  'template_variables': [{'default': 'host:my-host',\n    'name': 'host1',\n    'prefix': 'host'}],\n  'title': 'My Timeboard'},\n 'resource': '/api/v1/dash/4952',\n 'url': '/dash/dash/4952'}\n        [\"200\",\n {\"dash\"=>\n   {\"graphs\"=>\n     [{\"definition\"=>\n        {\"viz\"=>\"timeseries\",\n         \"events\"=>[],\n         \"requests \"=>[{\"q\"=>\"avg:system.mem.free{*}\"}]},\n       \"title\"=>\"Average Memory Free\"}],\n    \"description\"=>\"This has all the new hotness.\",\n    \"id\"=>2551,\n    \"title\"=>\"New and Improved Dashboard\"},\n  \"url\"=>\"/dash/dash/2551\",\n  \"resource\"=>\"/api/v1/dash/2551\",\n  \"created\"=>\"2015-12-17T21:29:40.890824+00:00\",\n  \"modified\"=>\"2015-12-17T21:39:20.770834+00:00\"}]\n        {\n    \"dash\": {\n        \"description\": \"A dashboard with memory info.\",\n        \"graphs\": [\n            {\n                \"definition\": {\n                    \"events\": [],\n                    \"requests\": [\n                        {\n                            \"q\": \"sum:system.mem.free{*}\"\n                        }\n                    ]\n                },\n                \"title\": \"Sum of Memory Free\"\n            }\n        ],\n        \"id\": 2532,\n        \"title\": \"Sum Memory Free Shell\"\n    },\n    \"resource\": \"/api/v1/dash/2532\",\n    \"url\": \"/dash/dash/2532\",\n    \"created\": \"2015-12-17T23:06:06.703087+00:00\",\n    \"modified\": \"2015-12-17T23:12:26.726234+00:00\",\n    \"read_only\": \"false\"\n}\n\n      \n    \n\n    \n    \nDelete a Timeboard\n    \n      \n        Delete an existing timeboard.\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        DELETE /api/v1/dash/:dash_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\ntitle = \"My Timeboard\"\ndescription = \"An informative timeboard.\"\ngraphs = [{\n    \"definition\": {\n        \"events\": [],\n        \"requests\": [\n            {\"q\": \"avg:system.mem.free{*}\"}\n        ],\n    \"viz\": \"timeseries\"\n    },\n    \"title\": \"Average Memory Free\"\n}]\n\ntemplate_variables = [{\n    \"name\": \"host1\",\n    \"prefix\": \"host\",\n    \"default\": \"host:my-host\"\n}]\n\nnewboard=api.Timeboard.create(title=title, description=description, graphs=graphs, template_variables=template_variables)\n\napi.Timeboard.delete(newboard['dash']['id'])\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndash_id = '2534'\ndog.delete_dashboard(dash_id)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\ndash_id=2471\n\n# Create a dashboard to delete. Use jq (http://stedolan.github.io/jq/download/) to get the dash id.\ndash_id=$(curl  -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"graphs\" : [{\n          \"title\": \"Average Memory Free\",\n          \"definition\": {\n              \"events\": [],\n              \"requests\": [\n                  {\"q\": \"avg:system.mem.free{*}\"}\n              ]\n          },\n          \"viz\": \"timeseries\"\n      }],\n      \"title\" : \"Average Memory Free Shell\",\n      \"description\" : \"A dashboard with memory info.\",\n      \"template_variables\": [{\n          \"name\": \"host1\",\n          \"prefix\": \"host\",\n          \"default\": \"host:my-host\"\n      }]\n    }' \\\n\"https://app.datadoghq.com/api/v1/dash?api_key=${api_key}&application_key=${app_key}\" | jq '.dash.id')\n\ncurl -X DELETE \"https://app.datadoghq.com/api/v1/dash/${dash_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        This end point does not return JSON on successful requests.\n      \n    \n\n    \n    \nGet all Timeboards\n    \n      \n        Fetch all of your timeboards' definitions.\n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        GET /api/v1/dash\n        Example Request\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl \"https://app.datadoghq.com/api/v1/dash?api_key=${api_key}&application_key=${app_key}\"\n\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndog.get_dashboards\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\nprint api.Timeboard.get_all()\n        Example Response\n        {\n    \"dashes\": [\n        {\n            \"description\": \"An informative dashboard.\",\n            \"id\": \"2473\",\n            \"resource\": \"/api/v1/dash/2473\",\n            \"title\": \"My Dashboard\",\n            \"created\": \"2015-12-12T23:06:06.703087+00:00\",\n            \"modified\": \"2015-12-12T23:12:26.726234+00:00\",\n            \"read_only\": \"true\"\n        },\n        {\n            \"description\": \"This has all the new hotness.\",\n            \"id\": \"2551\",\n            \"resource\": \"/api/v1/dash/2551\",\n            \"title\": \"New and Improved Dashboard\",\n            \"created\": \"2015-12-17T23:06:06.703087+00:00\",\n            \"modified\": \"2015-12-17T23:12:26.726234+00:00\",\n            \"read_only\": \"true\"\n        }\n    ]\n}\n\n        [\"200\",\n {\"dashes\"=>\n   [{\"title\"=>\"My Dashboard\",\n     \"resource\"=>\"/api/v1/dash/2473\",\n     \"id\"=>\"2473\",\n     \"description\"=>\"An informative dashboard.\",\n     \"created\"=>\"2015-12-17T21:29:40.890824+00:00\",\n     \"modified\"=>\"2015-12-17T21:39:20.770834+00:00\"},\n     {\"title\"=>\"My First Metrics\",\n     \"resource\"=>\"/api/v1/dash/2552\",\n     \"id\"=>\"2552\",\n     \"description\"=>\"And they are marvelous.\",\n     \"created\"=>\"2015-12-17T20:09:33.890824+00:00\",\n     \"modified\"=>\"2015-12-17T20:19:22.770834+00:00\",\n     \"read_only\"=>true}\n    ]}]\n        {'dashes': [{'description': 'This has all the new hotness.',\n  'id': '2551',\n  'resource': '/api/v1/dash/2551',\n  'title': 'New and Improved Dashboard',\n  'created': '2015-12-17T21:29:40.890824+00:00',\n  'modified': '2015-12-17T21:39:20.770834+00:00'},\n {'description': 'And they are marvelous.',\n  'id': '2552',\n  'resource': '/api/v1/dash/2552',\n  'title': 'My First Metrics',\n  'created': '2015-12-17T21:29:40.890824+00:00',\n  'modified': '2015-12-17T21:39:20.770834+00:00',\n  'read_only': True}\n]}\n      \n    \n\n    \n    \nGet a Timeboard\n    \n      \n        Fetch an existing dashboard's definition.\n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        GET /api/v1/dash/:dash_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\napi.Timeboard.get(4953)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndash_id = '2542'\ndog.get_dashboard(dash_id)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\ndash_id=2473\n\n# Create a dashboard to get. Use jq (http://stedolan.github.io/jq/download/) to get the dash id.\ndash_id=$(curl  -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"graphs\" : [{\n          \"title\": \"Average Memory Free\",\n          \"definition\": {\n              \"events\": [],\n              \"requests\": [\n                  {\"q\": \"avg:system.mem.free{*}\"}\n              ]\n          },\n          \"viz\": \"timeseries\"\n      }],\n      \"title\" : \"Average Memory Free Shell\",\n      \"description\" : \"A dashboard with memory info.\",\n      \"template_variables\": [{\n          \"name\": \"host1\",\n          \"prefix\": \"host\",\n          \"default\": \"host:my-host\"\n      }]\n    }' \\\n\"https://app.datadoghq.com/api/v1/dash?api_key=${api_key}&application_key=${app_key}\" | jq '.dash.id')\n\ncurl \"https://app.datadoghq.com/api/v1/dash/${dash_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'dash': {'description': 'A new and improved timeboard!',\n  'created': '2015-12-17T21:29:40.890824+00:00',\n  'modified': '2015-12-17T21:39:20.770834+00:00',\n  'read_only': True,\n  'graphs': [{'definition': {'events': [],\n     'requests': [{'q': 'avg:system.mem.free{*} by {host}'}],\n     'viz': 'timeseries'},\n    'title': 'Average Memory Free By Host'}],\n  'id': 4953,\n  'template_variables': [{'default': 'host:my-host',\n    'name': 'host1',\n    'prefix': 'host'}],\n  'title': 'My Timeboard'},\n 'resource': '/api/v1/dash/4953',\n 'url': '/dash/dash/4953'}\n        [\"200\",\n {\"dash\"=>\n   {\"graphs\"=>\n     [{\"definition\"=>\n        {\"viz\"=>\"timeseries\",\n         \"events\"=>[],\n         \"requests \"=>[{\"q\"=>\"avg:system.mem.free{*}\"}]},\n       \"title\"=>\"Average Memory Free\"}],\n    \"description\"=>\"desc\",\n    \"id\"=>2542,\n    \"title\"=>\"foobar\"},\n  \"url\"=>\"/dash/dash/2542\",\n  \"resource\"=>\"/api/v1/dash/2542\",\n  \"created\"=>\"2015-12-17T21:29:40.890824+00:00\",\n  \"modified\"=>\"2015-12-17T21:39:20.770834+00:00\",\n  \"read_only\"=>true}]\n        {\n    \"dash\": {\n        \"description\": \"An informative dashboard.\",\n        \"graphs\": [\n            {\n                \"definition\": {\n                    \"events\": [],\n                    \"requests\": [\n                        {\n                            \"q\": \"avg:system.mem.free{*}\"\n                        }\n                    ],\n                    \"viz\": \"timeseries\"\n                },\n                \"title\": \"Average Memory Free\"\n            }\n        ],\n        \"id\": 2473,\n        \"title\": \"My Dashboard\",\n    },\n    \"resource\": \"/api/v1/dash/2473\",\n    \"url\": \"/dash/dash/2473\",\n    \"created\": \"2015-12-17T23:06:06.703087+00:00\",\n    \"modified\": \"2015-12-17T23:12:26.726234+00:00\",\n    \"read_only\": \"true\"\n}\n\n      \n    \n\n   \n\n    \nScreenboards\n    \n      \n        \n        You can view more detailed documentation on the Screenboard API at\n        http://docs.datadoghq.com/api/screenboards/.\n        \n      \n    \n\n    \nCreate a Screenboard\n    \n      \n        Arguments\n        \n              \n      board_title [required]\n      The name of the dashboard.\n    \n\n              \n      description [optional, default=None]\n      A description of the dashboard's content.\n    \n\n              \n      widgets [required]\n      A list of widget definitions. See here for more examples.\n    \n\n              \n      template_variables [optional, default=None]\n      A list of template variables for using Dashboard templating.\n    \n\n              \n      width [optional, default=None]\n      Screenboard width in pixels\n    \n\n              \n      height [optional, default=None]\n      Height in pixels.\n    \n\n              \n      read_only [optional, default=False]\n      The read-only status of the screenboard.\n    \n\n        \n      \n      \n        Signature\n        POST /api/v1/screen\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\nboard_title = \"My Screenboard\"\ndescription = \"An informative screenboard.\"\nwidth = 1024\nwidgets = [{\n  \"type\": \"image\",\n  \"height\": 20,\n  \"width\": 32,\n  \"y\": 7,\n  \"x\": 32,\n  \"url\": \"https://path/to/image.jpg\"\n  }]\ntemplate_variables = [{\n  \"name\": \"host1\",\n  \"prefix\": \"host\",\n  \"default\": \"host:my-host\"\n}]\n\napi.Screenboard.create(board_title=board_title, description=description,\n  widgets=widgets, template_variables=template_variables, width=width)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nboard = {\n    \"width\" => 1024,\n    \"height\" => 768,\n    \"board_title\" => \"dogapi test\",\n    \"widgets\" => [\n        {\n          \"type\" => \"image\",\n          \"height\" => 20,\n          \"width\" => 32,\n          \"y\" => 7,\n          \"x\" => 32,\n          \"url\" => \"https://path/to/image.jpg\"\n        }\n    ]\n}\n\nresult = dog.create_screenboard(board)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -X POST -H \"Content-type: application/json\" \\\n-d '{\n        \"width\": 1024,\n        \"height\": 768,\n        \"board_title\": \"dogapi test\",\n        \"widgets\": [\n            {\n              \"type\": \"image\",\n              \"height\": 20,\n              \"width\": 32,\n              \"y\": 7,\n              \"x\": 32,\n              \"url\": \"https://path/to/image.jpg\"\n            }\n        ]\n    }' \\\n\"https://app.datadoghq.com/api/v1/screen?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'description': 'An informative screenboard.',\n 'created': '2015-12-17T21:29:40.890824+00:00',\n 'modified': '2015-12-17T21:29:40.890824+00:00',\n 'read_only': False,\n 'widgets': [{'height': 20,\n   'type': 'image',\n   'url': 'https://path/to/image.jpg',\n   'width': 32,\n   'x': 32,\n   'y': 7}],\n 'id': 811,\n 'template_variables': [{'default': 'host:my-host',\n   'name': 'host1',\n   'prefix': 'host'}],\n 'board_title': 'My Screenboard',\n 'width': 1024}\n        [\"200\",\n {\"board_title\"=>\"dogapi test\",\n  \"width\"=>1024,\n  \"height\"=>768,\n  \"id\"=>7952,\n  \"widgets\"=>\n   [{\"url\"=>\"https://path/to/image.jpg\",\n     \"height\"=>20,\n     \"width\"=>32,\n     \"y\"=>7,\n     \"x\"=>32,\n     \"type\"=>\"image\"}],\n  \"created\"=>\"2015-12-17T21:29:40.890824+00:00\",\n  \"modified\"=>\"2015-12-17T21:29:40.890824+00:00\",\n  \"read_only\"=>false}]\n        {\n    \"board_title\": \"dogapi test\",\n    \"height\": 768,\n    \"id\": 7953,\n    \"widgets\": [\n        {\n            \"height\": 20,\n            \"type\": \"image\",\n            \"url\": \"https://path/to/image.jpg\",\n            \"width\": 32,\n            \"x\": 32,\n            \"y\": 7\n        }\n    ],\n    \"width\": 1024,\n    \"created\": \"2015-12-17T23:06:06.703087+00:00\",\n    \"modified\": \"2015-12-17T23:06:06.705087+00:00\",\n    \"read_only\": \"false\"\n}\n\n      \n    \n\n    \nUpdate a Screenboard\n    \n      \n        Arguments\n        \n              \n      board_title [required]\n      The name of the dashboard.\n    \n\n              \n      description [optional, default=None]\n      A description of the dashboard's content.\n    \n\n              \n      widgets [required]\n      A list of widget definitions. See here for more examples.\n    \n\n              \n      template_variables [optional, default=None]\n      A list of template variables for using Dashboard templating.\n    \n\n              \n      width [optional, default=None]\n      Screenboard width in pixels\n    \n\n              \n      height [optional, default=None]\n      Height in pixels.\n    \n\n              \n      read_only [optional, default=False]\n      The read-only status of the screenboard.\n    \n\n        \n      \n      \n        Signature\n        PUT /api/v1/screen/:board_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\nboard_id = 2551\nboard_title = \"My Screenboard\"\ndescription = \"An informative screenboard.\"\nwidth = 1024\nwidgets = [{\n  \"type\": \"image\",\n  \"height\": 20,\n  \"width\": 32,\n  \"y\": 7,\n  \"x\": 32,\n  \"url\": \"https://path/to/image.jpg\"\n  }]\ntemplate_variables = [{\n  \"name\": \"host1\",\n  \"prefix\": \"host\",\n  \"default\": \"host:my-host\"\n}]\n\napi.Screenboard.update(board_id, board_title=board_title, description=description,\n  widgets=widgets, template_variables=template_variables, width=width)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n\nboard_id = 7953\nboard = {\n    \"width\" => 1024,\n    \"height\" => 768,\n    \"board_title\" => \"dogapi test\",\n    \"widgets\" => [\n        {\n          \"type\" => \"image\",\n          \"height\" => 20,\n          \"width\" => 32,\n          \"y\" => 7,\n          \"x\" => 32,\n          \"url\" => \"https://path/to/image.jpg\"\n        }\n    ]\n}\n\nresult = dog.update_screenboard(board_id,  board)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -X PUT -H \"Content-type: application/json\" \\\n-d '{\n        \"width\": 1024,\n        \"height\": 768,\n        \"board_title\": \"dogapi test\",\n        \"widgets\": [\n            {\n              \"type\": \"image\",\n              \"height\": 20,\n              \"width\": 32,\n              \"y\": 7,\n              \"x\": 32,\n              \"url\": \"https://path/to/image.jpg\"\n            }\n        ]\n    }' \\\n\"https://app.datadoghq.com/api/v1/screen/${board_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'board_title': 'My Screenboard',\n  'read_only': False,\n  'description': 'An informative screenboard.',\n  'created': '2016-06-01T08:59:24.636877+00:00',\n  'modified': '2016-06-01T09:41:06.482175+00:00',\n  'width': 1024,\n  'template_variables': [{'default': 'host:my-host',\n    'prefix': 'host',\n    'name': 'host1'}],\n  'widgets': [{'url': 'https://path/to/image.jpg',\n    'height': 20,\n    'width': 32,\n    'y': 7,\n    'x': 32,\n    'type': 'image'}],\n  'id': 2551\n}\n        [\"200\",\n {\"board_title\"=>\"dogapi test\",\n  \"read_only\"=>false,\n  \"created\"=>\"2016-06-01T08:59:24.636877+00:00\",\n  \"modified\"=>\"2016-06-01T09:27:25.608805+00:00\",\n  \"height\"=>768,\n  \"width\"=>1024,\n  \"widgets\"=>\n   [{\"url\"=>\"https://path/to/image.jpg\",\n     \"height\"=>20,\n     \"width\"=>32,\n     \"y\"=>7,\n     \"x\"=>32,\n     \"type\"=>\"image\"}],\n  \"id\"=>7953}]\n        {\n    \"board_title\": \"dogapi test\",\n    \"read_only\": false,\n    \"created\": \"2016-06-01T08:59:24.636877+00:00\",\n    \"modified\": \"2016-06-01T09:06:32.481009+00:00\",\n    \"height\": 768,\n    \"width\": 1024,\n    \"widgets\": [\n        {\"url\": \"https://path/to/image.jpg\",\n        \"height\": 20,\n        \"width\": 32,\n        \"y\": 7,\n        \"x\": 32,\n        \"type\": \"image\"}\n    ],\n    \"id\": 7953}\n\n      \n    \n\n\n    \n    \nDelete a Screenboard\n    \n      \n        Delete an existing screenboard.\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        DELETE /api/v1/screen/:board_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\napi.Screenboard.delete(811)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nboard_id = '2534'\nresult = dog.delete_screenboard(board_id)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nboard_id=2471\n\n# Create a screenboard to delete\nboard_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d '{\n        \"width\": 1024,\n        \"height\": 768,\n        \"board_title\": \"dogapi tests\",\n        \"widgets\": [\n            {\n              \"type\": \"image\",\n              \"height\": 20,\n              \"width\": 32,\n              \"y\": 7,\n              \"x\": 32,\n              \"url\": \"https://path/to/image.jpg\"\n            }\n        ]\n    }' \\\n\"https://app.datadoghq.com/api/v1/screen?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\n\ncurl -X DELETE \\\n\"https://app.datadoghq.com/api/v1/screen/${board_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        \n        This end point does not return JSON on successful requests.\n      \n    \n\n    \n    \nGet a Screenboard\n    \n      \n        Fetch an existing screenboard's definition.\n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        GET /api/v1/screen/:board_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\napi.Screenboard.get(811)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nboard_id = '6334'\nresult = dog.get_screenboard(board_id)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nboard_id=6334\n\n# Create a screenboard to get\nboard_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d '{\n        \"width\": 1024,\n        \"height\": 768,\n        \"board_title\": \"dogapi tests\",\n        \"widgets\": [\n            {\n              \"type\": \"image\",\n              \"height\": 20,\n              \"width\": 32,\n              \"y\": 7,\n              \"x\": 32,\n              \"url\": \"https://path/to/image.jpg\"\n            }\n        ]\n    }' \\\n\"https://app.datadoghq.com/api/v1/screen?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\n\ncurl -X GET \\\n\"https://app.datadoghq.com/api/v1/screen/${board_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'description': 'An informative screenboard.',\n 'created': '2015-12-17T21:29:40.890824+00:00',\n 'modified': '2015-12-17T21:39:20.770834+00:00',\n 'read_only': False,\n 'widgets': [{'height': 20,\n   'type': 'image',\n   'url': 'https://path/to/image.jpg',\n   'width': 32,\n   'x': 32,\n   'y': 7}],\n 'id': 811,\n 'template_variables': [{'default': 'host:my-host',\n   'name': 'host1',\n   'prefix': 'host'}],\n 'title': 'My Screenboard',\n 'width': 1024}\n        [\"200\",\n {\"board_title\"=>\"dogapi test\",\n  \"width\"=>1024,\n  \"height\"=>768,\n  \"id\"=>6334,\n  \"widgets\"=>\n   [{\"url\"=>\"http://path/to/image.jpg\",\n     \"height\"=>20,\n     \"width\"=>32,\n     \"y\"=>7,\n     \"x\"=>32,\n     \"type\"=>\"image\"}],\n  \"created\"=>\"2015-12-17T21:29:40.890824+00:00\",\n  \"modified\"=>\"2015-12-17T21:39:20.770834+00:00\",\n  \"read_only\"=>false}]\n        {\n    \"board_title\": \"dogapi test\",\n    \"height\": 768,\n    \"id\": 6334,\n    \"widgets\": [\n        {\n            \"height\": 20,\n            \"type\": \"image\",\n            \"url\": \"http://path/to/image.jpg\",\n            \"width\": 32,\n            \"x\": 32,\n            \"y\": 7\n        }\n    ],\n    \"width\": 1024,\n    \"created\": \"2015-12-17T23:06:06.703087+00:00\",\n    \"modified\": \"2015-12-17T23:12:26.726234+00:00\",\n    \"read_only\": \"false\"\n}\n\n      \n    \n\n    \n    \nGet all Screenboards\n    \n      \n        Fetch all of your screenboards' definitions.\n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        GET /api/v1/screen\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\napi.Screenboard.get_all()\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nresult = dog.get_all_screenboards()\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -X GET \"https://app.datadoghq.com/api/v1/screen?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {\n  'screenboards': [\n    {\n      'description': 'This has all the new hotness.',\n      'id': '2551',\n      'resource': '/api/v1/screen/2551',\n      'title': 'New and Improved Screenboard',\n      'created': '2015-12-17T21:29:40.890824+00:00',\n      'modified': '2015-12-17T21:39:20.770834+00:00',\n      'read_only': False\n    },\n    {\n      'description': 'And they are marvelous.',\n      'id': '2552',\n      'resource': '/api/v1/screen/2552',\n      'title': 'My First Metrics',\n      'created': '2015-12-17T21:29:40.890824+00:00',\n      'modified': '2015-12-17T21:39:20.770834+00:00',\n      'read_only': False\n    }\n  ]\n}\n        [\"200\",\n    {\"screenboards\"=>[\n        {\"created\"=>\"2015-12-17T20:00:25.050990+00:00\",\n         \"resource\"=>\"/api/v1/screen/6334\",\n         \"id\"=>6334,\n         \"modified\"=>\"2015-12-17T20:00:25.051176+00:00\",\n         \"title\"=>\"dogapi test\",\n         \"read_only\"=>false},\n        {\"created\"=>\"2015-12-17T20:00:25.868731+00:00\",\n         \"resource\"=>\"/api/v1/screen/2\",\n         \"id\"=>2,\n         \"modified\"=>\"2015-12-17T20:00:25.868752+00:00\",\n         \"title\"=>\"Database Screen Board\",\n         \"read_only\"=>false}\n        ]\n    }\n]\n        [{'description': 'This has all the new hotness.',\n  'id': '2551',\n  'resource': '/api/v1/screen/2551',\n  'title': 'New and Improved Screenboard',\n  'created': '2015-12-17T23:06:06.703087+00:00',\n  'modified': '2015-12-17T23:12:26.726234+00:00',\n  'read_only': 'false'}\n {'description': 'And they are marvelous.',\n  'id': '2552',\n  'resource': '/api/v1/screen/2552',\n  'title': 'My First Metrics',\n  'created': '2015-12-17T23:06:06.703087+00:00',\n  'modified': '2015-12-17T23:12:26.726234+00:00',\n  'read_only': 'false'}\n]\n\n      \n    \n\n\n    \n    \nShare a Screenboard\n    \n      \n        Share an existing screenboard's with a public URL.\n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        GET /api/v1/screen/share/:board_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\napi.Screenboard.share(812)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nboard_id = '6334'\ndog.share_screenboard(board_id)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nboard_id=6334\n\n# Create a screenboard to share\nboard_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d '{\n        \"width\": 1024,\n        \"height\": 768,\n        \"board_title\": \"dogapi tests\",\n        \"widgets\": [\n            {\n              \"type\": \"image\",\n              \"height\": 20,\n              \"width\": 32,\n              \"y\": 7,\n              \"x\": 32,\n              \"url\": \"https://path/to/image.jpg\"\n            }\n        ]\n    }' \\\n\"https://app.datadoghq.com/api/v1/screen?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\n\n\ncurl -X GET \\\n\"https://app.datadoghq.com/api/v1/screen/share/${board_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'board_id': 812,\n 'public_url': 'https://p.datadoghq.com/sb/20756e0cd4'}\n        [\"200\",\n {\"board_id\"=>6334, \"public_url\"=>\"https://p.datadoghq.com/sb/20756e0cd4\"}]\n        {\n    \"board_id\": 6334, \n    \"public_url\": \"https://p.datadoghq.com/sb/20756e0cd4\"\n}\n\n      \n    \n\n    \n    \nRevoke a shared a Screenboard\n    \n      \n        Revoke a currently shared screenboard's.\n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        DELETE /api/v1/screen/share/:board_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Share it\napi.Screenboard.share(812)\n\n# Revoke the sharing\napi.Screenboard.revoke(812)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nboard_id = '6334'\n\n# Share it\ndog.share_screenboard(board_id)\n\n# Revoke the sharing\ndog.revoke_screenboard(board_id)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nboard_id=6334\n\n# Create a screenboard to share\nboard_id=$(curl -X POST -H \"Content-type: application/json\" \\\n-d '{\n        \"width\": 1024,\n        \"height\": 768,\n        \"board_title\": \"dogapi tests\",\n        \"widgets\": [\n            {\n              \"type\": \"image\",\n              \"height\": 20,\n              \"width\": 32,\n              \"y\": 7,\n              \"x\": 32,\n              \"url\": \"https://path/to/image.jpg\"\n            }\n        ]\n    }' \\\n\"https://app.datadoghq.com/api/v1/screen?api_key=${api_key}&application_key=${app_key}\" | jq '.id')\n\n# Share it\ncurl -X GET \\\n\"https://app.datadoghq.com/api/v1/screen/share/${board_id}?api_key=${api_key}&application_key=${app_key}\"\n\n# Revoke the sharing\ncurl -X DELETE \\\n\"https://app.datadoghq.com/api/v1/screen/share/${board_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        This end point does not return JSON on successful requests.\n      \n    \n\n\n    \n    \nHosts\n\n    \nMute a Host\n    \n    \n      Arguments\n      \n            \n      end [optional, default=None]\n      POSIX timestamp when the host will be unmuted. If omitted, the host will remain muted until explicitly unmuted.\n    \n\n            \n      message [optional, default=None]\n      Message to associate with the muting of this host\n    \n\n            \n      override [optional, default=False]\n      If true and the host is already muted, will replace existing host mute settings.\n    \n\n      \n    \n    \n    Signature\n      POST /api/v1/host/:hostname/mute\n      Example Request\n      # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nhostname = \"test.host\"\nmessage = \"Muting this host for a test.\"\nend_ts = Time.now.to_i + 60 * 60\ndog.mute_host(hostname, :message => message, :end => end_ts)\n      # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Find a host to mute\nhosts = api.Infrastructure.search(q='hosts:')\n# Mute a host\napi.Host.mute(hosts['results']['hosts'][0])\n      #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -X POST -H \"Content-type: application/json\" \\\n-d '{\n      \"message\": \"Muting this host for a test!\"\n  }' \"https://app.datadoghq.com/api/v1/host/test.host/mute?api_key=${api_key}&application_key=${app_key}\"\n\n      Example Response\n      [\"200\", {\"action\"=>\"Muted\", \"message\"=>\"Muting this host for a test.\", \"hostname\"=>\"test.host\", \"end\"=>1433345249}]\n      {'action': 'Muted', 'hostname': 'test.host'}\n      {\n    \"action\": \"Muted\",\n    \"hostname\": \"test.host\",\n    \"message\": \"Muting this host for a test!\"\n}\n\n      \n    \n\n    \nUnmute a Host\n    \n    \n      Arguments\n        This end point takes no JSON arguments.\n    \n    \n    Signature\n      POST /api/v1/host/:hostname/unmute\n      Example Request\n      # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nhostname = \"test.host\"\ndog.unmute_host(hostname)\n      # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Find a host to unmute\nhosts = api.Infrastructure.search(q='hosts:')\n\n# Unmute host\napi.Host.unmute(hosts['results']['hosts'][0])\n      #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -X POST -H \"Content-type: application/json\" \"https://app.datadoghq.com/api/v1/host/test.host/unmute?api_key=${api_key}&application_key=${app_key}\"\n\n      Example Response\n      [\"200\", {\"action\"=>\"Unmuted\", \"hostname\"=>\"test.host\"}]\n      {'action': 'Unmuted', 'hostname': 'test.host'}\n      {\n    \"action\": \"Unmuted\",\n    \"hostname\": \"test.host\"\n}\n\n      \n    \n\n    \n\n    \nTags\n    \n      \n        \n          The tag end point allows you to tag hosts with keywords meaningful to you - like role:database.\n          All metrics sent from a host will have its tags applied.\n\n          When fetching and applying tags to a particular host, you can refer\n          to hosts by name (yourhost.example.com).\n        \n        \n        The component of your infrastructure responsible for a tag is identified by\n        a source. Valid sources are: nagios, hudson, jenkins, users,\n        feed, chef, puppet, git, bitbucket, fabric, capistrano.\n        \n      \n    \n\n    \nGet Tags\n    \n      \n        \n          Return a mapping of tags to hosts for your whole infrastructure.\n        \n        Arguments\n        \n              \n      source [optional, default=None]\n      Only show tags from a particular source. Otherwise shows all tags.\n    \n\n        \n      \n      \n        Signature\n        GET /api/v1/tags/hosts\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndog.all_tags()\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\nprint api.Tag.get_all()\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl \"https://app.datadoghq.com/api/v1/tags/hosts?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        [\"200\",\n {\"tags\"=>\n   {\"role:web\"=>[\"test.metric.host\"],\n    \"environment:test\"=>[\"test.metric.host\"],\n    \"environment:production\"=>[\"test.another.example.com\"],\n    \"role:webserver\"=>[\"test.another.example.com\"]}}]\n        {\n    \"tags\": {\n        \"role:database\",\n        \"env:test\": [\n            \"test.metric.host\"\n        ]\n    }\n}\n        {\n    \"tags\": {\n        \"environment:production\": [\n            \"test.another.example.com\", \n            \"test.host\"\n        ], \n        \"environment:test\": [\n            \"test.metric.host\"\n        ], \n        \"role:database\": [\n            \"test.metric.host\"\n        ], \n        \"role:webserver\": [\n            \"test.another.example.com\", \n            \"test.host\"\n        ]\n    }\n}\n\n      \n    \n\n    \nGet Host Tags\n    \n      \n        \n          Return the list of tags that apply to a given host.\n        \n        Arguments\n        \n              \n      source [optional, default=None]\n      Only show tags from a particular source. Otherwise shows all tags.\n    \n\n              \n      by_source [optional, default=False]\n      Return tags grouped by source.\n    \n\n        \n      \n      \n        Signature\n        GET /api/v1/tags/hosts/:host_name\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Get tags by host id.\nhosts = api.Infrastructure.search(q='hosts:')\nprint api.Tag.get(hosts['results']['hosts'][0])\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nhost_name = 'test.host'\ndog.host_tags(host_name)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\n# pass a single hostname as an argument to search for the specified host\nhost=$1\n \n# Find a host to add a tag to\nhost_name=$(curl -G \"https://app.datadoghq.com/api/v1/search\" \\\n    -d \"api_key=${api_key}\" \\\n    -d \"application_key=${app_key}\" \\\n\t-d \"q=hosts:$host\" | cut -d'\"' -f6)\n \ncurl \"https://app.datadoghq.com/api/v1/tags/hosts/${host_name}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'tags': ['role:database','env:test']}\n        [\"200\", {\"tags\"=>[\"role:web\", \"environment:test\"]}]\n        {\n    \"tags\": [\n        \"role:database\", \n        \"environment:test\"\n    ]\n}\n\n      \n    \n\n    \nAdd Tags to a Host\n    \n      \n        \n          This end point allows you to add tags to a host.\n        \n         Arguments\n          \n              \n      tags [required]\n      A list of tags to apply to the host\n    \n\n              \n      source [optional, default=users]\n      The source of the tags (e.g. chef, puppet).\n    \n\n          \n      \n      \n        Signature\n        POST /api/v1/tags/hosts/:host_name\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\nhosts = api.Infrastructure.search(q='hosts:')\napi.Tag.create(hosts['results']['hosts'][0], tags=[\"role:codesample\"])\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nhost=YourHostName\n\n# Find a host to add a tag to\nhost_name=$(curl -G \"https://app.datadoghq.com/api/v1/search\" \\\n    -d \"api_key=${api_key}\" \\\n    -d \"application_key=${app_key}\" \\\n    -d \"q=hosts:$host\" | cut -d'\"' -f6)\n\ncurl  -X POST -H \"Content-type: application/json\" \\\n-d \"{\n      \\\"tags\\\" : [\\\"environment:production\\\", \\\"role:webserver\\\"]\n    }\" \\\n\"https://app.datadoghq.com/api/v1/tags/hosts/${host_name}?api_key=${api_key}&application_key=${app_key}\"\n\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nhost_name = 'test.host'\ndog.add_tags(host_name, [\"role:database\", \"environment:production\"])\n        Example Response\n        {'host': 'hostname', 'tags': ['role:webserver','env:production']}\n        {\n    \"host\": \"test.host\", \n    \"tags\": [\n        \"role:database\", \n        \"environment:test\"\n    ]\n}\n\n        [\"201\",\n {\"host\"=>\"test.metric.host\",\n  \"tags\"=>\n   [\"environment:production\",\n    \"role:web\",\n    \"role:database\",\n    \"environment:test\"]}]\n      \n    \n\n    \nUpdate Host Tags\n    \n      \n        \n          This end point allows you to update all tags for a given host.\n        \n         Arguments\n          \n              \n      tags [required]\n      A list of tags\n    \n\n              \n      source [optional, default=users]\n      The source of the tags (e.g. chef, puppet).\n    \n\n          \n      \n      \n        Signature\n        PUT /api/v1/tags/hosts/:host_name\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\napi.Tag.update('hostname', tags=['role:database', 'environment:test'])\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nhost_name=test.host\n\ncurl -X PUT -H \"Content-type: application/json\" \\\n-d '{\n      \"tags\" : [\"environment:production\", \"role:webserver\"]\n    }' \\\n\"https://app.datadoghq.com/api/v1/tags/hosts/${host_name}?api_key=${api_key}&application_key=${app_key}\"\n\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nhost_name = 'test.host'\ndog.update_tags(host_name, [\"role:web\", \"environment:test\"])\n        Example Response\n        {'host': 'hostname', 'tags': ['role:database','environment:test']}\n        {\n    \"host\": \"test.host\", \n    \"tags\": [\n        \"environment:production\", \n        \"role:webserver\"\n    ]\n}\n\n        [\"201\", {\"host\"=>\"test.metric.host\", \"tags\"=>[\"role:web\", \"environment:test\"]}]\n      \n    \n\n    \nRemove Host Tags\n    \n      \n        \n          This end point allows you to remove all tags for a given host.\n        \n         Arguments\n          \n              \n      source [optional, default=users]\n      The source of the tags (e.g. chef, puppet).\n    \n\n          \n      \n      \n        Signature\n        DELETE /api/v1/tags/hosts/:host_name\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n\napi.Tag.delete('hostname')\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\n# Find a host to remove a tag from\nhost_name=$(curl -G \"https://app.datadoghq.com/api/v1/search\" \\\n    -d \"api_key=${api_key}\" \\\n    -d \"application_key=${app_key}\" \\\n    -d \"q=hosts:\" | jq -r '.results.hosts[0]')\n# Add tags to the host\ncurl  -X POST -H \"Content-type: application/json\" \\\n-d \"{\\\"tags\\\" : [\\\"environment:production\\\", \\\"role:webserver\\\"]}\" \\\n\"https://app.datadoghq.com/api/v1/tags/hosts/${host_name}?api_key=${api_key}&application_key=${app_key}\"\n\n\ncurl -X DELETE \"https://app.datadoghq.com/api/v1/tags/hosts/${host_name}?api_key=${api_key}&application_key=${app_key}\"\n\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nhost_name = 'test.host'\ndog.detach_tags(host_name)\n        Example Response\n        This end point does not return JSON on successful requests.\n      \n    \n\n    \n\n    \nSearch\n    \n      \n        \n          This end point allows you to search for entities from the last 24 hours in Datadog. The\n          currently searchable entities are:\n        \n        \n          hosts  \n          metrics\n        \n        Arguments\n        \n              \n      q [required]\n      The query string\n    \n\n        \n        Query Language\n        \n          Search queries allow for limited faceting. Available facets are:\n        \n        \n          hosts  \n          metrics\n        \n        \n          Faceting your search limits your results to only matches of the specified\n          type. Un-faceted queries return results for all possible types.\n        \n        \n          Un-faceted queries are of the form:\n        \n        query_string\n        \n          Faceted queries are of the form:\n        \n        facet:query_string\n      \n      \n        Signature\n        GET /api/v1/search\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Search by `host` facet.\napi.Infrastructure.search(q=\"hosts:database\")\n\n# Search by `metric` facet.\napi.Infrastructure.search(q=\"metrics:system\")\n\n# Search all facets.\napi.Infrastructure.search(q=\"test\")\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Search by `host` facet.\ndog.search(\"hosts:database\")\n\n# Search by `metric` facet.\ndog.search(\"metrics:system\")\n\n# Search all facets.\ndog.search(\"test\")\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -G \"https://app.datadoghq.com/api/v1/search\" \\\n    -d \"api_key=${api_key}\" \\\n    -d \"application_key=${app_key}\" \\\n    -d \"q=test\"\n\n        Example Response\n        {'results': {'hosts': ['test.metric.host', 'test.tag.host'],\n 'metrics': ['test.metric.metric', 'test.tag.metric']}}\n        [\"200\",\n {\"results\"=>\n   {\"metrics\"=>[\"test.metric\"],\n    \"hosts\"=>\n     [\"test.another.example.com\",\n      \"test.example.com\",\n      \"test.host\",\n      \"test.metric.host\",\n      \"test.tag.host\"]}}]\n        {\n    \"results\": {\n        \"hosts\": [\n            \"test.another.example.com\", \n            \"test.example.com\", \n            \"test.host\", \n            \"test.metric.host\", \n            \"test.tag.host\"\n        ], \n        \"metrics\": [\n            \"test.metric\"\n        ]\n    }\n}\n\n      \n    \n\n    \n\n    \nComments\n    \n      \n        \n        Comments are how discussion happens on Datadog. You can create, edit, delete\n        and reply to comments.\n        \n      \n    \n\n    \n    \nCreate a comment\n    \n      \n        \n          Comments are essentially special forms of events that\n          appear in the stream. They can start a new discussion thread or\n          optionally, reply in another thread.\n        \n        Arguments\n        \n              \n      message [required]\n      The comment text.\n    \n\n              \n      handle [optional, default=application key owner]\n      The handle of the user making the comment.\n    \n\n              \n      related_event_id [optional, default=None]\n      The id of another comment or event to\n          reply to\n    \n\n        \n      \n      \n        Signature\n        POST api/v1/comments\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Start a new discussion.\n# You can include a handle like this\napi.Comment.create(handle='matt@example.com', message='Should we use COBOL or Fortran! ')\n\n# Or you can set it to None\n# and the handle will default\n# to the owner of the application key\napi.Comment.create(message='Should we use COBOL or Fortran?')\n\n# Reply to a discussion.\napi.Comment.create(handle='joe@example.com', message='Smalltalk?', related_event_id=1234)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Make a comment.\ndog.comment(\"I have something to say.\")\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl  -X POST -H \"Content-type: application/json\" \\\n-d '{\n        \"message\" : \"There is a problem with the database.\"\n    }' \\\n\"https://app.datadoghq.com/api/v1/comments?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'comment': {'handle': 'matt@example.com',\n  'id': 2603645287324504065,\n  'message': 'Should we use COBOL or Fortran?',\n  'resource': '/api/v1/comments/2603645287324504065',\n  'url': '/event/jump_to?event_id=2603645287324504065'}}\n        [\"200\",\n {\"comment\"=>\n   {\"url\"=>\"/event/jump_to?event_id=1382579089039712607\",\n    \"resource\"=>\"/api/v1/comments/1382579089039712607\",\n    \"message\"=>\"I have something to say.\",\n    \"handle\"=>\"mattp+org-carlotest141@datadoghq.com\",\n    \"id\"=>1382579089039712607}}]\n        {\n    \"comment\": {\n        \"handle\": \"mattp+org-carlotest141@datadoghq.com\", \n        \"id\": 1382561676571697516, \n        \"message\": \"There is a problem with the database.\", \n        \"resource\": \"/api/v1/comments/1382561676571697516\", \n        \"url\": \"/event/jump_to?event_id=1382561676571697516\"\n    }\n}\n\n      \n    \n\n    \n    \nEdit a Comment\n    \n      \n        Arguments\n        \n              \n      message [optional, default=original message]\n      The comment text.\n    \n\n              \n      handle [optional, default=application key owner]\n      The handle of the user making the comment.\n    \n\n        \n      \n      \n        Signature\n        PUT api/v1/comments/:comment_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\nfrom time import sleep\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\n\ninitialize(**options)\n\n# Edit a comment.\nnewcomment = api.Comment.create(message='Should we use COBOL or Fortran or Widgets?')\nsleep(1)\napi.Comment.update(newcomment['comment']['id'], message='I think differently now!')\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\ncomment_id=\"1382579089039712607\"\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Update a comment.\ndog.update_comment(comment_id, :message => \"I've changed my mind again\")\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\ncomment_id=1382557387240472966\n\n# Create a comment to edit. Use jq (http://stedolan.github.io/jq/download/) to get the comment id.\ncomment_id=$(curl -X POST -H \"Content-type: application/json\" -d '{\"message\" : \"This comment was submitted and will be edited by the api.\"}' \"https://app.datadoghq.com/api/v1/comments?api_key=${api_key}&application_key=${app_key}\" | jq -r '.comment.resource|ltrimstr(\"/api/v1/comments/\")')\n\ncurl -X PUT -H \"Content-type: application/json\" \\\n-d '{\n        \"message\" : \"Actually, I am changing my mind.\"\n    }' \\\n\"https://app.datadoghq.com/api/v1/comments/${comment_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'comment': {'handle': 'matt@example.com',\n  'id': 2603645287324504065,\n  'message': 'I think differently now.',\n  'resource': '/api/v1/comments/2603645287324504065',\n  'url': '/event/jump_to?event_id=2603645287324504065'}}\n        [\"200\",\n {\"comment\"=>\n   {\"url\"=>\"/event/jump_to?event_id=1382579089039712607\",\n    \"resource\"=>\"/api/v1/comments/1382579089039712607\",\n    \"message\"=>\"I've changed my mind again\",\n    \"handle\"=>\"mattp+org-carlotest141@datadoghq.com\",\n    \"id\"=>1382579089039712607}}]\n        {\n    \"comment\": {\n        \"handle\": \"mattp+org-carlotest141@datadoghq.com\", \n        \"id\": 1382557387240472966, \n        \"message\": \"Actually, I am changing my mind.\", \n        \"resource\": \"/api/v1/comments/1382557387240472966\", \n        \"url\": \"/event/jump_to?event_id=1382557387240472966\"\n    }\n}\n\n      \n    \n\n    \n    \nDelete a Comment\n    \n      \n        Arguments\n        This end point takes no JSON arguments.\n      \n      \n        Signature\n        DELETE api/v1/comments/:comment_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\nnewcomment = api.Comment.create(message='Should we use COBOL or Fortran?')\napi.Comment.delete(newcomment['comment']['id'])\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndog.delete_comment(\"1378619807595725030\")\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n# comment_id=1382559936236196216\n\n# Create a comment to delete. Use jq (http://stedolan.github.io/jq/download/) to get the comment id.\ncomment_id=$(curl -X POST -H \"Content-type: application/json\" -d '{\"message\" : \"This comment was submitted and will be deleted by the api.\"}' \"https://app.datadoghq.com/api/v1/comments?api_key=${api_key}&application_key=${app_key}\" | jq -r '.comment.resource|ltrimstr(\"/api/v1/comments/\")')\nsleep 1\ncurl -X DELETE \"https://app.datadoghq.com/api/v1/comments/${comment_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        This end point does not return JSON on successful requests.\n      \n    \n\n    \n\n    \nUsers\n    \n      \n        \n        You can create, edit, and disable users.\n        \n      \n    \n\n    \n    \nCreate User\n    \n      \n        Arguments\n        \n              \n      handle [required]\n      The user handle, must be a valid email.\n    \n\n              \n      name [optional, default=None]\n      The name of the user.\n    \n\n              \n      access_role [optional, default=st]\n      The access role of the user. Choose from 'st' (standard user), 'adm' (admin user), or 'ro' (read-only user). Note: users can be created with admin access role only with application keys belonging to administrators.\n\n    \n\n        \n      \n      \n        Signature\n        POST api/v1/user\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Create user\napi.User.create(handle='test@datadoghq.com', name='test user')\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndog.create_user(:handle => 'test@datadoghq.com', :name => 'test user')\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -X POST -H \"Content-type: application/json\" \\\n    -d '{\"handle\":\"test@datadoghq.com\",\"name\":\"test user\"}' \\\n    \"https://app.datadoghq.com/api/v1/user?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'user': {'verified': False, 'name': 'test user', 'access_role': 'st', 'disabled': False, 'role': None, 'is_admin': False, 'handle': 'test@datadoghq.com', 'email': 'test@datadoghq.com'}}\n        [\"200\", {\"user\"=>{\"handle\"=>\"test@datadoghq.com\", \"name\"=>\"test user\", \"verified\"=>false, \"access_role\"=>\"st\", \"disabled\"=>false, \"role\"=>nil, \"is_admin\"=>false, \"email\"=>\"test@datadoghq.com\"}}]\n        {\"user\": {\"handle\": \"test@datadoghq.com\", \"name\": \"test user\", \"access_role\": \"st\", \"verified\": false, \"disabled\": false, \"role\": null, \"is_admin\": false, \"email\": \"test@datadoghq.com\"}}\n\n      \n    \n\n    \n    \nGet User\n    \n      \n        Arguments\n        \n              \n      handle [required]\n      The handle of the user.\n    \n\n        \n      \n      \n        Signature\n        GET api/v1/user/:handle\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Get one user\napi.User.get('test@datadoghq.com')\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndog.get_user('test@datadoghq.com')\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nuser=test@datadoghq.com\n\ncurl -X GET \"https://app.datadoghq.com/api/v1/user/${user}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'user': {'verified': False, 'name': 'test user', 'access_role': 'st', 'disabled': False, 'role': None, 'is_admin': False, 'handle': 'test@datadoghq.com', 'email': 'test@datadoghq.com'}}\n        [\"200\", {\"user\"=>{\"handle\"=>\"test@datadoghq.com\", \"name\"=>\"test user\", \"access_role\"=>\"st\", \"verified\"=>false, \"disabled\"=>false, \"role\"=>nil, \"is_admin\"=>false, \"email\"=>\"test@datadoghq.com\"}}]\n        {\"user\": {\"handle\": \"test@datadoghq.com\", \"name\": \"test user\", \"access_role\": \"st\", \"verified\": false, \"disabled\": false, \"role\": null, \"is_admin\": false, \"email\": \"test@datadoghq.com\"}}\n\n      \n    \n\n    \n    \nGet All Users\n    \n      \n        Arguments\n        \n          This end point takes no JSON arguments.\n        \n      \n      \n        Signature\n        GET api/v1/user \n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Get all users\napi.User.get_all()\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndog.get_all_users()\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -X GET \"https://app.datadoghq.com/api/v1/user?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'users': [{'verified': False, 'name': 'test user', 'access_role': 'st', 'disabled': False, 'role': None, 'is_admin': False, 'handle': 'test@datadoghq.com', 'email': 'test@datadoghq.com'}, {'verified': False, 'name': 'alt name', 'access_role': 'ro', 'disabled': False, 'role': None, 'is_admin': False, 'handle': 'test2@datadoghq.com', 'email': 'test+1@datadoghq.com'}]}\n        [\"200\", {\"users\"=>[{\"handle\"=>\"test@datadoghq.com\", \"name\"=>\"test user\", \"access_role\"=>\"st\", \"verified\"=>false, \"disabled\"=>false, \"role\"=>nil, \"is_admin\"=>false, \"email\"=>\"test@datadoghq.com\"}, {\"handle\"=>\"test2@datadoghq.com\", \"name\"=>\"alt name\", \"access_role\"=>\"ro\", \"verified\"=>false, \"disabled\"=>false, \"role\"=>nil, \"is_admin\"=>false, \"email\"=>\"test+1@datadoghq.com\"}]}]\n        {\"users\": [{\"handle\": \"test@datadoghq.com\", \"name\": \"test user\", \"access_role\": \"st\", \"verified\": false, \"disabled\": false, \"role\": null, \"is_admin\": false, \"email\": \"test@datadoghq.com\"},{\"handle\": \"test2@datadoghq.com\", \"name\": \"alt name\", \"access_role\": \"ro\", \"verified\": false, \"disabled\": false, \"role\": null, \"is_admin\": false, \"email\": \"test+1@datadoghq.com\"}]}\n\n      \n    \n\n\n    \n    \nUpdate User\n    \n      \n        \n          Can only be used with application keys belonging to administrators.\n        \n        Arguments\n        \n              \n      handle [required]\n      The handle of the user.\n    \n\n              \n      name [optional, default=None]\n      The new name of the user.\n    \n\n              \n      email [optional, default=None]\n      The new email of the user.\n    \n\n              \n      disabled [optional, default=None]\n      The new disabled status of the user.\n    \n\n              \n      access_role [optional, default=st]\n      The new access role of the user. Choose from 'st' (standard user), 'adm' (admin user), or 'ro' (read-only user).\n    \n\n        \n      \n      \n        Signature\n        PUT api/v1/user/:handle\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Update user\napi.User.update('test@datadoghq.com', name='alt name', email='test+1@datadoghq.com')\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n# Make sure you replace the API and or APP key below with the ones for your account\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndog.update_user('test@datadoghq.com', :email => 'test+1@datadoghq.com', :name => 'alt name')\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nuser=test@datadoghq.com\n\ncurl -X PUT -H \"Content-type: application/json\" \\\n    -d '{\"email\":\"test+1@datadoghq.com\",\"name\":\"alt user\", \"access_role\":\"ro\"}' \\\n    \"https://app.datadoghq.com/api/v1/user/${user}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'user': {'verified': False, 'name': 'alt name', 'access_role': 'st', 'disabled': False, 'role': None, 'is_admin': False, 'handle': 'test@datadoghq.com', 'email': 'test+1@datadoghq.com'}}\n        [\"200\", {\"user\"=>{\"handle\"=>\"test@datadoghq.com\", \"name\"=>\"alt name\", \"access_role\"=>\"st\", \"verified\"=>false, \"disabled\"=>false, \"role\"=>nil, \"is_admin\"=>false, \"email\"=>\"test+1@datadoghq.com\"}}]\n        {\"user\": {\"handle\": \"test@datadoghq.com\", \"name\": \"alt user\", \"access_role\": \"ro\", \"verified\": false, \"disabled\": false, \"role\": null, \"is_admin\": false, \"email\": \"test+1@datadoghq.com\"}}\n\n      \n    \n\n\n    \n    \nDisable User\n    \n      \n        \n          Can only be used with application keys belonging to administrators.\n        \n        Arguments\n        \n              \n      handle [required]\n      The handle of the user.\n    \n\n        \n      \n      \n        Signature\n        DELETE api/v1/user/:handle\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Disable user\napi.User.delete('test@datadoghq.com')\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\ndog.disable_user('test@datadoghq.com')\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nuser=test@datadoghq.com\n\ncurl -X DELETE \"https://app.datadoghq.com/api/v1/user/${user}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {'message': 'User test@datadoghq.com disabled'}\n        [\"200\", {\"message\"=>\"User test@datadoghq.com disabled\"}]\n        {\"message\": \"User test@datadoghq.com disabled\"}\n\n      \n    \n\n    \n\n    \nGraphs\n    \n      \n        \n        You can take graph snapshots using the API.\n        \n      \n    \n\n    \n    \nGraph Snapshot\n    \n      \n        Arguments\n        \n              \n      metric_query [required]\n      The metric query.\n    \n\n              \n      start [required]\n      The POSIX timestamp of the start of the query.\n    \n\n              \n      end [required]\n      The POSIX timestamp of the end of the query.\n    \n\n              \n      event_query [optional, default=None]\n      A query that will add event bands to the graph.\n    \n\n              \n      graph_def [optional, default=None]\n      A JSON document defining the graph. graph_def can be used instead of metric_query. The JSON document uses the grammar defined here and should be formatted to a single line then URLEncoded. The graph_def argument is only available in the REST API and not using the Ruby or Python wrappers. \n    \n\n              \n      title [optional, default=None]\n      A title for the graph. If no title is specified, the graph will not have a title.\n    \n\n        \n\n      \n      \n        Signature\n        GET api/v1/graph/snapshot\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\nimport time\n\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Take a graph snapshot\nend = int(time.time())\nstart = end - (60 * 60)\napi.Graph.create(metric_query=\"system.load.1{*}\", start=start, end=end)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nend_ts = Time.now().to_i\nstart_ts = end_ts - (60 * 60)\ndog.graph_snapshot(\"system.load.1{*}\", start_ts, end_ts)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\ncurrenttime=$(date +%s)\ncurrenttime2=$(date -v -1d +%s)\ncurl -G -H \"Content-type: application/json\" \\\n    -d \"metric_query=system.load.1{*}\" \\\n    -d \"start=${currenttime2}\" \\\n    -d \"end=${currenttime}\" \\\n    -d \"api_key=9775a026f1ca7d1c6c5af9d94d9595a4\" \\\n    -d \"application_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\" \\\n    'https://app.datadoghq.com/api/v1/graph/snapshot'\n\n        Example Response\n        {'graph_def': '{\"requests\": [{\"q\": \"system.load.1{*}\"}]}',\n 'metric_query': 'system.load.1{*}',\n 'snapshot_url': 'https://s3.amazonaws.com/dd-snapshots-prod/org_1499/2013-07-19/2459d291fc021c84f66aac3a87251b6c92b589da.png'}\n        [\"200\",\n {\"metric_query\"=>\"system.load.1{*}\",\n  \"snapshot_url\"=>\n   \"https://s3.amazonaws.com/dd-snapshots-prod/org_1499/2013-07-19/7f6dd29198ce0872a6fdfab33f534ef8d64a23ea.png\"}]\n        {\n    \"metric_query\": \"system.load.1{*}\", \n    \"snapshot_url\": \"https://s3.amazonaws.com/dd-snapshots-prod/org_1499/2013-07-19/53fd79f024e7796f4ca399f1d90adf3cf95a9bb8.png\"\n}\n\n      \n    \n\n    \n\n    \nEmbeddable Graphs\n    \n      \n        \n          You can interact with embeddable graphs through the API.\n        \n      \n    \n\n    \n    \nGet All Embeds\n    \n      \n        \n          Gets a list of previously created embeddable graphs.\n        \n        \n          Returns: A JSON list containing information on previously created embeds from both the UI\n          and the API. Each JSON graph response is in the same format as returned by\n          GET api/v1/graph/embed/:embed_id.\n        \n        Arguments\n        \n          This end point takes no JSON arguments.\n        \n      \n      \n        Signature\n        GET api/v1/graph/embed\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\n# Intialize request parameters including API/APP key\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Call Embed API function\napi.Embed.get_all()\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\n# Initialize API Client\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Get all with API Call\ndog.get_all_embeds()\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=\"9775a026f1ca7d1c6c5af9d94d9595a4\"\napp_key=\"87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\"\n\ncurl -X GET \"https://app.datadoghq.com/api/v1/graph/embed?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {\n    \"embedded_graphs\": [\n        {\n            \"embed_id\": \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\",\n            \"template_variables\": [],\n            \"html\": '<iframe src=\"https://app.datadoghq.com/graph/embed?token=5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c&height=300&width=600&legend=true\" width=\"600\" height=\"300\" frameBorder=\"0\"></iframe>',\n            \"graph_title\": \"Embed created through API\",\n            \"revoked\": False,\n            \"dash_url\": None,\n            \"shared_by\": 3658,\n            \"dash_name\": None\n        }\n    ]\n}\n        { \"embedded_graphs\" => [\n    {\n      \"embed_id\" => \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\", \n      \"template_variables\" => [], \n      \"html\" => '<iframe src=\"https://app.datadoghq.com/graph/embed?token=5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c&height=300&width=600&legend=true\" width=\"600\" height=\"300\" frameBorder=\"0\"></iframe>', \n      \"graph_title\" => \"Embed created through API\", \n      \"revoked\" => false, \n      \"dash_url\" => nil, \n      \"shared_by\" => 3658, \n      \"dash_name\" => nil\n    }\n  ]\n}\n        { \"embedded_graphs\": [\n    {\n      \"embed_id\": \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\", \n      \"template_variables\": [], \n      \"html\": \"<iframe src=\\\"https://app.datadoghq.com/graph/embed?token=5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c&height=300&width=600&legend=true\\\" width=\\\"600\\\" height=\\\"300\\\" frameBorder=\\\"0\\\"></iframe>\", \n      \"graph_title\": \"Embed created through API\", \n      \"revoked\": false, \n      \"dash_url\": null, \n      \"shared_by\": 3658, \n      \"dash_name\": null\n    }\n  ]\n}\n      \n    \n\n    \n    \nCreate Embed\n    \n      \n        \n          Creates a new embeddable graph.\n        \n        \n          Returns: A JSON consisting of the same elements returned by GET api/v1/graph/embed/:embed_id.\n          On failure, the return value will be a JSON containing an error message {errors: [messages]}.\n        \n        \n          Note: If an embed already exists for the exact same query in a given organization, the older embed will be returned instead of creating a new embed.\n        \n        Arguments\n        \n              \n      graph_json [required]\n      The graph definition in JSON.\n          Same format that is available on the JSON tab of the graph editor\n    \n\n              \n      timeframe [optional, default=1_hour]\n      The timegrame for the graph. Must be one of 1_hour,\n          4_hours, 1_day, 2_days, and 1_week.\n    \n\n              \n      size [optional, default=medium]\n      The size of the graph. Must be one of small, medium,\n          large, and xlarge.\n    \n\n              \n      legend [optional, default=no]\n      The flag determining if the graph includes a legend.\n          Must be one of yes or no.\n    \n\n              \n      title [optional, default=Embed created through API]\n      Determines graph title. Must be at least 1 character.\n    \n\n        \n      \n      \n        Signature\n        POST api/v1/graph/embed\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\nimport json\n\n# Intialize request parameters including API/APP key\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Create an embed graph definition as a dict and format as JSON\ngraph_json = {\n    \"requests\": [{\n        \"q\": \"avg:system.load.1{*}\"\n    }],\n    \"viz\": \"timeseries\",\n    \"events\": []\n}\ngraph_json = json.dumps(graph_json)\n\napi.Embed.create(graph_json=graph_json, timeframe=\"1_hour\", size=\"medium\", legend=\"no\")\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\n# Initialize API Client\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Prepare parameters\ngraph_json = '{\n  \"requests\": [{\n    \"q\": \"avg:system.load.1{*}\"\n  }],\n  \"viz\": \"timeseries\",\n  \"events\": []\n}'\ntimeframe = \"1_hour\"\nsize = \"medium\"\nlegend = \"no\"\ntitle = \"Embed created through API\"\n\n# Create parameter hash\ndescription = {\n  :timeframe => timeframe,\n  :size => size,\n  :legend => legend,\n  :title => title\n}\n\n# Make API Call\nstatus, result = dog.create_embed(graph_json, description)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=\"9775a026f1ca7d1c6c5af9d94d9595a4\"\napp_key=\"87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\"\n\ncurl -POST \\\n    -d 'graph_json={\"requests\":[{\"q\":\"avg:system.load.1{*}\"}],\"viz\":\"timeseries\",\"events\":[]}' \\\n    -d \"timeframe=1_hour\" \\\n    -d \"size=medium\" \\\n    -d \"legend=yes\" \\\n    \"https://app.datadoghq.com/api/v1/graph/embed?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {\n    \"embed_id\": \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\",\n    \"template_variables\": [],\n    \"html\": '<iframe src=\"https://app.datadoghq.com/graph/embed?token=5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c&height=300&width=600&legend=true\" width=\"600\" height=\"300\" frameBorder=\"0\"></iframe>',\n    \"graph_title\": \"Embed created through API\",\n    \"revoked\": False,\n    \"dash_url\": None,\n    \"shared_by\": 3658,\n    \"dash_name\": None\n}\n        {\n  \"embed_id\" => \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\", \n  \"template_variables\" => [], \n  \"html\" => '<iframe src=\"https://app.datadoghq.com/graph/embed?token=5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c&height=300&width=600&legend=true\" width=\"600\" height=\"300\" frameBorder=\"0\"></iframe>', \n  \"graph_title\"=> \"Embed created through API\", \n  \"revoked\" => false, \n  \"dash_url\" => nil, \n  \"shared_by\" => 3658, \n  \"dash_name\" => nil\n}\n        {   \n  \"embed_id\": \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\", \n  \"template_variables\": [], \n  \"html\": \"<iframe src=\\\"https://app.datadoghq.com/graph/embed?token=5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c&height=300&width=600&legend=true\\\" width=\\\"600\\\" height=\\\"300\\\" frameBorder=\\\"0\\\"></iframe>\", \n  \"graph_title\": \"Embed created through API\", \n  \"revoked\": false, \n  \"dash_url\": null, \n  \"shared_by\": 3658, \n  \"dash_name\": null\n}\n      \n    \n\n    \n    \nGet Specific Embed\n    \n      \n        \n          Get the HTML fragment for a previously generated embed with embed_id.\n        \n        \n          Returns: A JSON object with 8 elements:\n        \n        \n          embed_id: Token of the embed\n          graph_title: Tile of the graph\n          dash_name: Name of the dashboard the graph is on (null if none)\n          dash_url: URL of the dashboard the graph is on (null if none)\n          shared_by: ID of the use who shared the embed\n          html: HTML fragment for the embed (iframe)\n          revoked: Boolean flag for whther or not the embed is revoked\n        \n        \n          On failure, the return value will be a JSON containing an error message {errors: [messages]}.\n        \n        Arguments\n        \n              \n      size [optional, default=medium]\n      The size of the graph. Must be one of small, medium,\n          large, and xlarge.\n    \n\n              \n      legend [optional, default=no]\n      The flag determining if the graph includes a legend.\n          Must be one of yes or no.\n    \n\n              \n      template_variables [optional, default=None]\n      Replace template variables in queries with form $var. To\n          replace $var with val, use var=val as a parameter for each template variable you wish\n          to replace. If any template variables are missing values in the iframe source\n          url, then (*) will be used as the value.\n    \n\n        \n      \n      \n        Signature\n        GET api/v1/graph/embed/:embed_id\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\n# Intialize request parameters including API/APP key\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Set Embed ID (token)\nembed_id = \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\"\n\n# Call Embed API function\napi.Embed.get(embed_id, legend=\"no\", size=\"medium\", timeframe=\"1_hour\")\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\n# Initialize API Client\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Initialize Embed Token/ID\nembed_id = \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\"\n\n# Get embed with API Call\ndog.enable_embed(embed_id)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=\"9775a026f1ca7d1c6c5af9d94d9595a4\"\napp_key=\"87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\"\nembed_id=\"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\"\n\ncurl -X GET \"https://app.datadoghq.com/api/v1/graph/embed/${embed_id}?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {\n    \"embed_id\": \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\",\n    \"template_variables\": [],\n    \"html\": '<iframe src=\"https://app.datadoghq.com/graph/embed?token=5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c&height=300&width=600&legend=true\" width=\"600\" height=\"300\" frameBorder=\"0\"></iframe>',\n    \"graph_title\": \"Embed created through API\",\n    \"revoked\": False,\n    \"dash_url\": None,\n    \"shared_by\": 3658,\n    \"dash_name\": None\n}\n        {\n  \"embed_id\" => \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\", \n  \"template_variables\" => [], \n  \"html\" => '<iframe src=\"https://app.datadoghq.com/graph/embed?token=5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c&height=300&width=600&legend=true\" width=\"600\" height=\"300\" frameBorder=\"0\"></iframe>', \n  \"graph_title\"=> \"Embed created through API\", \n  \"revoked\" => false, \n  \"dash_url\" => nil, \n  \"shared_by\" => 3658, \n  \"dash_name\" => nil\n}\n        {\n  \"embed_id\": \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\", \n  \"template_variables\": [], \n  \"html\": \"<iframe src=\\\"https://app.datadoghq.com/graph/embed?token=5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c&height=300&width=600&legend=true\\\" width=\\\"600\\\" height=\\\"300\\\" frameBorder=\\\"0\\\"></iframe>\", \n  \"graph_title\": \"Embed created through API\", \n  \"revoked\": false, \n  \"dash_url\": null, \n  \"shared_by\": 3658, \n  \"dash_name\": null\n}\n\n      \n    \n\n    \n    \nEnable Embed\n    \n      \n        \n          Enable a specified embed.\n        \n        \n          Returns: A JSON containing the success message {success: [message]}.\n          On failure, the return value will be a JSON containing an error message {errors: [messages]}.\n        \n        Arguments\n        \n          This end point takes no JSON arguments.\n        \n      \n      \n        Signature\n        GET api/v1/graph/embed/:embed_id/enable\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\n# Intialize request parameters including API/APP key\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Set Embed ID (token)\nembed_id = \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\"\n\n# Call Embed API function\napi.Embed.enable(embed_id)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\n# Initialize API Client\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Initialize Embed Token/ID\nembed_id = \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\"\n\n# Enable with API Call\ndog.enable_embed(embed_id)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=\"9775a026f1ca7d1c6c5af9d94d9595a4\"\napp_key=\"87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\"\nembed_id=\"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\"\n\ncurl -X GET \"https://app.datadoghq.com/api/v1/graph/embed/${embed_id}/enable?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {\n    \"success\": \"Embed 5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c successfully enabled.\"\n}\n        {\n  \"success\" => \"Embed 5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c successfully enabled.\"\n}\n        {\n  \"success\": \"Embed 5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c successfully enabled.\"\n}\n      \n    \n\n    \n    \nRevoke Embed\n    \n      \n        \n          Revoke a specified embed.\n        \n        \n          Returns: A JSON containing the success message {success: [message]}.\n          On failure, the return value will be a JSON containing an error message {errors: [messages]}.\n        \n        Arguments\n        \n          This end point takes no JSON arguments.\n        \n      \n      \n        Signature\n        GET api/v1/graph/embed/:embed_id/revoke\n        Example Request\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nfrom datadog import initialize, api\n\n# Intialize request parameters including API/APP key\noptions = {\n    'api_key': '9775a026f1ca7d1c6c5af9d94d9595a4',\n    'app_key': '87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n}\n\ninitialize(**options)\n\n# Set Embed ID (token)\nembed_id = \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\"\n\n# Call Embed API function\napi.Embed.revoke(embed_id)\n        # Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nrequire 'rubygems'\nrequire 'dogapi'\n\n# Initialize API Client\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\n# Initialize Embed Token/ID\nembed_id = \"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\"\n\n# Revoke with API Call\ndog.revoke_embed(embed_id)\n        #!/bin/sh\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\napi_key=\"9775a026f1ca7d1c6c5af9d94d9595a4\"\napp_key=\"87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\"\nembed_id=\"5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c\"\n\ncurl -X GET \"https://app.datadoghq.com/api/v1/graph/embed/${embed_id}/revoke?api_key=${api_key}&application_key=${app_key}\"\n\n        Example Response\n        {\n    \"success\": \"Embed 5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c successfully revoked.\"\n}\n        {\n  \"success\" => \"Embed 5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c successfully revoked.\"\n}\n        {\n  \"success\": \"Embed 5f585b01c81b12ecdf5f40df0382738d0919170639985d3df5e2fc4232865b0c successfully revoked.\"\n}\n      \n    \n\n   \n\n    \nTroubleshooting\n    \n      \n        We do very minimal error checking on the API front-end, as we queue all data for asynchronous processing\n           (the goal being to always, always accept your data in production situations and decouple our systems from yours).\n        Thus it is possible you could receive a 202 'success' response but not see your data in Datadog.\n              The cause of this is most likely:\n        \n          Problems with the timestamp (either not in seconds or in the past, etc.)\n          Using the application key instead of API key\n          Events are succeeding, but because success events are low priority, they don't show up in the event stream until it is switched to priority 'all'\n        \n        To check your timestamp is correct run: date -u && curl -s -v https://app.datadoghq.com 2>&1 | grep Date\n        \n        This will output the current system’s date, and then make a request to our endpoint and grab\n               the date on our end. If these are more than a few minutes apart,\n               you may want to look at the time settings on your server.\n        \n        \n         There are also certain fields which are not mandatory for submission, but do require a valid input.\n         For example, in submitting an event the priority field must be one of the four given options.\n         Any other text will result in a 202 'success' but no event showing up.\n         Having an invalid source_type_name will not prevent the event from showing up, but that field will be dropped upon submission.\n        \n\n\n  \n\n\n\n\n\n","tags":"","loc":"/api/"},{"title":"Screenboards API","text":"Endpoints\n\n\n  create: POST /api/v1/screen\n  read: GET /api/v1/screen/{board_id}\n  update: PUT /api/v1/screen/{board_id}\n  delete: DELETE /api/v1/screen/{board_id}\n  sharing GET /api/v1/screen/share/{board_id}\n  revoke sharing DELETE /api/v1/screen/share/{board_id}\n\n\nFor create/read/update endpoints, the body is one JSON payload describing the Screenboard.\n\nBase Payload:\n\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n{\n  \"board_title\": \"My Board\",\n\n  // Options, e.g.: height, width, etc.\n\n  \"widgets\": [\n    // Put a list of widgets here. Each type described below.\n  ]\n}\n\n\nGeneral Notes\n\nSizing and positioning\n\nFor position and sizing Screenboards use a grid system which allows widgets to scale as the size of the window changes. This is currently used when you switch between a fullscreen and windowed view.\n\nBecause we use a grid system, all positioning and sizing values (x, y, height, width) are relative to that grid and are not in raw pixels as you might expect. You should note that the default grid size is 12px per 1 “grid length”.\n\nThis means if you give a widget a height and width of 2x2, the actual height will be 24x24px on the windowed view. Widgets will be scaled up/down on the fullscreen view to fit in the viewport given by your monitor.\n\nTimeframes\n\nTimeframes are all given as short names to represent a value. The available timeframes depend on the widget you’re using (in the widget descriptions below) but the overall options for timeframes are:\n\n\n  5m: 5 minutes\n  10m: 10 minutes\n  1h: 1 hour\n  4h: 4 hours\n  1d: 1 day\n  2d: 2 days\n  1w: 1 week\n\n\nTemplating\n\nIf you would like to create or update boards that use templated variables, you must have the following attributes in the base payload:\n\n\n  templated: boolean of true or false\n  template_variables: A list of variables you want to be “templateable.”  Variables are defined by a name and optional prefix and default parameters, which determine the list of tags associated with the variable and the variable’s initial value.\n\n\nThe final “base” payload of a templated board would look like this:\n\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n{\n  \"board_title\": \"My Board\",\n\n  // Template options\n  \"templated\": true,\n  \"template_variables\": [\n  \t{\n  \t\t\"name\": \"redis_port\",\n  \t\t\"prefix\": \"redis_port\",\n  \t\t\"default\": \"redis_port:1234\"\n  \t}, {\n  \t\t\"name\": \"availability-zone\",\n  \t\t\"prefix\": \"availability-zone\",\n  \t\t\"default\": \"availability-zone:us-east-1a\"\n  \t}],\n\n  // Options, e.g.: height, width, etc.\n\n  \"widgets\": [\n    // Put a list of widgets here. Each type described below.\n  ]\n}\n\n\nAPI Usage\n\nThe Screenboard API is supported in the Python and Ruby clients as well as with simple curl commands.\n\n\n\nCreating Boards\n\n      \n        Python\n      \n      \n        Ruby\n      \n      \n        Console\n      \n\n\n\n\n  \nfrom datadog import initialize, api\n\noptions = {\n    'api_key': 'api_key',\n    'app_key': 'app_key'\n}\n\ninitialize(**options)\n\nboard = {\n    \"width\": 1024,\n    \"height\": 768,\n    \"board_title\": \"dogapi test\",\n    \"widgets\": [\n        {\n          \"type\": \"image\",\n          \"height\": 20,\n          \"width\": 32,\n          \"y\": 7,\n          \"x\": 32,\n          \"url\": \"https://path/to/image.jpg\"\n        }\n    ]\n}\n\nresult = api.Screenboard.create(**board)\n\n\n\n  \nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nboard = {\n    \"width\" => 1024,\n    \"height\" => 768,\n    \"board_title\" => \"dogapi test\",\n    \"widgets\" => [\n        {\n          \"type\" => \"image\",\n          \"height\" => 20,\n          \"width\" => 32,\n          \"y\" => 7,\n          \"x\" => 32,\n          \"url\" => \"https://path/to/image.jpg\"\n        }\n    ]\n}\n\nresult = dog.create_screenboard(board)\n\n  \n  \napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\n\ncurl -X POST -H \"Content-type: application/json\" -d '{\n        \"width\": 1024,\n        \"height\": 768,\n        \"board_title\": \"dogapi test\",\n        \"widgets\": [\n            {\n              \"type\": \"image\",\n              \"height\": 20,\n              \"width\": 32,\n              \"y\": 7,\n              \"x\": 32,\n              \"url\": \"https://path/to/image.jpg\"\n            }\n        ]\n    }' \"https://app.datadoghq.com/api/v1/screen?api_key=${api_key}&application_key=${app_key}\"\n\n  \n\n\n\n\nUpdating Boards\n\n      \n        Python\n      \n      \n        Ruby\n      \n      \n        Console\n      \n\n\n\n\n  \nfrom datadog import initialize, api\n\noptions = {\n    'api_key': 'api_key',\n    'app_key': 'app_key'\n}\n\ninitialize(**options)\n\nboard_id = 1234\n\nupdated_board = {\n    \"width\": 1024,\n    \"height\": 768,\n    \"board_title\": \"dogapi test\",\n    \"widgets\": [\n        {\n          \"type\": \"image\",\n          \"height\": 25,\n          \"width\": 35,\n          \"y\": 7,\n          \"x\": 32,\n          \"url\": \"https://path/to/new_image.jpg\"\n        }\n    ]\n}\n\nresult = api.Screenboard.update(board_id, **updated_board)\n\n\n\n  \nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\nboard_id = 1234\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nupdated_board = {\n    \"width\" => 1024,\n    \"height\" => 768,\n    \"board_title\" => \"dogapi test\",\n    \"widgets\" => [\n        {\n          \"type\" => \"image\",\n          \"height\" => 25,\n          \"width\" => 35,\n          \"y\" => 7,\n          \"x\" => 32,\n          \"url\" => \"https://path/to/new_image.jpg\"\n        }\n    ]\n}\n\nresult = dog.update_screenboard(board_id, updated_board)\n\n  \n  \napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nboard_id=1234\n\ncurl -X PUT -H \"Content-type: application/json\" -d '{\n        \"width\": 1024,\n        \"height\": 768,\n        \"board_title\": \"dogapi test\",\n        \"widgets\": [\n            {\n              \"type\": \"image\",\n              \"height\": 25,\n              \"width\": 35,\n              \"y\": 7,\n              \"x\": 32,\n              \"url\": \"https://path/to/new_image.jpg\"\n            }\n        ]\n    }' \"https://app.datadoghq.com/api/v1/screen/${board_id}?api_key=${api_key}&application_key=${app_key}\"\n\n  \n\n\n\n\nGet Boards\n\n      \n        Python\n      \n      \n        Ruby\n      \n      \n        Console\n      \n\n\n\n\n  \nfrom datadog import initialize, api\n\noptions = {\n    'api_key': 'api_key',\n    'app_key': 'app_key'\n}\n\ninitialize(**options)\n\nboard_id = 1234\n\nresult = api.Screenboard.get(board_id)\n\n\n\n  \nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\nboard_id = 1234\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nresult = dog.get_screenboard(board_id)\n\n  \n  \napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nboard_id=1234\n\ncurl -X GET \"https://app.datadoghq.com/api/v1/screen/${board_id}?api_key=${api_key}&application_key=${app_key}\"\n\n  \n\n\n\n\nDeleting Boards\n\n      \n        Python\n      \n      \n        Ruby\n      \n      \n        Console\n      \n\n\n\n\n  \nfrom datadog import initialize, api\n\noptions = {\n    'api_key': 'api_key',\n    'app_key': 'app_key'\n}\n\ninitialize(**options)\n\nboard_id = 1234\n\nresult = api.Screenboard.delete(board_id)\n\n\n\n  \nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\nboard_id = 1234\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nresult = dog.delete_screenboard(board_id)\n\n  \n  \napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nboard_id=1234\n\ncurl -X DELETE \"https://app.datadoghq.com/api/v1/screen/${board_id}?api_key=${api_key}&application_key=${app_key}\"\n\n  \n\n\n\n\nSharing Boards\n\n      \n        Python\n      \n      \n        Ruby\n      \n      \n        Console\n      \n\n\n\n\n  \nfrom datadog import initialize, api\n\noptions = {\n    'api_key': 'api_key',\n    'app_key': 'app_key'\n}\n\ninitialize(**options)\n\nboard_id = 1234\n\nresult = api.Screenboard.share(board_id)\n\n\n\n  \nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key='9775a026f1ca7d1c6c5af9d94d9595a4'\napp_key='87ce4a24b5553d2e482ea8a8500e71b8ad4554ff'\nboard_id = 1234\n\ndog = Dogapi::Client.new(api_key, app_key)\n\nresult = dog.share_screenboard(board_id)\n# result = {\"board_id\" => board_id, \"public_url\" => \"https://path/to/sb\"}\n\n  \n  \napi_key=9775a026f1ca7d1c6c5af9d94d9595a4\napp_key=87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\nboard_id=1234\n\ncurl -X GET \"https://app.datadoghq.com/api/v1/screen/share/${board_id}?api_key=${api_key}&application_key=${app_key}\"\n\n  \n\n\nWidget Examples\n\nTimeseries Widget\n\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n{\n  \"type\": \"timeseries\",\n\n  // Title\n  \"title\": true,\n  \"title_size\": 16,\n  \"title_align\": \"left\",\n  \"title_text\": \"My Metric (m/s)\",\n\n  // Sizing\n  \"height\": 13,\n  \"width\": 47,\n\n  // Positioning\n  \"y\": 28,\n  \"x\": 32,\n\n  // Widget Parameters\n  \"timeframe\": \"1h\", // Choose from: [1h, 4h, 1d, 2d, 1w]\n  \"tile_def\": {\n    \"viz\": \"timeseries\",\n    \"requests\": [\n      {\n         \"q\": \"sum:my.important.metric{*} by {host}\"\n      }\n    ],\n    \"events\": [\n      {\n        \"q\": \"tags:release\"\n      }\n    ]\n  }\n}\n\n\nEvent Stream Widget\n\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n{\n    \"type\": \"event_stream\"\n\n    // Title\n    \"title\": false,\n\n    // Sizing\n    \"height\": 57,\n    \"width\": 59,\n\n    // Positioning\n    \"y\": 18,\n    \"x\": 84,\n\n    // Widgets Parameters\n    \"query\": \"tags:release\",\n    \"timeframe\": \"1w\" // Choose from: [1h, 4h, 1d, 2d, 1w]\n}\n\n\nQuery Value Widget\n\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n{\n  \"type\": \"query_value\",\n\n  // Title\n  \"title\": true,\n  \"title_size\": 16,\n  \"title_text\": \"Throughput\",\n  \"title_align\": \"left\",\n\n  // Sizing\n  \"height\": 4,\n  \"width\": 14,\n\n  // Positioning\n  \"y\": 21,\n  \"x\": 65,\n\n  // Widget Parameters\n  \"aggregator\": \"avg\", // Choose from: [avg, sum, min, max]\n  \"query\": \"sum:dd.sobotka.throughput.actual{*}\",\n  \"conditional_formats\": [\n    {\n      \"color\": \"white_on_green\",\n      \"invert\": false,\n      \"comparator\": \">\", // Choose from: [>, >=, <, <=]\n      \"value\": 20000\n    }\n  ],\n  \"text_align\": \"left\",\n  \"precision\": 1,\n  \"timeframe\": \"5m\", // Choose from: [5m, 10m, 1h, 4h, 1d, 2d, 1w]\n  \"text_size\": \"auto\",\n  \"unit\": \"/s\" // Give a custom unit or use \"auto\"\n}\n\n\nImage Widget\n\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n{\n  \"type\": \"image\",\n\n  // Sizing\n  \"height\": 20,\n  \"width\": 32,\n\n  // Positioning\n  \"y\": 7,\n  \"x\": 32\n\n  // Widget Parameters\n  \"url\": \"http://path/to/image.jpg\" // Note that you shouldn't hotlink to images you don't own.\n}\n\n\nNote Widget\n\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\n{\n    \"type\": \"note\",\n\n    // Title\n    \"title\": false,\n\n    // Sizing\n    \"height\": 15,\n    \"width\": 30,\n\n    // Positioning\n    \"x\": 1,\n    \"y\": 28,\n\n    // Widget Parameters\n    \"html\": \"Put your note text in here.\",\n    \"text_align\": \"left\",\n    \"font_size\": 14,\n    \"bgcolor\": \"yellow\", // Choose from: [yellow, blue, pink, gray, white, red, green]\n    \"tick\": true,\n    \"tick_pos\": \"50%\",\n    \"tick_edge\": \"right\" // Choose from: [top, right, bottom, left]\n    \"auto_refresh\": true // Defaults to false\n}\n\n","tags":"","loc":"/api/screenboards/"},{"title":"Uh oh, Something Went Wrong","text":"\n\n\n\nHead back home and start again.\n\n","tags":"","loc":"/error/"},{"title":"Frequently Asked Questions","text":"\n\nAgent\n\n\nIs the agent necessary to use Datadog?\n\n\n  No, it is not. You don’t have to install an agent if you only want to submit\nmetrics via our API. You can read more about our API here.\n  In general, most folks find a lot of value in installing an agent because\nthey get system metrics for free and metrics on common software like mysql,\npostgres, etc. with just a little bit of configuration. Another advantage is\nthat there is a small statsd server built-in to the agent.\n\n\n\nCan I use my own StatsD client?\n\nAny StatsD client will work just fine, but using the Datadog DogStatsD client\nwill give you a few extra features. You can read more about our clients extra\nfeatures here.\n\n\nHow can I change the hostname\n\nYou can change the hostname by updating your agent’s configuration file called\ndatadog.conf and replacing the value for the “hostname” key.  Use the following\nlink, select your OS in the left column, and go to\nthe Configuration section to find the location of your\nagent’s configuration file.\n\n\nHow do I uninstall the agent\n\n\n  \n    Mac OS:\n\n    Stop and Close the Datadog Agent: via the bone icon in the Tray. \n\n    Drag the Datadog Application from the application folder to the Trash Bin. \n\n    $ sudo rm -rf /opt/datadog-agent \n$ sudo rm -rf /usr/local/bin/datadog-agent \n$ sudo rm -rf ~/.datadog-agent/**​ #to remove broken symlinks\n\n    If you ran the optional install commands to have the Agent run at boot time, you will also need to run the following to finish uninstalling:\n\n    $ sudo launchctl unload -w /Library/LaunchDaemons/com.datadoghq.agent.plist \n$ sudo  rm /Library/LaunchDaemons/com.datadoghq.agent.plist \n  \n  Windows: You can uninstall the agent in Add/Remove Programs\n  Linux: $ sudo apt-get remove datadog-agent -y\n\n  CentOS 5: $ sudo yum remove datadog-agent-base\n\n  CentOS 6: $ sudo yum remove datadog-agent\n\n\n\n\nI stopped my agent but I’m still seeing the host in my Datadog account. Why is that?\n\nIt can take up to 24h for the host to disappear from the infrastructure page,\nbut it will only be part of the host count for billing purposes if we’re\nactually receiving data.\n\n\nOther Agent-related questions?\n\nPlease refer to the Basic Agent Usage Guide.\n\n\n\n\nAlerts\n\n\nI set up an alert with one of my integration metrics. Why am I getting so many No Data alerts?\n\nFor the AWS No Data errors, the issue here has to do with how frequently we\nreceive AWS metrics. Because our crawlers are rate-limited by the Cloudwatch\nAPIs, data is often delayed by 10 or more minutes, so we generally recommend\nthat an alert for an AWS metric be set to have a threshold window of at least\n30 minutes or an hour (you can see this in step 3 of alert creation, “during\nthe last…”). Switching the time frame on this alert will resolve this issue, or\nyou can install the agent on some AWS hosts to get more up-to-date data to\nalert on. Overall, we’re always working towards getting data more efficiently\nfrom AWS.\n\n\nIs it possible to set up alerts based on % utilisation? For example alerting when 50% of memory has been used or 80% of disk space is used?\n\n\n  Yes, this can be done! Here is an example for creating a disk space in use\nalert when at 80% or above:\n    \n      Select a metric like “system.disk.in_use”.\n      Select the “threshold alert” type.\n      For set alert grouping, select “simple alert”.\n      Set alert conditions: Select Above and for the value put 0.8.\n      Add a custom message for alert if you’d like.\n    \n  \n  You can read more about setting up monitors here.\n\n\n\n\n\nAPI\n\n\nWhat are valid metric names?\n\nMetric names must start with a letter, and after that may contain ascii alphanumerics, underscore and periods.\nOther characters will get converted to underscores. There is no max length. Unicode is not supported.\nWe recommend avoiding spaces.\nMetrics reported by the Agent are in a pseudo-hierarchical dotted format (e.g. http.nginx.response_time).\nWe say pseudo-hierarchical because we’re not actually enforcing a hierarchy or doing anything with it,\nbut we have aspirations to use it to infer things about servers (e.g. “hey, I see hostA and hostB are\nreporting http.nginx.*, those must be web frontends”).\n\n\nWhat are valid tags?\n\nTags must start with a letter, and after that may contain alphanumerics,\nunderscores, minuses, colons, periods and slashes. Other characters will get\nconverted to underscores. Tags can be up to 200 characters long and support\nunicode. Tags will be converted to lowercase as well.\n\nNote: An exception to this is with trailing underscores, which will be trimmed off of tags (e.g. path:thing_ becomes path:thing).\n\n\nI’m submitting points to the API- anything I should know?\n\nWe store metric points at the 1 second resolution, but we’d prefer if you only\nsubmitted points every 15 seconds. Any metrics with fractions of a second timestamps\nwill get rounded to the nearest second, and if any points have the same timestamp,\nthe latest point will overwrite the previous ones.\n\nWe have a soft limit of 100 time series per host, where a time series is\ndefined as a unique combination of metric name and tag.\n\n\n\n\nArchitecture\n\n\nIs Datadog a cloud service or server application?\n\nIt’s primarily a cloud service, but if you want to collect data on your servers,\nthere is an Agent you’ll need to install. We never make any direct connections\nto your infrastructure. For cloud integrations, we connect to them using the\ncredentials you provide to us.\n\n\nHow do I delete a host or metric?\n\nAll hosts or metrics that have not seen data in 24 hours will disappear from the UI;\nyou can still query against them, but it will not appear in drop downs or infrastructure.\nThere is not a way to immediately delete a metric.\n\n\nWhat’s the difference between Graphite’s query language and Datadog’s?\n\nIn terms of metric naming, we differ a little with Graphite in that a metric\nquery is defined by a metric name and a scope, where a scope is one or more tags.\nTo translate:\n\n<application>.requests.<HTTP Method>.<HTTP Method>.<Handler Method>.mean_90\n\n\ninto Datadog, we’d probably say:\n\n<application>.requests.mean_90{http_method:<HTTP Method>, handler_class:<HTTP Method>, handler_method:<Handler Method>}\n\n\nWhere <application>.requests.mean_90 is the metric name, and\nhttp_method:<HTTP Method>, handler_class:<HTTP Method>, handler_method:<Handler Method>\nare tags, so a concrete example might look like:\n\nfoo.requests.mean_90{http_method:GET, handler_class:ThingHandler, handler_method:list}\n\n\nTo do aggregation, we can specify an aggregator as part of the metric query:\n\navg:foo.requests.mean_90{http_method:GET, handler_class:ThingHandler, handler_method:list}\n\n\nThis will graph a single series that’s the average of that metric across the\nintersection of those tags. We support avg, sum, min, max aggregators. If you\nwanted to see all the possible series for a given tag facet, you can say:\n\navg:foo.requests.mean_90{handler_class:ThingHandler, handler_method:list} by {http_method}\n\n\nWhich would graph stacked area series for each http_method value like GET, POST, etc.\n\n\nHow are hostnames determined?\n\nThe hostnames are determined by what the Datadog Agent detects; this is fully\ndocumented here. You can see all names being detected by the Agent by running the info command:\n/etc/init.d/datadog-agent info\n\n\nTell me about tagging!\n\nTagging within Datadog is a powerful way to easily gather your metrics\nand makes scaling your infrastructure a breeze.\n\nFor a quick example to demonstrate the power of tagging, perhaps you’re\nlooking for a sum of two metrics, which you might normally define as follows:\n\nWeb server 1: api.metric('page.views', [(1317652676, 100), ...], host=\"example.com\")\nWeb server 2: api.metric('page.views', [(1317652676, 500), ...], host=\"example.com\")\n\n\nWhat we recommend doing is leaving off the hostname; it will then default to the host\nthat is sending that point, since they’re different hosts it will be treated as different points:\n\nWeb server 1: api.metric('page.views', [(1317652676, 100), ...], tags=['domain:example.com'])\nWeb server 2: api.metric('page.views', [(1317652676, 500), ...], tags=['domain:example.com'])\n\n\nWith these tags you can then do:\n\nsum:page.views{domain:example.com}\n\n\nwhich should give the desired result.\n\nTo get a breakdown by host, you can do:\n\nsum:page.views{domain:example.com} by {host}\n\n\nFurther tagging info can be found here.\n\nFor information on AWS tagging, please see here.\n\n\nWhat is the difference between an Admin and a User in Datadog?\n\nAdmins have just a few extra capabilities that standard users do not have. This includes access to billing info, the ability to revoke API keys, removing users, and can configure read-only dashboards. They can also promote standard users to Admins.\n\n\n\n\nAWS\n\n\nI just set up my AWS integration. Why am I seeing duplicate hosts?\n\nA single host running in EC2 might have an instance ID (i-abcd1234), a generic\nhostname provided by EC2 based on the host’s IP address (ip-192-0-0-1), and a\nmeaningful host name provided by an internal DNS server or a config-managed hosts\nfile (myhost.mydomain). Datadog creates aliases for host names when there are multiple\nuniquely identifiable names for a single host.  It takes about 10-20 minutes for the\nsingle host’s duplicate names to be aliased. You can read more about\nhostnames here.\n\n\nWhat metrics will I get from the AWS integration?\n\n\n  Our crawlers use the Cloudwatch API, and we collect everything available from it.\n  You can read in detail about our AWS integration here.\n\n\n\nI can’t filter out my ELB instances - will I be charged for them?\n\nWe do not charge for ELBs (as they can’t be filtered out).\n\n\nWhy is there a delay in receiving my data?\n\nIf you receive 5-minute metrics from Cloudwatch, there can be up to ~15-20 min delay in\nreceiving your metrics. This is because Cloudwatch makes your data available with a 5-10\nminute latency, and we run the crawler every 5 minutes. In addition, queuing and\nCloudwatch API limitations can add up to another 5 minutes. If you receive 1-minute\nmetrics with Cloudwatch, then their availability delay is about 2 minutes so total\nlatency to view your metrics may be ~10-12 minutes.\n\n\nCan I get my postgres data from RDS?\n\nYes you can! Follow the steps below to set this up:\n\n\n  Install the agent on an ec2 instance that can connect to the RDS instance\n  Use the RDS endpoint in conf.d/postgres.yaml (host and port)\n  Add tags in postgres.yaml: dbinstanceidentifier:(rds-instance-id), enginename:postgres\n\n  Restart the agent\n\n\n\n\n\nBilling\n\n\nHow can I change the Billing contact?\n\nYou can set a specific email address to receive invoices, even if that address\nis not a team member within Datadog (invoices@yourcompany.com) here.\n\n\nWhere can I get a copy of the invoice?\n\nAs an admin you can check out past invoices here.\n\nYou can read more about billing here.\n\n\n\n\nEvents\n\n\nWhat do @ notifications do in Datadog?\n\n\n  \n@support-datadog – this will reach Datadog support directly when posted in your stream.\n  \n@all – this will send a notification to all members of your organization.\n  \n@yourname – this will notify the specific user named ‘yourname’.\n  \n@test@test.com this will send an email to test@test.com.\n  If you have HipChat, Slack, Webhooks, Pagerduty or VictorOps you can use:\n    \n      \n@hipchat-[room-name] or @slack-[room-name] – posts the event or graph to that chat room.\n      \n@webhook – alerts or triggers whatever is attached to that webhook. Check out our blogpost on Webhooks!\n      \n@pagerduty – sends an alert to Pagerduty. You can also use @pagerduty-acknowledge and @pagerduty-resolve.\n    \n  \n\n\n\nSearching Events Help\n\nYour query runs a full text search of events and their comments. You can also\ntarget certain event properties, such as the event source or status, by using\nthe following search prefixes:\n\n\n  \nuser:pup@datadoghq.com Find all events with comments by pup@datadoghq.com.\n  \nsources:github,chef Show events from Github and Chef.\n  \ntags:env-prod,db Show events tagged with #env-prod AND #db.\n  \nhosts:db1.myapp.com,db2.myapp.com Show events from db1.myapp.com OR db2.myapp.com.\n  \nstatus:error Show only error status events. (supports: ‘error’, ‘warning’, ‘success’)\n  \npriority:low Show only low-priority events. (supports: ‘low’ or ‘normal’. defaults to ‘all’)\n  \nincident:claimed Show only claimed incidents. (supports: ‘open’, ‘claimed’, ‘resolved’, or ‘all’)\n\n\nPrefixes can easily be combined to make much more complex searches.  For example,\nif you wanted to find all open chef or nagios errors that mention cassandra, you’d\nhave a search like:\n\nsources:nagios,chef status:error cassandra\n\nNote: no spaces after the colon or commas in these lists and anything not attached\nto a prefix goes to full text search.\n\n\nIs it possible to submit events via email?\n\nYes! To get started you need to go the API tab in the settings page,\ncreate one or more API emails.\n\nFor a monitoring tool that does not allow you to edit the body of the email you\nneed to create a plain-text email, and have that system or tool send alarms or\nnotifications to this email.\n\nFor systems that allow you to edit the content of the notification emails, you\nmay use a JSON email. In the body of an email sent to a JSON API email you need\nto include a well formatted JSON event request as per our existing events API.\nFor more details about our events API, visit our API documentation.\n\nHere is an example:\n\n{\n  \"title\": “Host CPU above 75% for 5 minutes\",\n  \"text\": \"Host CPU has been above 75% for the last 5 minutes …etc\",\n  \"priority\": \"normal\",\n  \"tags\": [\"vsphere\", \"env:prod\", \"host:i-a4f761f0\", \"role:admin\"],\n  \"alert_type\": \"error\"\n}\n\n\n\nWhat formatting is available for event text?\n\nWe have adopted Daring Fireball’s Markdown throughout the site. To find out more\nabout Markdown, visit the Markdown docs.\n\n\n\n\nGraphing\n\n\nHow do I do arithmetic with grouped metrics?\n\nTo graph the sum of app.foo.bar{env:staging} and app.foo.baz{env:staging}\ngrouped by {host}, write a graph query that looks like:\n\nmetric.foo.bar{env:staging} by {host} + metric.foo.baz{env:staging} by {host}\n\n\n\nWhat’s the syntax to sum multiple datapoints into a single line?\n\nYou can switch commas separating the queries into plus signs, from:\n\n\"q\": \"sum:system.io.rkb_s{device:sda}*1024, sum:system.io.rkb_s{device:sdb}\n*1024, sum:system.io.rkb_s{device: sdc}*1024\"\n\n\nto:\n\n\"q\": \"sum:system.io.rkb_s{device:sda}*1024 + sum:system.io.rkb_s{device:sdb}\n*1024 + sum:system.io.rkb_s{device: sdc}*1024\"\n\n\n\nHow do I do graph smoothing?\n\nYou can apply smoothing averages to your series by droping to the JSON editor and\nadding ‘ewma’, for example:\nadd any of ewma_x(…) where x can be 5, 10, 20 around your series, e.g.\newma_20(exception.invalid{*}).\newma stands for exponentially-moving average and the full list of functions\nyou can apply is here.\n\n\nCan I stack CPU metrics on the same graph?\n\nCheck out our documentation on stacked series.\nThe metric explorer just does one metric per graph, but you can see a stacked CPU graph\non the overview page by clicking any host here.\n\n\nIs there a way to share graphs?\n\nThere are two ways to share a graph or screenboard\n\n\n  In a time board, pick a graph on a dashboard and click on the pencil to edit it.\nUnder step 2, “Choose metrics and events,” you’ll find the “share” tab that will\ngenerate an IFRAME of just that graph.\n  In a custom screenboard, click the settings cog in the upper right of the screen,\nthen click the “Generate public URL” option. This will create a URL which gives\nlive and read-only access to just the contents of that screenboard.\n\n\n\nHow do I track cron jobs?\n\nOften, you set cron jobs that trigger some meaningful script that you want to monitor and\ncorrelate with other metrics. For example, you might have a cron’d script to vacuum a Postgres table every day:\n\n0 0 * * * psql -c 'vacuum verbose my_table' >> /var/log/postgres_vacuums.log 2>&1\n\n\nVacuum is particularly resource-intensive though, so you might want Datadog events for\neach time they run so you can correlate metrics and other events with vacuums.\nYou can do this with the dogwrap command line tool provided by the datadog python client library:\n\n0 0 * * * /path/to/dogwrap -n \"Vacuuming mytable\" -k $API_KEY --submit_mode errors \"psql -c 'vacuum verbose my_table' 2>&1 /var/log/postgres_vacuums.log\"\n\n\nThis will call the command at the end of the script and\nsend Datadog events if it exits with a non-zero exit code (i.e. an error). --submit_mode all\nwill send events on every run.\n\n(To get the python client lib you can install it with pip install datadog).\n\n\n\n\nIntegrations\n\n\nI set up my integration. Why am I not seeing metrics?\n\nThere a several problems that could cause this.  Send a message to support\n(support@datadoghq.com) describing the issue and include the agent info, the logs, and\nthe configuration file as attachments to that message.  You can find the location of\nthese in the following link and selecting your OS on our agent usage guide\n\n\nHow is Datadog retrieving my data?\n\n\n  Traffic is always initiated by the agent to Datadog. No sessions are ever initiated from Datadog back to the agent.\n  All traffic is sent over SSL.\n  All communication to Datadog is via HTTPS.\n  The full license agreement can be found here.\n\n\n\nI’d like to tweak an integration or write up a new one. Do you accept pull requests?\n\nYes! The agent is entirely open source and can be found on our Github project page.\n\n\n\n\nMetrics\n\n\nHow do I submit custom metrics?\n\nYou can submit your custom metrics with the DogStatsD client. You can read more about this here.\n\n\nWhy is my counter metric showing decimal values?\n\nStatsD counters are normalized over the flush interval to report per-second units. You can read more about this here.\n\n\nIs there a way to submit metrics from my log data?\n\nYes there is! We detail log parsing here.\n\n\nI’d like to add historical data to my account. Is there a way to do that?\n\nUnfortunately, we do not allow adding historical data at this time.\n\n\nCorrect metric syntax (JSON)?\n\nThis depends on the medium you use to send metrics.\n\n\n  For an Agent Check, see this link.\n  For DogStatsD, see this link.\n  For the API, see this link.\n\n\n\nIs there a way I can get metric reports?\n\nWe offer reporting in a variety of ways so far, which include:\n\n\n  The ability to embed any chart anywhere. Pick a graph on a dashboard, click on\nthe pencil to edit it and you’ll find the “share” tab that will generate an IFRAME.\n  For certain sources (e.g. pagerduty), you’ll get a report in your mailbox once\na week to go over past alerts.\n  Metric alerts provide a way to report changes that are outside of what you define\nas “normal”.\n\n\n\nHow do I get disk usage as a percentage instead of in bytes?\n\nThe Datadog Agent emits a metric named system.disk.in_use which will give you disk\nusage as a percentage.\n\n\nHow is data aggregated in graphs\n\nWithin Datadog, a graph can only contain a set number of points and, as the timeframe\nover which a metric is viewed increases, aggregation between points will occur to\nstay below that set number.\n\nThus, if you are querying for larger timeframes of data, the points\nreturned will be more aggregated. The max granularity within Datadog\nis one point per second, so if you had submitted points at that interval\nand requested a very small time interval (in this case, probably less\nthan two minutes), you could end up getting all of those exact points\ndisplayed. Otherwise, you’ll see coarser and coarser granularity as the\namount of time requested increases. We do this time aggregation via\naverage,sum,  min, max, or count.\n\n\nWhat’s the difference between system.load.1, system.load.5, and system.load.15?\n\nWhen you run uptime on a *nix system, the three numbers at the end represent\nsystem.load.1, system.load.5, and system.load.15. System.load.1 is the system load\nfor the past 1 minute for a single core. Related to these is system.load.norm.1, which\nis the system.load for the past 1 minute on divided by the number of cores on that\nmachine.\n\n\nAny other things about metrics?\n\nWhen using the ‘sum/min/max/avg’ aggregator, we’re looking across series,\nnot at points within a single series. So if it is scoped to it’s most granular\nlevel, it’s possible that switching between those aggregators will not change\nthe values you’re seeing.\n\nFor example, let’s say you break down used memory by host, you’ll get one\ntime series for each host. If you don’t break down by host,\nby default you’ll get the average across all hosts.\n\n\n\n\nOther\n\n\nHow do I setup my team in Datadog?\n\nThe admin of the account should enter the email addresses of team members\nhere. Some team best practices are as follows:\n\n\n  When the team member receives the confirmation email, they will be provided with a link to log in directly. The user should not click ‘sign up’ during this process.\n  If multiple users from the same organization sign up separately, this will register as different organizations in Datadog. Please reach out to support to have these merged, but please note that all information contained in the account getting merged will not be transferred over.\n  The only access controls we have right now are around admin activities (adding/removing users, billing, etc.). As far as data goes (hosts, metrics, dashboards, etc.) all users have access to everything; more robust access controls are in our pipeline, but not something we’ve focused a lot of attention on yet.\n  To remove a team member use the “disable” button on the same ‘team’ page (only available for admins). You cannot permanently remove users, just disable; disabled users will only be visible to admins on the team page and can’t log in and any session they have open is invalidated. We don’t fully delete them because they might own events, dashboards, etc. which are not supposed to be removed.\n\n\n\nAre my data and credentials safe?\n\n\n  Traffic is always initiated by the agent to Datadog. No sessions are ever initiated from Datadog back to the agent.\n  All traffic is sent over SSL.\n  All communication to Datadog is via HTTPS.\n  The full license agreement can be found here.\n  The agent is entirely open source and can be found here.\n  Some installations (for example, installing the agent on CentOS 5), will request your password. The password is needed because it’s installing packages - Datadog does not retain it in anyway. You can also use the step-by-step directions if you prefer to see exactly what the script is doing.\n\n\n\nI have a feature request. How can I submit it?\n\nYou can send the request to support@datadoghq.com and we will add it to our feature request log.\n\n","tags":"","loc":"/faq/"},{"title":"Graphing Primer","text":"\nThere are two ways to interact with the Graphing Editor: using the GUI (the default method) and writing JSON (the more complete method). This page covers using the GUI. To learn more about using JSON, visit the JSON Graphing Primer Page\n\n\nFind the Graph Editor\n\nOn each graph you will find a pencil icon that opens the graph editor.\n\n\n\nThe graph editor has three tabs, Share, JSON, and Edit. Share will allow you to embed the graph on any external web page. JSON is the more flexible editor, but it requires knowledge of the graph definition language to make use of it. Edit is the default tab and will allow you to use a GUI to select the graphing options. The newest features are sometimes only available on the JSON tab.\n\n\nGraphing with the graphical editor interface\n\nWhen you first open the graph editor window, you will be on the Edit tab. Here you can use the UI to choose most settings to tweak your graphs. Here is an example of what you might see. This example comes from the first graph in the standard Postgres Integration dashboard:\n\n\n\nConfiguring a graph in a dashboard is a multi-step process. The first two steps depend\n\n\n1) Choose the Metric to graph\n\nWhen you create a graph, you will probably have a metric in mind that you want to show. You can select that in the first dropdown in the Choose metrics and events section. If you aren’t sure exactly which metric to use, you might want to start with the Metrics Explorer. You can also look in the Metrics Summary.\n\nThe Metrics Explorer will allow you to play around with different graph settings in a more ad-hoc way. The Metrics Summary will allow to learn more about the type of metric as well as setting the default unit for a metric.\n\n\n2) Select your visualization\n\nOnce you have a metric in mind to display in your graph, select your visualization.\n\n\nTimeseries\n\nThe Timeseries visualization is great for showing one or more metrics over time. The time window depends on what is selected on the timeboard or in the graph on a screenboard. Timeseries’ can be displayed as lines, areas, and bars. To see an example of a timeseries graph, click here. Timeseries is available on both timeboards and screenboards.\n\n\n  \n\n\n\nHeatmap\n\nThe Heatmap visualization is great for showing metrics aggregated across many tags, such as hosts. The more hosts that have a particular value, the darker that square will be. To see an example of a heatmap, click here. Heatmap is available on both timeboards and screenboards.\n\n\n  \n\n\n\nDistribution\n\nThe Distribution visualization is another way of showing metrics aggregated across many tags, such as hosts. Unlike the Heatmap, Distribution’s x-axis is the quantity rather than time. To see an example of a distribution graph, click here. Distribution is available on both timeboards and screenboards.\n\n\n  \n\n\n\nToplist\n\nThe Toplist visualization is perfect when you want to see the list of hosts with the most or least of any metric value, such as highest consumers of CPU, hosts with the least disk space, etc. To see an example of a Toplist,  click here. Toplist is available on both timeboards and screenboards.\n\n\n  \n\n\n\nChange\n\nThe Change graph will show you the change in a value over the time period chosen. To see an example of a Change graph, click here.\n\n\n  \n\n\n\nHostmap\n\nThe Hostmap will graph any metric for any subset of hosts on the same hostmap visualization available from the main Infrastructure Hostmap menu. To see an example of a Hostmap, click here.\n\n\n  \n\n\n\n3) Filter and Aggregate to show what you need\n\n\nFilter\n\nNow that you have the metric and a visualization in place, you can filter down the hosts to be graphed. To the right of the metric is a dropdown which by default says (everywhere). Click this and choose the tag(s) you want to filter by. To learn more about tags, refer to the Guide to Tagging.\n\n\nAggregation Method\n\nNext to the filter dropdown is the aggregation method. This defaults to avg by but can be changed to max by, min by, or sum by. In most cases, the metric will have many values for each time interval, coming from many hosts or instances. The aggregation method chosen determines how the metrics will be aggregated into a single line. So if you are graphing a metric that is from 100 hosts, sum by will add up all of those values and display the sum.\n\n\nAggregation Groups\n\nAfter the aggregation method you can determine what constitutes a line or grouping in a graph. If you choose host, then you will have a line (in the case of line graphs) for each host. If you choose role, then there is a line for every role. Then that line will be made up of metrics from all the hosts in that role, aggregated using the method you chose above.\n\n\n4) Rollup to aggregate over time\n\nRegardless of the options chosen above, there will always be some aggregation of data due to the physical size constraints of the window holding the graph. If a metric is updated every second and you are looking at 4 hours of data, you will need 14,400 points to display everything. Each graph we display will have about 300 points shown at any given time.\n\nIn the example above, each point displayed on the screen represents 48 data points. In practice, metrics are collected by the agent every 15-20 seconds. So one day’s worth of data is 4,320 data points. You might consider a rollup function that looks at 5 or 10 minutes worth of data if you would like to have more control over the display of your data for a graph that shows 1 day.\n\nTo use the rollup function, click the plus sign to the right of the aggregation group and choose rollup from the dropdown. Now choose how you want to aggregate the data and the interval in seconds.\n\nTo create a single line that represents the total available disk space on average across all machines rolled up in 60 seconds buckets, you would use a query like this:\n\n\n\nWhen switching to the JSON view, the query will look like this:\n\n\"q\": \"avg:system.disk.free{*}.rollup(avg, 60)\"\n\n\nFor more about using the JSON view, visit the JSON Graphing Primer page.\n\n\n5) Apply more advanced functions\n\nDepending on your analysis needs, you may choose to apply other mathematical functions to the query. Examples include rates and derivatives, smoothing, and more. For a list of available functions, click here.\n\n\n  \n\n  \n    \n      \n        Function\n        Category\n        Description\n      \n    \n    \n      \n        abs()\n        Arithmetic\n        absolute value\n      \n      \n        log2()\n        Arithmetic\n        base-2 logarithm\n      \n      \n        log10()\n        Arithmetic\n        base-10 logarithm\n      \n      \n        cumsum()\n        Arithmetic\n        cumulative sum over visible time window\n      \n      \n        integral()\n        Arithmetic\n        cumulative sum of ([time delta] x [value delta]) over all consecutive pairs of points in the visible time window\n      \n      \n        .fill()\n        Interpolation\n        choose how to interpolate missing values\n      \n      \n        hour_before()\n        Timeshift\n        metric values from one hour ago\n      \n      \n        day_before()\n        Timeshift\n        metric values from one day ago\n      \n      \n        week_before()\n        Timeshift\n        metric values from one week ago\n      \n      \n        month_before()\n        Timeshift\n        metric values from one month ago\n      \n      \n        per_second()\n        Rate\n        the rate at which the metric changes per second\n      \n      \n        per_minute()\n        Rate\n        \nper_second() * 60\n      \n      \n        per_hour()\n        Rate\n        \nper_second() * 3600\n      \n      \n        dt()\n        Rate\n        time delta between points\n      \n      \n        diff()\n        Rate\n        value delta between points\n      \n      \n        derivative()\n        Rate\n        1st order derivative; diff() / dt()\n\n      \n      \n        ewma_3()\n        Smoothing\n        exponentially weighted moving average with a span of 3\n      \n      \n        ewma_5()\n        Smoothing\n        EWMA with a span of 5\n      \n      \n        ewma_10()\n        Smoothing\n        EWMA with a span of 10\n      \n      \n        ewma_20()\n        Smoothing\n        EWMA with a span of 20\n      \n      \n        median_3()\n        Smoothing\n        rolling median with a span of 3\n      \n      \n        median_5()\n        Smoothing\n        rolling median with a span of 5\n      \n      \n        median_7()\n        Smoothing\n        rolling median with a span of 7\n      \n      \n        median_9()\n        Smoothing\n        rolling median with a span of 9\n      \n      \n        .rollup()\n        Rollup\n        override default time aggregation type and time period; see the “Rollup” section below for details\n      \n      \n        count_nonzero()\n        Count\n        count all the non-zero values\n      \n      \n        count_not_null()\n        Count\n        count all the non-null values\n      \n      \n        top()\n        Rank\n        select the top series responsive to a given query, according to some ranking method; see the “Top functions” section below for more details\n      \n      \n        top_offset()\n        Rank\n        similar to top(), except with an additional offset parameter, which controls where in the ordered sequence of series the graphing starts. For example, an offset of 2 would start graphing at the number 3 ranked series, according to the chosen ranking metric.\n      \n      \n        robust_trend()\n        Regression\n        fit a robust regression trend line using Huber loss; see the “Robust regression” section below for more details\n      \n      \n        trend_line()\n        Regression\n        fit an ordinary least squares regression line through the metric values\n      \n      \n        piecewise_constant()\n        Regression\n        approximate the metric with a piecewise function composed of constant-valued segments\n      \n      \n        anomalies()\n        Algorithms\n        overlay a gray band showing the expected behavior of a series based on past behavior; see our guide to anomaly detection\n\n      \n      \n        outliers()\n        Algorithms\n        highlight outlier series; see our guide to outlier detection\n\n      \n    \n  \n\n  .as_count() & .as_rate()\n\n  These functions are only intended for metrics submitted as rates or counters via statsd. These functions will have no effect for other metric types. For more on details about how to use .as_count() and .as_rate() please see our blog post.\n\n  Rollup\n\n  .rollup() is recommended for expert users only. Appending this function to the end of a query allows you to control the number of raw points rolled up into a single point plotted on the graph. The function takes two parameters, method and time: .rollup(method,time)\n\n  The method can be sum/min/max/count/avg and time is in seconds. You can use either one individually, or both together like .rollup(sum,120). We impose a limit of 350 points per time range. For example, if you’re requesting .rollup(20) for a month-long window, we will return data at a rollup far greater than 20 seconds in order to prevent returning a gigantic number of points.\n\n  Top functions\n\n  \n    a metric query string with some grouping, e.g. avg:system.cpu.idle{*} by {host}\n\n    the number of series to be displayed, as an integer.\n    one of 'max', 'min', 'last', 'l2norm', or 'area'.  'area' is the signed area under the curve being graphed, which can be negative.  'l2norm' uses the L2 Norm of the time series, which is always positive, to rank the series.\n    either 'desc' (rank the results in descending order) or 'asc' (ascending order).\n  \n\n  The top() method also has convenience functions of the following form, all of which take a single series list as input:\n\n  [top, bottom][5, 10, 15, 20]_[mean, min, max, last, area, l2norm]()\n\n  For example, bottom10_min() retrieves lowest-valued 10 series using the ‘min’ metric.\n\n  Robust regression\n\n  The most common type of linear regression – ordinary least squares (OLS) – can be heavily influenced by a small number of points with extreme values. Robust regression is an alternative method for fitting a regression line; it is not influenced as strongly by a small number of extreme values. As an example, see the following plot.\n\n  \n\n  The original metric is shown as a solid blue line. The purple dashed line is an OLS regression line, and the yellow dashed line is a robust regression line. The one short-lived spike in the metric leads to the OLS regression line trending upward, but the robust regression line ignores the spike and does a better job fitting the overall trend in the metric.\n\n\n\n\n6) Overlay events for additional context\n\nYou can repeat all the steps above to add additional metrics to your graph to add context. You can also add events from related system to add even more context. So an example would be to add github commits, Jenkins deploys, or Docker creation events. Just click the Overlay Events button and enter a query to find and display your events. To show anything from a source such as Github, use sources:github. For all the events with the tag role:web, use tag:role:web.\n\n\n7) Create a title\n\nIf you don’t enter a title, we will automatically generate a title based on the selections you have made. But it may be more useful to the users of the dashboard to create a title that more aptly describes the purpose of the graph. Linking the technical purpose to the business benefits adds even more value.\n\n\n8) Save\n\nThe final step is to click Save. You can always come back in to the editor and tweak the graph further depending on your needs.\n\n","tags":"","loc":"/graphing/"},{"title":"Graphing Primer using JSON","text":"\nThere are two ways to interact with the Graphing Editor: using the GUI (the default method) and writing JSON (the more complete method). This page covers using JSON. To learn more about the GUI editor, visit the main Graphing Primer Page\n\n\nGraphing with the JSON editor\n\n\n\n\nGrammar\n\nThe graph definition language is well-formed JSON and is structured in four parts:\n\n\n  Requests\n  Events\n  Visualization\n  Y Axis\n\n\nHere is how they fit together in a JSON dictionary:\n\n{\n  \"requests\": [\n    {\n      \"q\": \"metric{scope}\"\n    }\n  ],\n  \"events\": [\n    {\n      \"q\": \"search query\"\n    }\n  ],\n  \"viz\": \"visualization type\",\n  \"yaxis\": {\n    \"yaxisoptionkey\": \"yaxisoptionvalue\"\n  }\n}\n\n\nIn other words at the highest level the JSON structure is a dictionary with two, three, or four entries:\n\n\n  “requests” *\n  “events”\n  “viz” *\n  “yaxis”\n\n\n* only requests and viz are required.\n\n\nRequests\n\nThe general format for a series is:\n\n\"requests\": [\n    {\n      \"q\": \"function(aggregation method:metric{scope} [by {group}])\"\n    }\n]\n\n\nThe function and group are optional.\n\nA Series can be further combined together via binary operators (+, -, /, *):\n\nmetric{scope} [by {group}] operator metric{scope} [by {group}]\n\n\n\nFunctions\n\nYou can apply functions to the result of each query.\n\nA few of these functions have been further explained in a series of examples. Visit this page for more detail: Examples\n\n\n  \n    \n      Function\n      Category\n      Description\n    \n  \n  \n    \n      abs()\n      Arithmetic\n      absolute value\n    \n    \n      log2()\n      Arithmetic\n      base-2 logarithm\n    \n    \n      log10()\n      Arithmetic\n      base-10 logarithm\n    \n    \n      cumsum()\n      Arithmetic\n      cumulative sum over visible time window\n    \n    \n      integral()\n      Arithmetic\n      cumulative sum of ([time delta] x [value delta]) over all consecutive pairs of points in the visible time window\n    \n    \n      .fill()\n      Interpolation\n      choose how to interpolate missing values\n    \n    \n      hour_before()\n      Timeshift\n      metric values from one hour ago\n    \n    \n      day_before()\n      Timeshift\n      metric values from one day ago\n    \n    \n      week_before()\n      Timeshift\n      metric values from one week ago\n    \n    \n      month_before()\n      Timeshift\n      metric values from one month ago\n    \n    \n      per_second()\n      Rate\n      the rate at which the metric changes per second\n    \n    \n      per_minute()\n      Rate\n      \nper_second() * 60\n    \n    \n      per_hour()\n      Rate\n      \nper_second() * 3600\n    \n    \n      dt()\n      Rate\n      time delta between points\n    \n    \n      diff()\n      Rate\n      value delta between points\n    \n    \n      derivative()\n      Rate\n      1st order derivative; diff() / dt()\n\n    \n    \n      ewma_3()\n      Smoothing\n      exponentially weighted moving average with a span of 3\n    \n    \n      ewma_5()\n      Smoothing\n      EWMA with a span of 5\n    \n    \n      ewma_10()\n      Smoothing\n      EWMA with a span of 10\n    \n    \n      ewma_20()\n      Smoothing\n      EWMA with a span of 20\n    \n    \n      median_3()\n      Smoothing\n      rolling median with a span of 3\n    \n    \n      median_5()\n      Smoothing\n      rolling median with a span of 5\n    \n    \n      median_7()\n      Smoothing\n      rolling median with a span of 7\n    \n    \n      median_9()\n      Smoothing\n      rolling median with a span of 9\n    \n    \n      .rollup()\n      Rollup\n      override default time aggregation type and time period; see the “Rollup” section below for details\n    \n    \n      count_nonzero()\n      Count\n      count all the non-zero values\n    \n    \n      count_not_null()\n      Count\n      count all the non-null values\n    \n    \n      top()\n      Rank\n      select the top series responsive to a given query, according to some ranking method; see the “Top functions” section below for more details\n    \n    \n      top_offset()\n      Rank\n      similar to top(), except with an additional offset parameter, which controls where in the ordered sequence of series the graphing starts. For example, an offset of 2 would start graphing at the number 3 ranked series, according to the chosen ranking metric.\n    \n    \n      robust_trend()\n      Regression\n      fit a robust regression trend line using Huber loss; see the “Robust regression” section below for more details\n    \n    \n      trend_line()\n      Regression\n      fit an ordinary least squares regression line through the metric values\n    \n    \n      piecewise_constant()\n      Regression\n      approximate the metric with a piecewise function composed of constant-valued segments\n    \n    \n      anomalies()\n      Algorithms\n      overlay a gray band showing the expected behavior of a series based on past behavior; see our guide to anomaly detection\n\n    \n    \n      outliers()\n      Algorithms\n      highlight outlier series; see our guide to outlier detection\n\n    \n  \n\n\n.as_count() & .as_rate()\n\nThese functions are only intended for metrics submitted as rates or counters via statsd. These functions will have no effect for other metric types. For more on details about how to use .as_count() and .as_rate() please see our blog post.\n\nRollup\n\n.rollup() is recommended for expert users only. Appending this function to the end of a query allows you to control the number of raw points rolled up into a single point plotted on the graph. The function takes two parameters, method and time: .rollup(method,time)\n\nThe method can be sum/min/max/count/avg and time is in seconds. You can use either one individually, or both together like .rollup(sum,120). We impose a limit of 350 points per time range. For example, if you’re requesting .rollup(20) for a month-long window, we will return data at a rollup far greater than 20 seconds in order to prevent returning a gigantic number of points.\n\nTop functions\n\n\n  a metric query string with some grouping, e.g. avg:system.cpu.idle{*} by {host}\n\n  the number of series to be displayed, as an integer.\n  one of 'max', 'min', 'last', 'l2norm', or 'area'.  'area' is the signed area under the curve being graphed, which can be negative.  'l2norm' uses the L2 Norm of the time series, which is always positive, to rank the series.\n  either 'desc' (rank the results in descending order) or 'asc' (ascending order).\n\n\nThe top() method also has convenience functions of the following form, all of which take a single series list as input:\n\n[top, bottom][5, 10, 15, 20]_[mean, min, max, last, area, l2norm]()\n\nFor example, bottom10_min() retrieves lowest-valued 10 series using the ‘min’ metric.\n\nRobust regression\n\nThe most common type of linear regression – ordinary least squares (OLS) – can be heavily influenced by a small number of points with extreme values. Robust regression is an alternative method for fitting a regression line; it is not influenced as strongly by a small number of extreme values. As an example, see the following plot.\n\n\n\nThe original metric is shown as a solid blue line. The purple dashed line is an OLS regression line, and the yellow dashed line is a robust regression line. The one short-lived spike in the metric leads to the OLS regression line trending upward, but the robust regression line ignores the spike and does a better job fitting the overall trend in the metric.\n\nThere are also a few functions you can append to a query which we recommend for expert users only.\n\nOne of these is .rollup(). Appending this function allows you to control the\nnumber of points rolled up into a single point. This function takes two parameters, method and time, like so:\n.rollup(method,time).\n\nThe method can be sum/min/max/count/avg and time is in seconds. You can use either one individually,\nor both combined like .rollup(sum,120). There are some checks on this,\nthough, because for a given time range we do not return more than 350 points. Thus if\nyou're requesting .rollup(20) where 20 is in seconds, and ask for a\nmonth of data, we will be returning the points at a rollup of far greater than 20 seconds.\n\n\n.as_count() and .as_rate() are two other expert-only functions,\nwhich are only intended for metrics submitted in a certain way (for metadata types where\nthat is acceptable).  At present, for metrics submitted as rates or counters via statsd,\nappending .as_count() or .as_rate() will function correctly.\nFor other metrics, including gauges submitted by statsd, .as_count() and\n.as_rate() will have no effect.\n\nFor more on .as_count() please see our blog post\nhere.\n\n\nAggregation Method\n\nIn most cases, the number of data points available outnumbers the maximum number that can be shown on screen. To overcome this, the data is aggregated using one of 4 available methods: average,  max, min, and sum.\n\n\nMetrics\n\nThe metric is the main focus of the graph. You can find the list of metrics available to you in the Metrics Summary. Click on any metric to see more detail about that metric, including the type of data collected, units, tags, hosts, and more.\n\n\nScope\n\nA scope lets you filter a Series. It can be a host, a device on a host\nor any arbitrary tag you can think of that contains only alphanumeric\ncharacters plus colons and underscores ([a-zA-Z0-9:_]+).\n\nExamples of scope (meaning in parentheses):\n\nhost:my_host                      (related to a given host)\nhost:my_host, device:my_device    (related to a given device on a given host)\nsource:my_source                  (related to a given source)\nmy_tag                            (related to a tagged group of hosts)\nmy:tag                            (same)\n*                                 (wildcard for everything)\n\n\n\nGroups\n\nFor any given metric, data may come from a number of hosts. The data will normally be aggregated from all these hosts to a single value for each time slot. If you wish to split this out, you can by any tag. To include a data point seperated out by each host,  use {host} for your group.\n\n\nArithmetic\n\nYou can apply simple arithmetic to a Series (+, -, * and /). In this\nexample we graph 5-minute load and its double:\n\n{\n  \"viz\": \"timeseries\",\n  \"requests\": [\n    {\n      \"q\": \"system.load.5{intake} * 2\"\n    },\n    {\n      \"q\": \"system.load.5{intake}\"\n    }\n  ]\n}\n\n\nYou can also add, substract, multiply and divide a Series. Beware that\nDatadog does not enforce consistency at this point so you can divide\napples by oranges.\n\n{\n    \"viz\": \"timeseries\",\n    \"requests\": [\n      {\n        \"q\": \"metric{apples} / metric{oranges}\"\n      }\n    ]\n}\n\n\n\nEvents\n\nYou can overlay any event from Datadog. The general format is:\n\n\"events\": [\n  {\n    \"q\": \"search query\"\n  }\n]\n\n\nFor instance, to indicate that you want events for host X and tag Y:\n\n\"events\": [\n  {\n    \"q\": \"host:X tags:Y\"\n  }\n]\n\n\nor if you’re looking to display all errors:\n\n\"events\": [\n  {\n    \"q\": \"status:error\"\n  }\n]\n\n\n\nVisualization\n\nData can be visualized in a few different ways:\n\n\n  Time Series\n  Heatmap\n  Distribution\n  Toplist\n  Change\n  Hostmap\n\n\nThe Time Series can be further broken down to:\n\n\n  as line charts\n  as stacked areas\n  as slice-n-stack areas\n  as bar charts\n\n\n\nLine Charts\n\n\n\nThe representation is automatically derived from having multiple requests values.\n\n\"requests\": [\n    {\n      \"q\": \"metric1{scope}\"\n    },\n    {\n      \"q\": \"metric2{scope}\"\n    },\n    {\n      \"q\": \"metric3{scope}\"\n    }\n  ]\n\n\n\nStacked Series\n\n\n\nIn the case of related Time Series, you can easily draw them as stacked areas by using the following syntax:\n\n\"requests\": [\n    {\n      \"q\": \"metric1{scope}, metric2{scope}, metric3{scope}\"\n    }\n]\n\n\nInstead of one query per chart you can aggregate all queries into one and simply concatenate the queries.\n\n\nSlice-n-Stack\n\nA useful visualization is to represent a metric shared across\nhosts and stack the results. For instance, when selecting a tag that\napplies to more than 1 host you will see that ingress and egress\ntraffic is nicely stacked to give you the sum as well as the split per\nhost. This is useful to spot wild swings in the distribution of network\ntraffic.\n\nHere’s how to do it for any metric:\n\n\"requests\" [\n  {\n     \"q\": \"system.net.bytes_rcvd{some_tag, device:eth0} by {host}\"\n  }\n]\n\n\nNote that in this case you can only have 1 query. But you can also split by device, or a combination of both:\n\n\"requests\" [\n  {\n     \"q\": \"system.net.bytes_rcvd{some_tag} by {host,device}\"\n  }\n]\n\n\nto get traffic for all the tagged hosts, split by host and network device.\n\n\nY-Axis Controls\n\nThe Datadog y-axis controls (currently just via the JSON editor) allow you to:\n\n Clip y-axis to specific ranges\n Filter series either by specifying a percentage or an absolute value\n Change y-axis scale from linear to log, sqrt or power scale\n\n\nThere are four configuration settings:\n\n\nmin (optional): Specifies minimum value to show on y-axis. It takes a number, or \"auto\" for\n    default behvior. Default value is \"auto\"\n\nmax (optional): Specifies the maximum value to show on y-axis. It takes a number, or \"auto\"\n    for default behavior. Default value is \"auto\"\n\nscale (optional): Specifies the scale type. Possible values: \"linear\", \"log\", \"sqrt\", \"pow##\"\n    (eg. pow2, pow0.5, 2 is used if only \"pow\" was provided\"), Default scale is \"linear\".\n\nunits (optional): Specifies whether to show the metric unit along the y-axis. Possible values: \"true\"\n    or \"false\". Default is \"false\".\n\n\nExamples:\n\n\"yaxis\": {\n    \"min\": \"auto\",\n    \"max\": 200,\n    \"scale\": \"log\"\n}\n\n\"yaxis\": {\n    \"min\": 200,\n    \"scale\": \"sqrt\"\n}\n\n\"yaxis\": {\n    \"min\": 9000,\n    \"max\": 10000\n}\n\n\"yaxis\": {\n    \"scale\": \"pow0.1\"\n}\n\n\"yaxis\": {\n    \"scale\": \"pow3\"\n}\n\n\"yaxis\": {\n    \"units\": \"true\"\n}\n\n\n\nFiltering\n\nFilter configuration allows you to automatically change y-axis bounds based on a\nthreshold. Thresholds can be a percentage or an absolute value, and it can apply to\nboth both ends of the graph (lower and upper).\n\nFor y-axis filtering, there are two ways to set up the configuration.\n\nTo begin, there is a simple configuration where you specify an absolute value or a percentage and all\nvalues above the value or all values that sit within the top ##% will be cutoff.\n\nExamples:\n\n\"yaxis\": {\n    \"filter\": 30 // all values above 30 will not appear\n}\n\n\"yaxis\": {\n    \"filter\": \"5%\" // the top 5% of that data will not appear\n}\n\n\nAdvanced configuration works the same way as simple configuration, with the added\nflexibility of configuring the lower or the upper or both parts of the graph. For\nexample, the following configuration will limit the graph to data points that are\nnot in the bottom 10% nor in the top 30%.\n\n\"yaxis\": {\n    \"filter\": {\n        \"top\": \"30%\",\n        \"bottom\": \"10%\"\n    }\n}\n\n\nThe following will show all data except those with values higher than 15:\n\n\"yaxis\": {\n    \"filter\": {\n        \"above\": 15\n    }\n}\n\n\nThe following will hide data points below 2:\n\n\"yaxis\": {\n    \"filter\": {\n        \"below\": 2\n    }\n}\n\n\nHere is a full JSON example:\n\n{\n  \"viz\": \"timeseries\",\n  \"requests\": [\n    {\n      \"q\": \"system.cpu.idle{host:hostname}\",\n      \"stacked\": false\n    }\n  ],\n  \"events\": [],\n  \"yaxis\": {\n    \"scale\": \"log\"\n    \"filter\": {\n         \"top\": \"5%\",\n         \"below\": 15\n     }\n  },\n}\n\n\n\nExamples\n\nHere is an example using the rate() function, which takes only a single metric as a parameter.  Other functions, with the exception of top() and top_offset(), have identical syntax.\n\n{\n  \"viz\": \"timeseries\",\n  \"requests\": [\n    {\n      \"q\": \"rate(sum:system.load.5{role:intake-backend2} by {host})\",\n      \"stacked\": false\n    }\n  ]\n}\n\n\nHere is an example using the top() function:\n\n{\n  \"viz\": \"timeseries\",\n  \"requests\": [\n    {\n      \"q\": \"top(avg:system.cpu.iowait{*} by {host}, 5, 'max', 'desc')\",\n      \"stacked\": false\n    }\n  ]\n}\n\n\nThis will show the graphs for the five series with the highest peak system.cpu.iowait values in the query window.\n\nTo look at the hosts with the 6th through 10th highest values (for example), use top_offset instead:\n\n{\n  \"viz\": \"timeseries\",\n  \"requests\": [\n    {\n      \"q\": \"top_offset(avg:system.cpu.iowait{*} by {host}, 5, 'max', 'desc', 5)\",\n      \"stacked\": false\n    }\n  ]\n}\n\n\nHere is an example using the week_before() function:\n\n{\n  \"viz\": \"timeseries\",\n  \"requests\": [\n    {\n      \"q\": \"sum:haproxy.count_per_status{status:available} - week_before(sum:haproxy.count_per_status{status:available})\"\n    }\n  ]\n}\n\n","tags":"","loc":"/graphingjson/"},{"title":"Writing an Agent Check","text":"\n\nThis guide requires an Agent version >= 3.2.0. Older versions of the Agent do\nnot include the `AgentCheck` interface that we'll be using.\n\n\n\n\n\nOverview\nThis guide details how to collect metrics and events from a new data source\nby writing an Agent Check, a Python plugin to the Datadog Agent. We’ll\nlook at the AgentCheck interface, and then write a simple Agent Check\nthat collects timing metrics and status events from HTTP services.\n\nAny custom checks will be included in the main check run loop, meaning\nthey will run every check interval, which defaults to 15 seconds.\n\n\nShould you write an Agent Check or an Integration?\nAgent Checks are a great way to collect metrics from custom applications or unique systems. However, if you are trying to collect metrics from a generally available application, public service or open source project, we recommend that you write an Integration.\n\nStarting with version 5.9 of the Datadog Agent, we’ve enabled a new method for creating integrations and created a corresponding integrations-extras repository where you can contribute your own integrations. This allows integrations to be released and updated independently from Datadog Agent updates, it also provides an easier way for you to share integrations and will make it easier for the wider Datadog community to use your integrations.\n\nFor more information about how to write an Integration, please see the Creating New Integrations guide and check out the Integrations-Extras Github repo to see other contributed integrations.\n\n\n\n\nSetup\n\nFirst off, ensure you’ve properly\ninstalled the\nAgent on your machine. If you run into any issues during the setup, pop by\nour chatroom, #datadog on FreeNode,\nand we’ll be happy to answer any questions you might have. (There’s a\n\nweb chat client, too.)\n\n\n\n\nAgent Check Interface\n\nAll custom checks inherit from the AgentCheck class found in checks/__init__.py\nand require a check() method that takes one argument, instance which is a\ndict having the configuration of a particular instance. The check method is\nrun once per instance defined in the check configuration (discussed later).\n\n\nSending metrics\n\nSending metrics in a check is easy. If you’re already familiar with the\nmethods available in DogStatsD, then the transition will be very simple. If\nyou’re not already familiar with that interface, you’ll find sending metrics is\na breeze.\n\nYou have the following methods available to you:\n\nself.gauge( ... ) # Sample a gauge metric\n\nself.increment( ... ) # Increment a counter metric\n\nself.decrement( ... ) # Decrement a counter metric\n\nself.histogram( ... ) # Sample a histogram metric\n\nself.rate( ... ) # Sample a point, with the rate calculated at the end of the check\n\nself.count( ... ) # Sample a raw count metric\n\nself.monotonic_count( ... ) # Sample an increasing counter metric\n\n\nAll of these methods take the following arguments:\n\n\n  \nmetric: The name of the metric\n  \nvalue: The value for the metric (defaults to 1 on increment, -1 on decrement)\n  \ntags: (optional) A list of tags to associate with this metric.\n  \nhostname: (optional) A hostname to associate with this metric. Defaults to the current host.\n  \ndevice_name: (optional) A device name to associate with this metric.\n\n\nThese methods may be called from anywhere within your check logic. At the end of\nyour check function, all metrics that were submitted will be collected and\nflushed out with the other Agent metrics.\n\n\nSending events\n\nAt any time during your check, you can make a call to self.event(...) with one argument: the payload of the event. Your event should be structured like this:\n\n{\n    \"timestamp\": int, the epoch timestamp for the event,\n    \"event_type\": string, the event name,\n    \"api_key\": string, the api key for your account,\n    \"msg_title\": string, the title of the event,\n    \"msg_text\": string, the text body of the event,\n    \"aggregation_key\": string, a key to use for aggregating events,\n    \"alert_type\": (optional) string, one of ('error', 'warning', 'success', 'info');\n        defaults to 'info',\n    \"source_type_name\": (optional) string, the source type name,\n    \"host\": (optional) string, the name of the host,\n    \"tags\": (optional) list, a list of tags to associate with this event\n    \"priority\": (optional) string which specifies the priority of the event (Normal, Low)\n}\n\n\nAt the end of your check, all events will be collected and flushed with the rest\nof the Agent payload.\n\n\nSending service checks\n\nYour custom check can also report the status of a service by calling the self.service_check(...) method.\n\nThe service_check method will accept the following arguments:\n\n\n  \ncheck_name: The name of the service check.\n  \nstatus: An integer describing the service status. You may also use the class status definitions:\n    \n      \nAgentCheck.OK or 0 for success\n      \nAgentCheck.WARNING or 1 for warning\n      \nAgentCheck.CRITICAL or 2 for failure\n      \nAgentCheck.UNKNOWN or 3 for indeterminate status\n    \n  \n  \ntags: (optional) A list of key:val tags for this check.\n  \ntimestamp: (optional) The POSIX timestamp when the check occured.\n  \nhostname: (optional) The name of the host submitting the check. Defaults to the host_name of the agent.\n  \ncheck_run_id: (optional) An integer ID used for logging and tracing purposes. The ID does not need to be unique. If an ID is not provided, one will automatically be generated.\n  \nmessage: (optional) Additional information or a description of why this status occured.\n\n\n\nExceptions\n\nIf a check cannot run because of improper configuration,  programming error or\nbecause it could not collect any metrics, it should raise a meaningful exception.\nThis exception will be logged, as well as be shown in the Agent info command for\neasy debugging. For example:\n\n$ sudo /etc/init.d/datadog-agent info\n\n  Checks\n  ======\n\n    my_custom_check\n    ---------------\n      - instance #0 [ERROR]: ConnectionError('Connection refused.',)\n      - Collected 0 metrics & 0 events\n\n\n\nLogging\n\nAs part of the parent class, you’re given a logger at self.log, so you can do\nthings like self.log.info('hello'). The log handler will be checks.{name}\nwhere {name} is the name of your check (based on the filename of the check\nmodule).\n\n\n\n\nConfiguration\n\nEach check will have a configuration file that will be placed in the conf.d\ndirectory. Configuration is written using YAML. The\nfile name should match the name of the check module (e.g.: haproxy.py and\nhaproxy.yaml).\n\nThe configuration file has the following structure:\n\ninit_config:\n    min_collection_interval: 20\n    key1: val1\n    key2: val2\n\ninstances:\n    - username: jon_smith\n      password: 1234\n\n    - username: jane_smith\n      password: 5678\n\nmin_collection_interval can be added to the init_config section to help define how often the check should be run. If it is greater than the interval time for the agent collector, a line will be added to the log stating that collection for this script was skipped. The default is 0 which means it will be collected at the same interval as the rest of the integrations on that agent. If the value is set to 30, it does not mean that the metric will be collected every 30 seconds, but rather that it could be collected as often as every 30 seconds. The collector runs every 15-20 seconds depending on how many integrations are enabled. If the interval on this agent happens to be every 20 seconds, then the agent will collect and include the agent check. The next time it collects 20 seconds later, it will see that 20 < 30 and not collect the custom agent check. The next time it will see that the time since last run was 40 which is greater than 30 and therefore the agent check will be collected.\n\nNote: YAML files must use spaces instead of tabs.\n\n\ninit_config\n\nThe init_config section allows you to have an arbitrary number of global\nconfiguration options that will be available on every run of the check in\nself.init_config.\n\n\ninstances\n\nThe instances section is a list of instances that this check will be run\nagainst. Your actual check() method is run once per instance. This means that\nevery check will support multiple instances out of the box.\n\n\n\n\nDirectory Structure\n\nBefore starting your first check it is worth understanding the checks directory\nstructure. There are two places that you will need to add files for your check.\nThe first is the checks.d folder, which lives in your Agent root.\n\nFor all Linux systems, this means you will find it at:\n\n/etc/dd-agent/checks.d/\n\n\nFor Windows Server >= 2008 you’ll find it at:\n\nC:\\Program Files (x86)\\Datadog\\Agent\\checks.d\\\n\nOR\n\nC:\\Program Files\\Datadog\\Agent\\checks.d\\\n\n\nFor Mac OS X and source installations, you’ll find it at:\n\n~/.datadog-agent/agent/checks.d/\n\nOR\n\n~/.pup/agent/checks.d/\n\nOR\n\n<sandbox_folder>/checks.d/\n\n\nThe other folder that you need to care about is conf.d which lives in the\nAgent configuration root.\n\nFor Linux, you’ll find it at:\n\n/etc/dd-agent/conf.d/\n\n\nFor Windows, you’ll find it at:\n\nC:\\ProgramData\\Datadog\\conf.d\\\n\nOR\n\nC:\\Documents and Settings\\All Users\\Application Data\\Datadog\\conf.d\\\n\n\nFor Mac OS X and source installations, you’ll find it at:\n\n~/.datadog-agent/agent/conf.d/\n\nOR\n\n~/.pup/agent/conf.d/\n\nOR\n\n<sandbox_folder>/conf.d/\n\n\nYou can also add additional checks to a single directory, and point to it in datadog.conf:\n\nadditional_checksd: /path/to/custom/checks.d/\n\n\n\n\n\nYour First Check\n\n\nThe names of the configuration and check files must match. If your check\nis called mycheck.py your configuration file must be\nnamed mycheck.yaml.\n\n\nTo start off simple, we’ll write a check that does nothing more than send a\nvalue of 1 for the metric hello.world. The configuration file will be very\nsimple, including no real information. This will go into conf.d/hello.yaml:\n\ninit_config:\n\ninstances:\n    [{}]\n\n\n\nThe check itself will inherit from AgentCheck and send a gauge of 1 for\nhello.world on each call. This will go in checks.d/hello.py:\n\nfrom checks import AgentCheck\nclass HelloCheck(AgentCheck):\n    def check(self, instance):\n        self.gauge('hello.world', 1)\n\n\n\nAs you can see, the check interface is really simple and easy to get started\nwith. In the next section we’ll write a more useful check that will ping HTTP\nservices and return interesting data.\n\n\n\n\nAn HTTP Check\n\nNow we will guide you through the process of writing a basic check that will\ncheck the status of an HTTP endpoint. On each run of the check, a GET\nrequest will be made to the HTTP endpoint. Based on the response, one of the\nfollowing will happen:\n\n\n  If the response is successful (response is 200, no timeout) the response\n  time will be submitted as a metric.\n  If the response times out, an event will be submitted with the URL and\n  timeout.\n  If the response code != 200, an event will be submitted with the URL and\n  the response code.\n\n\n\nConfiguration\n\nFirst we will want to define how our configuration should look, so that we know\nhow to handle the structure of the instance payload that is passed into the\ncall to check.\n\nBesides just defining a URL per call, it’d be nice to allow you to set a timeout\nfor each URL. We’d also want to be able to configure a default timeout if no\ntimeout value is given for a particular URL.\n\nSo our final configuration would look something like this:\n\ninit_config:\n    default_timeout: 5\n\ninstances:\n    -   url: https://google.com\n\n    -   url: http://httpbin.org/delay/10\n        timeout: 8\n\n    -   url: http://httpbin.org/status/400\n\n\n\n\nThe Check\n\nNow we can start defining our check method. The main part of the check will make\na request to the URL and time the response time, handling error cases as it goes.\n\nIn this snippet, we start a timer, make the GET request using the\nrequests library and handle and\nerrors that might arise.\n\n# Load values from the instance config\nurl = instance['url']\ndefault_timeout = self.init_config.get('default_timeout', 5)\ntimeout = float(instance.get('timeout', default_time))\n\n# Use a hash of the URL as an aggregation key\naggregation_key = md5(url).hexdigest()\n\n# Check the URL\nstart_time = time.time()\ntry:\n    r = requests.get(url, timeout=timeout)\n    end_time = time.time()\nexcept requests.exceptions.Timeout as e:\n    # If there's a timeout\n    self.timeout_event(url, timeout, aggregation_key)\n\nif r.status_code != 200:\n    self.status_code_event(url, r, aggregation_key)\n\n\nIf the request passes, we want to submit the timing to Datadog as a metric. Let’s\ncall it http.response_time and tag it with the URL.\n\ntiming = end_time - start_time\nself.gauge('http.response_time', timing, tags=['http_check'])\n\n\nFinally, we’ll want to define what happens in the error cases. We have already\nseen that we call self.timeout_event in the case of a URL timeout and\nwe call self.status_code_event in the case of a bad status code. Let’s\ndefine those methods now.\n\nFirst, we’ll define timeout_event. Note that we want to aggregate all of these\nevents together based on the URL so we will define the aggregation_key as a hash\nof the URL.\n\ndef timeout_event(self, url, timeout, aggregation_key):\n    self.event({\n        'timestamp': int(time.time()),\n        'event_type': 'http_check',\n        'msg_title': 'URL timeout',\n        'msg_text': '%s timed out after %s seconds.' % (url, timeout),\n        'aggregation_key': aggregation_key\n    })\n\n\nNext, we’ll define status_code_event which looks very similar to the timeout\nevent method.\n\ndef status_code_event(self, url, r, aggregation_key):\n    self.event({\n        'timestamp': int(time.time()),\n        'event_type': 'http_check',\n        'msg_title': 'Invalid response code for %s' % url,\n        'msg_text': '%s returned a status of %s' % (url, r.status_code),\n        'aggregation_key': aggregation_key\n    })\n\n\n\nPutting It All Together\n\nFor the last part of this guide, we’ll show the entire check. This module would\nbe placed into the checks.d folder as http.py. The corresponding\nconfiguration would be placed into the conf.d folder as http.yaml.\n\nOnce the check is in checks.d, you can test it by running it as a python\nscript. Restart the Agent for the changes to be enabled. Make sure to change the conf.d path in the test method. From your\nAgent root, run:\n\nPYTHONPATH=. python checks.d/http.py\n\n\nYou’ll see what metrics and events are being generated for each instance.\n\nHere’s the full source of the check:\n\nimport time\nimport requests\n\nfrom checks import AgentCheck\nfrom hashlib import md5\n\nclass HTTPCheck(AgentCheck):\n    def check(self, instance):\n        if 'url' not in instance:\n            self.log.info(\"Skipping instance, no url found.\")\n            return\n\n        # Load values from the instance config\n        url = instance['url']\n        default_timeout = self.init_config.get('default_timeout', 5)\n        timeout = float(instance.get('timeout', default_timeout))\n\n        # Use a hash of the URL as an aggregation key\n        aggregation_key = md5(url).hexdigest()\n\n        # Check the URL\n        start_time = time.time()\n        try:\n            r = requests.get(url, timeout=timeout)\n            end_time = time.time()\n        except requests.exceptions.Timeout as e:\n            # If there's a timeout\n            self.timeout_event(url, timeout, aggregation_key)\n            return\n\n        if r.status_code != 200:\n            self.status_code_event(url, r, aggregation_key)\n\n        timing = end_time - start_time\n        self.gauge('http.reponse_time', timing, tags=['http_check'])\n\n    def timeout_event(self, url, timeout, aggregation_key):\n        self.event({\n            'timestamp': int(time.time()),\n            'event_type': 'http_check',\n            'msg_title': 'URL timeout',\n            'msg_text': '%s timed out after %s seconds.' % (url, timeout),\n            'aggregation_key': aggregation_key\n        })\n\n    def status_code_event(self, url, r, aggregation_key):\n        self.event({\n            'timestamp': int(time.time()),\n            'event_type': 'http_check',\n            'msg_title': 'Invalid reponse code for %s' % url,\n            'msg_text': '%s returned a status of %s' % (url, r.status_code),\n            'aggregation_key': aggregation_key\n        })\n\nif __name__ == '__main__':\n    check, instances = HTTPCheck.from_yaml('/path/to/conf.d/http.yaml')\n    for instance in instances:\n        print \"\\nRunning the check against url: %s\" % (instance['url'])\n        check.check(instance)\n        if check.has_events():\n            print 'Events: %s' % (check.get_events())\n        print 'Metrics: %s' % (check.get_metrics())\n\n\n\n\nTroubleshooting\n\nCustom Agent checks can’t be directly called from python and instead\n need to be called by the agent. To test this, run:\n\nsudo -u dd-agent dd-agent check my_check\n\n\nIf your issue continues, please reach out to Support with the help page that\n lists the paths it installs.\n\n\nTesting Custom Checks on Windows\n\nTesting custom checks on Windows is easy. The Agent install includes a file called shell.exe\nin your Program Files directory for the Datadog Agent which you can use to run python within the Agent environment.\n\nOnce your check (called “my_check”) is written and you have the .py and .yaml files\nin their correct places, you can run the following in shell.exe:\n\n>>> from checks import run_check\n>>> run_check('my_check')\n\n\nThis will output any metrics or events that the check will return.\n\n","tags":"","loc":"/guides/agent_checks/"},{"title":"Anomaly Detection","text":"\nAnomaly detection is an algorithmic feature that allows you to identify when a metric is behaving differently than it has in the past, taking into account trends, seasonal day-of-week and time-of-day patterns. It is well-suited for metrics with strong trends and recurring patterns that are hard or impossible to monitor with threshold-based alerting.\n\nFor example, anomaly detection can help you discover when your web traffic is unusually low on a weekday afternoon—even though that same level of traffic would be perfectly normal later in the evening. Or consider a metric measuring the number of logins to your steadily-growing site. As the number is increasing every day, any threshold would be quickly outdated, whereas anomaly detection can quickly alert you if there is an unexpected drop—potentially indicating an issue with the login system.\n\n\nHow to Use Anomaly Detection on Your Data\n\nWe’ve added a new query function called anomalies to our query language. When you apply this function to series, it returns the usual results along with an expected “normal” range.\n\nKeep in mind that anomalies uses the past to predict what is expected in the future, so using anomalies on a new metric, for which you have just started collecting data, may yield poor results.\n\n\n1. Visualize Anomalies in Dashboards\n\nThe chart below shows a dashboard chart that uses anomaly detection. The gray band represents the region where the metric is expected to be based on past behavior. The blue and red line is the actual observed value of the metric; the line is blue when within the expected range and red when it is outside of the expected range.\n\nPlease Note: The resolution at which you view the metric is the resolution that anomalies uses to calculate the band. If you would like to keep the resolution constant while zooming in and out, use the rollup() function. See the FAQ for more details.\n\n\n\nTo create an anomaly detection graph, start by adding a timeseries graph to your dashboard. As shown below, be sure to select “Timeseries” as the visualization type.\n\n\n\nNow, click on the + icon (Add functions and modifiers) on the right side of your expression. Choose the “Anomalies” function in the “Algorithms” submenu:\n\n\n\nThis will add anomaly detection to your expression, and you should immediately see the preview update to include the gray band. A number of the graphing options will disappear, as anomaly detection has a unique visualization.\n\nThe function has two parameters. The first parameter is for selecting which algorithm will be used. The second parameter is labeled bounds, and you can tune this to change the width of the grey band. You may think of bounds like standard deviations; a value of 2 or 3 should be large enough to include most “normal” points. After successfully adding anomalies, your editor should show something like this:\n\n\n\n\n2. Alert on Anomalies\n\nIn addition to viewing anomalies in dashboards, you may create monitors that trigger when metrics behave anomalously.\n\nStart by navigating to the New Monitor page and selecting Metric. Define the metric in step (1) just like you would for any other metric alert. In step (2), select “Anomaly Alert”.\n\n\n\nYou should now see something like what’s shown above, with a handful of selections that will help determine how sensitive your monitor is to different types of anomalies.\n\n\n  This number is equivalent to the bounds parameter used in the anomalies function in dashboards; it controls the width of the gray band. We recommend using a value of 2 or 3.\n  If you only care about unusually high or unusually low values, you can choose to only alert on values above or below the bounds.\n  We recommend using a window size of at least 15 minutes. (A 30 minute window works well in most cases.) \n  You can change the anomaly detection algorithm used here. See the next section of this guide for tips on how to choose the best algorithm for your use case.\n\n\nContinue with steps (3) and (4) as you would for any other monitor.\n\n\n3. Anomaly Detection Algorithms\n\nWe currently offer four different anomaly detection algorithms.\n\n\n  \n    Basic: Use this algorithm for metrics that have no repeating seasonal pattern. Basic uses a simple lagging rolling quantile computation to determine the range of expected values, but it uses very little data and adjusts quickly to changing conditions but has no knowledge of seasonal behavior or longer trends.\n  \n  \n    Agile: Use this algorithm for seasonal metrics when you want the algorithm to quickly adjust to level shifts in the metric. Agile is a robust version of the SARIMA algorithm. It incorporates the immediate past into its predictions, allowing it to update quickly to level shifts at the expense of being less robust to recent, long-lasting anomalies.\n  \n  \n    Robust: Use this algorithm for seasonal metrics where you expect the metric to be stable and want to consider slow level shifts as anomalies. Robust is a seasonal-trend decomposition algorithm. It is very stable and its predictions remain constant even through long-lasting anomalies at the expense of taking longer to respond to intended level shifts (e.g., if the level of a metric shifts due to a code change.)\n  \n  \n    Adaptive: Use this algorithm for seasonal metrics when you find agile and robust to be too sensitive to minor changes in the metrics behavior. This algorithm is dynamic and will adjust its predictions to a metric’s changes much more readily than agile or robust. On the other hand, it can be prone to following a metric too closely, which could lead to false negatives.\n  \n\n\nAll of the seasonal algorithms may use up to a couple of months of historical data when calculating a metric’s expected normal range of behavior. By using a significant amount of past data, the algorithms are able to avoid giving too much weight to abnormal behavior that might have occurred in the recent past.\n\nThe figures below illustrate how and when these four algorithms behave differently from one another. In the first figure, basic will successfully identify anomalies that spike out of the normal range of values, but it does not incorporate the repeating, seasonal pattern into its predicted range of values. By contrast, robust, agile, and adaptive all recognize the seasonal pattern and can detect more nuanced anomalies (e.g., if the metric was to flatline near its minimum value).\n\n\n\nIn the next figure, the metric exhibits a sudden level shift. Agile and adaptive adjust more quickly to the level shift than does robust. Also, the width of robust’s bounds increases to reflect greater uncertaintly after the level shift; the width of agile and adaptive bounds remains unchanged. Basic is clearly a poor fit for this scenario, where the metric exhibits a strong weekly seasonal pattern.\n\n\n\nThe next figure shows how the algorithms react to an hour-long anomaly. Robust completely ignores this anomaly. All the other algorithms start to behave as if the anomaly is the new normal. Agile and adaptive even identify the metric’s return to its original level as an anomaly.\n\n\n\nThe algorithms also deal with scale differently. Basic and Robust are scale-insensitive, while Agile and Adaptive are not. In the graphs on the left-hand side we see both Agile and Robust mark the level-shift as being anomalous. On the right-hand side we add 1000 to the same metric, and Agile no longer calls out the level-shift as being anomalous whereas robust continues do so.\n\n\n\nFinally, we see how each of the algorithms handle a new metric. Robust and agile won’t show any bounds during the first few weeks. Basic and adaptive will start showing bounds shortly after the metric first appears. Adaptive will leverage the metric’s daily seasonal patterns in its predictions, while basic simply reflects the range of recent values.\n\n\n\n\nFrequently Asked Questions\n\n\nShould I use anomaly detection for everything?\n\nNo. Anomaly detection is designed to assist with visualizing and monitoring metrics that have predictable patterns. For example, my_site.page_views{*} might be driven by user traffic and thus vary predictably by time of day and day of week. If your metric does not have any sort of repeated/predictable pattern, then a simple chart overlay or threshold alert might be better than anomaly detection.\n\nAlso, anomaly detection requires historical data to make good predictions. If you have only been collecting a metric for a few hours or a few days, anomaly detection probably won’t be very useful.\n\nTake care when creating multi-alerts. A metric such as service.requests_served{*} could be a good candidate for anomaly detection, but service.requests_served{*} by {host}is probably not. If your hosts are load-balanced, then an outlier monitor will be better for detecting hosts that are behaving abnormally. If your service scales up, each new host won’t be monitored at all until there is a minimum amount of history for anomaly detection to kick in, and even then alerts might be noisy due to instability in the number of requests handled by those hosts.\n\n\nWhy can’t I use anomaly detection over groups in the dashboard?\n\nLooking at many separate timeseries in a single graph can lead to spaghettification, and the problem gets only worse once the anomaly detection visualization is added in.\n\n\n\nYou can, however, add multiple series in a single graph one at a time. The gray envelope will only show up on mouseover.\n\n\n\n\nWill past anomalies affect the current predictions?\n\nAll the algorithms outside of Basic use extensive amounts of historical data so that they are robust to most anomalies. In the first graph, note how the envelope stays around 400K even after the metric has dropped to 0, and how it continues to do so throughout the day.\n\n\n\nThe second graph shows the same metric, a day later. Even though it uses the previous day in the calculation of the envelope, it is unaffected by the anomaly that occurred then.\n\n\n\n\nHow should I set the window size and alert threshold?\n\nSmaller window sizes will lead to faster alerts, however, with very small windows (<= 10 minutes), metrics often appear noisy, making it difficult to visualize the difference between anomalies and noise.\n\nNote that setting the window size to X minutes doesn’t require an anomaly to last X minutes before an alert is triggered. You can tune the threshold to control how long an anomaly must last to trigger an alert. For example, with the window size set to 30 minutes, you can get alerted when an anomaly lasts for just five minutes by setting the threshold to 5/30 = 17%. That said, we have found that anomaly alerts are most reliable when the window size is between 15 minutes and an hour and the threshold is on the higher side (> 40%).\n\n\nWhy does anomalies not add a gray prediction band in the dashboard? / Why am I getting “No Data” for an Anomaly Alert? / How much history do the algorithms require?\n\nAll the algorithms besides Basic require historical data before they can start making predictions. If your metric has only started reporting data for a short while, then Agile and Robust won’t try to make any predictions until it has at least two weeks of history. Adaptive will start working after it has at least two hours worth of history.\n\n\nWhy does an anomaly “disappear” when I zoom in?\n\nAt different zoom levels, the same query can result in time series with very different characteristics. When looking at longer time periods, each point represents the aggregate of many more-granular points. Therefore, each of these aggregate points may hide noise observed in the more granular points. For example, charts that show one week often appear smoother (less noisy) than charts that show just 10 minutes.\n\nThe width of the gray band that is drawn by our anomaly detection algorithm is, in part, based on the noisiness of the time series in the plot. The band must be wide enough that ordinary noise is mostly inside the band and doesn’t appear as anomalous. Unfortunately, when the band is wide enough to include ordinary noise, it might also be wide enough to hide some anomalies, especially when viewing short time windows.\n\nHere’s a concrete example to illustrate. The app.requests metric is noisy but has a constant average value of 8. On one day, there is a 10-minute anomalous period, starting a 9:00, during which the metric has an average value of 10. The chart below shows this series in a graph with a one-day time window; each point in the graph summarizes 5 minutes.\n\n\n\nThe gray band here makes sense; it is wide enough to capture the noise in the time series. Yet, it is narrow enough that the anomaly at 9:00 stands out clearly. This next chart shows a zoomed-in view of a half-hour time window that includes the 10-minute anomaly; each point in the graph summarizes 10 seconds.\n\n\n\nAgain, the band seems to be reasonably sized, because the non-anomalous data from 8:50 - 9:00 and from 9:10 - 9:20 is inside the band. A band any narrower would start to highlight normal data as anomalous. Notice the band in this graph is ~8x wider than the one in the previous graph. The anomalous period from 9:00 - 9:10 looks a little different from the rest of the series, but it is not extreme enough to fall outside of the band.\n\nIn general, if an anomaly disappears when you zoom in, this doesn’t mean that it’s not an anomaly. It means that, while the individual points in the zoomed-in view are not anomalous in isolation, the fact that many slightly unusual points occur together is anomalous.\n\n\nIs it possible to capture anomalies that occur within the bounds?\n\nIf the reason anomalies are occurring within the bounds is that the volatility of a metric leads to wide bounds that mask true anomalies (as described in the FAQ above), you may be able apply functions to the series to reduce its volatility, leading to narrower bounds and better anomaly detection.\n\nFor example, many important metrics (e.g., successful.logins, checkouts.completed, etc.) represent the success of some user-driven action. It can be useful to monitor for anomalous drops in one of those metrics, as this may be an indication that something is preventing successful completion of these events and that the user experience is suffering.\n\nIt’s common that these metrics have points that are at or near zero, especially when viewing the metric over a short window of time. Unfortunately, this results in the bounds of the anomaly detection forecast include zero, making it impossible to detect anomalous drops in the metric. An example is shown below.\n\n\n\nHow can we work around this problem? One approach is to add a rollup() to force the use of a larger interval. rollup() takes as an argument the number of seconds that should be aggregated into a single point on the graph. For example, applying rollup(120) will lead to a series with one point every two minutes. With larger intervals, zeros become rare and can correctly be categorized as anomalies. Here’s the same series as above but with a 2-minute rollup applied.\n\n\n\nAnother option is to apply the ewma() function to take a moving average. Like with rollups, this function will smooth away intermittent zeros so that drops in the metric can correctly be identified as anomalies.\n\n\n","tags":"","loc":"/guides/anomalies/"},{"title":"Guide to using Autodiscovery with Docker","text":"\nDocker is being adopted rapidly and platforms like Docker Swarm, Kubernetes and Amazon’s ECS make running services easier and more resilient by managing orchestration and replication across hosts. But all of that makes monitoring more difficult. How can you monitor a service which is dynamically shifting from one host to another?\n\nDatadog automatically keeps track of what is running where, thanks to its Autodiscovery feature. Autodiscovery allows you to define configuration templates that will be applied automatically to monitor your containers.\n\n\nHow it works\n\nAs we consider the problem of monitoring Docker, one strategy is to move from a host-centric model to a service-oriented model. To do this, we’ll run the Datadog Agent as a containerized service, rather than using Datadog Agents installed across all of our hosts.\n\nThe Autodiscovery feature watches for Docker events like when a container is created, destroyed, started or stopped. When one of these happens, the Agent identifies which service is impacted, loads the configuration template for this image, and automatically sets up its checks.\n\nConfiguration templates can be defined by simple template files or as single key-value stores using etcd or Consul.\n\n\nHow to set it up\n\nTo use Autodiscovery, you’ll first need to run the Datadog Agent as a service.\n\nIn Docker Swarm, you can do this by running the following command on one of your manager nodes (using your API key):\n\ndocker service create \\\n  --name dd-agent \\\n  --mode global \\\n  --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock \\\n  --mount type=bind,source=/proc/,target=/host/proc/,ro=true \\\n  --mount type=bind,source=/sys/fs/cgroup/,target=/host/sys/fs/cgroup,ro=true \\\n  -e API_KEY=<YOUR API KEY> \\\n  -e SD_BACKEND=docker \\\n  datadog/docker-dd-agent:latest\n\n\nFor Kubernetes, you can follow our Kubernetes Integration to create a DaemonSet. We also have Amazon ECS integration instructions available.\n\nBy default, the Datadog Agent includes Autodiscovery support for:\n\n\n  Apache Web Server\n  Consul\n  CouchDB\n  Couchbase\n  Elasticsearch\n  etcd\n  Kube State Metrics\n  Kyoto Tycoon\n  Memcached\n  Redis\n  Riak\n\n\nThese are provided by the configuration templates in the Datadog Agent conf.d/auto_conf directory.\n\nTo add Autodiscovery for your custom container images, you simply need to add a configuration template to the conf.d/auto_conf directory.\n\n\nConfiguration templates\n\nThe configuration templates in conf.d/auto_conf directory are nearly identical to the example YAML configuration files provided in the Datadog conf.d directory, but with one important field added. The docker_images field is required and identifies the container image(s) to which the configuration template should be applied.\n\n\nTemplate variables\n\nBecause orchestration tools like Docker Swarm and Kubernetes automatically run your containers on arbitrary hosts, the host address and port where your service reports metrics will be dynamic. To account for this in your configuration template, you can use the variables %%host%% and %%port%%.\n\nWhen a list of values is expected for the variable and selecting a specific one is mandatory, you can specify the value from the list by appending an underscore followed by an index or key. For example %%host_0%% or %%port_4%%. Note that indexes begin at 0 and if no index is provided, the last value in the value list ordered increasingly will be used.\n\nLet’s take the example of the port variable: a RabbitMQ container with the management module enabled has 6 exposed ports by default. The list of ports as seen by the agent is: [4369, 5671, 5672, 15671, 15672, 25672]. Notice the order. The Agent always sorts values in ascending order.\n\nThe default management port for the rabbitmq image is 15672 with index 4 in the list (starting from 0), so the template variable needs to be %%port_4%%.\n\nAs of version 5.8.3 of the Datadog Agent, you can also use keys as a suffix when a variable contains a dictionary. This is particularly useful to select an IP address for a container that has several networks attached.\n\nAs an example if the rabbitmq container mentioned above is available over two networks bridge and swarm, using %%host_swarm%% will pick the IP address from the swarm network.\nNote that for the host variable if several networks are found and no key is passed the agent attempts to use the default bridge network.\n\n\nConfiguration templates with key-value stores\n\nUsing Autodiscovery with the configuration templates in the Datadog Agent  conf.d/auto_conf directory is a straightforward process, though managing your templates and copying them into the Datadog Agent container (or building your own Datadog Agent container to include custom configuration templates) can make scaling this process difficult.\n\nTo make configuration template management easier, you can use etcd or Consul, two popular distributed key-value stores, as a repository for your templates.\n\nFirst you’ll need to configure etcd or Consul as your Autoiscovery backend by either updating the datadog.conf file or passing the settings as environment variables when starting the Datadog Agent service.\n\n\nConfiguring etcd or Consul in datadog.conf\n\n\nIn the datadog.conf file, you can enable etcd or Consul as a configuration backend by uncommenting and configuring the sd_config_backend, sd_backend_host, and sd_backend_port settings. If you are using Consul, you will also need to uncomment and set the consul_token.\n\n# For now only Docker is supported so you just need to un-comment this line.\nservice_discovery_backend: docker\n\n# Define which key/value store must be used to look for configuration templates.\n# Default is etcd. Consul is also supported.\nsd_config_backend: etcd\n\n# Settings for connecting to the backend. These are the default, edit them if you run a different config.\nsd_backend_host: 127.0.0.1\nsd_backend_port: 4001\n\n# By default, the agent will look for the configuration templates under the\n# `/datadog/check_configs` key in the back-end.\n# If you wish otherwise, uncomment this option and modify its value.\n# sd_template_dir: /datadog/check_configs\n\n# If you Consul store requires token authentication for service discovery, you can define that token here.\n# consul_token: f45cbd0b-5022-samp-le00-4eaa7c1f40f1\n\n\n\nConfiguring etcd or Consul using environment variables\n\nTo pass the settings listed above as environment variables when starting the Datadog Agent in Docker Swarm, you would run the command:\n\ndocker service create \\\n  --name dd-agent \\\n  --mode global \\\n  --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock \\\n  --mount type=bind,source=/proc/,target=/host/proc/,ro=true \\\n  --mount type=bind,source=/sys/fs/cgroup/,target=/host/sys/fs/cgroup,ro=true \\\n  -e API_KEY=<YOUR API KEY> \\\n  -e SD_BACKEND=docker \\\n  -e SD_CONFIG_BACKEND=etcd \\\n  -e SD_BACKEND_HOST=127.0.0.1 \\\n  -e SD_BACKEND_PORT=4001 \\\n  datadog/docker-dd-agent:latest\n\n\n\nTemplate structure in key-value stores\n\nAfter your Datadog Agent service has been configured to use your Autodiscovery configuration backend, you will need to store your configuration templates in the structure:\n\n/datadog/\n  check_configs/\n    docker_image_0/\n      - check_names: [\"check_name_0\"]\n      - init_configs: [{init_config}]\n      - instances: [{instance_config}]\n    docker_image_1/\n      - check_names: [\"check_name_1a\", \"check_name_1b\"]\n      - init_configs: [{init_config_1a}, {init_config_1b}]\n      - instances: [{instance_config_1a}, {instance_config_1b}]\n    ...\n\n\nNote that in the structure above, you may have multiple checks for a single container. For example you may run a Java service that provides an HTTP API, using the HTTP check and the JMX integration at the same time. To declare that in templates, simply add elements to the check_names, init_configs, and instances lists. These elements will be matched together based on their index in their respective lists.\n\n\nExample: Apache Web Server\n\nBy default, the Datadog Agent supports Autodiscovery for the Apache Web Server through the conf.d/auto_conf/apache.yaml file:\n\ndocker_images:\n  - httpd\n\ninit_config:\n\ninstances:\n  - apache_status_url: http://%%host%%/server-status?auto\n\n\nTo store the same configuration template in etcd you could run the following commands:\n\netcdctl mkdir /datadog/check_configs/httpd\netcdctl set /datadog/check_configs/httpd/check_names '[\"apache\"]'\netcdctl set /datadog/check_configs/httpd/init_configs '[{}]'\netcdctl set /datadog/check_configs/httpd/instances '[{\"apache_status_url\": \"http://%%host%%/server-status?auto\"}]'\n\n\n\nImage name format in the configuration store\n\nBefore version 5.8.3 of the Datadog Agent it was required to truncate the image name to its minimum. e.g. for the Docker image quay.io/coreos/etcd:latest the key in the configuration store needed to be datadog/check_configs/etcd/...\n\nTo make configuration more precise we now use the complete container image identifier in the key. So the agent will look in datadog/check_configs/quay.io/coreos/etcd:latest/..., and fallback to the old format if no template was found to ensure backward compatibility.\n\n\nUsing Docker label to specify the template path\n\nIn case you need to match different templates with containers running the same image, it is also possible starting with 5.8.3 to define explicitly which path the agent should look for in the configuration store to find a template using the com.datadoghq.sd.check.id label.\n\nFor example, if a container has this label configured as com.datadoghq.sd.check.id: foobar, it will look for a configuration template in the store under the key datadog/check_configs/foobar/....\n\n\nConfiguration templates with Kubernetes annotations\n\nAs of version 5.12 of the Datadog Agent, you can use Kubernetes pod annotations to store your configuration templates. Follow the Kubernetes integration instructions, then add annotations to your pod definitions. The basic format looks similar to the structure used in the key-value store configuration above, but for Kubernetes it takes the form:\n\nannotations:\n  service-discovery.datadoghq.com/<Kubernetes Container Name>.check_names: '[\"check_name_0\"]'\n  service-discovery.datadoghq.com/<Kubernetes Container Name>.init_configs: '[{init_config}]'\n  service-discovery.datadoghq.com/<Kubernetes Container Name>.instances: '[{instance_config}]'\n\n\nAlso similar to the key-value store configuration above, you include multiple checks for a container within in the pod. Each element from check_names, init_configs, and instances will be matched together based on their index. In pods with multiple containers, you can simply include additional annotations using the corresponding Kubernetes container name.\n\n\nExample: Apache Web Server\n\nHere’s an example of the Apache YAML file that would correspond to the configuration template conf.d/auto_conf/apache.yaml file:\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: apache\n  annotations:\n    service-discovery.datadoghq.com/apache.check_names: '[\"apache\"]'\n    service-discovery.datadoghq.com/apache.init_configs: '[{}]'\n    service-discovery.datadoghq.com/apache.instances: '[{\"apache_status_url\": \"http://%%host%%/server-status?auto\"}]'\n  labels:\n    name: apache\nspec:\n  containers:\n    - name: apache\n      image: httpd\n      ports:\n        - containerPort: 80\n\n","tags":"","loc":"/guides/autodiscovery/"},{"title":"Deploying the Datadog Agent to Azure","text":"\nThis guide assumes you are deploying an Azure Cloud Service.\n\n\nInstall the Agent on instance startup\n\nCreate a file called installDatadogAgent.cmd with the following contents:\n\nset log=datadog-install.log\nset api_key=%1\n\nsc query | findstr DatadogAgent\nif ERRORLEVEL 1 (\n    echo \"Datadog Agent service not detected\" >> %log%\n    echo \"Starting the installation\" >> %log%\n\n    if exist ddagent.msi (\n        echo \"Already has the installer\" >> %log%\n    ) else (\n        echo \"Fetching the Agent Installer\" >> %log%\n        powershell -Command \"(New-Object System.Net.WebClient).DownloadFile('https://s3.amazonaws.com/ddagent-windows-stable/ddagent-cli.msi', 'ddagent.msi')\"\n    )\n\n    echo \"Starting the installer\" >>%log%\n    msiexec.exe /qn /i ddagent.msi APIKEY=%api_key% /L+ %log%\n) else (\n    echo \"Agent already exists, skipping install\" >>%log%\n)\n\necho \"Finished Install\" >>%log%\nexit 0\n\n\nIf you are using Visual Studio, make sure that the file is included in the package: Set the Copy to Output Directory property of the file to Copy Always and make sure that the Build Action is Content .\n\nAdd the installation task to your ServiceDefinition.csdef file by adding the following in the <Startup> section:\n\n<Task commandLine=\"installDatadogAgent.cmd YOUR_API_KEY\" executionContext=\"elevated\" />\n\n\nBe sure to replace YOUR_API_KEY with your API key found at here.\n\nThe created file will download and install the latest version of the Agent on application deploy.\n\n\nDeploy your app\n\nYou should now repackage your app’s cloud service package file (*.cspkg), making sure to include the installDatadogAgent.cmd file in the package.\nYou can also directly upload from Visual Studio using the Publish button.\n\nOn deploy you should see your new hosts appear on your infrastructure overview:\n\n\n\n","tags":"","loc":"/guides/azure/"},{"title":"Basic Agent Usage for Amazon Linux","text":"\n\nOverview\n\nThis guide will outline the basic functionality of the Datadog Agent.\nIf you haven’t installed the Agent yet, instructions can be found \nhere.\n\nThe process to upgrade from the previous version of the agent is to simply re-run the installation. \n\n\n\n\nStarting and Stopping the Agent\n\nTo manually start the Agent:\n\nsudo /etc/init.d/datadog-agent start\n\n\nTo stop the Agent:\n\nsudo /etc/init.d/datadog-agent stop\n\n\nTo restart the Agent and to reload the configuration files:\n\nsudo /etc/init.d/datadog-agent restart\n\n\n\n\n\nStatus and Information\n\nTo check if the Agent is running: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent status\n\n\nTo receive information about the Agent’s state:\n\nsudo /etc/init.d/datadog-agent info\n\n\nTracebacks for errors can be retrieved by setting the -v flag: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent info -v\n\n\nMore information about the metrics, events and service checks for an integration can be retrieved with the check command:\n\nsudo /etc/init.d/datadog-agent check [integration]\n\n\nAdd the check_rate argument to get the most recent values for rates:\n\nsudo /etc/init.d/datadog-agent check [integration] check_rate\n\n\nsudo \n  /etc/init.d/datadog-agent check [integration]\n\n\n\n\nConfiguration\n\nThe configuration file for the Agent is located at /etc/dd-agent/datadog.conf\n\nConfiguration files for integrations are located in /etc/dd-agent/conf.d/\n\n\n\n\nTroubleshooting\n\nTry running the info command to see the state of the Agent.\n\nLogs for the subsystems are in the following files:\n\n\n  \n/var/log/supervisor/datadog-supervisord.log (since 3.8.0)\n\n  /var/log/datadog/collector.log\n  /var/log/datadog/dogstatsd.log\n  /var/log/datadog/forwarder.log\n\n\n\n\n\n\nIf you’re still having trouble, our support team will be glad to provide further assistance.\nYou can contact them in one of the following ways:\n\n\nVisit the Knowledge Base\nLearn more about what you can do in Datadog on the Support Knowledge Base.\n\n\nWeb Support\nMessages in the event stream containing\n@support-datadog will reach our Support Team. This is a convenient channel for referencing graph snapshots or a particular event. In addition, we have a livechat service available during the day (EST) from any page within the app.\n\n\nBy Email\nYou can also contact our Support Team via email at support@datadoghq.com.\n\n\nOver Slack\nReach out to our team and other Datadog users on Slack.\n\n\nStatus Page\nOur Status Page and Ops twitter account have the latest on any performance issues that we are experiencing.\n\n","tags":"","loc":"/guides/basic_agent_usage/amazonlinux/"},{"title":"Basic Agent Usage for CentOS","text":"\n\nOverview\n\nThis guide will outline the basic functionality of the Datadog Agent.\nIf you haven’t installed the Agent yet, instructions can be found \nhere.\n\nThe process to upgrade from the previous version of the agent is to simply re-run the installation. \n\n\n\n\nStarting and Stopping the Agent\n\nTo manually start the Agent:\n\nsudo /etc/init.d/datadog-agent start\n\n\nTo stop the Agent:\n\nsudo /etc/init.d/datadog-agent stop\n\n\nTo restart the Agent and to reload the configuration files:\n\nsudo /etc/init.d/datadog-agent restart\n\n\n\n\n\nStatus and Information\n\nTo check if the Agent is running: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent status\n\n\nTo receive information about the Agent’s state:\n\nsudo /etc/init.d/datadog-agent info\n\n\nTracebacks for errors can be retrieved by setting the -v flag: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent info -v\n\n\nMore information about the metrics, events and service checks for an integration can be retrieved with the check command:\n\nsudo /etc/init.d/datadog-agent check [integration]\n\n\nAdd the check_rate argument to get the most recent values for rates:\n\nsudo /etc/init.d/datadog-agent check [integration] check_rate\n\n\nsudo \n  /etc/init.d/datadog-agent check [integration]\n\n\n\n\nConfiguration\n\nThe configuration file for the Agent is located at /etc/dd-agent/datadog.conf\n\nConfiguration files for integrations are located in /etc/dd-agent/conf.d/\n\n\n\n\nTroubleshooting\n\nTry running the info command to see the state of the Agent.\n\nLogs for the subsystems are in the following files:\n\n\n  \n/var/log/supervisor/datadog-supervisord.log (since 3.8.0)\n\n  /var/log/datadog/collector.log\n  /var/log/datadog/dogstatsd.log\n  /var/log/datadog/forwarder.log\n\n\n\n\n\n\nIf you’re still having trouble, our support team will be glad to provide further assistance.\nYou can contact them in one of the following ways:\n\n\nVisit the Knowledge Base\nLearn more about what you can do in Datadog on the Support Knowledge Base.\n\n\nWeb Support\nMessages in the event stream containing\n@support-datadog will reach our Support Team. This is a convenient channel for referencing graph snapshots or a particular event. In addition, we have a livechat service available during the day (EST) from any page within the app.\n\n\nBy Email\nYou can also contact our Support Team via email at support@datadoghq.com.\n\n\nOver Slack\nReach out to our team and other Datadog users on Slack.\n\n\nStatus Page\nOur Status Page and Ops twitter account have the latest on any performance issues that we are experiencing.\n\n","tags":"","loc":"/guides/basic_agent_usage/centos/"},{"title":"Basic Agent Usage for Debian","text":"\n\nOverview\n\nThis guide will outline the basic functionality of the Datadog Agent.\nIf you haven’t installed the Agent yet, instructions can be found here. \n\nThe process to upgrade from the previous version of the agent is to simply re-run the installation. \n\n\n\n\nStarting and Stopping the Agent\n\nTo manually start the Agent:\n\nsudo /etc/init.d/datadog-agent start\n\n\nTo stop the Agent:\n\nsudo /etc/init.d/datadog-agent stop\n\n\nTo restart the Agent and to reload the configuration files:\n\nsudo /etc/init.d/datadog-agent restart\n\n\n\n\n\nStatus and Information\n\nTo check if the Agent is running: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent status\n\n\nTo receive information about the Agent’s state:\n\nsudo /etc/init.d/datadog-agent info\n\n\nTracebacks for errors can be retrieved by setting the -v flag: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent info -v\n\n\nMore information about the metrics, events and service checks for an integration can be retrieved with the check command:\n\nsudo /etc/init.d/datadog-agent check [integration]\n\n\nAdd the check_rate argument to get the most recent values for rates:\n\nsudo /etc/init.d/datadog-agent check [integration] check_rate\n\n\nsudo \n  /etc/init.d/datadog-agent check [integration]\n\n\n\n\nConfiguration\n\nThe configuration file for the Agent is located at /etc/dd-agent/datadog.conf\n\nConfiguration files for integrations are located in /etc/dd-agent/conf.d/\n\n\n\n\nTroubleshooting\n\nTry running the info command to see the state of the Agent.\n\nLogs for the subsystems are in the following files:\n\n\n  \n/var/log/datadog/supervisord.log (since 3.8.0)\n\n  /var/log/datadog/collector.log\n  /var/log/datadog/dogstatsd.log\n  /var/log/datadog/forwarder.log\n\n\n\n\nIf you’re still having trouble, our support team will be glad to provide further assistance.\nYou can contact them in one of the following ways:\n\n\nVisit the Knowledge Base\nLearn more about what you can do in Datadog on the Support Knowledge Base.\n\n\nWeb Support\nMessages in the event stream containing\n@support-datadog will reach our Support Team. This is a convenient channel for referencing graph snapshots or a particular event. In addition, we have a livechat service available during the day (EST) from any page within the app.\n\n\nBy Email\nYou can also contact our Support Team via email at support@datadoghq.com.\n\n\nOver Slack\nReach out to our team and other Datadog users on Slack.\n\n\nStatus Page\nOur Status Page and Ops twitter account have the latest on any performance issues that we are experiencing.\n\n","tags":"","loc":"/guides/basic_agent_usage/deb/"},{"title":"Basic Agent Usage for CoreOS and Docker","text":"\nFor details on how to work with the agent on Docker and on CoreOS, see the Docker integration docs.\n\nIf you’re still having trouble, our support team will be glad to provide further assistance.\nYou can contact them in one of the following ways:\n\n\nVisit the Knowledge Base\nLearn more about what you can do in Datadog on the Support Knowledge Base.\n\n\nWeb Support\nMessages in the event stream containing\n@support-datadog will reach our Support Team. This is a convenient channel for referencing graph snapshots or a particular event. In addition, we have a livechat service available during the day (EST) from any page within the app.\n\n\nBy Email\nYou can also contact our Support Team via email at support@datadoghq.com.\n\n\nOver Slack\nReach out to our team and other Datadog users on Slack.\n\n\nStatus Page\nOur Status Page and Ops twitter account have the latest on any performance issues that we are experiencing.\n\n","tags":"","loc":"/guides/basic_agent_usage/docker/"},{"title":"Basic Agent Usage for Fedora","text":"\n\nOverview\n\nThis guide will outline the basic functionality of the Datadog Agent.\nIf you haven’t installed the Agent yet, instructions can be found \nhere.\n\nThe process to upgrade from the previous version of the agent is to simply re-run the installation. \n\n\n\n\nStarting and Stopping the Agent\n\nTo manually start the Agent:\n\nsudo /etc/init.d/datadog-agent start\n\n\nTo stop the Agent:\n\nsudo /etc/init.d/datadog-agent stop\n\n\nTo restart the Agent and to reload the configuration files:\n\nsudo /etc/init.d/datadog-agent restart\n\n\n\n\n\nStatus and Information\n\nTo check if the Agent is running: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent status\n\n\nTo receive information about the Agent’s state:\n\nsudo /etc/init.d/datadog-agent info\n\n\nTracebacks for errors can be retrieved by setting the -v flag: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent info -v\n\n\nMore information about the metrics, events and service checks for an integration can be retrieved with the check command:\n\nsudo /etc/init.d/datadog-agent check [integration]\n\n\nAdd the check_rate argument to get the most recent values for rates:\n\nsudo /etc/init.d/datadog-agent check [integration] check_rate\n\n\nsudo \n  /etc/init.d/datadog-agent check [integration]\n\n\n\n\nConfiguration\n\nThe configuration file for the Agent is located at /etc/dd-agent/datadog.conf\n\nConfiguration files for integrations are located in /etc/dd-agent/conf.d/\n\n\n\n\nTroubleshooting\n\nTry running the info command to see the state of the Agent.\n\nLogs for the subsystems are in the following files:\n\n\n  \n/var/log/supervisor/datadog-supervisord.log (since 3.8.0)\n\n  /var/log/datadog/collector.log\n  /var/log/datadog/dogstatsd.log\n  /var/log/datadog/forwarder.log\n\n\n\n\n\n\nIf you’re still having trouble, our support team will be glad to provide further assistance.\nYou can contact them in one of the following ways:\n\n\nVisit the Knowledge Base\nLearn more about what you can do in Datadog on the Support Knowledge Base.\n\n\nWeb Support\nMessages in the event stream containing\n@support-datadog will reach our Support Team. This is a convenient channel for referencing graph snapshots or a particular event. In addition, we have a livechat service available during the day (EST) from any page within the app.\n\n\nBy Email\nYou can also contact our Support Team via email at support@datadoghq.com.\n\n\nOver Slack\nReach out to our team and other Datadog users on Slack.\n\n\nStatus Page\nOur Status Page and Ops twitter account have the latest on any performance issues that we are experiencing.\n\n","tags":"","loc":"/guides/basic_agent_usage/fedora/"},{"title":"Getting Started with the Agent","text":"\n\nTo get started using the Agent, please select your platform on the sidebar to the left.\n\n\n\n\n\nWhat is the Agent?\n\nThe Datadog Agent is piece of software that runs on your hosts. Its job is to faithfully collect events and metrics and bring them to Datadog on\nyour behalf so that you can do something useful with your monitoring and performance data.\n\nThe source code for the Datadog Agent can be found here.\n\nFor information on running the Agent through a proxy please see here;\nfor which ranges to allow, please see here.\n\nThe Agent has three main parts: the collector, dogstatsd, and the forwarder.\n\nThe collector runs checks on the current machine for whatever integrations you have\nand it will capture system metrics like memory and CPU.\n\nDogstatsd is a statsd backend server you can send custom metrics to from an application.\n\nThe forwarder retrieves data from both dogstatsd and the collector and then queues\nit up to be sent to Datadog.\n\n\nThis is all controlled by one supervisor process. We keep this separate so you don’t have to have the\noverhead of each application if you don’t want to run all parts (though we generally recommend you do).\n\n\n\n\nAgent Troubleshooting\n\nIf you ended up at this page and have not yet installed the Datadog Agent, please go here for installation instructions.\nIf you just installed the Agent, it might take a few moments before you start seeing metrics appear.\nThe first place you can check for metrics is the Metrics Explorer.\n\n\nIf you think you might be experiencing issues, the first thing to do is run the info command and check the Agent logs.\nThe info command and the log locations are dependent on your OS, which you can select from the navigation to the left for further information.\n\n\n\nIssues getting the Agent installed\n\nIf you encountered an issue during the Agent installation that prevented any installation whatsoever from occurring, please reach out to support@datadoghq.com.\nPlease let us know your OS and version, as well as how you are installing the Agent (and which agent version).\nAlso, please include the errors you encountered along the way.\n\n\nIssues getting the Agent reporting\n\nIf you get the Agent installed but are not seeing any data in Datadog, you can troubleshoot in the following manner.\nFirst, run the info command. Select your OS in the nav column on the left of this page to see how to run this.\nDoes running the info command show any errors?\n\nIf not, you should also check the logs (location of the logs again depends on OS). Errors in the logs may also reveal the cause of any issues.\n\nIf not, please send both the full output of the info command and the logs as attachments to support@datadoghq.com.\n\n\nCheck your machine's time\nWe have also seen a few cases where machines have their clock set further in the future or the past, which can sometimes cause problems with metric submission.\nTo check for this, run:\n\ndate -u && curl -s -v https://app.datadoghq.com 2>&1 | grep Date\n\nThis will output the current system’s date, and then make a request to our endpoint and grab the date on our end.\nIf these are more than a few minutes apart, you may want to look at the time settings on your server.\n\n\n\nIssues getting integrations working\n\nDatadog has quite a few integrations which are set\nup through YAML files in the Agent.\n\nHere is a quick guide for troubleshooting getting integrations installed:\n\n\n  \n    Run the info command (find this based on your OS in the left column above).\n  \n  \n    Is the integration showing up in the info command?\n\n    \n      \nNo, it’s not.\n        \n          Check the configuration file, make sure it is in the right location and named correctly.\n          Check it in a YAML parser to make sure it has the correct syntax. Example files can be found here.\n          If you moved or changed the file, restart the Agent and then rerun the info command to see if it is now showing up.\n        \n      \n      \nYes, it’s there.\n        \n          Check the Metrics Explorer to see if system metrics are showing up from the host. For example, look for system.cpu.user from the host that is running the Agent and has that integration setup.\n          If there are still no metrics, check the logs for errors and please send them along, with the info command output, to support@datadoghq.com.\n        \n      \n    \n  \n\n","tags":"","loc":"/guides/basic_agent_usage/"},{"title":"Basic Agent Usage for OS X","text":"\n\nOverview\n\nThis guide will outline the basic functionality of the Datadog Agent.\nIf you haven’t installed the Agent yet, instructions can be found \nhere.\n\nBy default, your Agent will be installed in its own sandbox located at  '/opt/datadog-agent'.\nYou’re free to move this folder wherever you like.\nHowever, this guide will assume that the Agent is installed in its default location, so be sure to modify the\ninstructions accordingly if you decide to move it to another location.\n\n\n\n\nStarting and Stopping the Agent\n\nTo manually start the Agent:\n\n/usr/local/bin/datadog-agent start\n\n\nTo stop the Agent:\n\n/usr/local/bin/datadog-agent stop\n\n\nTo restart the Agent and to reload the configuration files:\n\n/usr/local/bin/datadog-agent restart\n\n\n\n\n\nStatus and Information\n\nTo check if the Agent is running: (since 3.8.0)\n\n/usr/local/bin/datadog-agent status\n\n\nTo receive information about the Agent’s state:\n\n/usr/local/bin/datadog-agent info\n\n\nTracebacks for errors can be retrieved by setting the -v flag: (since 3.8.0)\n\n/usr/local/bin/datadog-agent info -v\n\n\nMore information about the metrics, events and service checks for an integration can be retrieved with the check command:\n\n/usr/local/bin/datadog-agent check [integration]\n\n\nAdd the check_rate argument to get the most recent values for rates:\n\n/usr/local/bin/datadog-agent check [integration] check_rate\n\n\n/usr/local/bin/datadog-agent check [integration]\n\n\n\n\nConfiguration\n\nThe configuration file for the Agent is located at ~/.datadog-agent/datadog.conf\n\nConfiguration files for integrations are located in ~/.datadog-agent/conf.d/\n\n\n\n\nTroubleshooting\n\nTry running the info command to see the state of the Agent.\n\nLogs for the subsystems are in the following files:\n\n\n  \n/var/log/datadog/supervisord.log (since 3.8.0)\n\n  /var/log/datadog/collector.log\n  /var/log/datadog/dogstatsd.log\n  /var/log/datadog/forwarder.log\n\n\n\n\n\n\nIf you’re still having trouble, our support team will be glad to provide further assistance.\nYou can contact them in one of the following ways:\n\n\nVisit the Knowledge Base\nLearn more about what you can do in Datadog on the Support Knowledge Base.\n\n\nWeb Support\nMessages in the event stream containing\n@support-datadog will reach our Support Team. This is a convenient channel for referencing graph snapshots or a particular event. In addition, we have a livechat service available during the day (EST) from any page within the app.\n\n\nBy Email\nYou can also contact our Support Team via email at support@datadoghq.com.\n\n\nOver Slack\nReach out to our team and other Datadog users on Slack.\n\n\nStatus Page\nOur Status Page and Ops twitter account have the latest on any performance issues that we are experiencing.\n\n","tags":"","loc":"/guides/basic_agent_usage/osx/"},{"title":"Basic Agent Usage for Red Hat","text":"\n\nOverview\n\nThis guide will outline the basic functionality of the Datadog Agent.\nIf you haven’t installed the Agent yet, instructions can be found \nhere.\n\nThe process to upgrade from the previous version of the agent is to simply re-run the installation. \n\n\n\n\nStarting and Stopping the Agent\n\nTo manually start the Agent:\n\nsudo /etc/init.d/datadog-agent start\n\n\nTo stop the Agent:\n\nsudo /etc/init.d/datadog-agent stop\n\n\nTo restart the Agent and to reload the configuration files:\n\nsudo /etc/init.d/datadog-agent restart\n\n\n\n\n\nStatus and Information\n\nTo check if the Agent is running: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent status\n\n\nTo receive information about the Agent’s state:\n\nsudo /etc/init.d/datadog-agent info\n\n\nTracebacks for errors can be retrieved by setting the -v flag: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent info -v\n\n\nMore information about the metrics, events and service checks for an integration can be retrieved with the check command:\n\nsudo /etc/init.d/datadog-agent check [integration]\n\n\nAdd the check_rate argument to get the most recent values for rates:\n\nsudo /etc/init.d/datadog-agent check [integration] check_rate\n\n\nsudo \n  /etc/init.d/datadog-agent check [integration]\n\n\n\n\nConfiguration\n\nThe configuration file for the Agent is located at /etc/dd-agent/datadog.conf\n\nConfiguration files for integrations are located in /etc/dd-agent/conf.d/\n\n\n\n\nTroubleshooting\n\nTry running the info command to see the state of the Agent.\n\nLogs for the subsystems are in the following files:\n\n\n  \n/var/log/supervisor/datadog-supervisord.log (since 3.8.0)\n\n  /var/log/datadog/collector.log\n  /var/log/datadog/dogstatsd.log\n  /var/log/datadog/forwarder.log\n\n\n\n\n\n\nIf you’re still having trouble, our support team will be glad to provide further assistance.\nYou can contact them in one of the following ways:\n\n\nVisit the Knowledge Base\nLearn more about what you can do in Datadog on the Support Knowledge Base.\n\n\nWeb Support\nMessages in the event stream containing\n@support-datadog will reach our Support Team. This is a convenient channel for referencing graph snapshots or a particular event. In addition, we have a livechat service available during the day (EST) from any page within the app.\n\n\nBy Email\nYou can also contact our Support Team via email at support@datadoghq.com.\n\n\nOver Slack\nReach out to our team and other Datadog users on Slack.\n\n\nStatus Page\nOur Status Page and Ops twitter account have the latest on any performance issues that we are experiencing.\n\n","tags":"","loc":"/guides/basic_agent_usage/redhat/"},{"title":"Basic Agent Usage for Source Installation","text":"\n\nOverview\n\nThis guide will outline the basic functionality of the Datadog Agent.\nIf you haven't installed the Agent yet, instructions can be found\nhere.\n\nBy default, your Agent will be installed in its own sandbox at  '~/.datadog-agent'.\nYou're free to move this folder wherever you like.\nHowever, this guide will assume that the Agent is installed in its default location, so be sure to modify the\ninstructions accordingly if you decide to move them.\n\n\n\n\n\nStarting and Stopping the Agent\n\nTo manually start the Agent:\n\nsudo ~/.datadog-agent/bin/agent start\n\nTo stop the Agent: \n\nsudo ~/.datadog-agent/bin/agent stop\n\nTo restart the Agent: \n\nsudo ~/.datadog-agent/bin/agent restart\n\n\n\n\nStatus and Information\n\nTo check if the Agent is running:\n\nsudo ~/.datadog-agent/bin/agent status\n\nTo receive more information about the Agent's state:\n\nsudo ~/.datadog-agent/bin/info\n\nTracebacks for errors can be retrieved by setting the -v flag: (since 3.8.0)\n\nsudo ~/.datadog-agent/bin/info -v\n\n\n\n\nConfiguration\n\nThe configuration file for the Agent is located at ~/.datadog-agent/agent/datadog.conf\n\nConfiguration files for integrations are located in ~/.datadog-agent/agent/conf.d/\n\n\n\n\nTroubleshooting\n\nFirst, make sure you are using the correct version of Python. The Agent requires version 2.7. You can check your version by executing:\n\npython -c 'import sys; print sys.version'\n\nNext, try running the info command to see the state of the Agent.\n\nLogs for the subsystems are in the following files:\n\n\n  ~/.datadog-agent/supervisord/logs/supervisord.log\n  ~/.datadog-agent/supervisord/logs/collector.log\n  ~/.datadog-agent/supervisord/logs/dogstatsd.log\n  ~/.datadog-agent/supervisord/logs/forwarder.log\n\n\n\n\nIf you're still having trouble, our support team will be glad to provide further assistance.\nYou can contact them in one of the following ways:\n\n\n\n\n\nVisit the Knowledge Base\nLearn more about what you can do in Datadog on the Support Knowledge Base.\n\n\nWeb Support\nMessages in the event stream containing\n@support-datadog will reach our Support Team. This is a convenient channel for referencing graph snapshots or a particular event. In addition, we have a livechat service available during the day (EST) from any page within the app.\n\n\nBy Email\nYou can also contact our Support Team via email at support@datadoghq.com.\n\n\nOver Slack\nReach out to our team and other Datadog users on Slack.\n\n\nStatus Page\nOur Status Page and Ops twitter account have the latest on any performance issues that we are experiencing.\n\n\n\n","tags":"","loc":"/guides/basic_agent_usage/source/"},{"title":"Basic Agent Usage for Ubuntu","text":"\n\nOverview\n\nThis guide will outline the basic functionality of the Datadog Agent.\nIf you haven’t installed the Agent yet, instructions can be found here. \n\nThe process to upgrade from the previous version of the agent is to simply re-run the installation. \n\n\n\n\nStarting and Stopping the Agent\n\nTo manually start the Agent:\n\nsudo /etc/init.d/datadog-agent start\n\n\nTo stop the Agent:\n\nsudo /etc/init.d/datadog-agent stop\n\n\nTo restart the Agent and to reload the configuration files:\n\nsudo /etc/init.d/datadog-agent restart\n\n\n\n\n\nStatus and Information\n\nTo check if the Agent is running: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent status\n\n\nTo receive information about the Agent’s state:\n\nsudo /etc/init.d/datadog-agent info\n\n\nTracebacks for errors can be retrieved by setting the -v flag: (since 3.8.0)\n\nsudo /etc/init.d/datadog-agent info -v\n\n\nMore information about the metrics, events and service checks for an integration can be retrieved with the check command:\n\nsudo /etc/init.d/datadog-agent check [integration]\n\n\nAdd the check_rate argument to get the most recent values for rates:\n\nsudo /etc/init.d/datadog-agent check [integration] check_rate\n\n\nsudo \n  /etc/init.d/datadog-agent check [integration]\n\n\n\n\nConfiguration\n\nThe configuration file for the Agent is located at /etc/dd-agent/datadog.conf\n\nConfiguration files for integrations are located in /etc/dd-agent/conf.d/\n\n\n\n\nTroubleshooting\n\nTry running the info command to see the state of the Agent.\n\nLogs for the subsystems are in the following files:\n\n\n  \n/var/log/datadog/supervisord.log (since 3.8.0)\n\n  /var/log/datadog/collector.log\n  /var/log/datadog/dogstatsd.log\n  /var/log/datadog/forwarder.log\n\n\n\n\nIf you’re still having trouble, our support team will be glad to provide further assistance.\nYou can contact them in one of the following ways:\n\n\nVisit the Knowledge Base\nLearn more about what you can do in Datadog on the Support Knowledge Base.\n\n\nWeb Support\nMessages in the event stream containing\n@support-datadog will reach our Support Team. This is a convenient channel for referencing graph snapshots or a particular event. In addition, we have a livechat service available during the day (EST) from any page within the app.\n\n\nBy Email\nYou can also contact our Support Team via email at support@datadoghq.com.\n\n\nOver Slack\nReach out to our team and other Datadog users on Slack.\n\n\nStatus Page\nOur Status Page and Ops twitter account have the latest on any performance issues that we are experiencing.\n\n","tags":"","loc":"/guides/basic_agent_usage/ubuntu/"},{"title":"Basic Agent Usage for Windows","text":"\n\nOverview\n\nThis guide will outline the basic functionality of the Datadog Agent. If you haven’t installed the Agent yet, instructions can be found here.\n\n\nStarting and Stopping the Agent\nThe execution of the Agent is controlled by a Windows service.\n\n\nFor version >= 3.9.1\n\nYou can use the Datadog Agent Manager that you can find in the Start Menu.\n\n\n\n\n\nYou can also use Windows Powershell if you are running on a modern version of Windows: \n[start|stop|restart]-service datadogagent\n\n\nFor version < 3.9.1\n\nThe Agent can be started, stopped, and restarted from the Services panel. To view the Services panel, execute the following in a cmd.exe shell: services.msc. Once you’re in the console, find the “Datadog Agent” service. Right clicking on the service will reveal options to start, stop, and restart the Agent.\n\n\nStatus and Information\n\nTo check if the Agent is running, check if the service status in the Services panel is listed as “Started”. A process called “ddagent.exe” should also exist in the Task Manager. To receive more information about the Agent’s state, visit the status page by going to Settings -> Agent Status in Agent version 5.2 and above and by going to  http://localhost:17125/status in Agent version 3.9.1 to 5.1.\n\n\nConfiguration\n\n\nFor version >= 3.9.1\n\nYou can use the Datadog Agent Manager located in the start menu to enable, disable and configure checks. You have to restart the agent in order for your changes to be applied.\n\n\nFor version < 3.9.1\n\nThe configuration file location depends on the version of Windows on which the Agent is installed. For Windows Server 2003, XP or older:\n\n\n  Agent configuration:\nC:\\Documents and Settings\\All Users\\Application Data\\Datadog\\datadog.conf\n\n  Integration configuration:\nC:\\Documents and Settings\\All Users\\Application Data\\Datadog\\conf.d\\\n\n\n\nFor Windows Server 2008, Vista and newer:\n\n\n  Agent configuration:\nC:\\ProgramData\\Datadog\\datadog.conf\n\n  Integration configuration:\nC:\\ProgramData\\Datadog\\conf.d\\\n\n\n\n\nTroubleshooting\n\nFirst, check if the Agent is running in the Services panel and in the Task Manager. Next, try opening the status page to see the state of the Agent.\n\n\nFor version >= 3.9.1\n\nLog is available at:\n\n\n  For Windows Server 2003, XP or older:\nC:\\Documents and Settings\\All Users\\Application Data\\Datadog\\logs\\ddagent.log\n\n  For Windows Server 2008, Vista and newer:\nC:\\ProgramData\\datadog\\logs\\ddagent.log\n\n\n\n\nFor version < 3.9.1\n\nLogs for the subsystems are available in Event Viewer, under Windows Logs -> Application.  If you’re still having trouble, our support team will be glad to provide further assistance. \n\n","tags":"","loc":"/guides/basic_agent_usage/windows/"},{"title":"Billing FAQ","text":"\nWe occasionally receive questions regarding the specifics of our pricing; the basic plans and the most frequently seen questions can be found below.\n\n\nPlan Overview\n\nThere are three plans within Datadog:\n\n\n  \nFree is only for 5 hosts or less. Free has a single day of data retention. The\n good news is that switching from the Free plan to Pro will not affect your\n setup, so anything you’ve begun monitoring would not be affected by that status\n change.\n  \nPro is for 6-999 hosts and comes with 13 months of data retention.\n Pro includes metric alerts and email support.\n  \nEnterprise is for 1,000+ hosts or any number of hosts but needing custom adjustments to what is\n offered in the Pro plan. Enterprise includes phone support and pricing is based on three factors:\n    \n      Data retention requirements and number of custom metrics (base plan includes 13 months retention,\nand 100 custom metrics)\n      Size of your environment in servers\n      Payment terms (month to month or annual prepaid)\n    \n  \n\n\nCustom metrics are supported in every plan. A custom metric is any metric that is not automatically collected by any of Datadog’s integrations—for example custom checks or API-level metrics from your application. Each host may submit up to 100 custom metrics at no additional cost.\n\nDocker Containers are also supported in every plan. Each host may submit metrics from 10 containers an hour at no additional cost. Additional containers will be billed at $0.002 per container per hour. In addition, Enterprise customers can purchase prepaid containers at $1 per container per month.\n\nPro and Enterprise data retention is for 13 months at full resolution (maximum is one point per second). For greater data retention needs, please reach out to sales@datadoghq.com.\n\nEach invoice is determined by the high watermark of concurrently running hosts for that month.\n\nThis is per active host in Datadog, whether or not it’s running the agent.\n\n\nFrequently Asked Questions\n\nDo you support hourly pricing?\n\nYes. Our standard hourly rate for Datadog Pro is $0.03 per host per hour. You \ncan choose to pay for all of your monitored hosts hourly, or commit to a subset \nof hosts upfront on a monthly or annual plan and pay any additional hosts on an \nhourly basis, billed at the end of each month. This works out to be much less \nexpensive for extra hosts that may come up for a short period, but a bit more \nthan monthly/annual rates if you ran on an hourly rate all the time.\n\nDo non-reporting or inactive hosts count?\n\nNon-reporting hosts (status ‘???’) do not count towards billing. It might take\nsome time (up to 24 hours) for the hosts with the inactive status ‘???’ to drop\nout of the infrastructure view.\n\nA transient server that you monitored in Datadog for a short period of time\nwill clear out of the infrastructure view after 24 hours of not reporting any\ndata. We will still however retain the historical data (for a paid account),\nand you can graph it on a dashboard if you know the specific host by name (or\nby its tags).\n\nHow will an AWS integration impact my monthly billing?\n\nWe bill for all hosts running the Agent as well as for all EC2 instances\npicked up by the AWS integration. You will not get billed twice if\nyou are running the Agent on an EC2 instance picked up by the AWS\nintegration.\n\nOther AWS resources (e.g. ELB, EBS, RDS, Dynamo) are not currently\npart of monthly billing. Note that this may change in the future.\n\nIf you would like to control which AWS metrics you are collecting,\nselect ‘limit metric collection for all accounts’ in the \nAWS Integration tile and customize accordingly.\n\nHow will a VMware integration impact my monthly billing?\n\nThe base pricing is $15 per virtual machine per month. See above for more general information.\n\nHow do I see what I’ll get charged for this current month?\n\nThere is not currently a way to see what the upcoming bill looks like; as an\nadmin you can review past invoices here.\n\nCan I set a specific email address to receive invoices at?\n\nYou can set a specific email address to receive invoices here, even if that address\nis not a team member within Datadog (eg. invoices@yourcompany.com).\n\n","tags":"","loc":"/guides/billing/"},{"title":"Deploying the Agent with Chef","text":"\n\nOverview\n\nIn this guide, we will explore how to leverage Chef\nto automate installation of the Datadog Agent\n\nDeploying Datadog with Chef is meant to be very simple, and provide you with a method of getting the value of monitoring across all of your infrastructure as simply as possible.\n\nWe also provide a Chef Execution and Report Handler that can capture chef-client failures as well as metrics related to the Chef run, such as timing and resources updated.\n\n\n\n\nDeploying the Agent\n\nWe created a cookbook to assist with Agent deployment.\n\nInstall the latest released version of the Datadog Chef cookbook from the Community Site via knife, and upload to your Chef Server:\n\nknife cookbook site install datadog\nknife cookbook upload datadog\n\n\nYou may also be using another tool to manage your cookbook workflow, such as Berkshelf or Librarian Chef, in which case you will need to add a line like this to your Berksfile/Cheffile:\n\ncookbook 'datadog'\n\n\nAnd follow the instructions for your tool to upload the cookbook to your Chef Server.\n\nBefore adding the cookbook’s recipe to your node’s run_list, you need to add account-specific details to be provided to the Agent configuration file.\n\nThis is commonly done via role or environment files, or another cookbook declaring the attributes.\n\nHere is an example of a base.rb role file, typically applied to every host in an organization.\n\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nname 'base'\ndescription 'base role, runs on every node'\nrun_list(\n  'ntp',\n  'datadog::dd-agent',\n  'some_other_base_cookbook::recipe'\n)\ndefault_attributes(\n  'datadog' => {\n    'api_key' => \"PUT_YOUR_API_KEY_HERE\",\n    'application_key' => \"PUT_YOUR_APPLICATION_KEY_HERE\"\n  }\n)\n\n\nNote that there are two keys needed. Your API Key can be found in Datadog, under the Integrations => API menu item, or click this link to log in and go there directly.\n\nThen, on the same page, you must create an Application Key for use with Chef. You may name the key whatever you wish, we recommend something like ‘chef_appkey’ or something of that nature.\n\nProvide both values in the attributes as shown above.\n\nThen upload your role file to Chef Server like so:\n\nknife role from file roles/base.rb\n\n\nThe next time Chef runs, it should install the Agent and set the configuration file with the API and application keys.\n\nNOTE: If you are using another cookbook to define these attributes, use a higher attribute precedence level than default.\n\n\n\n\nDeploying the Handler\n\nIn order to further raise the visibility of your Chef runs, you may use the Datadog Chef Handler to monitor your Chef execution.\n\nThis has the added value of bringing the output of a Chef run back to Datadog’s Event stream, so failures can be highlighted quickly, discussed amongst the team, and resolved.\n\nSuccesses typically will be found in the “Low” priority, whereas failures are of “Normal” priority, and when the same node passes the Chef run, then it is put pack into “Low” priority.\n\nAdding the handler is very simple, as you can see in this role snippet:\n\n# Make sure you replace the API and/or APP key below\n# with the ones for your account\n\nname 'base'\ndescription 'base role, runs on every node'\nrun_list(\n  'datadog::dd-handler',\n  'ntp',\n  'datadog::dd-agent',\n  'some_other_base_cookbook::recipe'\n)\ndefault_attributes(\n  'datadog' => {\n    'api_key' => \"PUT_YOUR_API_KEY_HERE\",\n    'application_key' => \"PUT_YOUR_APPLICATION_KEY_HERE\"\n  }\n)\n\n\nAll we’ve done is add the datadog::dd-handler recipe to the beginning of the node’s run list. Adding it to the beginning allows the handler to capture details about everything in it observes after being invoked, so if you added it to the end of the run_list and something failed prior to it being executed, you may not receive the full output.\n\nOnce set, upload the role to your Chef Server, and wait. After Chef has run on a few hosts, a new automatic Dashboard will be created, with the relevant Chef Metrics. You can find it in your Dashboards List, on the right-hand side.\n\n\n\n\nCustomizations\n\nThe Datadog Chef Cookbook provides more integration-specific recipes.\n\nIncluding one of these recipes in your run list will install any monitoring dependencies, such as any Python modules that are required to monitor that service, as well as write out the correct configuration file.\n\nHere’s an example of how we’ve extended a webserver.rb role file to automatically monitor Apache via Datadog:\n\nname 'webserver'\ndescription 'Webserver role, runs apache'\nrun_list(\n  'apache2',\n  'datadog::apache',\n)\ndefault_attributes(\n  'apache' => {\n    'ext_status' => true,\n  }\n  'datadog' => {\n    'apache' => {\n      'instances' => [\n        { 'status_url' => 'http://localhost:8080/server-status/',\n          'tags' => ['extra_tag', 'env:example'] }\n      ]\n    }\n  }\n)\n\n\nAs you can see, we’ve added the datadog::apache recipe to the run list, and provided some attributes to control what instances of Apache should be monitored by Datadog.\n\nRead each recipe file for the exact details of the integration values to pass into the instances part of the attributes.\n","tags":"","loc":"/guides/chef/"},{"title":"Guide to Composite Monitors","text":"\nIf you’re unfamiliar with the basics of Datadog Monitors, first read the Guide to Monitors\n\n\n\nComposite monitors let you combine many individual monitors into one so that you can define more specific alert conditions. You can choose up to 10 existing monitors - monitor A and monitor B, say - and then set a trigger condition using boolean operators (e.g. “A && B”). The composite monitor will trigger when its individual monitors’ statuses simultaneously have values that cause the composite’s trigger condition to be true.\n\nWith regard to configuration, a composite monitor is independent of its constituent monitors. You can modify the notification policy of a composite monitor without affecting the policies of its constituent monitors, and vice versa. Furthermore, deleting a composite monitor will not delete its constituent monitors; a composite monitor does not own other monitors, it only uses their results. Also, many composite monitors may reference the same individual monitor.\n\nNote: this guide refers variously to ‘individual monitors’, ‘constituent monitors’, and ‘non-composite monitors’. They all mean the same thing: the monitors that a composite monitor uses to calculate its status.\n\n\nCreating composite monitors\n\nIn Datadog, go to the New Monitor page and select ‘Composite’ from the list of monitor types:\n\n\n\n\nChoose individual monitors\n\nChoose up to 10 individual monitors to use in the new composite monitor. You can mix and match monitors of different alert types; they can all be simple alerts, all multi-alerts, or a combination of the two. No individual monitor may itself be a composite monitor.\n\nAfter you choose your first monitor, the UI will show its alert type and current status:\n\n\n\nIf you choose a multi-alert monitor, the UI will show its group-by clause (e.g. host) and how many unique sources (i.e. how many hosts) are currently reporting. When you want to combine many multi-alert monitors, this information can help you choose monitors that pair naturally together: you should almost always choose monitors that have the same group-by. If you don’t, the UI will warn you that such a composite monitor may never trigger:\n\n\n\nEven if you choose multi-alert monitors with the same group-by, the UI may still warn you about the selection. In the following screenshot, both monitors are grouped by host:\n\n\n\nSince there’s still a ‘Group Matching Error’ despite matching group-bys, we can assume that these monitors currently have no reporting sources in common. As long as there are no common reporting sources, Datadog cannot compute a status for the composite monitor, and it will never trigger. However, you can ignore the warning and create the monitor anyway. To understand why, read more below.\n\nWhen you select a second monitor that doesn’t cause a warning, the UI will populate the ‘Trigger when’ field with the default trigger condition a && b and show the status of the proposed composite monitor:\n\n\n\n\nSet a trigger condition\n\nIn the ‘Trigger when’ field, write your desired trigger condition using boolean operators, referring to individual monitors by their labels in the form (a, b, c, etc). You can use parentheses to control operator precedence and create more complex conditions. \n\nThe following are all valid trigger conditions: \n\n!(a && b)\na || b && !c\n(a || b) && (c || d)\n\n\nOutside of a composite monitor’s New Monitor and Edit forms, its individual monitors are known by their numeric IDs:\n\n\n\nIn the API, a composite monitor’s trigger condition is called its query. While a non-composite monitor’s query can encapsulate many things — a metric, tags, an aggregation function like avg, a group-by clause, etc — a composite monitor’s query is simply its trigger condition defined in terms of its constituent monitors.\n\nFor two non-composite monitors with the following queries:\n\n\"avg(last_1m):avg:system.mem.free{role:database} < 2147483648\" # monitor ID: 1234\n\"avg(last_1m):avg:system.cpu.system{role:database} > 50\" # monitor ID: 5678\n\n\na composite monitor’s query is simply \"1234 && 5678\", \"!1234 || 5678\", etc.\n\n\nConfigure behavior for No Data\n\n\nAs with a non-composite monitor, you may configure whether or not a composite monitor triggers when it has the No Data status. Whatever you choose here will not affect the constituent monitors’ notify_no_data settings.\n\n\nWrite a notification message\n\nWrite a notification message as you would with any other monitor, using the @-syntax (e.g. @you@example.com) to notify individuals or teams:\n\n\n\nIn addition to your own message, delivered notifications (e.g. emails) for the composite monitor will show the status of the individual monitors:\n\n[Triggered] CPU + Memory composite monitor\n\nDatabase servers are high on CPU usage AND low on memory. @kent@datadoghq.com\n\nQuery: 1896131 && 1896130\n\n1 Alert | 4 OK\n\n* CPU monitor for database servers\n  ID: 1896131\n  5 host groups\n  1 Alert | 4 OK\n\n* Memory monitor for database servers\n  ID: 1896130\n  5 host groups\n  1 Alert | 4 OK\n\nThe monitor was last triggered at Mon Apr 17 2017 11:31:47 EDT (28 secs ago)\n\n\n\nSave the monitor\n\nAfter setting any other miscellaneous options, click ‘Save’. Remember: each option you select only affects the composite monitor, not its constituent monitors.\n\n\nHow composite monitors work\n\nThis section uses examples to show how we compute trigger conditions and how many alerts you may receive in different scenarios.\n\n\nHow we compute trigger conditions\n\nDatadog doesn’t compute A && B && C any differently than you would expect, but which monitor statuses are considered true and which false?\n\nRecall the seven statuses a monitor may have (in order of increasing severity): Ok, Skipped, Ignored, No Data, Unknown, Warn, and Alert. Composite monitors consider Unknown, Warn and Alert to be alert-worthy (i.e. true). The rest — Ok, Skipped, Ignored, and No Data — are not alert-worthy (i.e. false). However, you can configure No Data to be alert-worthy by setting notify_no_data to true.\n\nWhen a composite monitor evaluates as alert-worthy, it inherits the most severe status among its individual monitors and triggers an alert. When a composite monitor does not evaluate as alert-worthy, it inherits the least severe status. The not (!) function causes a result — individual or composite — to be either Alert or Ok: if monitor A has any alert-worthy status, !A is OK; if monitor A has any alert-unworthy status, !A is Alert.\n\nConsider a composite monitor that uses three individual monitors — A, B, and C — and a trigger condition A && B && C. The following table shows the resulting status of the composite monitor given different statuses for its individual monitors (alert-worthiness is indicated with T or F):\n\n\n  \n    \n      monitor A\n      monitor B\n      monitor C\n      composite status\n    \n  \n  \n    \n      Unknown (T)\n      Warn (T)\n      Unknown (T)\n      Warn (T) - triggered!\n    \n    \n      Skipped (F)\n      Ok (F)\n      Unknown (T)\n      Ok (F)\n    \n    \n      Alert (T)\n      Warn (T)\n      Unknown (T)\n      Alert (T) - triggered!\n    \n    \n      Skipped (F)\n      No Data (F)\n      Unknown (T)\n      Skipped (F)\n    \n  \n\n\nTwo of the four scenarios will trigger an alert, even though not all of the individual monitors have the most severe status, Alert (and in row 1, none do). But how many alerts might you potentially receive from the composite monitor? That depends on the individual monitors’ alert types.\n\n\nHow many alerts you will receive\n\nIf all individual monitors are simple alerts, the composite monitor will also have a simple alert type; the composite monitor will trigger a single alert when the queries for A, B, and C are all true at the same time.\n\nIf even one individual monitor is multi-alert, then the composite monitor is also multi-alert. How many alerts it may send at a time depends on whether the composite monitor uses one or uses many multi-alert monitors.\n\n\nOne multi-alert monitor\n\nConsider a scenario where monitor A is a multi-alert monitor grouped by host. If the monitor has four reporting sources — hosts web01 through web04 — you may receive up to four alerts each time Datadog evaluates the composite monitor. In other words: for a given evaluation cycle, Datadog has 4 cases to consider. For each case, monitor A’s status may vary across its sources, but the statuses of monitors B and C — which are simple alerts — are unchanging.\n\nThe previous table showed the composite monitor status across four points in time, but in this example, the table shows the status of each multi-alert case, all at one point in time:\n\n\n  \n    \n      source\n      monitor A\n      monitor B\n      monitor C\n      composite status (A && B && C)\n    \n  \n  \n    \n      web01\n      Alert\n      Warn\n      Alert\n      Alert - triggered!\n    \n    \n      web02\n      Ok\n      Warn\n      Alert\n      Ok\n    \n    \n      web03\n      Warn\n      Warn\n      Alert\n      Alert - triggered!\n    \n    \n      web04\n      Skipped\n      Warn\n      Alert\n      Skipped\n    \n  \n\n\nIn this cycle, you would receive two alerts.\n\n\nMany multi-alert monitors\n\nNow consider a scenario where monitor B is multi-alert, too, and is also grouped by host. The number of alerts per cycle will be, at most, the number of common reporting sources between monitors A and B. If web01 through web05 are reporting for monitor A, and web04 through web09 are reporting for monitor B, the composite monitor only considers the common sources: web04 and web05. You can only receive up to two alerts in an evaluation cycle. \n\nHere’s an example cycle:\n\n\n  \n    \n      source\n      monitor A\n      monitor B\n      monitor C\n      composite status (A && B && C)\n    \n  \n  \n    \n      web04\n      Unknown\n      Warn\n      Alert\n      Alert - triggered!\n    \n    \n      web05\n      Ok\n      Ok\n      Alert\n      Ok\n    \n  \n\n\nIn this cycle, you would receive one alert.\n\n\nHow composite monitors select common reporting sources\n\nAs explained above, composite monitors that use many multi-alert monitors only consider the individual monitors’ common reporting sources. In the example, the common sources were host:web04 and host:web05, but there’s a subtle caveat: in identifying common reporting sources, composite monitors only look at tag values (i.e. web04), not tag names (i.e. host). This technically makes it possible for a composite monitor to trigger on multi-alert monitors that group by different tags.\n\nIf the example above had included a multi-alert monitor ‘D’ grouped by environment, and that monitor had a single reporting source, environment:web04, then the composite monitor would consider web04 the single common reporting source between A, B, and D, and would compute its trigger condition.\n\nOften, two monitors grouped by different tags tend to have reporting sources whose tag values never overlap, e.g. web04 and web05 for monitor A, dev and prod for monitor D. But if and when they do overlap, a composite monitor that uses two such monitors becomes capable of triggering an alert.\n\nFurthermore, as with an individual multi-alert monitor, the number of common reporting sources for a composite monitor may change over time (e.g. when you provision or deprovision hosts). This is why it’s possible for composite monitors to use multi-alert monitors that group by the same tag, but which initially have no reporting sources in common; they might in the future.\n\nUse your best judgement to choose multi-alert monitors that makes sense together.\n","tags":"","loc":"/guides/composite_monitors/"},{"title":"Getting Started with DogStatsD","text":"\n\n  This tutorial will walk you through instrumenting your application to send\n  custom metrics to Datadog. If you need some help as you go, pop by\n  #datadog on freenode,\n  where we'll be happy to answer any questions you might have. (There's a\n  \n  web chat client, too.)\n\n\nThe easiest way to get your custom metrics into Datadog is to send them to DogStatsD,\na metrics aggregation server bundled with the Datadog Agent (in versions 3.0\nand above).\nDogStatsD implements the\nStatsD\nprotocol, along with a few extensions for special Datadog features.\n\n\nHow It Works\n\nDogStatsD accepts custom application metrics points over\nUDP,\nand then periodically aggregates and forwards the metrics to Datadog, where\nthey can be graphed on dashboards. Here’s a pretty standard DogStatsd setup:\n\n\n\n\n\nAggregation\n\nDogStatsD’s primary function is to aggregate many data points into a single\nmetric for a given interval of time (ten seconds by default). Let’s walk through an\nexample to understand how this works.\n\nSuppose you want to know how many times you are running a database query,\nyour application can tell DogStatsD to increment a counter each\ntime this query is executed. For example:\n\ndef query_my_database():\n    dog.increment('database.query.count')\n    # Run the query ...\n\n\nIf this function is executed one hundred times in a flush interval (ten\nseconds by default), it will send DogStatsD one hundred UDP packets that say\n“increment the ‘database.query.count’ counter”. DogStatsD will aggregate these\npoints into a single metric value - 100 in this case - and send it to the\nserver where it can be graphed.\n\nThis means expect DogStatsD to produce one point per metric per flush interval\nwhile data is being submitted for that metric.\n\n\nWhy UDP?\n\nLike StatsD, DogStatsD receives points over UDP. UDP is good fit for application\ninstrumentation because it is a fire and\nforget protocol. This means your application won’t stop its actual work to wait for a\nresponse from the metrics server, which is very important if the metrics\nserver is down or inaccessible.\n\n\nSet Up\n\nOnce you have the Datadog Agent up and running, grab a DogStatsD client for your\nlanguage and you’ll be ready to start hacking. Any StatsD client will work\njust fine, but using a Datadog StatsD client will give you a few extra features\n(namely tags and histograms, but more on that later).\n\n\nDogStatsD Clients\n\nYou can see the list of StatsD clients on our libraries page.\n\n\nMetrics\n\nWe’ll walk through the types of metrics supported by DogStatsD in Python, but\nthe principles are easily translated into other languages.\nDogStatsD supports the following types of metrics:\n\n\nGauges\n\nGauges measure the value of a particular thing at a\nparticular time, like the amount of fuel in a car’s gas tank or\nthe number of users connected to a system.\n\ndog.gauge('gas_tank.level', 0.75)\ndog.gauge('users.active', 1001)\n\n\n\nCounters\n\nCounters track how many times something happened per second, like the number of\ndatabase requests or page views.\n\ndog.increment('database.query.count')\ndog.increment('page_view.count', 10)\n\n\n\nHistograms\n\nHistograms track the statistical distribution of a set of values, like the\nduration of a number of database queries or the size of files uploaded by users. Each\nhistogram will track the average, the minimum, the maximum, the median,\nthe 95th percentile and the count.\n\ndog.histogram('database.query.time', 0.5)\ndog.histogram('file.upload.size', file.get_size())\n\n\nHistograms are an extension to StatsD, so you’ll need to use a client that\nsupports them.\n\n\nSets\n\nSets are used to count the number of unique elements in a group. If you want to\ntrack the number of unique visitor to your site, sets are a great way to do\nthat.\n\ndog.set('users.uniques', user.id)\n\n\nSets are an extension to StatsD, so you’ll need to use a client that\nsupports them.\n\n\nTimers\n\nStatsD only supports histograms for timing, not generic values (like the size\nof uploaded files or the number of rows returned from a query). Timers are\nessentially a special case of histograms, so they are treated in the same manner\nby DogStatsD for backwards compatibility.\n\n\nSample Rates\n\nThe overhead of sending UDP packets can be too great for some performance\nintensive code paths. To work around this, StatsD clients support sampling,\nthat is to say, only sending metrics a percentage of the time. For example:\n\ndog.histogram('my.histogram', 1, sample_rate=0.5)\n\n\nwill only be sent to the server about half of the time, but it will be\nmultipled by the sample rate to provide an estimate of the real data.\n\n\nTags\n\nTags are a Datadog specific extension to StatsD. They allow you to tag a metric\nwith a dimension that’s meaningful to you and slice and dice along that\ndimension in your graphs. For example, if you wanted to measure the\nperformance of two video rendering algorithms, you could tag the rendering time\nmetric with the version of the algorithm you used.\n\nSince tags are an extension to StatsD, so you’ll need to use a client that\nsupports them.\n\n\n# Randomly choose which rendering function we want to use ...\nif random() < 0.5:\n    renderer = old_slow_renderer\n    version = 'old'\nelse:\n    renderer = new_shiny_renderer\n    version = 'new'\n\nstart_time = time()\nrenderer()\nduration = time() - start_time\ndog.histogram('rendering.duration', duration, tags=[version])\n\n\n\nEvents\nYou can post events to your Datadog event stream. You can tag them, set priority and even aggregate them with other events.\n\nMandatory fields:\n\n\n  \ntitle (String) — Event title.\n  \ntext (String) — Event text. Supports line breaks.\n\n\nEvents are aggregated on the Event Stream based on: \n‘hostname/source_type/aggregation_key’\n\n\n# Post a simple message\nstatsd.event('There might be a storm tomorrow', 'A friend warned me earlier.')\n\n# Cry for help\nstatsd.event('SO MUCH SNOW', 'The city is paralyzed!', alert_type='error', tags=['urgent', 'endoftheworld'])\n\n\n\nFields\n\n  Mandatory:\n    \n      Event title.\n      Event text. Supports line breaks.\n    \n  \n  Optional:\n    \n      \ndate_happened (Time, None) — default: None — Assign a POSIX timestamp in seconds to the event. Default is now when none.\n      \nhostname (String, None) — default: None — Assign a hostname to the event.\n      \naggregation_key (String, None) — default: None — Assign an aggregation key to the event, to group it with some others.\n      \npriority (String, None) — default: ‘normal’ — Can be ‘normal’ or ‘low’.\n      \nsource_type_name (String, None) — default: None — Assign a source type to the event.\n      \nalert_type (String, None) — default: ‘info’ — Can be ‘error’, ‘warning’, ‘info’ or ‘success’.\n      \ntags - (Array[str], None) — default: None — An array of tags\n    \n  \n\n\n\nConfiguration\n\nDogStatsD supports the following option, that can be tweaked in the\nAgent \nconfiguration file:\n\n# The port DogStatsD runs on. If you change this, make your the apps sending to\n# it change as well.\ndogstatsd_port: 8125\n\n\n\nDatagram Format\n\n\nMetrics\n\nIf you want to send metrics to DogStatsD in your own way, here is the format of\nthe packets:\n\nmetric.name:value|type|@sample_rate|#tag1:value,tag2\n\nHere’s  breakdown of the fields:\n\n\n  \nmetric.name should be a String with no colons, bars or @ characters and fit our naming policy.\n  \nvalue should be a number\n  type should be c for Counter, g for Gauge, h for Histogram, ms for\nTimer or s for Set.\n  sample rate is optional and should be a float between 0 and 1 inclusive.\n  tags are optional, and should be a comma seperated list of tags. Colons are\nused for key value tags. Note that the key device is reserved, tags like “device:xyc” will be dropped by Datadog.\n\n\nHere are some example datagrams and comments explaining them:\n\n# Increment the page.views counter.\npage.views:1|c\n\n# Record the fuel tank is half-empty\nfuel.level:0.5|g\n\n# Sample a the song length histogram half of the time.\nsong.length:240|h|@0.5\n\n# Track a unique visitor to the site.\nusers.uniques:1234|s\n\n# Increment the users online counter tagged by country of origin.\nusers.online:1|c|#country:china\n\n# An example putting it all together.\nusers.online:1|c|@0.5|#country:china\n\n\n\nEvents\n\nIf you want to send events to DogStatsD in your own way, here is the format of\nthe packets:\n\n_e{title.length,text.length}:title|text|d:date_happened|h:hostname|p:priority|t:alert_type|#tag1,tag2\n\n\nFields\n\n  Mandatory:\n    \n      \ntitle — Event title.\n      \ntext — Event text. Insert line breaks with an escaped slash (\\\\n)\n    \n  \n  Optional: |[key]:[value]\n    \n      \n|d:date_happened — default: None — Assign a timestamp to the event. Default is the current Unix epoch timestamp when not supplied.\n      \n|h:hostname — default: None — Assign a hostname to the event.\n      \n|k:aggregation_key — default: None — Assign an aggregation key to the event, to group it with some others.\n      \n|p:priority — default: ‘normal’ — Can be “normal” or “low”.\n      \n|s:source_type_name — default: None — Assign a source type to the event.\n      \n|t:alert_type — default: ‘info’ — Can be “error”, “warning”, “info” or “success”.\n      \n|#tag1:value1,tag2,tag3:value3 — default: None. \nNote: The : in tags is part of the tag list string and has no parsing purpose like for the other parameters.\n\n    \n  \n\n\n\nService Checks\n\nIf you want to send service checks to DogStatsD, here is the format of the packets:\n\n_sc|name|status|metadata\n\n\nFields\n\n  Mandatory:\n    \n      \nname — service check name string, shouldn’t contain any |\n\n      \nstatus — digit corresponding to the status you’re reporting (OK = 0, WARNING = 1, CRITICAL = 2, UNKNOWN = 3)\n    \n  \n  Optional metadata |metadata:\nIt’s either nothing, or a combination of those suffixes:\n    \n      \n|d:timestamp — Assign a timestamp to the check. Default is the current Unix epoch timestamp when not supplied.\n      \n|h:hostname — default: None — Assign a hostname to the event.\n      \n|#tag1:value1,tag2,tag3:value3 — default: None. Note: The : in tags is part of the tag list string and\nhas no parsing purpose like for the other parameters.\n\n      \n|m:service_check_message — A message describing the current state of the service check. This field should always be\npositioned last among the metadata fields.\n\n    \n  \n\n\n\nSource\n\nDogStatsD is open-sourced under the BSD License. Check out the source\nhere.\n\n","tags":"","loc":"/guides/dogstatsd/"},{"title":"Correlating Events with Metrics","text":"\n\nOverview\n\nEvent Correlation refers to overlaying events on top of a dashboard graph and is an important feature of the Datadog platform. You can setup correlation at two different times: either when you setup the dashboard or adhoc at the time you view the dashboard.\n\n\nEvent Correlation at Design Time\n\n\nSetup event correlation at design time by editing any graph on both Time Boards and Screen Boards and adding events to the graph. To learn more about this, visit the Graphing Primer. You can find details about adding events using the UI or via the JSON interface further down the page.\n\n\nEvent Correlation at View Time\n\n\nSetup event correlation at view time by adding a query in the Search box at the top left of any Time Board dashboard window. This will replace any events added at design time, but will apply the events to all graphs on that particular dashboard.\n\n\nEvent Query Language\n\nYou can narrow down your search by filtering on certain event properties. See the list of filters below for more details. Please note that filters perform an exact match search and will not work with partial strings.\n\n\n  \n    \n      Filter\n      Description\n    \n  \n  \n    \n      user:pup@datadoghq.com\n      Find all events with comments by pup@datadoghq.com.\n    \n    \n      sources:github,chef\n      Show events from Github OR Chef.\n    \n    \n      tags:env-prod OR db\n      Show events tagged with #env-prod OR #db.\n    \n    \n      tags:security-group:sg-123 AND role:common-node\n      Show events tagged with #security-group:sg-123 AND #role:common-node.\n    \n    \n      hosts:i-0ade23e6,db.myapp.com\n      Show events from i-0ade23e6 OR db.myapp.com.\n    \n    \n      status:error\n      Show events with error status. (supports: ‘error’, ‘warning’, ‘success’)\n    \n    \n      priority:low\n      Show only low-priority events. (supports: ‘low’ or ‘normal’. defaults to ‘all’)\n    \n    \n      incident:claimed\n      Show only claimed incidents. (supports: ‘open’, ‘claimed’, ‘resolved’, or ‘all’)\n    \n  \n\n\nFull text search works on all keywords provided in the search query after applying any filters. Full text search will look inside the event text, title, tags, users who commented on the event and host names and devices tied to the event for any related information.\n\nYou can use full text search to find all events with the same key tags. For example, to show all events with the #service key you would search #service.\n\nIn the example below, a full text search is performed to find all open chef or nagios errors that mention one or more redis instances that are currently down.\n\nsources:nagios,chef status:error redis_* AND down\n\nPlease note that some of the advanced query language features (e.g. boolean logic) work only in the event stream page, and do not work in graph tiles or in screen board widgets.\n","tags":"","loc":"/guides/eventcorrelation/"},{"title":"Events via Email","text":"\n\nOverview\n\nWhen you need to integrate an application or system with Datadog, you have a\nfew choices. The first is using one of our many existing integrations.\nThis will get you access to a wide variety of metrics and events with minimal\nconfiguration effort on your part. If your application isn’t one of the\nintegrated applications, then you can opt to create a check using the agent.\nThis requires much more effort and potentially more knowledge on how the\napplication and how Datadog work.\n\nThere is another option available if you aren’t using an application that has\nan integration and you don’t want to create an agent check. You can rely on\nthe application or system sending an email instead. There are two different ways\nto use Events via Email, depending mostly on whether the application offers you\nthe ability to customize the format of the email body being sent.\n\n\nJSON-Formatted vs Plain Text\n\nIf you have complete control over the email sent by the application to Datadog,\nthen you will probably want to configure a JSON-formatted message to be sent.\nThis will allow you to set everything in the event that appears in the event\nstream. Here are examples of each:\n\n\nPlain Text\n\n\nSource Email\n\nIn the source plain text email, you only have three fields you can control: sender\nemail address, subject, and body.\n\n\n\n\nDatadog Event\n\n\n\nNote that the subject of the email becomes the title of the event and the body\nof the email becomes the body of the event. Although it looks like a tag appears\nat the end of the title and body of the event, neither instance are actually\ntags. The sender of the email also appears at the bottom of the event, so be sure\nto take advantage of that to help identify the sending application.\n\n\nJSON\n\n\nSource Email\n\nIn the source JSON-formatted email, you have 10 fields you can control: sender\nemail address, and up to 9 JSON keys. Those keys are title, text, priority, tags,\nalert type,  date happened,  host, aggregation key, and source type name.\n\n\n\n\nDatadog Event\n\n\n\nIn a JSON-formatted email, the subject of the email message is irrelevant as it\nwill be replaced by the title in the JSON in the body of the email. All data that\nappears in the event is defined in the JSON in the body of the email. This JSON\nmust be well-formed or the message will be ignored. This means that not only should\nit look correct with commas separating key value pairs, it also must be pure JSON.\nIf you are testing the email with a standard email client, the body may be converted\nto HTML as a convenience to the user. This will cause the JSON to no longer be\nJSON and the email will be ignored by Datadog.\n\nThe allowable JSON keys can be found in the events API documentation.\n\n\nSetting Up The Email Address\n\nTo set up the email, first log in to your Datadog account at\nhttps://app.datadoghq.com. From the Integrations menu, choose APIs,\nthen scroll down to Events API Emails. This section will show you all the emails\navailable for your applications and who created them. Choose the format for your\nmessages from the Format: dropdown, then click Create API Email.\n\n\n\n","tags":"","loc":"/guides/eventsemail/"},{"title":"Host Map Overview","text":"\n\nOverview\n\nHost Maps let you see all of your hosts together on one screen, grouped however you want, filtered however you want, with metrics made instantly comprehensible via color and shape. This is a new and simple way to spot outliers, detect usage patterns, avoid resource problems, and make decisions about how to best manage your infrastructure. Host Maps work at any scale, whether you have 10, 100 or 10,000 hosts.\n\nWhen you use Host Maps, we wanted the experience to be like waving a magic wand, and having every host leap to attention, telling you the high-level story instantly, ready to report further details on demand.\n\n\nWays to use it\n\nWe built Host Maps for ultimate flexibility; with just a few clicks, you can ask innumerable infrastructure-level questions and get instant, visual answers. Below are some common uses, but we would also love to hear on twitter about the ways you use Host Maps at your company (@datadoghq).\n\n\nResource Optimization\n\nIf you are an AWS user, you probably use a variety of instance types. Some instances are optimized for memory, some for compute, some are small, some are big. If you want to reduce your AWS spend, a great place to start is by figuring out what the expensive instances are used for. With Host Maps this is easy. First group by “instance-type” and then group by role or name. Take a look at your expensive instance types, such as c3.8xlarge. Are there any host roles whose CPU is underutilized? If so, you can zoom in to individual hosts and see whether all that computational horsepower has been needed in the last several months, or whether this group of hosts is a candidate for migrating to a cheaper instance type.\n\nBelow is a subset of Datadog’s infrastructure. As you can see, c3.2xlarge instances are pretty heavily loaded.\n\n\n\nAs seen below, by clicking on the c3.2xlarge group and then sub-grouping by role, we found that only some of the roles are loaded, while others are nearly idling. If we downgraded those 7 green nodes to a c3.xlarge, we would save almost $13K per year. That’s worth investigating! ( $0.21 saved per hour per host x 24 hr/day * 365 days/year * 7 hosts = $12,877.20 / year )\n\n\n\n\nAvailability Zone Placement\n\nHost maps make it easy to see distributions of machines in each of your availability zones (AZ). Filter for the hosts you are interested in, group by AZ, and you can immediately see whether resources need rebalancing. As seen below, at Datadog we have an uneven distribution of hosts with role:daniels across availability zones. (Daniels is the name of one of our internal applications.)\n\n\n\n\nProblem Investigation\n\nImagine you are having a problem in production. Maybe the CPUs on some of your hosts are pegged, which is causing long response times. Host Maps can help you quickly see whether there is anything different about the loaded and not-loaded hosts. You can rapidly group by any dimension you would like to investigate, and visually determine whether the problem servers belong to a certain group. For example, you can group by availability zone, region, instance type, image, or any tag that you use at your company. You will either find a problem very quickly, or rule out these explanations before spending time on deeper investigations.\n\nBelow is a screenshot from a recent issue we had a Datadog. As you can see, some hosts had much less usable memory than others, despite being part of the same cluster. Why? We grouped by machine image in Host Maps, and the problem was immediately clear: there were in fact two different images in use, and one of them had become overloaded.\n\n\n\n\n\n\nMore Details\n\n\nTags\n\nYour hosts probably have a lot of tags. Some tags are applied automatically by Datadog integrations, and some tags were probably applied by members of your team. Regardless of how the tags were created, you can use any of them to slice and dice your Host Maps.\n\nIf some of your hosts are running on AWS, the following AWS-specific tags are available to you right now:\n\n\n  availability-zone\n  region\n  image\n  instance-type\n  security-group\n  and any EC2 tags you might use, such as ‘name’\n\n\n\nFilter by\n\n‘Filter by’ limits the Host Maps to a specific subset of your infrastructure. Located in the top-left of Host Maps, the filter input bar lets you filter your map by any of your tags, plus the Datadog-provided attributes below. If your filter input bar is empty, then the map displays all hosts that are reporting metrics to Datadog. If you want to focus your attention on just a subset of your hosts, then add filters. Example: if you tag your hosts by the environment they are in, you can filter by ‘production’ to remove hosts in your staging and other environments from the map. If you want to eliminate all but one host role in production, then add that role to the filter, too—the filters will be ANDed together.\n\nFilterable host attributes (automatically provided):\n\n\n  up : the host is reporting a heartbeat\n  down : the host is not reporting a heartbeat\n  muted : Datadog alerts are muted for this host\n  agent : the host is running the datadog agent\n  agent_issue : often indicates an integration problem such failed access to a resource\n  upgrade_required : the Datadog agent requires an upgrade\n\n\n\nGroup hosts by tags\n\n‘Group hosts by tags’ spatially arranges your hosts into clusters, or groups. Any host in a group shares the tag or tags you group by. A simple example is grouping your hosts by AWS availability zone. If you add a second grouping tag, such as instance type, then the hosts will be further subdivided into groups, first by availability zone and then by instance type, as seen below.\n\n\n\n\nZoom in\n\nWhen you’ve identified a host that you want to investigate, click it for details. You will zoom in and see up to six integrations reporting metrics from that host. (If there are more than six integrations, they will be listed under the “Apps” header in the host’s detail pane, as in the screenshot below.) Click the name of an integration, and you will get a condensed dashboard of metrics for that integration. In the screenshot below, we have clicked “system” to get system metrics such as CPU usage, memory usage, disk latency, etc.\n\n\n\n\nShapes and colors\n\nBy default the color of each host (hexagon) is set to represent the percentage of CPU usage on each host, where the color ranges from green (0% utilized) to red (100% utilized). You can select different metrics from the ‘Color by’ selector. The Host Maps can also communicate an additional, optional metric with the size of the hexagon; use the ‘Size by’ selector. In the screenshot below the size of the hexagons is the 15 minute average load, normalized so that machines’ workloads can be compared even if they have different numbers of cores.\n\n\n\nToday the ‘Color by’ selector and ‘Size by’ selector contain only CPU-based metrics: load, idle, wait, etc. We will be adding additional metrics in the very near future.\n\nNote that the “% CPU utilized” metric uses the most reliable and up-to-date measurement of CPU utilization, whether it is being reported by the Datadog agent, or directly by AWS, or vSphere.\n\n\nData freshness and meaning\n\nData in the Host Maps is refreshed about once a minute—unless you are continuously interacting with the map. In that case it will not refresh because it can be disorienting to have colors and shapes spontaneously change while you are still investigating. The bottom right of your screen will tell you when data was last updated.\n","tags":"","loc":"/guides/hostmap/"},{"title":"Installing Core & Extra Integrations","text":"\n\nOverview\nStarting with version 5.12 of the Datadog Agent, we are moving integrations from the dd-agent repository on GitHub to the integrations-core and integrations-extras repositories. This move will allow us to have a method to distribute more community-developed integrations, as well as being able to update supported integrations out of band with the Agent. Note: these integrations are not designed for Windows operating systems.\n\nFor more information on adding new integrations to integrations-extras, see the guide on the Integration SDK\n\nThe two integration repositories are defined as follows:\n\n\n  \nintegrations-core - Datadog-supported integrations that were formerly found in the core Agent. \n  \nintegrations-extras - Community-supported integrations that have been written according to the guidelines specified by Datadog\n\n\nAll core integrations will continue to be installed with the agent install. You only have to install an integration in core separately if there is an out of band update to that integration. To either install an out-of-band update to a core integration or to install one of the extra integrations, follow these steps:\n\n\nInstalling on yum-based systems\n\n\n  Run yum update to ensure your system has access to the latest packages.\n  Run yum install dd-check-integration, replacing integration with the name of the chosen integration. So if you are installing mysql, then run yum install dd-check-mysql.  \n\n\n\nInstalling on apt-get-based systems\n\n\n  Run apt-get update to ensure your system has access to the latest packages.\n  Run apt-get install dd-check-integration, replacing integration with the name of the chosen integration. So if you are installing mysql, then run apt-get install dd-check-mysql.  \n\n\n\nInstalling on systems with no package management\n\n\n  Copy the Python script for your chosen integration to the checks.d directory where you installed the Agent.\n  Copy the corresponding yaml configuration file to the conf.d directory where you installed the Agent.\n\n\n","tags":"","loc":"/guides/installcoreextra/"},{"title":"Creating New Integrations","text":"\n\nRequirements\n\nYou will need a working Ruby environment. For more information on installing Ruby, please reference the Ruby installation documentation.\n\nYou will also need Wget. Wget is already installed on most Linux systems and is easy to install on Mac using Homebrew or on Windows using Chocolatey.\n\n\nSetup\n\nWe’ve written a gem and a set of scripts to help you get set up, ease development, and provide testing. To begin:\n\n\n  Fork the integrations-extras repository on Github and clone the repository to your dev environment.\n  Run gem install bundler\n\n  Run bundle install\n\n\n\nOnce the required Ruby gems have been installed by Bundler, you can easily create a Python environment:\n\n\n  Run rake setup_env. This will install a Python virtual environment along with all the components necessary for integration development.\n  Run source venv/bin/activate to activate the installed Python virtual environment. To exit the virtual environment, run deactivate. You can learn more about the Python virtual environment on the Virtualenv documentation.\n\n\n\nBuilding an integration\n\nYou can use rake to generate the skeleton for a new integration by running rake generate:skeleton[my_integration], where “my_integration” is the name of your new integration (note: you must enclose your integration name in square brackets).\n\nThis will create a new directory, my_integration, that contains all the files required for your new integration. This will also create an entry for your new integration in our .travis.yml and circle.yml continuous integration files to ensure that your tests are run whenever new builds are created.\n\n\nIntegration files\n\nNew integrations should contain the following files:\n\n\nREADME.md\n\n\nYour README file should provide the following sections:\n\n\n  \nOverview (required): Let others know what they can expect to do with your integration.\n  \nInstallation (required): Provide information about how to install your integration.\n  \nConfiguration (required): Detail any steps necessary to configure your integration or the service you are integrating.\n  \nValidation (required): How can users ensure the integration is working as intended?\n  \nTroubleshooting: Help other users by sharing solutions to common problems they might experience.\n  \nCompatibility (required): List the version(s) of the application or service that your integration has been tested and validated against.\n  \nMetrics (required): Include a list of the metrics your integration will provide.\n  \nEvents: Include a list of events if your integration provides any.\n  \nService Checks: Include a list of service checks if your integration provides any.\n\n\n\ncheck.py\n\n\nThe file where your check logic should reside. The skeleton function will boilerplate an integration class for your integration, including a check method where you should place your check logic.\n\nFor example:\n\n# Example check.py\nimport time\nfrom checks import AgentCheck\n\nclass MyIntegrationCheck(AgentCheck):\n  def __init__(self, name, init_config, agentConfig, instances=None):\n    AgentCheck.__init__(self, name, init_config, agentConfig, instances)\n\n  def check(self, instance):\n    # Send a custom event.\n    self.event({\n      'timestamp': int(time.time()),\n      'source_type_name': 'my_integration',\n      'msg_title': 'Custom event',\n      'msg_text': 'My custom integration event occurred.',\n      'host': self.hostname,\n      'tags': [\n          'action:my_integration_custom_event',\n      ]\n    })\n\n\nFor more information about writing checks and how to send metrics to the Datadog agent, reference our Writing an Agent Check guide\n\nIf you need to import any third party libraries, you can add them to the requirements.txt file.\n\n\nci/my_integration.rake\n\n\nIf your tests require a testing environment, you can use the install and cleanup tasks to respectively set up and tear down a testing environment.\n\nFor example:\n\n# Example my_integration.rake\nnamespace :ci do\n  namespace :my_integration do |flavor|\n    task install: ['ci:common:install'] do\n\n      # Use the Python Virtual Environment and install packages.\n      use_venv = in_venv\n      install_requirements('my_integration/requirements.txt',\n                           \"--cache-dir #{ENV['PIP_CACHE']}\",\n                           \"#{ENV['VOLATILE_DIR']}/ci.log\",\n                           use_venv)\n\n      # Setup a docker testing container.\n      $(docker run -p 80:80 --name my_int_container -d my_docker)\n\n\nFor more information about writing integration tests, please see the documentation in the Datadog agent repository. You can also reference the ci common library for helper functions such as install_requirements and sleep_for.\n\nA note about terminology: You may notice the variable flavor in this file and other areas of testing. Flavor is a term we use to denote variations of integrated software, typically versions. This allows you to write one set of tests, but target different flavors, variants or versions of the software you are integrating.\n\n\nconf.yaml.example\n\n\nIn order to install your integration, users will need to configure the integration for their specific instances. To do this, they’ll copy the conf.yaml.example file that you provide into their Agent’s conf.d directory, then update it with their instance specific information.\n\nYour conf.yaml.example file should provide two sections:\n\n\n  \ninit_config for any globally configured parameters\n  \ninstances for specific instances to integrate. This often includes a server or host address with additional parameters such as authentication information, additional tags and configuration settings.\n\n\n\nmanifest.json\n\n\nThis JSON file provides metadata about your integration and should include:\n\n\n  \nmaintainer: Provide a valid email address where you can be contacted regarding this integration.\n  \nmanifest_version: The version of this manifest file.\n  \nmax_agent_version: The maximum version of the Datadog agent that is compatible with your integration. We do our best to maintain integration stability within major versions, so you should leave this at the number generated for you. If your integration breaks with a new release of the Datadog agent, please set this number and submit an issue on the Datadog Agent project.\n  \nmin_agent_version: The minimum version of the Datadog agent that is compatible with your integration.\n  \nname: The name of your integration.\n  \nshort_description: Provide a short description of your integration.\n  \nsupport: As a community contributed integration, this should be set to “contrib”. Only set this to another value if directed to do so by Datadog staff.\n  \nversion: The current version of your integration.\n\n\nYou can reference one of the existing integrations for an example of the manifest file.\n\n\nmetadata.csv\n\n\nThe metadata CSV contains a list of the metrics your integration will provide and basic details that will help inform the Datadog web application as to which graphs and alerts can be provided for the metric.\n\nThe CSV should include a header row and the following columns:\n\nmetric_name (required): The name of the metric as it should appear in the Datadog web application when creating dashboards or monitors. Often this name is a period delimited combination of the provider, service, and metric (e.g. aws.ec2.disk_write_ops) or the application, application feature, and metric (e.g. apache.net.request_per_s).\n\nmetric_type (required): The type of metric you are reporting. This will influence how the Datadog web application handles and displays your data. Accepted values are: count, gauge, or rate.\n\n\n  \ncount: A count is the number of particular events that have occurred. When reporting a count, you should only submit the number of new events (delta) recorded since the previous submission. For example, the aws.apigateway.5xxerror metric is a count of the number of server-side errors.\n  \ngauge: A gauge is a metric that tracks a value at a specific point in time. For example, docker.io.read_bytes is a guage of the number of bytes read per second.\n  \nrate: A rate a metric over time (and as such, will typically include a per_unit_name value). For example, lighttpd.response.status_2xx is a rate metric capturing the number of 2xx status codes produced per second.\n\n\ninterval: The interval used for conversion between rates and counts. This is required when the metric_type is set to the rate type.\n\nunit_name: The label for the unit of measure you are gathering. The following units (grouped by type) are available:\n\n\n  \nBytes: bit, byte, kibibyte, mebibyte, gibibyte, tebibyte, pebibyte, exbibyte\n\n  \nCache: eviction, get,  hit,  miss,  set\n\n  \nDatabase: assertion, column, command, commit, cursor, document, fetch, flush, index, key, lock, merge, object, offset, query, question, record, refresh, row, scan, shard, table, ticket, transaction, wait\n\n  \nDisk: block, file, inode, sector\n\n  \nFrequency: hertz, kilohertz, megahertz, gigahertz\n\n  \nGeneral: buffer, check, email, error, event, garbage,  collection, item, location, monitor, occurrence, operation, read, resource, sample, stage, task, time, unit, worker, write\n\n  \nMemory: page, split\n\n  \nMoney: cent, dollar\n\n  \nNetwork: connection, datagram, message, packet, payload, request, response, segment, timeout\n\n  \nPercentage: apdex, fraction, percent, percent_nano\n\n  \nSystem: core, fault, host, instance, node, process, service, thread\n\n  \nTime: microsecond, millisecond, second, minute, hour, day, week\n\n\n\nIf the unit name is not listed above, please leave this value blank. To add a unit to this listing, please file an issue\n\nper_unit_name: If you are gathering a per unit metric, you may provide an additional unit name here and it will be combined with the unit_name. For example, providing a unit_name of “request” and a per_unit_name of “second” will result in a metric of “requests per second”. If provided, this must be a value from the available units listed above.\n\ndescription: A basic description (limited to 400 characters) of the information this metric represents.\n\norientation (required): An integer of -1, 0, or 1.\n\n\n  \n-1 indicates that smaller values are better. For example, mysql.performance.slow_queries or varnish.fetch_failed where low counts are desirable.\n  \n0 indicates no intrinsic preference in values. For example, rabbitmq.queue.messages or postgresql.rows_inserted where there is no preference for the size of the value or the preference will depend on the business objectives of the system.\n  \n1 indicates that larger values are better. For example, mesos.stats.uptime_secs where higher uptime or mysql.performance.key_cache_utilization where more cache hits are desired.\n\n\nintegration (required): This must match the name of your integration. (e.g. “my_integration”).\n\nshort_name: A more human-readable and abbreviated version of the metric name. For example, postgresql.index_blocks_read might be set to idx blks read. Aim for human-readability and easy understandability over brevity. Don’t repeat the integration name. If you can’t make the short_name shorter and easier to understand than the metric_name, leave this field empty.\n\n\nrequirements.txt\n\n\nIf you require any additional Python libraries, you can list them here and they will be automatically installed via pip when others use your integration.\n\n\ntest_my_integration.py\n\n\nIntegration tests ensure that the Datadog agent is correctly receiving and recording metrics from the software you are integrating.\n\nThough we don’t require test for each of the metrics collected by your integration, we strongly encourage you to provide as much coverage as possible. You can run the self.coverage_report() method in your test to see which metrics are covered.\n\nHere’s an example test_my_integration.py:\n\n# Example test_my_integraion.py\nfrom nose.plugins.attrib import attr\nfrom checks import AgentCheck\nfrom tests.checks.common import AgentCheckTest\n\n@attr(requires='my_integration')\nClass TestMyIntegration(AgentCheckTest):\n\n  def testMyIntegration(self):\n    self.assertServiceCheck('my_integration.can_connect',\n                            count=1,\n                            status=AgentCheck.OK,\n                            tags=[host:localhost', 'port:80'])\n    self.coverage_report()\n\n\nFor more information about tests and available test methods, please reference the AgentCheckTest class in the Datadog Agent repository\n\n\nLibraries\n\nThe Datadog Agent provides a number of useful libraries in the utils directory. These libraries can be helpful when building your integration and we encourage you to use them, but please be aware that these libraries will be moved in the upcoming Datadog Agent version 6.0. We will provide more details regarding integrations and these libraries prior to the Datadog Agent 6.0 release.\n\n\nTesting your integration\n\nAs you build your check and test code, you can use the following to run your tests:\n\n\n  \nrake lint: Lint your code for potential errors\n  \nrake ci:run[my_integration]: Run the tests that you have created in your test_my_integration.py file.\n  \nrake ci:run[default]: Run the tests you have written in addition to some additional generic tests we have written.\n\n\nTravis CI will automatically run tests when you create a pull request. Please ensure that you have thorough test coverage and that you are passing all tests prior to submitting pull requests.\n\n\nDocker test environments\n\nAt Datadog we’re using Docker containers for testing environments and we highly encourage you to do the same. Containers are lightweight, easy to manage, and provide consistent, standardized environments for each test run.\n\nFor example in our MySQL integration, the ci/mysql.rake file uses the official MySQL container and involves four main tasks\n\n\n  \nbefore_install - Prior to starting our new Docker test environment, we need to ensure that any previous Docker test environments are stopped and removed.\n  \ninstall - The install task performs the Docker run which will start the MySQL test server.\n  \nbefore_script - This task first ensures that the MySQL server is running, then connects to the server to perform some setup tasks. We highly recommend that you keep setup tasks in your test_integration.py file when possible, but we recognize that sometimes setup and configurations will need to be performed prior to the python test script.\n  \ncleanup - After the tests are complete, the Docker test environment is stopped and removed.\n\n\n\nInstalling your integration locally\n\nWhen your integration is merged into the integrations-extras repository, we will generate packages so that others can easily install your integration (see the Installing Core & Extra Integrations guide). However, you may want to install your integration locally before it’s merged.\n\nTo run locally, first copy your check.py file into the Datadog Agent’s checks.d directory and rename it to my_integration.py (using the actual name of your integration).\n\nNext, copy your conf.yaml.example file into the Datadog Agent’s conf.d directory and rename it to my_integration.yaml (again, using the actual name of your integration).\n\nSee the Agent Check guide for more information about the Datadog Agent directory structure).\n\n\nTeardown and cleanup\n\nWhen you have finished building your integration, you can run rake clean_env to remove the Python virtual environment.\n\n\nSubmitting Your integration\n\nOnce you have completed the development of your integration, submit a pull request to have Datadog review your integration. After we’ve reviewed your integration, we will approve and merge your pull request or provide feedback and next steps required for approval.\n\n\nOther Considerations\n\nIn our experience building integrations, we’ve also faced a number of challenges. As your write your tests, here are a few things to consider:\n\n\n  Test clusters. Testing single instances of your software is often easier, but tests are more useful when run against setups that are representative of real-world uses. For example, MongoDB is typically used with sharding and replica set features, so our tests reflect that.\n  Consider generating calculated metrics in addition to raw metrics. For example, many databases will have slow, but less frequently run queries. So it’s often useful to look at percentiles. For example, our MySQL integration includes a calculated metric for the 95th percentile query execution time.\n\n","tags":"","loc":"/guides/integration_sdk/"},{"title":"Log Parsing in the Agent","text":"\nLog files contain tons of valuable application and business data.\nUnfortunately, this value is oftentimes never realized because log files go\nignored. The Datadog Agent can help remedy this by parsing metrics and events from\nlogs, so the data within can be graphed in real-time, all the time.\n\n\nParsing Metrics\n\nThe Datadog Agent can read metrics directly from your log files:\n\n\n  from the Datadog canonical log format, without any additional programming\n  from any other log format, with a customized log parsing function\n\n\n\nDatadog Canonical Log Format\n\nDatadog logs are formatted as follows:\n\nmetric unix_timestamp value [attribute1=v1 attributes2=v2 ...]\n\n\nFor example, imagining the content of /var/log/web.log to be:\n\nme.web.requests 1320786966 157 metric_type=counter unit=request\nme.web.latency 1320786966 250 metric_type=gauge unit=ms\n\n\nThen all you need for Datadog to read metrics is to add this line to your Agent\nconfiguration file (usually at /etc/dd-agent/datadog.conf):\n\ndogstreams: /var/log/web.log\n\n\nYou can also specify multiple log files like this:\n\ndogstreams: /var/log/web.log, /var/log/db.log, /var/log/cache.log\n\n\n\nParsing Custom Log Formats\n\nIf you want to parse a different log format - say for a piece of vendor\nor legacy software - you can use a custom Python function to extract the proper\nfields from the log by specifying your log file in your Agent configuration\nfile in the following format:\n\ndogstreams: /var/log/web.log:parsers:parse_web\n\n\nThe parsers:parse_web portion indicates that the custom Python function lives\nin a package called  parsers in the Agent’s PYTHONPATH, and the parsers package\nhas a function named parse_web. The Agent’s PYTHONPATH is set in the Agent\nstartup script, /etc/init.d/datadog-agent for Agent versions < 2.0, and in the\nsupervisor config for Agent version >= 2.0.\n\nIf your parser does not live on the Agent’s PYTHONPATH, you can use an\nalternative syntax to configure your line parser:\n\ndogstreams: /path/to/log1:/path/to/my/parsers_module.py:custom_parser\n\n\nIn this format, the agent will attempt to import a function called\ncustom_parser from /path/to/my/parsers_module.py.\n\nIf your custom log parser is not working, the first place to check is the\nAgent collector logs. If the Agent is unable to import your function, there will\nbe a line with Could not load Dogstream line parser. (On the other hand, if\nall goes well you should see dogstream: parsing {filename} with\n{function name} (requested {config option text}).)\n\n\nWriting Parsing Functions\n\nCustom parsing functions must:\n\n\n  take two parameters: a Python logger object (for debugging) and a string parameter of the current line to parse.\n  \n    return a tuple or list of tuples of the form:\n\n    (metric (str), timestamp (unix timestamp), value (float), attributes (dict))\n\n    Where attributes should at least contain the key metric_type, specifying whether the given metric is a counter or gauge.\n\n    If the line doesn’t match, instead return None.\n  \n\n\n\nExample\n\nHere’s an example of what parsers.py might contain:\n\nimport time\nfrom datetime import datetime\n\ndef parse_web(logger, line):\n    # Split the line into fields\n    date, metric_name, metric_value, attrs = line.split('|')\n\n    # Convert the iso8601 date into a unix timestamp, assuming the timestamp\n    # string is in the same timezone as the machine that's parsing it.\n    date = datetime.strptime(date, \"%Y-%m-%dT%H:%M:%S\")\n    date = time.mktime(date.timetuple())\n\n    # Remove surrounding whitespace from the metric name\n    metric_name = metric_name.strip()\n\n    # Convert the metric value into a float\n    metric_value = float(metric_value.strip())\n\n    # Convert the attribute string field into a dictionary\n    attr_dict = {}\n    for attr_pair in attrs.split(','):\n        attr_name, attr_val = attr_pair.split('=')\n        attr_name = attr_name.strip()\n        attr_val = attr_val.strip()\n        attr_dict[attr_name] = attr_val\n\n    # Return the output as a tuple\n    return (metric_name, date, metric_value, attr_dict)\n\n\nYou’ll want to be able to test your parser outside of the Agent, so for the above example,\nyou might add a test function like this:\n\ndef test():\n    # Set up the test logger\n    import logging\n    logging.basicConfig(level=logging.DEBUG)\n\n    # Set up the test input and expected output\n    test_input = \"2011-11-08T21:16:06|me.web.requests|157|metric_type=counter,unit=request\"\n    expected = (\n        \"me.web.requests\",\n        1320786966,\n        157,\n        {\"metric_type\": \"counter\",\n         \"unit\":        \"request\" }\n    )\n\n    # Call the parse function\n    actual = parse_web(logging, test_input)\n\n    # Validate the results\n    assert expected == actual, \"%s != %s\" % (expected, actual)\n    print 'test passes'\n\n\nif __name__ == '__main__':\n    # For local testing, callable as \"python /path/to/parsers.py\"\n    test()\n\n\nAnd you can test your parsing logic by calling python /path/to/parsers.py.\n\n\nParsing Events\n\nEvent parsing is done via the same custom parsing functions as described above, except if you return a\ndict (or a list of dict) from your custom parsing function, Datadog will treat it as an event instead of a metric.\n\nHere are the event fields (bold means the field is required):\n\n\n\n\nField\nType\nValue\n\n\n\n\nmsg_title\nstring\nTitle of the event. Will get indexed by our full-text\nsearch.\n\n\ntimestamp\ninteger\nUnix epoch timestamp. If omitted, will default to the time that\nthe Agent parsed the event.\n\n\nmsg_text\nstring\nBody of the event. Will get indexed by our full-text\nsearch.\n\n\nalert_type\nstring enum\nIndicates the severity of the event. Must be one of `error`,\n`warning`, `success` or `info`. If omitted, will default to `info`.\nSearchable by `alert_type:value`\n\n\nevent_type\nstring\nDescribes what kind of event this is. Used as part of the\naggregation key\n\n\naggregation_key\nstring\nDescribes what this event affected, if anything. Used as part\nof the aggregation key\n\n\nhost\nstring\nName of the host this event originated from. The event will\nautomatically get tagged with any tags you've given this host using\nthe tagging\npage or the tagging\napi. The host value is used as part of the aggregation\nkey.\n\n\npriority\nstring\nDetermines whether the event will be visible or hidden by default\nin the stream; Must be one of low or normal\n\n\n\n\n\nThe events with the same aggregation key within a 24 hour time window will get aggregated together on the stream.\nThe aggregation key is a combination of the following fields:\n\n\n  event_type\n  aggregation_key\n  host\n\n\nFor an example of an event parser, see our cassandra compaction event parser\nthat is bundled with the Agent.\n","tags":"","loc":"/guides/logs/"},{"title":"Using Markdown in Datadog events","text":"\n\nOverview\nDatadog event text supports markdown. This guide help you better format Datadog events by using Markdown.\n\nThe detailed markdown syntax can be found here.\nPlease note that embedding HTML in markdown is not supported with in Datadog.\n\nTo use Markdown in the event text, you need to begin the text block by %%% \\n and end the text block with \\n %%%\n\nAn example below:\n\n{\n      \"title\": \"Did you hear the news today?\",\n      \"text\": \"%%% \\n [an example link](http://catchpoint.com/session_id \\\"Title\\\") \\n %%%\",\n      \"priority\": \"normal\",\n      \"tags\": [\"environment:test\"],\n      \"alert_type\": \"info\"\n}\n\n\nNote: if you are embedding a link in a Markdown block, make sure the URL is encoded properly.\n\nFor example, the following url: “http://catchpoint.com/session_id:123456”\n\nShould be encoded to: “http://catchpoint.com/session_id%3A123456”\n","tags":"","loc":"/guides/markdown/"},{"title":"Sending Metrics with DogStatsD","text":"\n\nOverview\n\nThis guide explains how to send your application’s custom metrics to Datadog.\nSending your application’s custom metrics to Datadog will let you correlate\nwhat’s happening with your application, your users and your system.\n\nMetrics are collected by sending them to StatsD, a small metrics aggregation\nserver that is bundled with the Datadog Agent. You can read about how it works here. If you want to dive into code right away,\nread on.\n\nIn this tutorial, we’ll cover some common instrumentation use cases, like:\n\n\n  How to count web page views\n  How to time database queries\n  How to measure the amount of free memory\n\n\n\n\n\nSetup\n\nFirst off, install\nthe Datadog Agent (version 3 or greater), which\ncontains our StatsD server, and make sure it’s running.\n\nNext, let’s set up a client library for your language.\n\n      \n        Python\n      \n      \n        Ruby\n      \n\n\n\n\n  \nFirst, install the module:\n\n$ pip install datadog\n\nAnd import it, so it's ready to use:\n\nfrom datadog import statsd\n\n  \n\n  \nFirst, install the module:\n$ gem install dogstatsd-ruby\n\nAnd add it to your code:\n# Import the library\nrequire 'datadog/statsd'\n\n# Create a statsd client instance.\nstatsd = Datadog::Statsd.new\n\n  \n  Now we're ready to roll.\n  \n    This tutorial has examples for Python and Ruby, but check out the\n    libraries page if you use another language.\n  \n\n\n\n\nMetric names\nThere are a few rules to stick to when naming metrics:\n\nMetric names must start with a letter\nCan only contain ascii alphanumerics, underscore and periods (other characters will get converted to underscores)\nShould not exceed 200 characters (though less than 100 is genearlly preferred from a UI perspective)\nUnicode is not supported\nWe recommend avoiding spaces\n\nMetrics reported by the Agent are in a\npseudo-hierarchical dotted format (e.g. http.nginx.response_time). We say\npseudo-hierarchical because we’re not actually enforcing a hierarchy or doing\nanything with it, but we have aspirations to use it to infer things about\nservers (e.g. “hey, I see hostA and hostB are reporting ‘http.nginx.*’, those\nmust be web frontends”).\n\n\n\n\nCounters\n\nCounters are used to (ahem) count things. Let’s walk through a common example -\ncounting web page views. To achieve this, we’ll increment a metric called\nweb.page_views each time our render_page function is called.\n\n      \n        Python\n      \n      \n        Ruby\n      \n\n\n\n  \ndef render_page():\n    \"\"\" Render a web page. \"\"\"\n    statsd.increment('web.page_views')\n    return 'Hello World!'\n\n  \n  \ndef render_page()\n  # Render a web page.\n  statsd.increment('web.page_views')\n  return 'Hello World!'\nend\n\n  \n\n\nThat’s it. With this one line of code we can start graphing the data.\nHere’s an example:\n\n\n\nNote that StatsD counters are normalized over the flush interval to report\nper-second units. In the graph above, the marker is reporting\n35.33 web page views per second at ~15:24. In contrast, if one person visited\nthe webpage each second, the graph would be a flat line at y = 1. To increment or\nmeasure values over time, please see gauges.\n\nWe can also count by arbitrary numbers. Suppose we wanted to count the number\nof bytes processed by a file uploading service. We’ll increment a metric\ncalled file_service.bytes_uploaded by the size of the file each time our\nupload_file function is called:\n\n      \n        Python\n      \n      \n        Ruby\n      \n\n\n\n  \ndef upload_file(file):\n    statsd.increment('file_service.bytes_uploaded', file.size())\n    save_file(file)\n    return 'File uploaded!'\n\n  \n  \ndef upload_file(file)\n  statsd.count('file_service.bytes_uploaded', file.size())\n  save_file(file)\n  return 'File uploaded!'\nend\n\n  \n\n\nNote that for counters coming from another source that are ever-increasing and never\nreset – for example, the number of queries from MySQL over time – we track the\nrate between flushed values. While there currently isn’t an elegant solution to\nget raw counts within Datadog, you may want to apply a function to\nyour series like cumulative sum or integral. There is more information on those\nhere.\n\n\n\n\nGauges\n\nGauges measure the value of a particular thing over time. Suppose a developer\nwanted to track the amount of free memory on a machine, we can periodically\nsample that value as the metric system.mem.free:\n\n      \n        Python\n      \n      \n        Ruby\n      \n\n\n\n  \n# Record the amount of free memory every ten seconds.\nwhile True:\n    statsd.gauge('system.mem.free', get_free_memory())\n    time.sleep(10)\n\n  \n  \n# Record the amount of free memory every ten seconds.\nwhile true do\n    statsd.gauge('system.mem.free', get_free_memory())\n    sleep(10)\nend\n\n  \n\n\n\n\n\nHistograms\n\nHistograms measure the statistical distribution of a set of values.\nSuppose we wanted to measure the duration of a database query,\nwe can sample each query time with the metric database.query.time.\n\n      \n        Python\n      \n      \n        Ruby\n      \n\n\n\n  \n# Track the run time of the database query.\nstart_time = time.time()\nresults = db.query()\nduration = time.time() - start_time\nstatsd.histogram('database.query.time', duration)\n\n# We can also use the `timed` decorator as a short-hand for timing functions.\n@statsd.timed('database.query.time')\ndef get_data():\n    return db.query()\n\n  \n  \nstart_time = Time.now\nresults = db.query()\nduration = Time.now - start_time\nstatsd.histogram('database.query.time', duration)\n\n# We can also use the `time` helper as a short-hand for timing blocks\n# of code.\nstatsd.time('database.query.time') do\n  return db.query()\nend\n\n  \n\n\nThe above instrumentation will produce the following metrics:\n\n\n  \ndatabase.query.time.count - the number of times this metric was sampled\n  \ndatabase.query.time.avg - the average time of the sampled values\n  \ndatabase.query.time.median - the median sampled value\n  \ndatabase.query.time.max - the maximum sampled value\n  \ndatabase.query.time.95percentile - the 95th percentile sampled value\n\n\nThese metrics give insight into how different each query time is. We can see\nhow long the query usually takes by graphing the median. We can see how long\nmost queries take by graphing the 95percentile.\n\n\n\nFor this toy example, let’s say a query time of 1 second is acceptable.\nOur median query time (graphed in purple) is usually less than 100\nmilliseconds, which is great. But unfortunately, our 95th percentile (graphed in\nblue) has large spikes sometimes nearing three seconds, which is unacceptable.\nThis means most of our queries are running just fine, but our worst ones are\nvery bad. If the 95th percentile was close to the median, than we would know\nthat almost all of our queries are performing just fine.\n\n\nHistograms aren't just for measuring times. They can be used to measure the\ndistribution of any type of value, like the size of uploaded files or classroom\ntest scores.\n\n\n\n\n\nService Checks\n\nService checks are used to send information about the status of a service.\n\n      \n        Python\n      \n      \n        Ruby\n      \n\n\n\n  \nfrom datadog.api.constants import CheckStatus\n\n# Report the status of an app.\nname = 'web.app1'\nstatus = CheckStatus.OK\nmessage = 'Response: 200 OK'\n\nstatsd.service_check(check_name=name, status=status, message=message)\n\n  \n  \n# Report the status of an app.\nname = 'web.app1'\nstatus = Datadog::Statsd::OK\nopts = {\n  'message' => 'Response: 200 OK'\n}\n\nstatsd.service_check(name, status, opts)\n\n  \n\n\nAfter a service check has been reported, you can use it to trigger a Custom Check monitor.\n\n\n\n\nSets\n\nSets are used to count the number of unique elements in a group. If you want to\ntrack the number of unique visitors to your site, sets are a great way to do\nthat.\n\n      \n        Python\n      \n      \n        Ruby\n      \n\n\n\n  \ndef login(self, user_id):\n    # Log the user in ...\n    statsd.set('users.uniques', user_id)\n\n  \n  \ndef login(self, user_id)\n    # Log the user in ...\n    statsd.set('users.uniques', user_id)\nend\n\n  \n\n\n\n\n\nTags\n\nTags are a way of adding dimensions to metrics, so they can be sliced, diced,\naggregated and compared on the front end. Suppose we wanted to measure the\nperformance of two algorithms in the real world. We could sample one metric\nalgorithm.run_time and specify each version with a tag:\n\n      \n        Python\n      \n      \n        Ruby\n      \n\n\n\n  \n@statsd.timed('algorithm.run_time', tags=['algorithm:one'])\ndef algorithm_one():\n    # Do fancy things here ...\n\n@statsd.timed('algorithm.run_time', tags=['algorithm:two'])\ndef algorithm_two():\n    # Do fancy things here ...\n\n  \n  \ndef algorithm_one()\n  statsd.timed('algorithm.run_time', :tags => ['algorithm:one']) do\n    # Do fancy things here ...\n  end\nend\n\ndef algorithm_two()\n  statsd.timed('algorithm.run_time', :tags => ['algorithm:two']) do\n    # Do different fancy things here ...\n  end\nend\n\n  \n\n\nOn the front end, the metric instances can be aggregated as sums or averages,\nor the minimum/maximum can be reported. The metrics can also be broken down by\neach tag ‘key’ (in the key:value syntax). For instance, we could run a\nquery like this:\n\navg:algorithm.run_time{*} by {algorithm}\n\nIn this query, all instances of this metric (e.g. across all hosts, indicated by *) are averaged\n(avg) and broken down by the tag key algorithm.\n\n\nWe store one time series per host + metric + tag combination on our backend,\nthus we cannot support infinitely bounded tags. Please don't include endlessly\ngrowing tags in your metrics, like timestamps or user ids. Please limit each\nmetric to 1000 tags.\n\n\nTags must start with a letter, and after that may contain alphanumerics,\nunderscores, minuses, colons, periods and slashes. Other characters will get\nconverted to underscores. Tags can be up to 200 characters long and support\nunicode. Tags will be converted to lowercase as well.\n\nFor optimal functionality, we recommend constructing tags that use the key:value\nsyntax. Examples of commonly used metric tag keys are env, instance, name, and role.\nNote that device, host, and source are treated specially and cannot be specified\nin the standard way. Check out some of our other docs for how to use these:\n\n\n  metrics in the API\n  tags in the API\n  Agent Checks\n  log parsing\n\n\n\nSample Rates\n\nEach metric point is sent over UDP to the StatsD server. This can incur a lot\nof overhead for performance intensive code paths. To work around this, StatsD\nsupports sample rates, which allows sending a metric a fraction of the time\nand scaling up correctly on the server.\n\n      \n        Python\n      \n      \n        Ruby\n      \n\n\nThe following code will only send points half of the time:\n\n\n  \nwhile True:\n  do_something_intense()\n  statsd.increment('loop.count', sample_rate=0.5)\n\n  \n  \nwhile true do\n  do_something_intense()\n  statsd.increment('loop.count', :sample_rate => 0.5)\nend\n\n  \n\n\n\nOther Submission Methods\n\nUsing the StatsD server bundled with the Datadog Agent is the simplest\nway of submitting metrics to Datadog, but it’s not\nthe only one. Here are some other ways of getting your metrics data into\nDatadog:\n\n\n  \n    Submit metrics directly to Datadog's HTTP API\n  \n  \n    Use Dropwizard's Java metrics library, with the\nmetrics-datadog\n    backend (thanks to the good folks at\n    Vistar Media,\n    Coursera, and\n    Bazaarvoice for the great\n    contributions).\n  \n\n\n\nSeeing Your Custom Metrics\n\nThe quickest way to see your custom metric is to use the metrics explorer. You\ncan navigate to it by clicking the “Metrics” link in the top navigation bar.\n\nOnce you’re at the metrics explorer you can type in the custom metric you set\nin the “Graph:” field and it should autocomplete. If it doesn’t autocomplete,\nthen it might mean that we haven’t received data for that metric in the last\nfew hours.\n\nYou can also filter the metric by tag using the “Over:” field, or graph the\nmetric by tag group using the “One graph per:” field.\n\nNote that the metrics explorer doesn’t save any of these graphs. If you’ve\ncreated some graphs that you’d like to save, you need to click one of the\nsave buttons at the bottom left, either saving to a new dashboard or to\nan existing one.\n\n","tags":"","loc":"/guides/metrics/"},{"title":"Guide to Monitors","text":"\nFor more detail about monitors, review the Monitoring Reference page.\n\nMonitoring all of your infrastructure in one place wouldn’t be complete without\nthe ability to know when critical changes are occurring. Datadog gives you the\nability to create monitors that will actively check metrics, integration\navailability, network endpoints, and more.\n\nOnce a monitor is created, you will be notified when its conditions are met.\nYou can notify team members via email, 3rd party services (e.g. Pagerduty or\nHipchat) or other custom endpoints via webhooks.\n\nTriggered monitors will appear in the event stream, allowing collaboration\naround active issues in your applications or infrastructure. Datadog provides a\nhigh-level view of open issues on the\nTriggered Monitors\npage as well as general monitor management on the\nManage Monitors page.\n\n\nGlossary\n\nHere is a quick overview of the different terms used in this guide.\n\n\n  \nStatus: Each check run submits a status of OK, WARNING or CRITICAL.\n  \nCheck: Emits one more more statuses.\n  \nMonitor: Sends notifications based on a sequence of check statuses, metric\nthreshold or other alerting conditions.\n  \nMonitor type: host-, metric-, integration-, process-, network-, event-based, and custom. See side navigation to drill into a specific type.\n  \nTags: Configurable labels that can be applied to each metric and host. See the Tagging page for more details.\n\n\n\nCreating a Monitor\n\nNavigate to the Create Monitors\npage by highlighting the “Monitors” tab in the main menu and selecting the\n“New Monitor” sub-tab (depending on your chosen theme, the main menu may be at the top or on the left).  You will be presented with a list of monitor types\non the left. This guide will walk through the configuration of the Metric type. To learn more about setting up the other types of monitors, go to the Monitoring Reference page.\n\n\n\n\nChoose what to monitor\n\n\n  \n    Select the metric and scope you want to monitor.\n  \n\n    You can create a monitor on any metrics that you are currently sending to\n Datadog. The standard scoping rules apply here. Please refer to the\n scope section of the Graphing Primer using JSON for\n further information.\n  \n  \n    Select the alert grouping.\n \n\n    A simple alert aggregates over all reporting sources. You will get one\n alert when the aggregated value meets the conditions set below. This works\n best to monitor a metric from a single host, like avg of\n system.cpu.iowait over host:bits, or for an aggregate metric across many\n hosts like sum of nginx.bytes.net over region:us-east.\n\n    A multi alert applies the alert to each source, according to your group\n parameters. E.g. to alert on disk space you might group by host and device,\n creating the query:\n\n     avg:system.disk.in_use{*} by {host,device}\n\n\n    This will trigger a separate alert for each device on each host that is\n running out of space.\n  \n  \n    Select the alert type.\n \n\n    A threshold alert will compare the value in the selected\n timeframe against a given threshold. There are additional options available\n in the alerting conditions section. This is the standard alert case where\n you know what sort values are unexpected.\n\n    A change alert will compare the change or % change of a value between\n now and some time ago against a given threshold.\n The compared data points will not be single points but are computed using\n the parameters in the alert conditions section.\n\n    This type of alert is useful to track fast spikes or drops as well as slow\n changes in a metric when you might not have an exact “unexpected” threshold.\n Note: the calculated value is not the absolute value - meaning it will be\n negative for a downward change.\n  \n\n\n\nDefine the conditions\n\n  \n    Select the alert conditions\n\n    \n      \n        The threshold options vary slightly depending on what alert type you\nhave chosen. For either case, you input a threshold and comparison type\nbased on your metric. As you change your threshold, you will see the graph\nupdate with a marker showing the cutoff point.\n\n        \n\n        Note that you can use formatted values in this input based on the\nmetric itself. For example, if you are monitoring system.disk.used, you\ncan give a threshold of 20GB.\n\n        For a threshold alert you will be able to chose a time aggregation\nof the data. The alerting engine will generate a single series and perform\nselected aggregation.\n\n        Let’s look at the details of each option:\n\n        \n          \n            on average: The series will be averaged to produce a single\nvalue that will be checked against the threshold.\n          \n          \n            at least once: If any single value in the generated series crosses\nthe threshold then an alert will be triggered.\n          \n          \n            at all times: If every point in the generated series is outside the\nthreshold then an alert will be triggered.\n          \n          \n            in total: If the summation of every point in the series is outside\nthe threshold then an alert will be triggered.\n          \n        \n\n        Note the on average and at all times aggregations require a full\nwindow of data in the final series. This does not mean that each series\nmust be full but that there shouldn’t be a gap of more than 1 minute\nacross all aggregated series. In other words, we recommend using at least\nonce or in total for metrics with > 1 minute interval.\n      \n      \n        When you select the change alert option, you will have additional\n parameters you can adjust.\n        \n          \nchange is an absolute change of the value whereas % change is the\npercentage change of your value compared to its previous value (so if\nit was a value of 2 and now 4, the % change will be 100%).\n          You can compare the change of the value during a given timeframe by\nselecting the period you want to compare against. This can range from 5\nminutes to up to 2 days.\n          Like the threshold alert, you will need to select the\ntime aggregation and a time window on which the change will be\ncalculated.\n        \n      \n    \n  \n  \n    You can optionally notify on no data after a configurable timeframe. At\nthe minimum, your chosen timeframe must be greater than 2x the alerting\nwindow. For example, if you are alerting over the last 5 minutes then you\nwould need to wait at least 10 minutes before notifying on missing data.\n  \n  \n    You can opt to automatically resolve the monitor from a triggered\nstate. In general you’ll want to leave this option off as you only want\nan alert to be resolved when it’s fixed.\n\n    This most common use-case for this option is when you have very sparse\ncounters, e.g. for errors. When errors stop occuring the metric will stop\nreporting. This means the monitor will not resolve because there are not\nanymore values to trigger a resolution.\n  \n\n\n\nSetup Notifications\n\n\n\n\n  \n    Give your monitor a title. It is often useful to use a succinct\nexplanation of the monitor so a notified team member can quickly understand\nwhat is going on.\n  \n  \n    Enter a message for the monitor. This field allows standard\nmarkdown formatting\nas well as Datadog’s @-notification syntax. Note: you can notify any\nnon-Datadog users via email by simply adding @their-email to the\nmessage.\n\n    A common use-case for the monitor message is to include a step-by-step way\nto resolve the problem. For example if you are monitoring a database then you\nmight want to include steps for failing over to a standby node. All in all,\nyou should attempt to give as much context to the monitor as possible.\n  \n  \n    Optionally enable monitor renotification. This option is useful to remind\nyour team that a problem is not solved until the monitor is marked as\nresolved. If enabled, you can configure an escalation message to be sent\nanytime the monitor renotifies. The original message will be included as\nwell.\n  \n\n\nNote: To avoid notification storms we now group notifications with the same monitor ID and alert type in 20 second buckets. The first two notifications in the group within a 20 second bucket will be sent as normal. All other notifications within that 20 seconds will be sent as a single message listing all of them after the first two.\n\n\nScheduling Downtime\n\nYou may occasionally need to shut systems down or take them offline to perform maintenance or upgrades. Scheduling downtime allows you to do this without triggering monitors.\n\n\nManage Downtime\n\nNavigate to the Manage Downtime page by highlighting the “Monitors” tab in the main menu and selecting the “Manage Downtime” link. You may also navigate to the “Manage Downtime” page from other Monitor related pages by clicking the link at the top of the page.\n\n\n\nThe Manage Downtime page will display a list of active and scheduled downtimes. Select a downtime to view more details about the host and monitors affected.\n\n\n\n\nSchedule Downtime\n\nTo schedule downtime, click the “Schedule Downtime” button in the upper right.\n\n\n  \n    Choose what to silence.\n\n    \n\n    You can select a specific monitor to silence, or leave this field empty to silence all monitors. You can also select a scope to constrain your downtime to a specific host, device or arbitrary tag.  Please refer to the scope section of the Graphing Primer using JSON for further information about scope.\n\n    If you choose to silence all monitors constrained by a scope, clicking the “Preview affected monitors” will show which monitors are currently affected. Any monitors within your scope that are created or edited after the downtime is schedule will also be silenced.\n\n    Note that if a multi alert is included, it will only be silenced for systems covered by the scope. For example, if a downtime scope is set for host:X and a multi alert is triggered on both host:X and host:Y, Datadog will generate a monitor notification for host:Y, but not host:X.\n  \n  \n    Set a schedule.\n\n    \n\n    You can set a start date and time or leave the field empty to immediately start the downtime. You may also set a repeating schedule to accomimodate regularly scheduled downtimes.\n  \n  \n    Add an optional message to notify your team\n\n    \n\n    Enter a message to notify your team about this downtime. The message field allows standard markdown formatting as well as Datadog’s @-notification syntax. The “Notify your team” field allows you to specify team members or send the message to a service integration.\n  \n\n\n\nMonitor FAQs\n\n\n  \n    Can I manage my monitors programatically?\n\n    Yes. Refer to the Datadog API docs\nfor detailed information on managing monitors through the API using the\navailable libraries or cURL.\n  \n  \n    Can you alert on a function?\n\n    Yes, selecting the ‘Source’ tab of a monitor editor (Step 1) will allow you to\nalert on custom queries and functions, similar to the JSON editor for graphs.\n  \n  \n    Can I manually resolve a monitor?\n\n    Yes, you can manually resolve monitors but it only makes sense in a couple cases:\n\n    \n      If the monitor is in a “no data” state then resolving it will hide it from the\ntriggered monitors page.\n      If the monitor is in the triggered state but has stopped reporting data then\nresolving it will hide it from the triggered monitors page.\n    \n\n    Otherwise the monitor will pick up the current state on the next evaluation. In other\nwords, if the value is still above/below the configured threshold then the monitor may\nre-trigger upon the next evaluation (in about 60 seconds).\n  \n\n","tags":"","loc":"/guides/monitors/"},{"title":"Configuring Teams & Organizations with Multiple Accounts","text":"\nThere are two ways to have multiple accounts have access to the same data. First, you can simply add multiple users to the same team from the Team Page. The second is through the use of organizations. Organizations are typically used by Managed Service Providers which have multiple large scale customers which should not have access to each others’ data. When a user is added to multiple organizations, they will be able to quickly switch between orgs from the avatar menu in the main menu.\n\n\n\n\nTeams\n\n\nAdd New Members\n\n\n  To add members to a team, start by visiting the Team Page.\n  Enter the email address of the person you want to add to your team. Click Invite Users\n  \n\n\n\nThe new user will receive an email with a link to login.\n\n\nDisable Existing Members\nNOTE: You must be an Admin of the team to disable members\n\n\n  Go to the Team Page.\n  \n    Hover over the avatar for the user you wish to disable. Choose Disable from the menu.\n\n    \n  \n\n\n\nPromote Existing Members to Admin\nNOTE: You must be an Admin of the team to promote members\n\n\n  Go to the Team Page.\n  Hover over the avatar for the user you wish to disable. Choose Make Admin from the menu.\n\n\n\nOrganizations\n\nThe Multi-Account Organizations feature must be enabled by support. If this is a feature you need, please contact support at support@datadoghq.com.\n\n\nCreate a New Organization\n\n\n  After the feature has been enabled, visit the New Account Page.\n  \n    Enter the name of the organization you wish to create and click the Create button.\n\n    \n  \n\n\nA new trial account will be created. If you wish to add this account to your existing billing settings, please contact your sales representative.\n\n\nLeave an Organization\n\n\n  Go to your Account Profile page.\n  \n    Scroll down to Organizations and click Leave next to the org you want to leave.\n\n    \n  \n\n\nTo add, disable, and promote members, see the instructions above for Teams.\n\n","tags":"","loc":"/guides/multiaccountorg/"},{"title":"Officially Integrating with Datadog","text":"\nBeing able to see all of your metrics from across your infrastructure is key within Datadog. While we do have guides to submit custom metrics via our API and code instrumentation, it’s possible you might want to see a certain source become an official integration. Overall, the largest deciding factor in what integrations we build is what our clients request.\n\nIf you would like to propose an integration, please reach out to support@datadoghq.com and tell us what metrics you would like to see from that given source.\n\nIf you manage or work with a service and would like to see Datadog integrate it, the following information is needed:\n\n\n  How will data get into Datadog? There are currently three options:\n    \n      Push data from the source to Datadog\n      Crawl the data source’s API\n      Have the Datadog Agent pick up the information from the source\n    \n  \n  What are the metrics and tags should be picked up from the source?\n  What metrics should be included on the default dashboard that we generate for each integration?\n\n\nWe will also need a short blurb describing the integration as well as the correct image to use across our site.\n\n","tags":"","loc":"/guides/new_integration/"},{"title":"Outlier Detection","text":"\nOutlier Detection is an algorithmic feature that allows you to detect when some members of a group are behaving strangely compared to the others. For example, you could detect that one web server in a pool is processing an unusual number of requests, and hence should be a target for replacement. Or, you could get an early warning that significantly more 500s are happening in one AWS Availability Zone (AZ) than the others, which might indicate an issue brewing in that AZ.\n\n\n\n\nHow to Use Outlier Detection on Your Data\n\nThe outliers query function, when applied to your query, will return the usual results but with outlier series marked.\n\nYou can use this function to display and alert on outliers in your data. To try it out, you’ll first need a metric for which a group of hosts (or availability zones, partitions, etc) should exhibit uniform behavior. For the function to work, be sure that there are at least 3 or more members in the group. Given that, here are two ways to use outlier detection on that group.\n\n\n1. Show Outliers in Dashboards or Screenboards\n\nFor example, here is a graph of gunicorn requests by host with outlier detection enabled:\n\n\n\nYou can see that one of the series is an outlier: it is handling significantly lower traffic than the others for the time window in question.\n\nTo set up an outlier detection graph for your data add a metric to the graph showing all series in the groups. Then apply the outlier detection algorithm by adding the outliers function on your data. After applying the function, any outlier series will be colored with a bold, warm palette, while all other series will be colored with a lightweight, greyscale color palette.\n\nFirst create a new timeseries graph on your dashboard with your chosen metric. \n\n\n\nTo enable outlier detection, click on the + icon on the right side of the metrics line. Choose “Algorithms” from the function categories, then one of the four outlier algorithms:\n\n\n\nThis will apply the outliers function to your graph, and you’ll see any outliers in the group highlighted in bold, warm colors.\n\n\n\nThere are several outlier detection algorithms you can choose. The default algorithm (DBSCAN) and parameter values should work for most scenarios. However, if you see too many or too few outliers identified, you can tune the algorithm or try an alternate algorithm. To learn more, see the “Outlier Algorithms and Parameters” section below.\n\n\n2. Alert on Outliers\n\nYou can also define a monitor to alert when an outlier is detected in an important group.\n\n\n\nFor example, to alert when a Cassandra host is abnormally loaded compared to the rest of the group, you can add a new outlier monitor for the metric:\n\n\n\nYou will select the metric and scope as with other metric-based monitors.\n\nIn the alert conditions you will select the grouping and timeframe.\n\nThen select an algorithm and parameter values to use for outlier detection. \n\n\n\nTo ensure that your alert is properly calibrated, you can set the time window at the top of the screen and use the reverse («) button to look back in time for when outliers would have be found and alerted. This is also a good way to tune the parameters to the specific outliers algorithm you’re using.\n\n\n\n\nReference: Outlier Algorithms and Parameters\n\nThere are two different types of outlier detection algorithms you can use on your data: DBSCAN/ScaledDBSCAN and MAD/ScaledMAD. We recommend starting with the default algorithm, DBSCAN. If you have trouble detecting the right outliers, you can adjust the parameters to DBSCAN or try the alternate algorithm, MAD. If you have metrics on a larger scale that look to be closely clustered but the DBSCAN/MAD algorithms are identifying some as outliers, try the scaled algorithms. Explanation of each algorithm and its parameters follows.\n\n\nDBSCAN/ScaledDBSCAN\n\nA natural way to group together hosts that are behaving similarly is to use a clustering algorithm. We use DBSCAN, a popular density-based clustering algorithm, for this purpose. DBSCAN works by greedily agglomerating points that are close to each other. Clusters with few points in them are considered outliers.\n\nTraditionally, DBSCAN takes: 1) a parameter 𝜀 that specifies a distance threshold under which two points are considered to be close; and 2) the minimum number of points that have to be within a point’s 𝜀-radius before that point can start agglomerating. The image below shows an example of DBSCAN in action on points in the plane. There are two clusters. The large points had enough close neighbors to agglomerate those points, while the small colored points did no agglomerating themselves but are within the 𝜀-radius of a large point. The points in black are the outliers.\n\n\n\n\nParameters\n\nWe use a simplified form of DBSCAN to detect outliers on time series. We consider each host to be a point in d-dimensions, where d is the number of elements in the time series. Any point can agglomerate, and any point that is not in the largest cluster will be considered an outlier.\n\nWe set the initial distance threshold as follows. We create a new median time series by taking the median of the values from the existing time series at every time point. Then we calculate the Euclidean distance between each host and the median series. The threshold is the median of those distances, multiplied by a normalizing constant.\n\nThe only parameter we take is tolerance, the constant by which the initial threshold is multiplied to yield DBSCAN’s distance parameter 𝜀. Here is DBSCAN with a tolerance of 3.0 in action on a pool of Cassandra workers:\n\n\n\nYou should set the tolerance parameter depending on how similarly you expect your group of hosts to behave—larger values allow for more tolerance in how much a host can deviate from its peers.\n\n\nScaledDBSCAN\n\nThe distance threshold of the DBSCAN algorithm is independent of the overall scale of the metrics. Consider a group of constant time series with values {1000, 1001, 1002, 1005, 1015}. The median series will be a constant series at 1002. DBSCAN with a tolerance of 3.0 will identify the series at 1015 to be an outlier, even though it may be almost indistinguishable from the other series visually on the graph when the origin of the y-axis is at 0.\n\nThe ScaledDBSCAN algorithm scales the distance threshold according to the relative magnitudes of the median series and the hosts’ distances to the median series. In most situations, it will behave the same as regular DBSCAN does. However, when the median series is large compared to the distances to the median series, the distance threshold becomes proportional to the size of the median series. As a result, assessing whether two time series are close depends on the scale of the median series.\n\nHere is a comparison of DBSCAN and ScaledDBSCAN with tolerances of 3 on field data size in a group of Elasticsearch nodes:\n\n\n\n\nMAD/ScaledMAD\n\nThe  Median Absolute Deviation is a robust measure of variability, and can be viewed as the robust analog for standard deviation. Robust statistics describe data in such a way that they are not unduly influenced by outliers.\n\nFor a given set of data D = {d1, …, dn}, the deviations are the difference between each di and median(D). The MAD is then the median of the absolute values of all the deviations. For example if D = {1, 2, 3, 4, 5, 6, 100}, then the median is 4, the deviations are {-3, -2, -1, 0, 1, 2, 96}, and the MAD is 2. (Note that the standard deviation by contrast is 33.8.)\n\n\nParameters\n\nIn our case, the data set is the set of all points in every time series. We take the MAD of all the points then multiply it by a normalizing constant and our first parameter, tolerance. The constant normalizes MAD so that it is comparable to the standard deviation of the normal distribution. The tolerance parameter then specifies how many “deviations” a point has to be away from the median for it to be considered an outlier.\n\nNow to mark a time series as an outlier, we use the second parameter, pct. If more than pct% of a particular series’ points are considered outliers, then the whole series is marked to be an outlier. Here is MAD with a tolerance of 3 and pct of 20 in action when comparing the average system load by availability zone:\n\n\n\nThe tolerance parameter should be tuned depending on the expected variability of the data. For example, if the data is generally within a small range of values, then this should be small. On the other hand, if points can vary greatly, then you want a higher scale so these variabilities do not trigger a false positive.\n\n\nScaledMAD\n\nLike for DBSCAN, the MAD algorithm is designed to be independent of the overall magnitude of the metrics. If D = {1000, 1001, 1002, 1005, 1010}, the median is 1002, and the MAD is 2. Even though the point at 1010 seems close to the median in terms of their relative scales, it is still an outlier point for a tolerance of 3.\n\nThe ScaledMAD algorithm, like ScaledDBSCAN, considers the relative scales of the MAD and the median. In most cases, it will behave the same as the MAD algorithm does. However, when the MAD of the data set becomes small compared to the median, the measure of deviation becomes proportional to the median. Therefore, determining whether a point is an outlier depends on the overall scale of the metrics.\n\nHere is an example of MAD and ScaledMAD algorithms for comparing the usable memory in Cassandra hosts. Both have tolerances of 3 and pct of 20:\n\n\n\n\nDBSCAN vs. MAD\n\nSo which algorithm should you use? For most outliers, any algorithm will perform well at the default settings. However, there are subtle cases where one algorithm is more appropriate than the other.\n\nIn the following image, we see a group of hosts flushing their buffers together while one host is flushing its buffer slightly later. DBSCAN picks this up as an outlier whereas MAD does not. This is a case where we would prefer to use MAD, as we don’t care about when the buffers get flushed. The synchronicity of the group is just an artifact of the hosts being restarted at the same time. On the other hand, if instead of flushed buffers, the metrics below represented a scheduled job that actually should be synchronized across hosts, DBSCAN would be the right choice.\n\n\n\n\nScaled vs. Regular Algorithms\n\nIn most situations, the scaled algorithms will behave the same as their regular counterparts. However, if DBSCAN/MAD algorithms are identifying outliers within a closely clustered group of metrics, and you would like the outlier detection algorithm to scale with the overall magnitude of the metrics, try the scaled algorithms.\n\n\nSetting up alerts\n\nWhen setting up an outlier alert, an important parameter is the size of the time window. If the window size is too large, by the time an outlier is detected, the bad behavior might have been going on for longer than one would like. If the window size is too short, the alerts will not be as resilient to unimportant, one-off spikes.\n\nBoth algorithms are set up to identify outliers that differ from the majority of metrics that are behaving similarly. If your hosts exhibit “banding” behavior as shown below (perhaps because each band represents a different shard), we recommend tagging each band with an identifier, and setting up outlier detection alerts on each band separately.\n\n\n\n","tags":"","loc":"/guides/outliers/"},{"title":"Datadog Overview","text":"\nSo, you’ve just finished installing the Datadog\nAgent, or maybe you’re just curious about what (else) Datadog can do for you.\nThis document gives a high level overview of Datadog’s capabilities and how\nit can help you bring your infrastructure to heel.\n\n\nIntegrations\n\n\n\n\n  About 100 integrations officially listed, always adding more.\n  Custom integrations are available via our API, many documented by our active user community.\n  The Agent is open source and you can instrument your own if you’d like.\n  Once integrations have been configured, data living in a datacenter or\nin an online service is treated the same throughout Datadog.\n\n\n\nInfrastructure\n\n\n\n\n  All machines show up in the infrastructure overview\n  Here you can see the tags applied to each machine; as they’re assigned to\nperform certain roles, tagging allows you to indicate machines have\na certain purpose\n  We do as much as possible to automatically categorize your servers\nfor you, to create structure in your infrastructure with as little\nwork as possible (unlike explicitly creating all your clusters).\nThus if a new machine is tagged, you can immediately see the stats\nfor that machine based on what was previously set up for that tag.\n  For more on tagging, please see here.\n\n\n\nHost Map\n\n\n\nThe Host Map can be found under the Infrastructure menu and offers the ability to:\n\n\n  Quickly visualize your entire environment regardless of whether it’s 5, 500, or 50,000 hosts.\n  Identify outliers\n  Detect usage patterns\n  Optimize resources\n\n\nTo learn more about the Host Map, visit the Host Map Guide.\n\n\nEvents\n\n\n\nThe Event Stream is based on the same conventions as a blog:\n\n\n  Every event in the stream can be commented on.\n  Great for distributed teams and maintaining the focus of an investigation\n  You can filter\nby: user, source, tag, host, status, priority, incident\n\n\n\n\nFor each incident users can:\n\n\n  Claim it\n  Increase/decrease priority\n  Comment\n  See similar incidents\n  \n@ notify team members, who receive an email\n  @support-datadog to ask for assistance\n\n\n\n\n\nDashboards\n\n\n\nDashboards contain graphs with real-time performance metrics\n\n\n  Synchronous mousing across all graphs in a dashboard.\n  Vertical bars are events in the context of the metric.\n  Click & drag on a graph to zoom-in on a particular time-frame.\n  As you hover over the graph the event stream moves with you.\n  Display by zone, host, or total usage.\n  We expose the JSON editor of the graph allowing for arithmetic and\nfunctions to be applied to metrics.\n  Share a graph snapshot that will appear in the stream; clicking on\nthat snapshot returns you to the original dashboard (via the camera in the upper right of a graph).\n  Graphs can be embedded in an iframe, giving a 3rd party a live graph\nwithout access to your data or any other information (via the pencil in the upper right of a graph).\n\n\n\nMonitoring\n\n\n\nMonitoring gives you the ability to be notified if the aggregate of a specific\nmetric is above or below a certain threshold:\n\n\n  Across your entire infrastructure\n  Per machine (average, max, min, or sum)\n  Applies to any metric you want, revenue: data center temperature, etc.\n  Multi alerts (by device, host, etc.)\n  Set alert notification message, including @ capabilities\n\n\n\n\nDoes the data have to be pushed to Datadog?\n\nCurrently, yes:\n\n\n  All integrations we have get data flowing almost automatically after\nlaunching the Agent (intial reporting may take a few minutes, but not longer than 10).\n  If you have custom metrics, you can indicate specifically where\nto pull the data from.\n\n","tags":"","loc":"/guides/overview/"},{"title":"Single Sign On With SAML","text":"\nThis guide assumes that you already have a SAML Identity Provider up and running.\n\n\nSAML\n\nConfiguring SAML (Security Assertion Markup Language) for your Datadog account will let you and all your teammates log in to Datadog using the credentials stored in your organization’s Active Directory, LDAP, or other identity store that has been configured with a SAML Identity Provider.\n\n\nConfigure SAML\nIf you are a Datadog Admin, there is a “Configure SAML” option in the drop down menu that is accessed by clicking on your username in the upper right corner of the Datadog web page.\n\n\nThat brings you to the “SAML Single Sign On Configuration” page where you can:\n\n\n  \n    Upload the IdP Metadata from your SAML Identity provider by clicking the “Choose File” button.\n\n    \n\n    After you’ve chosen the file, click “Upload File”.\n  \n  Datadog’s Service Provider metadata can be found here. You can use this SP Metadata to configure your IdP to recognize Datadog as a Service Provider.\n  \n    After you upload the IdP Metadata and configure your IdP, you will need up enable SAML in Datadog by clicking the Enable button.\n\nOnce SAML is configured in Datadog and your IdP is set up to accept requests from Datadog, users can log in by using the Single Sign On URL that is shown in the Status box at the top of the SAML Configuration page.\n\nThe Single Sign On URL will also be displayed on the Team page. Loading this URL will initiate a SAML authentication against your IdP. Please note that the URL will not be displayed until SAML is enabled for your account.\n\n  \n\n\n\nDatadog Service Provider Details\n\n\n  Datadog supports the HTTP-POST binding for SAML2:\nurn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST.\n  Datadog will specify urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress for the Format of the NameIDPolicy in Assertion Requests.\n  Assertions must be signed.\n  Assertions can be encrypted, but unencrypted assertions will be accepted.\n  \n    Datadog’s SP Metadata can be found at https://app.datadoghq.com/account/saml/metadata.xml.\n\n  \n\n\n\nSetting Attributes\n\n\n  Attributes may be included with the Assertion. Datadog looks for 3 Attributes in the AttributeStatement:\n    \n      \neduPersonPrincipalName: If specified, the eduPersonPrincipalName must correspond to the user’s Datadog username. The username is usually the user’s email address.\n      \nsn: This is optional, and should be set to the user’s surname.\n      \ngivenName: This is optional, and should be set to the user’s first, or given name.\n    \n  \n  Datadog expects that Attributes use the NameFormat\nurn:oasis:names:tc:SAML:2.0:attrname-format:uri or urn:oasis:names:tc:SAML:2.0:attrname-format:basic. The name used for each attribute will depend on the NameFormat that your IdP uses.\n  If your IdP is configured to use the NameFormat urn:oasis:names:tc:SAML:2.0:attrname-format:uri:\n    \n      \neduPersonPrincipalName: The IdP should set urn:oid:1.3.6.1.4.1.5923.1.1.1.6 as the Name of the Attribute\n      \nsn: The IdP should set urn:oid:2.5.4.4 as the Name of the Attribute\n      \ngivenName: The IdP should set urn:oid:2.5.4.42 as the Name of the Attribute\n    \n  \n  If your IdP is configured to use the NameFormat urn:oasis:names:tc:SAML:2.0:attrname-format:basic:\n    \n      \neduPersonPrincipalName: The IdP should set urn:mace:dir:attribute-def:eduPersonPrincipalName as the Name of the Attribute\n      \nsn: The IdP should set urn:mace:dir:attribute-def:sn as the Name of the Attribute\n      \ngivenName: The IdP should set urn:mace:dir:attribute-def:givenName as the Name of the Attribute\n    \n  \n  If eduPersonPrincipalName exists in the AttributeStatement, the value of this attribute will be used for the username. If eduPersonPrincipalName is not included in the AttributeStatement, the username will be taken from the NameID in the Subject. The NameID must use the Format urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress.\n  If sn and givenName are provided, they will be used to update the user’s name in their Datadog profile.\n\n\n\nSpecific SAML IdP\n\nFor more information about configuring specific IdP’s, refer to the following Knowledge Base articles:\n\n\n  Google\n  Microsoft Active Directory Federation Services\n  NoPassword\n  Okta\n\n\n\nAdditional Features\nThe following features can be enabled through the SAML Configuration dialog.\n\n\nJust in Time Provisioning (JIT Provisioning)\nNormally users must be invited to Datadog, even for organizations with SAML enabled. If a user that has not been invited to Datadog logs in via an Org’s IdP, the SAML assertion will be validated, but they will be redirected to a SAML Error page.\n\nSome organizations might not want to have to invite all of their users to Datadog. If you would like to make changes to how SAML works for your account, contact support.\n\nIt is up to the organization to configure their IdP to not send assertions to Datadog if they don’t want a particular user to access Datadog.\n\n\nIdP Initiated Login\n\nThe normal workflow is that when the Datadog url is loaded, the browser is redirected to the customer IdP, user types in credentials, then the IdP redirects back to Datadog. Some IdPs have the ability to send an assertion directly to Datadog without first getting an AuthnRequest (IdP Initiated Login).\n\nIn the normal setup, we won’t know which org the assertion came from and this will result in an error page with a message saying that SAML Response is missing “InResponseTo” attribute.\n\nAfter enabling the feature (and waiting for caches to clear) the customer will need to get a new version of the SP Metadata, which will have a different, org-specific AssertionConsumerService endpoint to send assertions to.\n\n","tags":"","loc":"/guides/saml/"},{"title":"Guide to Tagging","text":"\n\nOverview\nTagging is used throughout the Datadog product to make it easier to subset and query the machines and metrics that you have to monitor. Without the ability to assign and filter based on tags, finding the problems that exist in your environment and narrowing them down enough to discover the true causes would be extremely difficult.\n\n\nHow to assign tags\nThere are four primary ways to assign tags: inherited from the integration, in the configuration, in the UI, and using the API, though the UI and API only allow you to assign tags at the host level. The recommended method is to rely on the integration or via the configuration files.\n\n\nInheriting tags from an integration\n\nThe easiest method for assigning tags is to rely on the integration. Tags assigned to your Amazon Web Services instances, Chef recipes, Docker labels, and more are all automatically assigned to the hosts and metrics when they are brought in to Datadog.\n\nThe following integration sources create tags automatically in Datadog:\n\n\n  \n    \n      Amazon CloudFront\n      Distribution\n    \n    \n      Amazon EC2\n      AMI, Customer Gateway, DHCP Option, EBS Volume, Instance, Internet Gateway, Network ACL, Network Interface, Reserved Instance, Reserved Instance Listing, Route Table , Security Group - EC2 Classic, Security Group - VPC, Snapshot, Spot Batch, Spot Instance Request, Spot Instances, Subnet, Virtual Private Gateway, VPC, VPN Connection\n    \n    \n      Amazon Elastic File System\n      Filesystem\n    \n    \n      Amazon Kinesis\n      Stream State\n    \n    \n      Amazon Machine Learning\n      BatchPrediction, DataSource, Evaluation  , MLModel\n    \n    \n      Amazon Route 53\n      Domains, Healthchecks  , HostedZone\n    \n    \n      Amazon WorkSpaces\n      WorkSpaces\n    \n    \n      AWS CloudTrail\n      CloudTrail\n    \n    \n      AWS Elastic Load Balancing\n      Loadbalancer, TargetGroups\n    \n    \n      AWS Identity and Access Management\n      Profile Name\n    \n    \n      AWS SQS\n      Queue Name\n    \n    \n      Apache\n      Apache Host and Port\n    \n    \n      Azure\n      Tenant Name, Status, Tags, Subscription ID and Name, Availability Zone in common with AWS tag after contacting Datadog support\n    \n    \n      BTRFS\n      Usage & Replication Type\n    \n    \n      Chef\n      Chef Roles\n    \n    \n      Consul\n      Previous and Current Consul Leaders and Followers, Consul Datacenter,  Service Name, Service ID\n    \n    \n      CouchDB\n      Database Name,  Instance Name\n    \n    \n      CouchBase\n      CouchBase Tags,  Instance Name\n    \n    \n      Docker\n      Docker Container and Image Name, Container Command, Container Labels\n    \n    \n      Dyn\n      Zone, Record Type\n    \n    \n      Elasticsearch\n      Cluster Name,  Host Name, Port Number\n    \n    \n      Etcd\n      State Leader or Follower\n    \n    \n      Fluentd\n      Host Name, Port Number\n    \n    \n      Google App Engine\n      Project Name, Version ID, Task Queue\n    \n    \n      Google Cloud Platform\n      Zone, Instance Type and ID, Automatic Restart, Project Name and ID, Name, Availability Zone in common with AWS tag after contacting Datadog support\n    \n    \n      Go Expvar\n      Expvar Path\n    \n    \n      Gunicorn\n      State Idle or Working, App Name\n    \n    \n      HAProxy\n      Service Name, Availability, Backend Host, Status, Type\n    \n    \n      HTTP Check\n      URL, Instance\n    \n    \n      IIS\n      Site\n    \n    \n      Jenkins\n      Job Name, Build Number, Branch, and Results\n    \n    \n      JMX\n      JMX Tags\n    \n    \n      Kafka\n      Topic\n    \n    \n      Kubernetes\n      Minion Name, Namespace, Replication Controller, Labels, Container Alias\n    \n    \n      Marathon\n      URL\n    \n    \n      Memcached\n      Host, Port,  Request, Cache Hit or Miss\n    \n    \n      Mesos\n      Role, URL, PID, Slave or Master Role, Node, Cluster,\n    \n    \n      Mongo\n      Server Name\n    \n    \n      OpenStack\n      Network ID, Network Name, Hypervisor Name, ID, and Type, Tenant ID,  Availability Zone\n    \n    \n      PHP FPM\n      Pool Name\n    \n    \n      Pivotal\n      Current State, Owner, Labels, Requester, Story Type\n    \n    \n      Postfix\n      Queue, Instance\n    \n    \n      * Puppet\n      Puppet Tags\n    \n    \n      RabbitMQ\n      Node, Queue Name, Vhost, Policy, Host\n    \n    \n      Redis\n      Host, Port,  Slave or Master\n    \n    \n      RiakCS\n      Aggregation Key\n    \n    \n      SNMP\n      Device IP Address\n    \n    \n      Supervisord\n      Server Name, Process Name\n    \n    \n      TeamCity\n      Tags, Code Deployments, Build Number\n    \n    \n      TokuMX\n      Role Primary or Secondary, Replset, Replstate, Db, Coll, Shard\n    \n    \n      Varnish\n      Name, Backend\n    \n    \n      VSphere\n      Host, Datacenter, Server, Instance\n    \n    \n      Win32 Events\n      Event ID\n    \n    \n      Windows Services\n      Service Name\n    \n  \n\n\n\nAssigning tags using the configuration files\nThe Datadog integrations are all configured via the yaml configuration files located in the conf.d directory in your agent install. For more about where to look for your configuration files, refer to this article. You can define tags in the configuration file for the overall agent as well as for each integration, though the datadog.conf file is a more traditional ini file. In yaml files, there is a tag dictionary with a list of tags you want assigned at that level. Any tag you assign to the agent will apply to every integration on that agent’s host.\n\nDictionaries with lists of values have two different yet functionally equivalent forms:\n\ntags: firsttag, secondtag, thirdtag\n\n\nor\n\ntags:\n  - firsttag\n  - secondtag\n  - thirdtag\n\n\nYou will see both forms in the yaml configuration files, but for the datadog.conf ini file only the first form is valid.\n\nEach tag can be anything you like but you will have the best success with tagging if your tags are key:value pairs. Keys could represent the role, or function, or region, or application and the value is the instance of that role, function, region, or application. Here are some examples of good tags:\n\nregion:east\nregion:nw\napplication:database\ndatabase:primary\nrole:sobotka\n\n\nThe reason why you should use key value pairs instead of simply values will become apparent when you start using the tags to filter and group metrics and machines. That said, you are not required to use key value pairs and simple values are valid.\n\n\nAssigning host tags in the UI\nYou can also assign tags to hosts, but not to integrations in the UI. To assign tags in the UI, start by going to the Infrastructure List page. Click on any host and then click the Update Host Tags button. In the host overlay that appears, click Edit Tags and make the changes you wish.\n\n\nAssigning host tags using the API\nYou can also assign tags to hosts, but not to integrations using the API. The endpoints you want to work with are /tags/hosts and depending on whether you PUT, POST, or DELETE you will update, add, or delete tags for the chosen host. For more details on using the Tags endpoints in the API, review this document\n\n\nHow to use tags\nAfter you have assigned tags at the host and integration level, you can start using them to filter and group in interesting ways. There are several places you can use tags:\n\n\n  Events List\n  Dashboards\n  Infrastructure List\n  Host Map\n  Monitors\n\n\n\nUsing tags in the Events List\nThe Events List will show you all the events that have occured in your environment over the time period specified. This can be overwhelming so you can use tags to filter down the list based on the tags you have assigned. You can enter any text you want in the search box above the Event List and a full text search will be performed. You can also enter tags: followed by a tag to see all the events that come from a host or integration with that tag. The example in the image is the tag role:sobotka. So the search text is tags:role:sobotka.\n\n\n\n\nUsing tags in Dashboards\nYou can use tags to narrow down the metrics to display on a dashboard grapm, or to create groups of metrics to display. To narrow down the metrics to display, enter the tag in the over: textbox. You will now be looking at a chosen metric over all the hosts that have that particular tag assigned. To group using tags, enter the key part of the tag in the group: textbox. For instance, if you have a timeseries graph and you have assigned the tags role:database, role:frontend, and role:loadbalancer, you will get one line in your timeseries graph representing all the machines with the database, another of machines wth the frontend, and third of machines with the loadbalancer.\n\n\n\nYou can also use tags to overlay events on the dashboard. This works in exactly the same way as in the Events List. Simply enter tags: followed by the tag and you will see the corresponding events overlaid as vertical bars on each graph.\n\n\nUsing tags in the Infrastructure List and the Host Map\n\nTo filter the list of hosts in the Infrastructure list, enter a tag in the filter textbox at the top of the page. You can also group the hosts by entering the key portion of the tag in the group by textbox. So if you enter role in the group box, you will see each role as a group heading followed by the hosts with that tag.\n\n\n\n\nUsing tags in Monitors\n\nWhen defining a monitor, you can use tags to allow the monitor to apply to any subset of hosts across your environment.\n\n\n\n","tags":"","loc":"/guides/tagging/"},{"title":"Guide to Dashboard Templating","text":"\nDashboard templating allows you to create dashboards that use variables like $scope or $redis in place of specific tags or hosts. You can then dynamically explore the metrics across different sets of tags. Simply select a new variable value in the dropdown menu, and that value will apply across the dashboard.\n\n\nEditing template variables\n\nTo create, edit, and delete template variables click the gear icon at the upper right-hand side of the screen, then select ‘Edit Template Variables’ from the actions menu.\n\n\n\nThis will open the template variable editing panel.\n\n\n\nA template variable is defined by a name and optional parameters for ‘Tag Group’ and ‘Default Tag.’ A tag group is a prefix shared among several tags, like redis_port for the tags redis_port:6379 and redis_port:6380. Setting a tag group eliminates irrelevant tags from the variable’s scope selector, and removes the prefix from the listed values for clarity - so you’ll see 6379 and 6380 in the ‘Default Tag’ dropdown instead. The ‘Default Tag’ option determines the initial value for the variable on dashboard load.\n\n\nUsing template variables in graph editors\n\n\n\nOnce defined, template variables appear alongside normal tag and host options in graph editors. If you set 6379 as the value of $redis, all graphs defined with $redis will be scoped to redis_port:6379.\n\n\n\n","tags":"","loc":"/guides/templating/"},{"title":"Testing Integrations","text":"\n\nOverview\n\nAutomated unit tests help ensure that your integration is working as designed and guard against regression.\n\nThough we don’t require tests for each metric collected, we strongly encourage you to provide as much coverage as possible.\n\n\nAdding Tests\n\nTests can be easily added by extending the AgentCheckTest class. Additionally, you may import Attributes from Nose to manage requirements.\n\nfrom nose.plugins.attrib import attr\nfrom tests.checks.common import AgentCheckTest\n\n@attr(requires='network')\nclass HTTPCheckTest(AgentCheckTest)`\n  ...\n\n\n\nDatadog Integrations\n\nTo test integrations, add your test code to the test_[integration_name].py file in your integration directory. Creating New Integrations for more details.\n\n\nDatadog Agent Checks\n\nIf you are submitting your Agent Check as a Pull Request to be included with the Datadog Agent, please reference the README.md in the dd-agent repository.\n\n\nThe AgentCheckTest Class\n\nThe following test methods are provided by the AgentCheckTest class. For more details about the class, please reference the source code.\n\n\nTest and Check Status Methods\n\n\ncoverage_report()\n\n\nPrints the test coverage status of metrics, events, service checks and service metadata. Also lists items for each that lack test coverage.\n\n\nprint_current_state()\n\n\nPrints a report of the metrics, events, service checks, service metadata and warnings provided by the integration.\n\n\nRun Checks Methods\n\n\nrun_check(config, agent_config=None, mocks=None, force_reload=False)\n\n\nParameters:\n\n\n  \nconfig (dictionary) – A check configuration dictionary containing an array of instances. For example:\n\n\n{\n    'instances': [\n        {\n            'name': 'simple_config',\n            'url': 'http://httpbin.org',\n        }\n    ]\n}\n\n\n\n  \nagent_config (dictionary) – A customized Datadog agent configuration.\n  \nmocks (dictionary) – A dictionary keyed by method name (string) with values of method. For example:\n\n\n{\n    'get_services_in_cluster': self.mock_get_services_in_cluster,\n    'get_nodes_with_service': self.mock_get_nodes_with_service,\n}\n\n\n\n  \nforce_reload (boolean) – Reload the check before running it.\n\n\n\nrun_check_twice(config, agent_config=None, mocks=None, force_reload=False)\n\n\nSimilar to run_check, this method will run the check twice with a 1 second delay between runs.\n\n\nrun_check_n(config, agent_config=None, mocks=None, force_reload=False, repeat=1, sleep=1)\n\n\nSimilar to run_check, this method will run the check multiple times.\n\nParameters:\n\n\n  \nrepeat (integer) – The number of times the check will run.\n  \nsleep (integer) – The delay in seconds between check runs.\n\n\n\nMetric Methods\n\n\nassertMetric(metric_name, value=None, tags=None, count=None, at_least=1, hostname=None, device_name=None, metric_type=None)\n\n\nParameters:\n\n\n  \nmetric_name (string) – The name of the metric.\n  \nvalue (variable) – The value for the metric.\n  \ntags (list of strings) – The tags associated with the metric.\n  \ncount (integer) – The number of candidate metrics the assertion should test for. Typical values are:\n    \n      \nNone: will not test for the count\n      \n1: tests for exactly one metric\n      \n0: tests for no matches (works as a negation)\n    \n  \n  \nat_least (integer) – The minimum number of candidate metrics the assertion should test for.\n  \nhostname (string) – The name of the host associated with the metric.\n  \ndevice_name (string) – The name of the device associated with the metric.\n  \nmetric_type (string) – The type of metric to test for. If set, it must be one of gauge, counter, rate, or count as defined by the checks metric types.\n\n\n\nassertMetricTagPrefix(metric_name, tag_prefix, count=None, at_least=1)\n\n\nParameters:\n\n\n  \nmetric_name (string) – The name of the metric.\n  \ntag_prefix (string) – Match metrics with tags that begin with this string.\n  \ncount (integer) – The number of data points the assertion should test for.\n  \nat_least (integer) – The minimum number of data points the assertion should test for.\n\n\n\nassertMetricTag(metric_name, tag, count=None, at_least=1)\n\n\nParameters:\n\n\n  \nmetric_name (string) – The name of the metric.\n  \ntag (string) – The tag associated with the metric.\n  \ncount (integer) – The number of data points the assertion should test for.\n  \nat_least (integer) – The minimum number of data points the assertion should test for.\n\n\n\nService Methods\n\n\nassertServiceMetadata(meta_keys, count=None, at_least=1)\n\n\nParameters:\n\n\n  \nmeta_keys (list of strings) – A list of metadata keys.\n  \ncount (integer) – The number of candidate metrics the assertion should test for. Typical values are:\n    \n      \nNone: will not test for the count\n      \n1: tests for exactly one metric\n      \n0: tests for no matches (works as a negation)\n    \n  \n  \nat_least (integer) – The minimum number of candidate metrics the assertion should test for.\n\n\n\nassertServiceCheck(service_check_name, status=None, tags=None, count=None, at_least=1)\n\n\n\nassertServiceCheckOK(service_check_name, tags=None, count=None, at_least=1)\n\n\n\nassertServiceCheckWarning(service_check_name, tags=None, count=None, at_least=1)\n\n\n\nassertServiceCheckCritical(service_check_name, tags=None, count=None, at_least=1)\n\n\n\nassertServiceCheckUnknown(service_check_name, tags=None, count=None, at_least=1)\n\n\nParameters:\n\n\n  \nservice_check_name (string) – The name of the service check.\n  \ntags (list of strings) – The tags associated with the service check.\n  \ncount (integer) – The number of data points the assertion should test for.\n  \nat_least (integer) – The minimum number of data points the assertion should test for.\n\n\n\nEvent Method\n\n\nassertEvent(msg_text, count=None, at_least=1, exact_match=True, tags=None, **kwargs)\n\n\nParameters:\n\n\n  \nmsg_text (string) – The event message text.\n  \ncount (integer) – The number of candidate metrics the assertion should test for. Typical values are:\n    \n      \nNone: will not test for the count\n      \n1: tests for exactly one metric\n      \n0: tests for no matches (works as a negation)\n    \n  \n  \nat_least (integer) – The minimum number of candidate metrics the assertion should test for.\n  \nexact_match (boolean) – When true, the event message text must equal msg_text. When false, the event message text must contain msg_text.\n  \ntags (list of strings) – The tags associated with the event.\n  \nkwargs – Keyword arguments can be used to match additional event attributes.\n\n\n\nWarning Method\n\n\nassertWarning(warning, count=None, at_least=1, exact_match=True)\n\n\nParameters:\n\n\n  \nwarning (string) – The warning message text.\n  \ncount (integer) – The number of candidate warnings the assertion should test for. Typical values are:\n    \n      \nNone: will not test for the count\n      \n1: tests for exactly one warning\n      \n0: tests for no matches (works as a negation)\n    \n  \n  \nat_least (integer) – The minimum number of candidate warnings the assertion should test for.\n  \nexact_match (boolean) – When true, the warning message text must equal warning. When false, the event message text must contain warning.\n\n\n\nHelper Methods\n\nThe AgentCheckTest class provides some useful test methods that are not specifically related to Datadog metrics and events.\n\n\nassertIn(first, second)\n\n\n\nassertNotIn(first, second)\n\n\nThese methods test if the first argument is contained in the second argument using Python’s in operator.\n\nParameters:\n\n\n  \nfirst (multiple types) – The “needle” data.\n  \nsecond (multiple types) – The “haystack” data.\n\n\n\nExamples\n\n\nDatadog Integrations\n\nFor further examples of testing Datadog integrations, you can view the test files for core integrations such as the test_mysql.py file for the MySQL integration.\n\n\nDatadog Agent Checks\n\nFor examples of Agent Check tests, you can view the test files for agent checks such as test_http_check.py file.\n","tags":"","loc":"/guides/testing/"},{"title":"Getting Help","text":"\nIf you have any questions about Datadog or a use case our Docs didn’t mention, we’d love to help! Here’s how\nyou can reach out to us:\n\n\nVisit the Knowledge Base\nLearn more about what you can do in Datadog on the Support Knowledge Base.\n\n\nWeb Support\nMessages in the event stream containing\n@support-datadog will reach our Support Team. This is a convenient channel for referencing graph snapshots or a particular event. In addition, we have a livechat service available during the day (EST) from any page within the app.\n\n\nBy Email\nYou can also contact our Support Team via email at support@datadoghq.com.\n\n\nOver Slack\nReach out to our team and other Datadog users on Slack.\n\n\nStatus Page\nOur Status Page and Ops twitter account have the latest on any performance issues that we are experiencing.\n\n","tags":"","loc":"/help/"},{"title":"Host Naming","text":"\n\n  An overview of how we uniquely identify hosts and how they are displayed in\n  Datadog. If you have more questions, stop by #datadog on freenode,\nwhere we'll be happy to answer any questions you might have. (There's a \n\nweb chat client, too.)\n\n\n\nAgent Host Names\n\n\n  This applies to version 3.6 of the Agent and later. If you're having issues\n  with host names, we recommend updating to the latest version of the Agent.\n\n\nThe Datadog Agent collects potential hostnames from a number of different\nsources. To see all the names the Agent is detecting, run the Agent info\ncommand:\n\n$ sudo /etc/init.d/datadog-agent info\n\n...\n\nHostnames\n=========\n\n  hostname: my.special.hostname\n  agent-hostname: my.special.hostname\n  ec2-hostname: ip-192-0-0-1.internal\n  instance-id: i-deadbeef\n  socket-hostname: myhost\n  socket-fqdn: myhost.mydomain\n\n...\n\n\nFrom these names, a canonical name is picked for the host. This is the name the\nAgent will primarily use to identify itself to Datadog. The other names are\nsubmitted as well, but only as candidates for aliasing.\n\nThe canonical host name is picked according to the following rules. The first\nmatch is selected.\n\n\n  \nagent-hostname: If a host name is explicitly set in the Agent configuration file.\n  \nhostname: If the DNS host name is not an EC2 default (e.g. ip-192-0-0-1).\n  \ninstance-id: If the Agent can reach the EC2 metadata endpoint from the host.\n  \nhostname: Fall back on the DNS host name even if it is an EC2 default.\n\n\nIf name is recognized as obviously non-unique (e.g. localhost.localdomain),\nthe current rule fails and passes through to the next.\n\n\nHost Aliases\n\nA single host running in EC2 might have an\ninstance ID (i-abcd1234), a generic hostname provided by EC2 based on the\nhost’s IP address (ip-192-0-0-1), and a meaningful host name provided by an\ninternal DNS server or a config-managed hosts file (myhost.mydomain). Datadog\ncreates aliases for host names when there are multiple uniquely identifiable\nnames for a single host.\n\nThe names collected by the Agent (detailed above) are\nadded as aliases for the chosen canonical name.\n\nYou can see a list of all the hosts in your account from the Infrastructure tab\nin Datadog. From the Inspect panel, you can see (among other things) the list of\naliases associated with each host.\n\n\n","tags":"","loc":"/hostnames/"},{"title":"Get Started with Datadog","text":"\n\n1. Get the Datadog Agent running!\n\n\n2. Dive into Metrics!\n\n\n3. Graph them!\n\n\nNot sure where to look? Our documentation is split into guides and references. Guides explain how to\naccomplish a particular task with Datadog, while the references are more general (as you might expect).\nIt might be a good idea to start with the Datadog Overview, which explains Datadog’s\ncapabilities at a high level.\n\nSearch for it! If you know roughly what you are looking for, enter it in the search box on the top left of the sidebar.\n\nIf you have questions, we’re here to help. You can get in touch with\nour support team by mentioning @support-datadog in a comment on Datadog itself, or by\nemail, on Slack, or on our customer service site.\n\nFind a mistake in this documentation? Let us know on GitHub\nand we’ll take care of it.\n\n","tags":"","loc":"/"},{"title":"Installing the Agent on Debian 5","text":"\n\nOne-Step\nThe Agent can be installed on Debian Lenny (5.0) using our one-step install command: \n\nDD_API_KEY=your_api_key bash -c \"$(wget -qO- http://dtdg.co/agent-install-debian)\"\n\n\nBe sure to substitute your API key into the command. Your key can be found here.\n\n\nStep-by-Step\nIf you prefer, the Agent can also be installed by following our step-by-step instructions:\n\nSet up the Datadog deb repo on your system and import Datadog’s apt key:\n\nsudo sh -c \"echo 'deb http://apt.datadoghq.com/ unstable main' > /etc/apt/sources.list.d/datadog.list\"\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C7A7DA52\n\n\nUpdate your local apt repo and install the Agent:\n\nsudo apt-get update\nsudo apt-get install datadog-agent-base\n\n\nCopy the example config into place. Be sure to plug in your API key into the command:\n\nsudo sh -c \"sed 's/api_key:.*/api_key: your_api_key' /etc/dd-agent/datadog.conf.example > /etc/dd-agent/datadog.conf\"\n\n\nStart the Agent:\n\nsudo /etc/init.d/datadog-agent start\n\n","tags":"","loc":"/install_debian_5/"},{"title":"Datadog-ActiveMQ Integration","text":"\n\nOverview\n\nGet metrics from ActiveMQ in real time to\n\n\n  Visualize your web ActiveMQ server performance\n  Correlate the performance of ActiveMQ with the rest of your applications\n\n\n\nConfiguration\n\nThis integration requires Linux or Mac OS X.\n\nTo capture ActiveMQ metrics you need to install the Datadog agent. Metrics will be captured using a JMX connection. We recommend the use of Oracle’s JDK for this integration.\n\n\n  Make sure that  JMX Remote is enabled on your ActiveMQ server.\n  \n    Configure the agent to connect to ActiveMQ. Edit ${confd_help('conf.d/activemq.yaml')}\n\n     instances:\n   - host: localhost\n     port: 7199\n     user: username\n     password: password\n     name: activemq_instance\n # List of metrics to be collected by the integration\n # You should not have to modify this.\n init_config:\n   conf:\n     - include:\n       Type: Queue\n       attribute:\n         AverageEnqueueTime:\n           alias: activemq.queue.avg_enqueue_time\n           metric_type: gauge\n         ConsumerCount:\n           alias: activemq.queue.consumer_count\n           metric_type: gauge\n         ProducerCount:\n           alias: activemq.queue.producer_count\n           metric_type: gauge\n         MaxEnqueueTime:\n           alias: activemq.queue.max_enqueue_time\n           metric_type: gauge\n         MinEnqueueTime:\n           alias: activemq.queue.min_enqueue_time\n           metric_type: gauge\n         MemoryPercentUsage:\n           alias: activemq.queue.memory_pct\n           metric_type: gauge\n         QueueSize:\n           alias: activemq.queue.size\n           metric_type: gauge\n         DequeueCount:\n           alias: activemq.queue.dequeue_count\n           metric_type: counter\n         DispatchCount:\n           alias: activemq.queue.dispatch_count\n           metric_type: counter\n         EnqueueCount:\n           alias: activemq.queue.enqueue_count\n           metric_type: counter\n         ExpiredCount:\n           alias: activemq.queue.expired_count\n           type: counter\n         InFlightCount:\n           alias: activemq.queue.in_flight_count\n           metric_type: counter\n\n     - include:\n       Type: Broker\n       attribute:\n         StorePercentUsage:\n           alias: activemq.broker.store_pct\n           metric_type: gauge\n         TempPercentUsage:\n           alias: activemq.broker.temp_pct\n           metric_type: gauge\n         MemoryPercentUsage:\n           alias: activemq.broker.memory_pct\n           metric_type: gauge\n\n  \n  \n    Restart the agent\n\n     sudo /etc/init.d/datadog-agent restart\n\n\n     if [ $(sudo supervisorctl status | egrep \"datadog-agent.*RUNNING\" | wc -l) == 3 ]; \\\n then echo -e \"\\e[0;32mAgent is running\\e[0m\"; \\\n else echo -e \"\\e[031mAgent is not running\\e[0m\"; fi\n\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\nActiveMQ YAML example\n\n\nMetrics\n\n\n\n\nactivemq.queue.avg_enqueue_time(gauge every 10 seconds)\nOn average  the amount of time (ms) that messages remained enqueued.shown as millisecond\n\n\n\n\nactivemq.queue.consumer_count(gauge every 10 seconds)\nThe number of consumers connected\n\n\n\n\nactivemq.queue.producer_count(gauge every 10 seconds)\nThe number of producers connected\n\n\n\n\nactivemq.queue.max_enqueue_time(gauge every 10 seconds)\nThe max  the amount of time (ms) that messages remained enqueued.shown as millisecond\n\n\n\n\nactivemq.queue.min_enqueue_time(gauge every 10 seconds)\nThe min  the amount of time (ms) that messages remained enqueued.shown as millisecond\n\n\n\n\nactivemq.queue.memory_pct(gauge every 10 seconds)\nThe percentage of memory currently in useshown as percent\n\n\n\n\nactivemq.queue.size(gauge every 10 seconds)\nThe amount of messages that remained queued.\n\n\n\n\nactivemq.queue.dequeue_count(gauge every 10 seconds)\nThe amount of messages that remained dequeued.\n\n\n\n\nactivemq.queue.dispatch_count(gauge every 10 seconds)\nThe amount of messages that have been dispatched.\n\n\n\n\nactivemq.queue.enqueue_count(gauge every 10 seconds)\nThe amount of messages that have been enqueued.\n\n\n\n\nactivemq.queue.expired_count(gauge every 10 seconds)\nThe amount of messages that have been expired.\n\n\n\n\nactivemq.queue.in_flight_count(gauge every 10 seconds)\nThe amount of messages that have been in flight.\n\n\n\n\nactivemq.broker.store_pct(gauge every 10 seconds)\nThe percentage of store in use.shown as percent\n\n\n\n\nactivemq.broker.temp_pct(gauge every 10 seconds)\nThe percentage of temporary in use.shown as percent\n\n\n\n\nactivemq.broker.memory_pct(gauge every 10 seconds)\nThe percentage of memory in use.shown as percent\n\n\n\n\n","tags":"","loc":"/integrations/activemq/"},{"title":"Datadog-Airbrake Integration","text":"\n\nOverview\n\n\n\nConnect Airbrake to Datadog to:\n\n\n  See exceptions in the stream, in real time\n  Search for exceptions in your graphs\n  Discuss exceptions with your team\n\n\n\nConfiguration\n\nGo to your Airbrake account page and copy your Account Name and Token into the form below.\nYou can either choose to follow all projects or specify a project name to follow.\nIf “All projects” box is ticked and a project name is specified, all projects will be followed.\n\n\nMetrics\n\n\n\nairbrake.exception_rate(gauge)\nThe rate of exceptions.shown as occurrence/minute\n\n\n","tags":"","loc":"/integrations/airbrake/"},{"title":"Datadog-Ansible Integration","text":"\n\nOverview\n\n\n\nInstall the Datadog Ansible callback integration to:\n\n\n  Get real-time reports on Ansible server runs\n  Track key Ansible performance metrics across all your servers\n  Quickly identify and discuss failed Ansible runs with your team\n\n\nFor more information about using our integration with Ansible, read this post on our blog.\n\n\nInstallation\n\n\n  \n    Ensure the prerequisite python libraries are installed on the server:\n\n    \n      datadogpy\n      pyyaml (install with pip install pyyaml)\n    \n  \n  Clone the ansible-datadog-callback GitHub repo.\n  Copy datadog_callback.py to your playbook callback directory (by default callback_plugins/ in your playbook’s root directory). Create the directory if it doesn’t exist.\n  \n    Create a datadog_callback.yml file alongside datadog_callback.py, and set its contents with your API key, as following:\n\n    api_key: <your-api-key>\n\n  \n  You should start seeing Ansible events and metrics appear on Datadog when your playbook is run.\n\n\nTo install the Datadog Agent using Ansible, refer to the installation documentation here.\n\n\nMetrics\n\n\n\n\nansible.elapsed_time(gauge)\nTime taken to execute a playbookshown as second\n\n\n\n\nansible.task.ok(gauge)\nNumber of tasks that did not require any changeshown as task\n\n\n\n\nansible.task.failures(gauge)\nNumber of tasks that failedshown as task\n\n\n\n\nansible.task.skipped(gauge)\nNumber of tasks that got skippedshown as task\n\n\n\n\nansible.task.unreachable(gauge)\nNumber of tasks for which nodes were unreachableshown as task\n\n\n\n\nansible.task.changed(gauge)\nNumber of tasks that successfully applied changesshown as task\n\n\n\n","tags":"","loc":"/integrations/ansible/"},{"title":"Datadog-Apache Integration","text":"\n\nOverview\n\n\n\nGet metrics from Apache in real time; graph them and correlate them with other relevant system metrics and events.\n\n\n  Visualize your web server performance\n  Correlate the performance of Apache with the rest of your applications\n\n\n\nInstallation\n\nMake sure that mod_status is installed on your Apache server with ExtendedStatus set to on\n\n\nConfiguration\n\nTo capture Apache metrics you need to install the Datadog agent.\n\n\n  \n    Configure the agent to connect to Apache. Edit /etc/dd-agent/conf.d/apache.yaml\n\n    init_config:\n\ninstances:\n  - apache_status_url: http://example.com/server-status?auto\n    # apache_user: example_user\n    # apache_password: example_password\n    tags:\n      - instance:foo\n    disable_ssl_validation: true # if you want to disable SSL cert validation\n\n  \n  \n    Restart the agent\n\n     sudo /etc/init.d/datadog-agent restart\n\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nApache YAML example\nApache checks.d\n\n\n\nValidation\n\nTo ensure the integration is installed correctly, run the agent info command.\n\nsudo /etc/init.d/datadog-agent info\n\n\nYou should see something similar to the following if everything is working correctly:\n\nChecks\n======\n\n  [...]\n\n  apache\n  ------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\nThe following metrics are collected by default with the Apache integration:\n\n\n\n\napache.net.bytes(gauge)\nThe total number of bytes served.shown as byte\n\n\n\n\napache.net.bytes_per_s(gauge)\nThe number of bytes served per second.shown as byte/second\n\n\n\n\napache.net.hits(gauge)\nThe total number of requests performed.shown as request\n\n\n\n\napache.net.request_per_s(gauge)\nThe number of requests performed per second.shown as request/second\n\n\n\n\napache.performance.cpu_load(gauge)\nThe percent of CPU used.shown as percent\n\n\n\n\napache.performance.busy_workers(gauge)\nThe number of workers serving requests.shown as thread\n\n\n\n\napache.performance.idle_workers(gauge)\nThe number of idle workers.shown as thread\n\n\n\n\napache.performance.uptime(gauge)\nThe amount of time the server has been running.shown as second\n\n\n\n\n","tags":"","loc":"/integrations/apache/"},{"title":"Datadog-AWS Integration","text":"\n\nOverview\n\nConnect to Amazon Web Services (AWS) in order to:\n\n\n  See automatic AWS status updates in your stream\n  Get CloudWatch metrics for EC2 hosts without installing the Agent\n  Tag your EC2 hosts with EC2-specific information (e.g. availability zone)\n  See EC2 scheduled maintenances events in your stream\n  Collect CloudWatch metrics and events from many other AWS products\n\n\nRelated integrations include:\n\n\n  \n    \n      API Gateway\n      create, publish, maintain, and secure APIs\n    \n    \n      Autoscaling\n      scale EC2 capacity\n    \n    \n      Billing\n      billing and budgets\n    \n    \n      CloudFront\n      glocal content delivery network\n    \n    \n      CloudTrail\n      Access to log files and AWS API calls\n    \n    \n      CloudSearch\n      Access to log files and AWS API calls\n    \n    \n      Dynamo DB\n      NoSQL Database\n    \n    \n      EC2 Container Service (ECS)\n      container management service that supports Docker containers\n    \n    \n      Elastic Beanstalk\n      easy-to-use service for deploying and scaling web applications and services\n    \n    \n      Elastic Block Store (EBS)\n      persistent block level storage volumes\n    \n    \n      ElastiCache\n      in-memory cache in the cloud\n    \n    \n      Elastic Cloud Compute (EC2)\n      resizable compute capacity in the cloud\n    \n    \n      Elastic File System (EFS)\n      shared file storage\n    \n    \n      Elastic Load Balancing (ELB)\n      distributes incoming application traffic across multiple Amazon EC2 instances\n    \n    \n      Elastic Map Reduce (EMR)\n      data processing using Hadoop\n    \n    \n      Elasticsearch Service (ES)\n      deploy, operate, and scale Elasticsearch clusters\n    \n    \n      Firehose\n      capture and load streaming data\n    \n    \n      IOT\n      connect IOT devices with cloud services\n    \n    \n      Kinesis\n      service for real-time processing of large, distributed data streams\n    \n    \n      Key Management Service (KMS)\n      create and control encryption keys\n    \n    \n      Lambda\n      serverless computing\n    \n    \n      Machine Learning (ML)\n      create machine learning models\n    \n    \n      OpsWorks\n      configuration management\n    \n    \n      Polly\n      text-speech service\n    \n    \n      Redshift\n      data warehouse solution\n    \n    \n      Relational Database Service (RDS)\n      relational database in the cloud\n    \n    \n      Route 53\n      DNS and traffic management with availability monitoring\n    \n    \n      Simple Email Service (SES)\n      cost-effective, outbound-only email-sending service\n    \n    \n      Simple Notification System (SNS)\n      alert and notifications\n    \n    \n      Simple Queue Service (SQS)\n      messaging queue service\n    \n    \n      Simple Storage Service (S3)\n      highly available and scalable cloud storage service\n    \n    \n      Simple Workflow Service (SWF)\n      cloud workflow management\n    \n    \n      Storage Gateway\n      hybrid cloud storage\n    \n    \n      Web Application Firewall (WAF)\n      protect web applications from common web exploits\n    \n    \n      Workspaces\n      secure desktop computing service\n    \n  \n\n\n\nInstallation\n\nSetting up the Datadog integration with Amazon Web Services requires configuring role delegation using AWS IAM. To get a better\nunderstanding of role delegation, refer to the AWS IAM Best Practices guide.\n\nNote: The GovCloud and China regions do not currently support IAM role delegation. If you are deploying in these regions please skip to the configuration section below.\n\n\n  \n    First create a new policy in the IAM Console. Name the policy DatadogAWSIntegrationPolicy, or choose a name that is more relevant for you. To take advantage of every AWS integration offered by Datadog, using the following in the Policy Document textbox. As we add other components to the integration, these permissions may change.\n\n    {\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"autoscaling:Describe*\",\n        \"budgets:ViewBudget\",\n        \"cloudtrail:DescribeTrails\",\n        \"cloudtrail:GetTrailStatus\",\n        \"cloudwatch:Describe*\",\n        \"cloudwatch:Get*\",\n        \"cloudwatch:List*\",\n        \"dynamodb:list*\",\n        \"dynamodb:describe*\",\n        \"ec2:Describe*\",\n        \"ec2:Get*\",\n        \"ecs:Describe*\",\n        \"ecs:List*\",\n        \"elasticache:Describe*\",\n        \"elasticache:List*\",\n        \"elasticloadbalancing:Describe*\",\n        \"elasticmapreduce:List*\",\n        \"elasticmapreduce:Describe*\",\n        \"es:ListTags\",\n        \"es:ListDomainNames\",\n        \"es:DescribeElasticsearchDomains\",\n        \"kinesis:List*\",\n        \"kinesis:Describe*\",\n        \"logs:Get*\",\n        \"logs:Describe*\",\n        \"logs:FilterLogEvents\",\n        \"logs:TestMetricFilter\",\n        \"rds:Describe*\",\n        \"rds:List*\",\n        \"route53:List*\",\n        \"s3:GetBucketTagging\",\n        \"s3:ListAllMyBuckets\",\n        \"ses:Get*\",\n        \"sns:List*\",\n        \"sns:Publish\",\n        \"sqs:ListQueues\",\n        \"support:*\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\n\n\n    If you are not comfortable with granting all of these permissions, at the very least use the existing policies named AmazonEC2ReadOnlyAccess and CloudWatchReadOnlyAccess. For more detailed information regarding permissions, please see the Permissions section below.\n  \n  Create a new role in the IAM Console. Name it anything you like, such as DatadogAWSIntegrationRole.\n  From the selection, choose Role for Cross-Account Access.\n  Click the Select button for Allows IAM users from a 3rd party AWS account to access this account.\n  For Account ID, enter 464622532012 (Datadog’s account ID). This means that you will grant Datadog and Datadog only read access to your AWS data. For External ID, enter the one generated on our website. Make sure you leave Require MFA disabled. For more information about the External ID, refer to this document in the IAM User Guide.\n  Select the policy you created above.\n  Review what you selected and click the Create Role button.\n\n\n\nConfiguration\n\n\n\n\n  Open the AWS Integration tile.\n  Select the Role Delegation tab.\n  Enter your AWS Account ID without dashes, e.g. 123456789012, not 1234-5678-9012. Your Account ID can be found in the ARN of the newly created role. Then enter the name of the role you just created. Finally enter the External ID you specified above.\n  Choose the services you want to collect metrics for on the left side of the dialog. You can optionally add tags to all hosts and metrics. Also if you want to only monitor a subset of EC2 instances on AWS, tag them and specify the tag in the limit textbox here.\n  Click Install Integration.\n\n\n\nConfiguration for China and GovCloud\n\n\n  Open the AWS Integration tile.\n  Select the Access Keys (GovCloud or China Only) tab.\n  Enter your AWS Access Key and AWS Secret Key. Note: only access and secret keys for China and GovCloud are accepted.\n  Choose the services you want to collect metrics for on the left side of the dialog. You can optionally add tags to all hosts and metrics. Also if you want to only monitor a subset of EC2 instances on AWS, tag them and specify the tag in the limit textbox here.\n  Click Install Integration.\n\n\n\nMetrics\n\n\n\n\naws.logs.incoming_bytes(gauge)\nThe volume of log events in uncompressed bytes uploaded to Cloudwatch Logs.shown as byte\n\n\n\n\naws.logs.incoming_log_events(count)\nThe number of log events uploaded to Cloudwatch Logs.shown as event\n\n\n\n\naws.logs.forwarded_bytes(gauge)\nThe volume of log events in compressed bytes forwarded to the subscription destination.shown as byte\n\n\n\n\naws.logs.forwarded_log_events(count)\nThe number of log events forwarded to the subscription destination.shown as event\n\n\n\n\naws.logs.delivery_errors(count)\nThe number of log events for which CloudWatch Logs received an error when forwarding data to the subscription destination.shown as event\n\n\n\n\naws.logs.delivery_throttling(count)\nThe number of log events for which CloudWatch Logs was throttled when forwarding data to the subscription destination.shown as event\n\n\n\n\naws.ec2spot.available_instance_pools_count(count)\nThe Spot Instance pools specified in the Spot Fleet request.shown as instance\n\n\n\n\naws.ec2spot.bids_submitted_for_capacity(count)\nThe capacity for which Amazon EC2 has submitted bids.shown as instance\n\n\n\n\naws.ec2spot.eligible_instance_pool_count(count)\nThe Spot Instance pools specified in the Spot Fleet request where Amazon EC2 can fulfill bids.shown as instance\n\n\n\n\naws.ec2spot.fulfilled_capacity(count)\nThe capacity that Amazon EC2 has fulfilled.shown as instance\n\n\n\n\naws.ec2spot.max_percent_capacity_allocation(gauge)\nThe maximum value of PercentCapacityAllocation across all Spot Instance pools specified in the Spot Fleet request.shown as percent\n\n\n\n\naws.ec2spot.pending_capacity(count)\nThe difference between TargetCapacity and FulfilledCapacity.shown as instance\n\n\n\n\naws.ec2spot.percent_capacity_allocation(gauge)\nThe capacity allocated for the Spot Instance pool for the specified dimensions.shown as percent\n\n\n\n\naws.ec2spot.target_capacity(count)\nThe target capacity of the Spot Fleet request.shown as instance\n\n\n\n\naws.ec2spot.terminating_capacity(count)\nThe capacity that is being terminated due to Spot Instance interruptions.shown as instance\n\n\n\n\naws.dms.cpuutilization(gauge)\nAverage percentage of allocated EC2 compute units that are currently in use on the instance.\n\n\n\n\naws.dms.free_storage_space(gauge)\nThe amount of available storage spaceshown as byte\n\n\n\n\naws.dms.freeable_memory(gauge)\nThe amount of available random access memory.shown as byte\n\n\n\n\naws.dms.write_iops(gauge)\nThe average number of disk I/O operations per secondshown as operation/second\n\n\n\n\naws.dms.read_iops(gauge)\nThe average number of disk I/O operations per second.shown as operation/second\n\n\n\n\naws.dms.write_throughput(gauge)\nThe average number of bytes written to disk per second.shown as byte/second\n\n\n\n\naws.dms.read_throughput(gauge)\nThe average number of bytes read from disk per second.shown as byte/second\n\n\n\n\naws.dms.write_latency(gauge)\nThe average amount of time taken per write disk I/O operationshown as second\n\n\n\n\naws.dms.read_latency(gauge)\nThe average amount of time taken per read disk I/O operationshown as second\n\n\n\n\naws.dms.swap_usage(gauge)\nThe amount of swap space used on the DB Instanceshown as byte\n\n\n\n\naws.dms.network_transmit_throughput(gauge)\nThe outgoing (Transmit) network traffic on the DB instance including both customer database traffic and Amazon RDS traffic used for monitoring and replicationshown as byte/second\n\n\n\n\naws.dms.network_receive_throughput(gauge)\nThe incoming (Receive) network traffic on the DB instance including both customer database traffic and Amazon RDS traffic used for monitoring and replication.shown as byte/second\n\n\n\n\naws.dms.full_load_throughput_bandwidth_source(gauge)\nIncoming network bandwidth from a full load from the sourceshown as kibibyte/second\n\n\n\n\naws.dms.full_load_throughput_bandwidth_target(gauge)\nOutgoing network bandwidth from a full load for the targetshown as kibibyte/second\n\n\n\n\naws.dms.full_load_throughput_rows_source(gauge)\nIncoming changes from a full load from the source in rows per secondshown as row/second\n\n\n\n\naws.dms.full_load_throughput_rows_target(gauge)\nOutgoing changes from a full load for the targetshown as row\n\n\n\n\naws.dms.cdcincoming_changes(gauge)\nTotal row count of changes for the taskshown as row\n\n\n\n\naws.dms.cdcchanges_memory_source(gauge)\nAmount of rows accumulating in a memory and waiting to be committed from the sourceshown as row\n\n\n\n\naws.dms.cdcchanges_memory_target(gauge)\nAmount of rows accumulating in a memory and waiting to be committed to the targetshown as row\n\n\n\n\naws.dms.cdcchanges_disk_source(gauge)\nAmount of rows accumulating on disk and waiting to be committed from the sourceshown as row\n\n\n\n\naws.dms.cdcchanges_disk_target(gauge)\nAmount of rows accumulating on disk and waiting to be committed to the targetshown as row\n\n\n\n\naws.dms.cdcthroughput_bandwidth_source(gauge)\nIncoming task network bandwidth from the sourceshown as kibibyte/second\n\n\n\n\naws.dms.cdcthroughput_bandwidth_target(gauge)\nOutgoing task network bandwidth for the targetshown as kibibyte/second\n\n\n\n\naws.dms.cdcthroughput_rows_source(gauge)\nIncoming task changes from the sourceshown as row/second\n\n\n\n\naws.dms.cdcthroughput_rows_target(gauge)\nOutgoing task changes for the targetshown as row/second\n\n\n\n\naws.dms.cdclatency_source(gauge)\nLatency reading from sourceshown as second\n\n\n\n\naws.dms.cdclatency_target(gauge)\nLatency writing to the targetshown as second\n\n\n\n\naws.events.invocations(count)\nMeasures the number of times a target is invoked for a rule in response to an event. This includes successful and failed invocations but does not include throttled or retried attempts until they fail permanently.\n\n\n\n\naws.events.failed_invocations(count)\nMeasures the number of invocations that failed permanently. This does not include invocations that are retried or that succeeded after a retry attempt\n\n\n\n\naws.events.triggered_rules(count)\nMeasures the number of triggered rules that matched with any event.\n\n\n\n\naws.events.matched_events(count)\nMeasures the number of events that matched with any rule.\n\n\n\n\naws.events.throttled_rules(count)\nMeasures the number of triggered rules that are being throttled.\n\n\n\n\naws.states.execution_time(gauge every 60 seconds)\nThe average time interval, in milliseconds, between the time the execution started and the time it closed.shown as millisecond\n\n\n\n\naws.states.execution_time.maximum(gauge every 60 seconds)\nThe maximum time interval, in milliseconds, between the time the execution started and the time it closed.shown as millisecond\n\n\n\n\naws.states.execution_time.minimum(gauge every 60 seconds)\nThe minimum time interval, in milliseconds, between the time the execution started and the time it closed.shown as millisecond\n\n\n\n\naws.states.execution_time.p95(gauge every 60 seconds)\nThe 95th percentile time interval, in milliseconds, between the time the execution started and the time it closed.shown as millisecond\n\n\n\n\naws.states.execution_time.p99(gauge every 60 seconds)\nThe 99th percentile time interval, in milliseconds, between the time the execution started and the time it closed.ilshown as millisecond\n\n\n\n\naws.states.executions_aborted(count every 60 seconds)\nThe number of executions that were aborted/terminated.\n\n\n\n\naws.states.executions_failed(count every 60 seconds)\nThe number of executions that failed.\n\n\n\n\naws.states.executions_started(count every 60 seconds)\nThe number of executions started.\n\n\n\n\naws.states.executions_succeeded(count every 60 seconds)\nThe number of executions that completed successfully.\n\n\n\n\naws.states.executions_timed_out(count every 60 seconds)\nThe number of executions that timed out for any reason.\n\n\n\n\naws.states.lambda_function_run_time(gauge every 60 seconds)\nThe average time interval, in milliseconds, between the time the lambda function was started and when it was closed.shown as millisecond\n\n\n\n\naws.states.lambda_function_run_time.maximum(gauge every 60 seconds)\nThe  maximum time interval, in milliseconds, between the time the lambda function was started and when it was closed.shown as millisecond\n\n\n\n\naws.states.lambda_function_run_time.minimum(gauge every 60 seconds)\nThe minimum time interval, in milliseconds, between the time the lambda function was started and when it was closed.shown as millisecond\n\n\n\n\naws.states.lambda_function_run_time.p95(gauge every 60 seconds)\nThe 95th percentile time interval, in milliseconds, between the time the lambda function was started and when it was closed.shown as millisecond\n\n\n\n\naws.states.lambda_function_run_time.p99(gauge every 60 seconds)\nThe 99th percentile time interval, in milliseconds, between the time the lambda function was started and when it was closed.shown as millisecond\n\n\n\n\naws.states.lambda_function_schedule_time(gauge every 60 seconds)\nThe avg time interval, in milliseconds, that the activity stayed in the schedule state.shown as millisecond\n\n\n\n\naws.states.lambda_function_schedule_time.maximum(gauge every 60 seconds)\nThe maximum time interval, in milliseconds, that the activity stayed in the schedule state.shown as millisecond\n\n\n\n\naws.states.lambda_function_schedule_time.minimum(gauge every 60 seconds)\nThe minimum time interval, in milliseconds, that the activity stayed in the schedule state.shown as millisecond\n\n\n\n\naws.states.lambda_function_schedule_time.p95(gauge every 60 seconds)\nThe 95th percentile time interval, in milliseconds, that the activity stayed in the schedule state.shown as millisecond\n\n\n\n\naws.states.lambda_function_schedule_time.p99(gauge every 60 seconds)\nThe 99th percentile time interval, in milliseconds, that the activity stayed in the schedule state.shown as millisecond\n\n\n\n\naws.states.lambda_function_time(gauge every 60 seconds)\nThe average time interval, in milliseconds, between the time the lambda function was scheduled and when it was closed.shown as millisecond\n\n\n\n\naws.states.lambda_function_time.maximum(gauge every 60 seconds)\nThe maximum time interval, in milliseconds, between the time the lambda function was scheduled and when it was closed.shown as millisecond\n\n\n\n\naws.states.lambda_function_time.minimum(gauge every 60 seconds)\nThe minimum time interval, in milliseconds, between the time the lambda function was scheduled and when it was closed.shown as millisecond\n\n\n\n\naws.states.lambda_function_time.p95(gauge every 60 seconds)\nThe 95th percentile time interval, in milliseconds, between the time the lambda function was scheduled and when it was closed.shown as millisecond\n\n\n\n\naws.states.lambda_function_time.p99(gauge every 60 seconds)\nThe 99th percentile time interval, in milliseconds, between the time the lambda function was scheduled and when it was closed.shown as millisecond\n\n\n\n\naws.states.lambda_functions_failed(count every 60 seconds)\nThe number of lambda functions that failed.\n\n\n\n\naws.states.lambda_functions_heartbeat_timed_out(count every 60 seconds)\nThe number of lambda functions that were timed out due to a heartbeat timeout.\n\n\n\n\naws.states.lambda_functions_scheduled(count every 60 seconds)\nThe number of lambda functions that were scheduled.\n\n\n\n\naws.states.lambda_functions_started(count every 60 seconds)\nThe number of lambda functions that were started.\n\n\n\n\naws.states.lambda_functions_succeeded(count every 60 seconds)\nThe number of lambda functions that completed successfully.\n\n\n\n\naws.states.lambda_functions_timed_out(count every 60 seconds)\nThe number of lambda functions that were timed out on close.\n\n\n\n\naws.states.activity_run_time(gauge every 60 seconds)\nThe average time interval, in milliseconds, between the time the activity was started and when it was closed.shown as millisecond\n\n\n\n\naws.states.activity_run_time.maximum(gauge every 60 seconds)\nThe  maximum time interval, in milliseconds, between the time the activity was started and when it was closed.shown as millisecond\n\n\n\n\naws.states.activity_run_time.minimum(gauge every 60 seconds)\nThe minimum time interval, in milliseconds, between the time the activity was started and when it was closed.shown as millisecond\n\n\n\n\naws.states.activity_run_time.p95(gauge every 60 seconds)\nThe 95th percentile time interval, in milliseconds, between the time the activity was started and when it was closed.shown as millisecond\n\n\n\n\naws.states.activity_run_time.p99(gauge every 60 seconds)\nThe 99th percentile time interval, in milliseconds, between the time the activity was started and when it was closed.shown as millisecond\n\n\n\n\naws.states.activity_schedule_time(gauge every 60 seconds)\nThe avg time interval, in milliseconds, that the activity stayed in the schedule state.shown as millisecond\n\n\n\n\naws.states.activity_schedule_time.maximum(gauge every 60 seconds)\nThe maximum time interval, in milliseconds, that the activity stayed in the schedule state.shown as millisecond\n\n\n\n\naws.states.activity_schedule_time.minimum(gauge every 60 seconds)\nThe minimum time interval, in milliseconds, that the activity stayed in the schedule state.shown as millisecond\n\n\n\n\naws.states.activity_schedule_time.p95(gauge every 60 seconds)\nThe 95th percentile time interval, in milliseconds, that the activity stayed in the schedule state.shown as millisecond\n\n\n\n\naws.states.activity_schedule_time.p99(gauge every 60 seconds)\nThe 99th percentile time interval, in milliseconds, that the activity stayed in the schedule state.shown as millisecond\n\n\n\n\naws.states.activity_time(gauge every 60 seconds)\nThe average time interval, in milliseconds, between the time the activity was scheduled and when it was closed.shown as millisecond\n\n\n\n\naws.states.activity_time.maximum(gauge every 60 seconds)\nThe maximum time interval, in milliseconds, between the time the activity was scheduled and when it was closed.shown as millisecond\n\n\n\n\naws.states.activity_time.minimum(gauge every 60 seconds)\nThe minimum time interval, in milliseconds, between the time the activity was scheduled and when it was closed.shown as millisecond\n\n\n\n\naws.states.activity_time.p95(gauge every 60 seconds)\nThe 95th percentile time interval, in milliseconds, between the time the activity was scheduled and when it was closed.shown as millisecond\n\n\n\n\naws.states.activity_time.p99(gauge every 60 seconds)\nThe 99th percentile time interval, in milliseconds, between the time the activity was scheduled and when it was closed.shown as millisecond\n\n\n\n\naws.states.activitys_failed(count every 60 seconds)\nThe number of activities that failed.\n\n\n\n\naws.states.activitys_heartbeat_timed_out(count every 60 seconds)\nThe number of activities that were timed out due to a heartbeat timeout.\n\n\n\n\naws.states.activitys_scheduled(count every 60 seconds)\nThe number of activities that were scheduled.\n\n\n\n\naws.states.activitys_started(count every 60 seconds)\nThe number of activities that were started.\n\n\n\n\naws.states.activitys_succeeded(count every 60 seconds)\nThe number of activities that completed successfully.\n\n\n\n\naws.states.activitys_timed_out(count every 60 seconds)\nThe number of activities that were timed out on close.\n\n\n\n\n\nPermissions\n\nThe core Datadog-AWS integration pulls data from AWS CloudWatch. At a minimum, your Policy Document will need to allow the following actions:\n\n\n  \ncloudwatch:ListMetrics to list the available CloudWatch metrics.\n  \ncloudwatch:GetMetricStatistics to fetch data points for a given metric.\n\n\nNote that these actions and the ones listed below are included in the Policy Document using wild cards such as List* and Get*. If you require strict policies, please use the complete action names as listed and reference the Amazon API documentation for the services you require.\n\nBy allowing Datadog to read the following additional endpoints, the AWS integration will be able to add tags to CloudWatch metrics and generate additional metrics.\n\n\nAutoscaling\n\n\n  \nautoscaling:DescribeAutoScalingGroups: Used to list all autoscaling groups.\n  \nautoscaling:DescribePolicies: List available policies (for autocompletion in events and monitors).\n  \nautoscaling:DescribeTags: Used to list tags for a given autoscaling group. This will add ASG custom tags on ASG CloudWatch metrics.\n  \nautoscaling:DescribeScalingActivities: Used to generate events when an ASG scales up or down.\n  \nautoscaling:ExecutePolicy: Execute one policy (scale up or down from a monitor or the events feed). Note: This is not included in the installation Policy Document and should only be included if you are using monitors or events to execute an autoscaling policy.\n\n\nFor more information on Autoscaling policies, review the documentation on the AWS website.\n\n\nBilling\n\n\n  \nbudgets:ViewBudget: Used to view budget metrics\n\n\nFor more information on Budget policies, review the documentation on the AWS website.\n\n\nCloudTrail\n\n\n  \ncloudtrail:DescribeTrails: Used to list trails and find in which s3 bucket they store the trails\n  \ncloudtrail:GetTrailStatus: Used to skip inactive trails\n\n\nFor more information on CloudTrail policies, review the documentation on the AWS website.\n\nCloudTrail also requires some s3 permissions to access the trails. These are required on the CloudTrail bucket only\n\n\n  \ns3:ListBucket: List objects in the CloudTrail bucket to get available trails\n  \ns3:GetBucketLocation: Get bucket’s region to download trails\n  \ns3:GetObject: Fetch available trails\n\n\nFor more information on S3 policies, review the documentation on the AWS website.\n\n\nDynamoDB\n\n\n  \ndynamodb:ListTables: Used to list available DynamoDB tables.\n  \ndynamodb:DescribeTable: Used to add metrics on a table size and item count.\n  \ndynamodb:ListTagsOfResource: Used to collect all tags on a DynamoDB resource.\n\n\nFor more information on DynamoDB policies, review the documentation on the AWS website.\n\n\nEC2\n\n\n  \nec2:DescribeInstanceStatus: Used by the ELB integration to assert the health of an instance. Used by the EC2 integration to describe the health of all instances.\n  \nec2:DescribeSecurityGroups: Adds SecurityGroup names and custom tags to ec2 instances.\n  \nec2:DescribeInstances: Adds tags to ec2 instances and ec2 cloudwatch metrics.\n\n\nFor more information on EC2 policies, review the documentation on the AWS website.\n\n\nECS\n\n\n  \necs:ListClusters: List available clusters.\n  \necs:ListContainerInstances: List instances of a cluster.\n  \necs:DescribeContainerInstances: Describe instances to add metrics on resources and tasks running, adds cluster tag to ec2 instances.\n\n\nFor more information on ECS policies, review the documentation on the AWS website.\n\n\nElasticache\n\n\n  \nelasticache:DescribeCacheClusters: List and describe Cache clusters, to add tags and additional metrics.\n  \nelasticache:ListTagsForResource: List custom tags of a cluster, to add custom tags.\n  \nelasticache:DescribeEvents: Add events avout snapshots and maintenances.\n\n\nFor more information on Elasticache policies, review the documentation on the AWS website.\n\n\nELB\n\n\n  \nelasticloadbalancing:DescribeLoadBalancers: List ELBs, add additional tags and metrics.\n  \nelasticloadbalancing:DescribeTags: Add custom ELB tags to ELB metrics.\n\n\nFor more information on ELB policies, review the documentation on the AWS website.\n\n\nEMR\n\n\n  \nelasticmapreduce:ListClusters: List available clusters.\n  \nelasticmapreduce:DescribeCluster: Add tags to CloudWatch EMR metrics.\n\n\nFor more information on EMR policies, review the documentation on the AWS website.\n\n\nES\n\n\n  \nes:ListTags: Add custom ES domain tags to ES metrics\n  \nes:ListDomainNames: Add custom ES domain tags to ES metrics\n  \nes:DescribeElasticsearchDomains: Add custom ES domain tags to ES metrics\n\n\nFor more information on ES policies, review the documentation on the AWS website.\n\n\nKinesis\n\n\n  \nkinesis:ListStreams: List available streams.\n  \nkinesis:DescribeStreams: Add tags and new metrics for kinesis streams.\n  \nkinesis:ListTagsForStream: Add custom tags.\n\n\nFor more information on Kinesis policies, review the documentation on the AWS website.\n\n\nCloudWatch Logs\n\n\n  \nlogs:DescribeLogGroups: List available groups.\n  \nlogs:DescribeLogStreams: List available streams for a group.\n  \nlogs:FilterLogEvents: Fetch some specific log events for a stream to generate metrics.\n\n\nFor more information on CloudWatch Logs policies, review the documentation on the AWS website.\n\n\nRDS\n\n\n  \nrds:DescribeDBInstances: Descrive RDS instances to add tags.\n  \nrds:ListTagsForResource: Add custom tags on RDS instances.\n  \nrds:DescribeEvents: Add events related to RDS databases.\n\n\nFor more information on RDS policies, review the documentation on the AWS website.\n\n\nRoute53\n\n\n  \nroute53:listHealthChecks: List available health checks.\n  \nroute53:listTagsForResources: Add custom tags on Route53 CloudWatch metrics.\n\n\nFor more information on Route53 policies, review the documentation on the AWS website.\n\n\nS3\n\n\n  \ns3:ListAllMyBuckets: Used to list available buckets\n  \ns3:GetBucketTagging: Used to get custom bucket tags\n\n\nFor more information on S3 policies, review the documentation on the AWS website.\n\n\nSES\n\n\n  \nses:GetSendQuota: Add metrics about send quotas.\n  \nses:GetSendStatistics: Add metrics about send statistics.\n\n\nFor more information on SES policies, review the documentation on the AWS website.\n\n\nSNS\n\n\n  \nsns:ListTopics: Used to list available topics.\n  \nsns:Publish: Used to publish notifications (monitors or event feed).\n\n\nFor more information on SNS policies, review the documentation on the AWS website.\n\n\nSQS\n\n\n  \nsqs:ListQueues: Used to list alive queues.\n\n\nFor more information on SQS policies, review the documentation on the AWS website.\n\n\nSupport\n\n\n  \nsupport:*: Used to add metrics about service limits. Note: it requires full access because of AWS limitations\n\n\n\n\nTroubleshooting\n\nDo you believe you’re seeing a discrepancy between your data in CloudWatch and Datadog?\n\nThere are two important distinctions to be aware of:\n\n\n  In AWS for counters, a graph that is set to ‘sum’ ‘1minute’ shows the total number of occurrences in one minute leading up to that point, i.e. the rate per 1 minute. Datadog is displaying the raw data from AWS normalized to per second values, regardless of the timeframe selected in AWS, which is why you will probably see our value as lower.\n  Overall, min/max/avg have a different meaning within AWS than in Datadog. In AWS, average latency, minimum latency, and maximum latency are three distinct metrics that AWS collects. When Datadog pulls metrics from AWS CloudWatch, we only get the average latency as a single time series per ELB. Within Datadog, when you are selecting ‘min’, ‘max’, or ‘avg’, you are controlling how multiple time series will be combined. For example, requesting system.cpu.idle without any filter would return one series for each host that reports that metric and those series need to be combined to be graphed. On the other hand, if you requested system.cpu.idle from a single host, no aggregation would be necessary and switching between average and max would yield the same result.\n\n\nMetrics delayed?\n\nWhen using the AWS integration, we’re pulling in metrics via the CloudWatch API. You may see a slight delay in metrics from AWS due to some constraints that exist for their API.\n\nTo begin, the CloudWatch API only offers a metric-by-metric crawl to pull data. The CloudWatch APIs have a rate limit that varies based on the combination of authentication credentials, region, and service. Metrics are made available by AWS dependent on the account level. For example, if you are paying for “detailed metrics” within AWS, they are available more quickly. This level of service for detailed metrics also applies to granularity, with some metrics being available per minute and others per five minutes.\n\nOn the Datadog side, we do have the ability to prioritize certain metrics within an account to pull them in faster, depending on the circumstances. Please contact support@datadoghq.com for more info on this.\n\nTo obtain metrics with virtually zero delay, we recommend installing the Datadog Agent on those hosts. We’ve\nwritten a bit about this here,  especially in relation to CloudWatch.\n\nMissing metrics?\nCloudWatch’s api returns only metrics with datapoints, so if for instance an ELB has no attached instances, it is expected not to see metrics related to this ELB in Datadog.\n\nWrong count of aws.elb.healthy_host_count?\n\nWhen the Cross-Zone Load Balancing option is enabled on an ELB, all the instances attached to this ELB are considered part of all A-Zs (on CloudWatch’s side), so if you have 2 instances in 1a and 3 in ab, the metric will display 5 instances per A-Z.\nAs this can be counter-intuitive, we’ve added a new metric, aws.elb.host_count, that displays the count of healthy instances per AZ, regardless of if this Cross-Zone Load Balancing option is enabled or not.\nThis metric should have value you would expect.\n\nDuplicated hosts when installing the agent?\n\nWhen installing the agent on an aws host, you might see duplicated hosts on the infra page for a few hours if you manually set the hostname in the agent’s configuration. This second host will disapear a few hours later, and won’t affect your billing.\n\n","tags":"","loc":"/integrations/aws/"},{"title":"Datadog-AWS API Gateway Integration","text":"\n\nOverview\n\nAmazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale.\n\nEnable this integration to see in Datadog all your API Gateway metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that API Gateway is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.apigateway.4xxerror(count every 60 seconds)\nThe number of client-side errorsshown as operation\n\n\n\n\naws.apigateway.5xxerror(count every 60 seconds)\nThe number of server-side errorsshown as operation\n\n\n\n\naws.apigateway.count(count every 60 seconds)\nThe number call to API methodsshown as operation\n\n\n\n\naws.apigateway.cache_hit_count(count every 60 seconds)\nThe number of requests served from the API cacheshown as operation\n\n\n\n\naws.apigateway.cache_miss_count(count every 60 seconds)\nThe number of requests served from the back end when API caching is enabledshown as operation\n\n\n\n\naws.apigateway.latency(gauge)\nThe average time between when requests are received and when responses returnedshown as millisecond\n\n\n\n\naws.apigateway.latency.maximum(gauge)\nThe maximum time between when requests are received and when responses returnedshown as millisecond\n\n\n\n\naws.apigateway.latency.minimum(gauge)\nThe minimum time between when requests are received and when responses returnedshown as millisecond\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsapigateway/"},{"title":"Datadog-AWS Auto Scaling Integration","text":"\n\nOverview\n\nAmazon Auto Scaling is a service to launch or terminate EC2 instances automatically based on user-defined policies.\n\nEnable this integration to see in Datadog all your Auto Scaling metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that Auto Scaling is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.autoscaling.group_desired_capacity(gauge)\nThe number of instances that the Auto Scaling group attempts to maintain.\n\n\n\n\naws.autoscaling.group_in_service_instances(gauge)\nThe number of instances that are running as part of the Auto Scaling group. This metric does not include instances that are pending or terminating.\n\n\n\n\naws.autoscaling.group_max_size(gauge)\nThe maximum size of the Auto Scaling group.\n\n\n\n\naws.autoscaling.group_min_size(gauge)\nThe minimum size of the Auto Scaling group.\n\n\n\n\naws.autoscaling.group_pending_instances(gauge)\nThe number of instances that are pending. A pending instance is not yet in service. This metric does not include instances that are in service or terminating.\n\n\n\n\naws.autoscaling.group_terminating_instances(gauge)\nThe number of instances that are in the process of terminating. This metric does not include instances that are in service or pending.\n\n\n\n\naws.autoscaling.group_total_instances(gauge)\nThe total number of instances in the Auto Scaling group. This metric identifies the number of instances that are in service and/or pending and/or terminating.\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsautoscaling/"},{"title":"Datadog-Elastic Beanstalk Integration","text":"\n\nOverview\n\nAWS Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker on familiar servers such as Apache, Nginx, Passenger, and IIS.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. \n\n\nConfiguration\n\n\nMonitor Elastic Beanstalk environments with the Datadog agent container\nIf you use Docker containers in a Beanstalk environment, and want to monitor your Docker usage in this environment, the containerized Datadog agent is a tool of choice.\n\nRead on to understand how to configure your Beanstalk environment to integrate the Datadog agent container.\n\n\nTask definition\nTo run docker environments with multiple containers per instance, Elastic Beanstalk relies on Amazon EC2 Container Service (ECS).\nFor this reason you need to describe the containers you want to deploy the ECS-way. Elastic Beanstalk allows you to do so through a file called Dockerrun.aws.json.\n\nA Dockerrun.aws.json file is an Elastic Beanstalk–specific JSON file that describes how to deploy a set of Docker containers as an Elastic Beanstalk application. You can use this file for a multicontainer Docker environment.\n\nDockerrun.aws.json describes the containers to deploy to each container instance in the environment as well as the data volumes to create on the host instance for the containers to mount.\n\nA Dockerrun.aws.json file can be used on its own or zipped up with additional source code in a single archive. Source code that is archived with a Dockerrun.aws.json is deployed to container instances and accessible in the /var/app/current/ directory. Use the volumes section of the config to provide mount points for the containers running on the instance, and the mountPoints section of the embedded container definitions to mount them from the containers.\n\nThe following snippet illustrates a Dockerrun.aws.json declaring the Datadog agent. Update it with the definition of your containers to define your own Dockerrun.aws.json. This file can be zipped with additional content to send to the instances which run the described containers, and shipped to Beanstalk. For more info about the syntax of this file you can refer to the Beanstalk documentation.\n\n{\n  \"AWSEBDockerrunVersion\": 2,\n  \"volumes\": [\n    {\n       \"name\": \"docker_sock\",\n       \"host\": {\n            \"sourcePath\": \"/var/run/docker.sock\"\n      }\n    },\n    {\n       \"name\": \"proc\",\n       \"host\": {\n            \"sourcePath\": \"/proc/\"\n      }\n    },\n    {\n       \"name\": \"cgroup\",\n       \"host\": {\n            \"sourcePath\": \"/cgroup/\"\n      }\n    }\n  ],\n  \"containerDefinitions\": [\n    {\n      \"name\": \"dd-agent\",\n      \"image\": \"datadog/docker-dd-agent:latest\",\n      \"environment\": [\n            {\n              \"name\": \"API_KEY\",\n              \"value\": \"your_api_key\"\n            },\n            {\n              \"name\": \"TAGS\",\n              \"value\": \"simple-tag-0, tag-key-1:tag-value-1\"\n            }\n      ],\n      \"memory\": 128,\n      \"mountPoints\": [\n        {\n          \"sourceVolume\": \"docker_sock\",\n          \"containerPath\": \"/var/run/docker.sock\",\n          \"readOnly\": false\n        },\n        {\n          \"sourceVolume\": \"proc\",\n          \"containerPath\": \"/host/proc\",\n          \"readOnly\": true\n        },\n        {\n          \"sourceVolume\": \"cgroup\",\n          \"containerPath\": \"/host/sys/fs/cgroup\",\n          \"readOnly\": true\n        }\n      ]\n    }\n  ]\n}\n\n\n\nCreating the environment\n\nOnce the container definition is ready, the last step is to ship it to Beanstalk.\nThis step is explained in the multicontainer Docker tutorial of the Elastic Beanstalk documentation.\n\n\nMetrics\n\n\n\naws.elasticbeanstalk.environment_health(gauge)\nThe health status of your environment: 0 is OK - 1 is Info - 5 is Unknown - 10 is No data - 15 is Warning - 20 is Degraded - 25 is Severe\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsbeanstalk/"},{"title":"Datadog-AWS Billing Integration","text":"\n\nOverview\n\nAmazon Billing allows you to track your AWS infrastructure billing forecasts and costs.\n\nEnable this integration to see in Datadog all your Billing metrics.\n\n\nInstallation\n\nIn order to see AWS Budget metrics, the requirement for this integration is the permission budgets:ViewBudget.\n\nYou must also enable billing metrics within the AWS Console.\n\nNote: AWS Budget metrics can only be collected from the AWS master account.\n\n\nMetrics\n\n\n\n\naws.billing.estimated_charges(gauge)\nThe estimated charges for your AWS usage. This can either be estimated charges for one service or a roll-up of estimated charges for all services.shown as dollar\n\n\n\n\naws.billing.actual_spend(gauge)\nThe actual spending costs for your budget periodshown as dollar\n\n\n\n\naws.billing.forecasted_spend(gauge)\nThe forecasted spending costs for your budget periodshown as dollar\n\n\n\n\naws.billing.budget_limit(gauge)\nThe spending limit for your budget periodshown as dollar\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsbilling/"},{"title":"Datadog-AWS CloudFront Integration","text":"\n\nOverview\n\nAmazon CloudFront is a global content delivery network (CDN) service that accelerates delivery of your websites, APIs, video content or other web assets.\n\nEnable this integration to see in Datadog all your CloudFront metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that CloudFront is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.cloudfront.4xx_error_rate(gauge every 60 seconds)\nThe percentage of all requests for which the HTTP status code is 4xx.shown as percent\n\n\n\n\naws.cloudfront.5xx_error_rate(gauge every 60 seconds)\nThe percentage of all requests for which the HTTP status code is 5xx.shown as percent\n\n\n\n\naws.cloudfront.bytes_downloaded(count every 60 seconds)\nThe number of bytes downloaded by viewers for GET, HEAD, and OPTIONS requests.shown as byte\n\n\n\n\naws.cloudfront.bytes_uploaded(count every 60 seconds)\nThe number of bytes uploaded to your origin with CloudFront using POST and PUT requests.shown as byte\n\n\n\n\naws.cloudfront.requests(count every 60 seconds)\nThe number of requests for all HTTP methods and for both HTTP and HTTPS requests.\n\n\n\n\naws.cloudfront.total_error_rate(gauge every 60 seconds)\nThe percentage of all requests for which the HTTP status code is 4xx or 5xx.shown as percent\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awscloudfront/"},{"title":"Datadog-AWS CloudSearch Integration","text":"\n\nOverview\n\nAmazon CloudSearch is a managed service in the AWS Cloud that makes it simple and cost-effective to set up, manage, and scale a search solution.\n\nEnable this integration to see in Datadog all your CloudSearch metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that CloudSearch is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.cloudsearch.index_utilization(gauge)\nThe percentage of the search instance's index capacity that has been used.shown as percent\n\n\n\n\naws.cloudsearch.partitions(gauge)\nThe number of partitions the index is distributed across.\n\n\n\n\naws.cloudsearch.searchable_documents(gauge)\nThe number of searchable documents in the domain's search index.\n\n\n\n\naws.cloudsearch.successful_requests(count every 60 seconds)\nThe number of search requests successfully processed by a search instance.\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awscloudsearch/"},{"title":"Datadog-AWS CloudTrail Integration","text":"\n\nOverview\n\nAWS CloudTrail provides an audit trail for your AWS account. Datadog reads this audit trail and creates events you can search for in your stream and use for correlation on your dashboards. Here is an example of a CloudTrail event:\n\n\n\nFor information about the rest of the AWS services, see the AWS tile\n\n\nInstallation\n\nConfigure CloudWatch on AWS and ensure that the policy you created has the equivalent of the AWSCloudTrailReadOnlyAccess policy assigned. The actions in that policy are s3:ListBucket, s3:GetBucketLocation, and s3:GetObject. Also ensure that the policy gives access to the S3 bucket you selected for the CloudTrail Trail. Here is an example policy to give access to an S3 bucket.\n\n{ \n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n  {\n    \"Action\": [\n      \"s3:ListBucket\",\n      \"s3:GetBucketLocation\",\n      \"s3:GetObject\"\n    ],\n    \"Effect\": \"Allow\",\n    \"Resource\": [\n      \"arn:aws:s3:::your-s3-bucket-name\",\n      \"arn:aws:s3:::your-s3-bucket-name/*\"\n    ]\n  } ]\n}\n\n\n\nConfiguration\n\nOpen the AWS CloudTrail tile. The accounts you configured in the Amazon Web Services tile are shown here and you can choose what kinds of events will be collected by Datadog. If you would like to see other events that are not mentioned here, please reach out to our support team.\n\n\nTroubleshooting\n\n\nI don’t see a CloudTrail tile or there are no accounts listed\n\nYou need to first configure the Amazon Web Services tile. Once you complete this, the CloudTrail tile will be available and configurable.\n\n","tags":"","loc":"/integrations/awscloudtrail/"},{"title":"Datadog-AWS DynamoDB Integration","text":"\n\nOverview\n\n\n\nAmazon DynamoDB is a fully managed NoSQL database cloud service, part of the AWS portfolio. Fast and easily scalable, it is meant to serve applications which require very low latency, even when dealing with large amounts of data. It supports both document and key-value store models, and has properties of both a database and a distributed hash table.\n\nLearn more about how to monitor DynamoDB performance metrics thanks to our series of posts. We detail the key performance metrics, how to collect them, and how Medium monitors DynamoDB using Datadog.\n\n\nInstallation\n\nThis integration requires the permissions dynamodb:list* and dynamodb:describe* to be fully enabled.\n\n\nMetrics\n\n\n\n\naws.dynamodb.conditional_check_failed_requests(count every 60 seconds)\nNumber of failed attempts to perform conditional writes.shown as request\n\n\n\n\naws.dynamodb.consumed_read_capacity_units(gauge every 60 seconds)\nNumber of read capacity units consumed over the specified time period.shown as unit/minute\n\n\n\n\naws.dynamodb.consumed_write_capacity_units(gauge every 60 seconds)\nNumber of write capacity units consumed over the specified time period.shown as unit/minute\n\n\n\n\naws.dynamodb.online_index_consumed_write_capacity(gauge every 60 seconds)\nNumber of write capacity units consumed when adding a new global secondary index to a table.shown as unit/minute\n\n\n\n\naws.dynamodb.online_index_percentage_progress(gauge every 60 seconds)\nPercentage of completion when a new global secondary index is being added to a table.shown as percent\n\n\n\n\naws.dynamodb.online_index_throttle_events(gauge every 60 seconds)\nNumber of write throttle events that occur when adding a new global secondary index to a table.shown as event\n\n\n\n\naws.dynamodb.provisioned_read_capacity_units(gauge every 60 seconds)\nNumber of provisioned read capacity units for a table or a global secondary index.shown as unit\n\n\n\n\naws.dynamodb.provisioned_write_capacity_units(gauge every 60 seconds)\nNumber of provisioned write capacity units for a table or a global secondary index.shown as unit\n\n\n\n\naws.dynamodb.read_throttle_events(count every 60 seconds)\nNumber of read events that exceeded the preset provisioned throughput limits in the specified time period.shown as read\n\n\n\n\naws.dynamodb.returned_item_count(gauge every 60 seconds)\nThe average number of items returned by a scan or query operation.shown as item\n\n\n\n\naws.dynamodb.returned_item_count.maximum(gauge every 60 seconds)\nThe maximum number of items returned by a scan or query operation.shown as item\n\n\n\n\naws.dynamodb.returned_item_count.minimum(gauge every 60 seconds)\nThe minimum number of items returned by a scan or query operation.shown as item\n\n\n\n\naws.dynamodb.returned_item_count.sum(count every 60 seconds)\nThe total number of items returned by a scan or query operation.shown as item\n\n\n\n\naws.dynamodb.returned_item_count.samplecount(count every 60 seconds)\nThe number of scan or query operations.shown as item\n\n\n\n\naws.dynamodb.successful_request_latency(gauge)\nThe average latency for successful requests.shown as millisecond\n\n\n\n\naws.dynamodb.successful_request_latency.maximum(gauge)\nThe maximum latency for successful requests.shown as millisecond\n\n\n\n\naws.dynamodb.successful_request_latency.samplecount(count every 60 seconds)\nThe total number of successful requests.shown as request\n\n\n\n\naws.dynamodb.system_errors(count every 60 seconds)\nNumber of requests generating a 500 status code response.shown as request\n\n\n\n\naws.dynamodb.throttled_requests(count every 60 seconds)\nNumber of user requests that exceeded the preset provisioned throughput limits.shown as request\n\n\n\n\naws.dynamodb.user_errors(count every 60 seconds)\nNumber of requests generating an HTTP 400 status code response.shown as request\n\n\n\n\naws.dynamodb.write_throttle_events(count every 60 seconds)\nNumber of write events that exceeded the preset provisioned throughput limits in the specified time period.shown as write\n\n\n\n\naws.dynamodb.table_size(gauge every 60 seconds)\nApproximate size of the table (updated every 6h).shown as byte\n\n\n\n\naws.dynamodb.item_count(gauge every 60 seconds)\nApproximate number of items in table (updated every 6h).shown as item\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsdynamo/"},{"title":"Datadog-AWS Elastic Block Store Integration","text":"\n\nOverview\n\nAmazon EBS provides persistent block storage volumes for use with Amazon EC2 instances in the AWS Cloud.\n\nEnable this integration to see in Datadog all your EBS metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that EBS is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.ebs.burst_balance(gauge)\nBalance available in the burst bucketshown as percent\n\n\n\n\naws.ebs.volume_consumed_read_write_ops(gauge)\nThe total amount of read and write operations (normalized to 256K capacity units).\n\n\n\n\naws.ebs.volume_idle_time(gauge)\nThe total number of seconds in a specified period of time when no read or write operations were submitted.shown as second\n\n\n\n\naws.ebs.volume_queue_length(gauge)\nThe number of read and write operation requests waiting to be completed.\n\n\n\n\naws.ebs.volume_read_bytes(gauge)\nAverage size of each read operationshown as byte\n\n\n\n\naws.ebs.volume_read_bytes.sum(gauge)\nTotal number of bytes read by read operationsshown as byte\n\n\n\n\naws.ebs.volume_read_ops(gauge)\nThe total number of read operations.shown as operation\n\n\n\n\naws.ebs.volume_throughput_percentage(gauge)\nThe percentage of I/O operations per second (IOPS) delivered of the total IOPS provisioned for an Amazon EBS volume.shown as percent\n\n\n\n\naws.ebs.volume_total_read_time(gauge)\nThe Average time spent by read operations.shown as second\n\n\n\n\naws.ebs.volume_total_read_time.sum(gauge)\nThe total number of seconds spent for read operations.shown as second\n\n\n\n\naws.ebs.volume_total_write_time(gauge)\nThe average time spent by write operations.shown as second\n\n\n\n\naws.ebs.volume_total_write_time.sum(gauge)\nThe total number of seconds spent for write operations.shown as second\n\n\n\n\naws.ebs.volume_write_bytes(gauge)\nAverage size of each write operationshown as byte\n\n\n\n\naws.ebs.volume_write_bytes.sum(gauge)\nTotal amount of bytes written by write operationsshown as byte\n\n\n\n\naws.ebs.volume_write_ops(gauge)\nThe total number of write operations.shown as operation\n\n\n\n\naws.ebs.snapshot_age(gauge)\nTime since the most recent complete snapshot was createdshown as second\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsebs/"},{"title":"Datadog-AWS EC2 Integration","text":"\n\nOverview\n\nAmazon Elastic Compute Cloud (Amazon EC2) is a web service that provides resizable compute capacity in the cloud. It is designed to make web-scale cloud computing easier for developers.\n\nEnable this integration to see in Datadog all your EC2 metrics, and additional events like scheduled maintenances.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that EC2 is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.ec2.cpucredit_balance(gauge)\nNumber of CPU credits that an instance has accumulated.shown as unit\n\n\n\n\naws.ec2.cpucredit_usage(gauge)\nNumber of CPU credits consumed.shown as unit\n\n\n\n\naws.ec2.cpuutilization(gauge)\nAverage percentage of allocated EC2 compute units that are currently in use on the instance.shown as percent\n\n\n\n\naws.ec2.cpuutilization.maximum(gauge)\nMaximum percentage of allocated EC2 compute units that are currently in use on the instance.shown as percent\n\n\n\n\naws.ec2.disk_read_bytes(gauge)\nBytes read from all ephemeral disks available to the instance.shown as byte/minute\n\n\n\n\naws.ec2.disk_read_ops(gauge)\nCompleted read operations from all ephemeral disks available to the instance.shown as operation/minute\n\n\n\n\naws.ec2.disk_write_bytes(gauge)\nBytes written to all ephemeral disks available to the instance.shown as byte/minute\n\n\n\n\naws.ec2.disk_write_ops(gauge)\nCompleted write operations to all ephemeral disks available to the instance.shown as operation/minute\n\n\n\n\naws.ec2.network_in(gauge)\nAverage number of bytes received on all network interfaces by the instance.shown as byte/minute\n\n\n\n\naws.ec2.network_in.maximum(gauge)\nMaximum number of bytes received on all network interfaces by the instance.shown as byte/minute\n\n\n\n\naws.ec2.network_out(gauge)\nAverage number of bytes sent out on all network interfaces by the instance.shown as byte/minute\n\n\n\n\naws.ec2.network_out.maximum(gauge)\nMaximum number of bytes sent out on all network interfaces by the instance.shown as byte/minute\n\n\n\n\naws.ec2.network_packets_in(gauge)\nNumber of packets received on all network interfaces by the instanceshown as packet/minute\n\n\n\n\naws.ec2.network_packets_out(gauge)\nNumber of packets sent out on all network interfaces by the instanceshown as packet/minute\n\n\n\n\naws.ec2.status_check_failed(gauge)\n1 if one of the status checks failed.\n\n\n\n\naws.ec2.status_check_failed_instance(gauge)\n0 if the instance has passed the EC2 instance status check.\n\n\n\n\naws.ec2.status_check_failed_system(gauge)\n0 if the instance has passed the EC2 system status check.\n\n\n\n\naws.ec2.host_ok(gauge)\n1 if the instance's system status is ok.\n\n\n\n\naws.ec2.instance_age(gauge)\nTime since instance launchshown as second\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsec2/"},{"title":"Datadog-AWS Elastic File System Integration","text":"\n\nOverview\n\nAmazon EFS provides simple, scalable file storage for use with Amazon EC2 instances in the AWS Cloud.\n\nEnable this integration to see in Datadog all your EFS metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that EFS is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.efs.client_connections(gauge)\nNumber of Amazon EC2 instances that are connected to a file systemshown as connection\n\n\n\n\naws.efs.data_write_iobytes(count)\n\nshown as byte\n\n\n\n\naws.efs.data_read_iobytes(count)\n\nshown as byte\n\n\n\n\naws.efs.total_iobytes(count)\n\nshown as byte\n\n\n\n\naws.efs.metadata_iobytes(count)\n\nshown as byte\n\n\n\n\naws.efs.burst_credit_balance(gauge)\n\nshown as byte\n\n\n\n\naws.efs.permitted_throughput(gauge)\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsefs/"},{"title":"Datadog-AWS ElastiCache Integration","text":"\n\n\nLearn more about how to monitor ElastiCache performance metrics, whether you use Redis or Memcached, thanks to our series of posts. We detail the key performance metrics, how to collect them, and how Coursera monitors ElastiCache using Datadog.\n\nTo collect all available ElastiCache metrics, you need to do two things:\n\n\n  \nTurn on the ElastiCache integration to pull metrics from ElastiCache into Datadog\n  Set up the Datadog Agent as described in this article (optional, but recommended)\n\n\n\nCollecting native metrics with the Agent\n\nThe following diagram shows how Datadog collects metrics directly from CloudWatch via the native ElastiCache integration, and how it can additionally collect native metrics directly from the backend technology: Redis or Memcached. By collecting from the backend directly, you will have access to a greater number of important metrics, and at a higher resolution.\n\n\n\n\nHow this works\n\nBecause the agent metrics will be tied to the EC2 instance where the agent is running and not to the actual ElastiCache instance, you will need to use the cacheclusterid tag to connect all metrics together. Once the agent is configured with the same tags as the ElastiCache instance, combining Redis/Memcached metrics with ElastiCache metrics is straightforward.\n\n\nStep-by-step\n\nSince the Agent is not running on an actual ElastiCache instance, but on a remote machine, the key to setting up this integration correctly is telling the Agent where to collect the metrics from.\n\n\nGather connection details for your ElastiCache instance\n\nFirst navigate to the AWS Console, open the ElastiCache section and then the Cache Clusters tab to find the cluster you want to monitor. It should look like:\n\n\n\nThen click on the “node” link to access its endpoint URL:\n\n\n\nWrite down the endpoint URL (e.g. replica-001.xxxx.use1.cache.amazonaws.com) and the cacheclusterid (e.g. replica-001). You will need these values to configure the agent and to create graphs and dashboards.\n\n\nConfigure the Agent\n\nThe Redis/Memcached integrations support the tagging of individual cache instances. Originally designed to allow the monitoring of multiple instances on the same machine, you can use these tags to your advantage. Here is an example of a configuration for ElastiCache with Redis using redisdb.yaml, usually found in /etc/dd-agent/conf.d\n\ninit_config:\n\ninstances:\n  - host: replica-001.xxxx.use1.cache.amazonaws.com # Endpoint URL from AWS console\n    port: 6379\n    tags:\n      - cacheclusterid:replicaa-001 # Cache Cluster ID from AWS console\n\n\nThen restart the agent: sudo /etc/init.d/datadog-agent restart (on linux).\n\n\nVisualize ElastiCache and Redis/Memcached metrics together\n\nAfter a few minutes, ElastiCache metrics and Redis/Memcached metrics will be accessible in Datadog for graphing, monitoring, etc.\n\nHere’s an example of setting up a graph to combine cache hit metrics from ElastiCache with native latency metrics from Redis using the same cacheclusterid tag replicaa-001.\n\n\n\n\nMetrics\n\n\n\n\naws.elasticache.bytes_read_into_memcached(count every 60 seconds)\nMemcached - The number of bytes that have been read from the network by the cache node.shown as byte\n\n\n\n\naws.elasticache.bytes_used_for_cache(gauge)\nRedis - The total number of bytes allocated by Redis.shown as byte\n\n\n\n\naws.elasticache.bytes_used_for_cache_items(gauge)\nMemcached - The number of bytes used to store cache items.shown as byte\n\n\n\n\naws.elasticache.bytes_used_for_hash(gauge)\nMemcached - The number of bytes currently used by hash tables.shown as byte\n\n\n\n\naws.elasticache.bytes_written_out_from_memcached(count every 60 seconds)\nMemcached - The number of bytes that have been written to the network by the cache node.shown as byte\n\n\n\n\naws.elasticache.cache_hits(count every 60 seconds)\nRedis - The number of successful key lookups.shown as hit\n\n\n\n\naws.elasticache.cache_misses(count every 60 seconds)\nRedis - The number of unsuccessful key lookups.shown as miss\n\n\n\n\naws.elasticache.cas_badval(count every 60 seconds)\nMemcached - The number of CAS (check and set) requests the cache has received where the Cas value did not match the Cas value stored.\n\n\n\n\naws.elasticache.cas_hits(count every 60 seconds)\nMemcached - The number of CAS requests the cache has received where the requested key was found and the Cas value matched.shown as hit\n\n\n\n\naws.elasticache.cas_misses(count every 60 seconds)\nMemcached - The number of CAS requests the cache has received where the key requested was not found.shown as miss\n\n\n\n\naws.elasticache.cmd_config_get(count every 60 seconds)\nMemcached - The cumulative number of config get requests.shown as get\n\n\n\n\naws.elasticache.cmd_config_set(count every 60 seconds)\nMemcached - The cumulative number of config set requests.shown as set\n\n\n\n\naws.elasticache.cmd_flush(count every 60 seconds)\nMemcached - The number of flush commands the cache has received.shown as flush\n\n\n\n\naws.elasticache.cmd_get(count every 60 seconds)\nMemcached - The number of get commands the cache has received.shown as get\n\n\n\n\naws.elasticache.cmd_set(count every 60 seconds)\nMemcached - The number of set commands the cache has received.shown as set\n\n\n\n\naws.elasticache.cmd_touch(count every 60 seconds)\nMemcached - The cumulative number of touch requests.\n\n\n\n\naws.elasticache.cpuutilization(gauge)\nThe percentage of CPU utilization.shown as percent\n\n\n\n\naws.elasticache.curr_config(gauge)\nMemcached - The current number of configurations stored.\n\n\n\n\naws.elasticache.curr_connections(gauge)\nRedis - The number of client connections, excluding connections from read replicas.  Memcached - A count of the number of connections connected to the cache at an instant in time.shown as connection\n\n\n\n\naws.elasticache.curr_items(gauge)\nRedis - The number of items in the cache. This is derived from the Redis keyspace statistic, summing all of the keys in the entire keyspace.  Memcached - A count of the number of items currently stored in the cache.shown as item\n\n\n\n\naws.elasticache.decr_hits(count every 60 seconds)\nMemcached - The number of decrement requests the cache has received where the requested key was found.shown as hit\n\n\n\n\naws.elasticache.decr_misses(count every 60 seconds)\nMemcached - The number of decrement requests the cache has received where the requested key was not found.shown as miss\n\n\n\n\naws.elasticache.delete_hits(count every 60 seconds)\nMemcached - The number of delete requests the cache has received where the requested key was found.shown as hit\n\n\n\n\naws.elasticache.delete_misses(count every 60 seconds)\nMemcached - The number of delete requests the cache has received where the requested key was not found.shown as miss\n\n\n\n\naws.elasticache.evicted_unfetched(count every 60 seconds)\nMemcached - The number of valid items evicted from the least recently used cache (LRU) which were never touched after being set.shown as item\n\n\n\n\naws.elasticache.evictions(count every 60 seconds)\nRedis - The number of keys that have been evicted due to the maxmemory limit.  Memcached - The number of non-expired items the cache evicted to allow space for new writes.shown as eviction\n\n\n\n\naws.elasticache.expired_unfetched(count every 60 seconds)\nMemcached - The number of expired items reclaimed from the LRU which were never touched after being set.shown as item\n\n\n\n\naws.elasticache.freeable_memory(gauge)\nThe amount of free memory available on the host.shown as byte\n\n\n\n\naws.elasticache.get_hits(count every 60 seconds)\nMemcached - The number of get requests the cache has received where the key requested was found.shown as hit\n\n\n\n\naws.elasticache.get_misses(count every 60 seconds)\nMemcached - The number of get requests the cache has received where the key requested was not found.shown as miss\n\n\n\n\naws.elasticache.get_type_cmds(count every 60 seconds)\nRedis - The total number of get types of commands. This is derived from the Redis commandstats statistic by summing all of the get types of commands (get, mget, hget, etc.)shown as command\n\n\n\n\naws.elasticache.hash_based_cmds(count every 60 seconds)\nRedis - The total number of commands that are hash-based. This is derived from the Redis commandstats statistic by summing all of the commands that act upon one or more hashes.shown as command\n\n\n\n\naws.elasticache.hyper_log_log_based_cmds(count every 60 seconds)\nRedis - The total number of HyperLogLog based commands. This is derived from the Redis commandstats statistic by summing all of the pf type of commands (pfadd, pfcount, pfmerge).shown as command\n\n\n\n\naws.elasticache.incr_hits(count every 60 seconds)\nMemcached - The number of increment requests the cache has received where the key requested was found.shown as hit\n\n\n\n\naws.elasticache.incr_misses(count every 60 seconds)\nMemcached - The number of increment requests the cache has received where the key requested was not found.shown as miss\n\n\n\n\naws.elasticache.key_based_cmds(count every 60 seconds)\nRedis - The total number of commands that are key-based. This is derived from the Redis commandstats statistic by summing all of the commands that act upon one or more keys.shown as command\n\n\n\n\naws.elasticache.list_based_cmds(count every 60 seconds)\nRedis - The total number of commands that are list-based. This is derived from the Redis commandstats statistic by summing all of the commands that act upon one or more lists.shown as command\n\n\n\n\naws.elasticache.network_bytes_in(count every 60 seconds)\nThe number of bytes the host has read from the network.shown as byte\n\n\n\n\naws.elasticache.network_bytes_out(count every 60 seconds)\nThe number of bytes the host has written to the network.shown as byte\n\n\n\n\naws.elasticache.new_connections(count every 60 seconds)\nRedis - The total number of connections that have been accepted by the server during this period.  Memcached - The number of new connections the cache has received. This is derived from the memcached total_connections statistic by recording the change in total_connections across a period of time. This will always be at least 1, due to a connection reserved for a ElastiCache.shown as connection\n\n\n\n\naws.elasticache.new_items(count every 60 seconds)\nMemcached - The number of new items the cache has stored. This is derived from the memcached total_items statistic by recording the change in total_items across a period of time.shown as item\n\n\n\n\naws.elasticache.reclaimed(count every 60 seconds)\nRedis - The total number of key expiration events.  Memcached - The number of expired items the cache evicted to allow space for new writes.\n\n\n\n\naws.elasticache.replication_bytes(gauge)\nRedis - For primaries with attached replicas, ReplicationBytes reports the number of bytes that the primary is sending to all of its replicas. This metric is representative of the write load on the replication group. For replicas and standalone primaries, ReplicationBytes is always 0.shown as byte\n\n\n\n\naws.elasticache.replication_lag(gauge)\nRedis - This metric is only applicable for a cache node running as a read replica. It represents how far behind, in seconds, the replica is in applying changes from the primary cache cluster.shown as second\n\n\n\n\naws.elasticache.save_in_progress(gauge)\nRedis - This binary metric returns 1 whenever a background save (forked or forkless) is in progress, and 0 otherwise. A background save process is typically used during snapshots and syncs. These operations can cause degraded performance. Using the SaveInProgress metric, you can diagnose whether or not degraded performance was caused by a background save process.\n\n\n\n\naws.elasticache.set_based_cmds(count every 60 seconds)\nRedis - The total number of commands that are set-based. This is derived from the Redis commandstats statistic by summing all of the commands that act upon one or more sets.shown as command\n\n\n\n\naws.elasticache.set_type_cmds(count every 60 seconds)\nRedis - The total number of set types of commands. This is derived from the Redis commandstats statistic by summing all of the set types of commands (set, hset, etc.)shown as command\n\n\n\n\naws.elasticache.slabs_moved(count every 60 seconds)\nMemcached - The total number of slab pages that have been moved.\n\n\n\n\naws.elasticache.sorted_set_based_cmds(count every 60 seconds)\nRedis - The total number of commands that are sorted set-based. This is derived from the Redis commandstats statistic by summing all of the commands that act upon one or more sorted sets.shown as command\n\n\n\n\naws.elasticache.string_based_cmds(count every 60 seconds)\nRedis - The total number of commands that are string-based. This is derived from the Redis commandstats statistic by summing all of the commands that act upon one or more strings.shown as command\n\n\n\n\naws.elasticache.swap_usage(gauge)\nThe amount of swap used on the host.shown as byte\n\n\n\n\naws.elasticache.touch_hits(count every 60 seconds)\nMemcached - The number of keys that have been touched and were given a new expiration time.shown as hit\n\n\n\n\naws.elasticache.touch_misses(count every 60 seconds)\nMemcached - The number of items that have been touched, but were not found.shown as miss\n\n\n\n\naws.elasticache.unused_memory(gauge)\nMemcached - The amount of unused memory the cache can use to store items. This is derived from the memcached statistics limit_maxbytes and bytes by subtracting bytes from limit_maxbytes.shown as byte\n\n\n\n\naws.elasticache.is_master(gauge)\nRedis - Returns 1 if the node is master, 0 otherwise.\n\n\n\n\naws.elasticache.geo_spatial_based_cmds(count)\nRedis - The total number of geo spatial based commands.\n\n\n\n\n\nWhat’s next?\n\nNot working? Have questions for us? Don’t hesitate to contact our support team.\n","tags":"","loc":"/integrations/awselasticache/"},{"title":"Datadog-AWS ELB Integration","text":"\n\nOverview\n\n\n\nElastic Load Balancing (ELB) is an AWS service used to dispatch incoming web traffic from your applications across your Amazon EC2 backend instances, which may be in different availability zones. ELB helps ensure a smooth user experience and provide increased fault tolerance, handling traffic peaks and failed EC2 instances without interruption.\n\nTo start collecting ELB metrics, the only thing you need to do is to set up our integration with AWS CloudWatch by following these instructions.\n\nLearn more about how to monitor ELB performance metrics thanks to our series of posts. We detail the key performance metrics, how to collect them, and how to use Datadog to monitor ELB.\n\n\nConfiguration\n\n\n  Enable the Amazon Web Services integration.\n  Open the AWS integration tile and ensure the ELB checkbox on the left is checked.\n\n\n\nMetrics\n\n\n\n\naws.elb.healthy_host_count(gauge every 60 seconds)\nAverage number of healthy instances in each Availability Zone.shown as host\n\n\n\n\naws.elb.healthy_host_count.minimum(gauge every 60 seconds)\nMinimum number of healthy instances in each Availability Zone.shown as host\n\n\n\n\naws.elb.healthy_host_count.maximum(gauge every 60 seconds)\nMaximum number of healthy instances in each Availability Zone.shown as host\n\n\n\n\naws.elb.un_healthy_host_count(gauge every 60 seconds)\nAverage number of unhealthy instances in each Availability Zone.shown as host\n\n\n\n\naws.elb.un_healthy_host_count.minimum(gauge every 60 seconds)\nMinimium number of unhealthy instances in each Availability Zone.shown as host\n\n\n\n\naws.elb.un_healthy_host_count.maximum(gauge every 60 seconds)\nMaximum number of unhealthy instances in each Availability Zone.shown as host\n\n\n\n\naws.elb.healthy_host_count_deduped(gauge every 60 seconds)\nDeduped number of healthy instances in each Availability Zone.shown as host\n\n\n\n\naws.elb.unhealthy_host_count_deduped(gauge every 60 seconds)\nDeduped number of unhealthy instances in each Availability Zone.shown as host\n\n\n\n\naws.elb.request_count(rate every 60 seconds)\nTotal number of completed requests that were received and routed to the registered instances.shown as request/second\n\n\n\n\naws.elb.backend_connection_errors(rate every 60 seconds)\nNumber of connections that were not successfully established between the load balancer and the registered instances.shown as error/second\n\n\n\n\naws.elb.surge_queue_length(gauge every 60 seconds)\nMaximum number of requests that are pending submission to a registered instance.shown as request\n\n\n\n\naws.elb.latency(gauge every 60 seconds)\nAverage time elapsed after the request leaves the load balancer until a response is received.shown as second\n\n\n\n\naws.elb.latency.maximum(gauge every 60 seconds)\nMaximum time elapsed after the request leaves the load balancer until a response is received.shown as second\n\n\n\n\naws.elb.latency.p95(gauge every 60 seconds)\n95th percentile of the time elapsed after the request leaves the load balancer until a response is received.shown as second\n\n\n\n\naws.elb.latency.p99(gauge every 60 seconds)\n99th percentile of the time elapsed after the request leaves the load balancer until a response is received.shown as second\n\n\n\n\naws.elb.latency.minimum(gauge every 60 seconds)\nMinimum time elapsed after the request leaves the load balancer until a response is received.shown as second\n\n\n\n\naws.elb.spillover_count(rate every 60 seconds)\nTotal number of requests that were rejected because the queue was full.shown as request/second\n\n\n\n\naws.elb.spillover_count.maximum(rate every 60 seconds)\nMaximum number of requests that were rejected because the queue was full per load balancer node.shown as request/second\n\n\n\n\naws.elb.httpcode_backend_2xx(rate every 60 seconds)\nNumber of HTTP 2XX response codes generated by registered instances.shown as response/second\n\n\n\n\naws.elb.httpcode_backend_3xx(rate every 60 seconds)\nNumber of HTTP 3XX response codes generated by registered instances.shown as response/second\n\n\n\n\naws.elb.httpcode_backend_4xx(rate every 60 seconds)\nNumber of HTTP 4XX response codes generated by registered instances.shown as response/second\n\n\n\n\naws.elb.httpcode_backend_5xx(rate every 60 seconds)\nNumber of HTTP 5XX response codes generated by registered instances.shown as response/second\n\n\n\n\naws.elb.httpcode_elb_4xx(rate every 60 seconds)\nNumber of HTTP 4XX client error codes generated by the load balancer.shown as response/second\n\n\n\n\naws.elb.httpcode_elb_5xx(rate every 60 seconds)\nNumber of HTTP 5XX client error codes generated by the load balancer.shown as response/second\n\n\n\n\naws.elb.httpcode_target_2xx(rate every 60 seconds)\nNumber of HTTP 2XX response codes generated by registered instances.shown as response/minute\n\n\n\n\naws.elb.httpcode_target_3xx(rate every 60 seconds)\nNumber of HTTP 3XX response codes generated by registered instances.shown as response/minute\n\n\n\n\naws.elb.httpcode_target_4xx(rate every 60 seconds)\nNumber of HTTP 4XX response codes generated by registered instances.shown as response/minute\n\n\n\n\naws.elb.httpcode_target_5xx(rate every 60 seconds)\nNumber of HTTP 5XX response codes generated by registered instances.shown as response/minute\n\n\n\n\naws.elb.target_response_time.maximum(gauge every 60 seconds)\nMaximum time elapsed after the request leaves the load balancer until a response is received.shown as second\n\n\n\n\naws.elb.target_response_time.average(gauge every 60 seconds)\nAverage time elapsed after the request leaves the load balancer until a response is received.shown as second\n\n\n\n\naws.elb.target_response_time.p95(gauge every 60 seconds)\n(beta) 95th percentile of the time elapsed after the request leaves the load balancer until a response is received.shown as second\n\n\n\n\naws.elb.target_response_time.p99(gauge every 60 seconds)\n(beta) 99th percentile of the time elapsed after the request leaves the load balancer until a response is received.shown as second\n\n\n\n\naws.elb.target_connection_error_count(count every 60 seconds)\nNumber of connections that were not successfully established between the load balancer and the registered instances.shown as error\n\n\n\n\naws.elb.client_tlsnegotiation_error_count(count every 60 seconds)\nNumber of TLS negociation errorsshown as error\n\n\n\n\naws.elb.consumed_lbcapacity_units(gauge every 60 seconds)\nNumber of ELB capacity units consumedshown as unit\n\n\n\n\naws.applicationelb.consumed_lbcapacity_units(gauge every 60 seconds)\n(beta) Number of ELB capacity units consumedshown as unit\n\n\n\n\naws.applicationelb.client_tlsnegotiation_error_count(gauge every 60 seconds)\n(beta) Number of TLS negociation errorsshown as error\n\n\n\n\naws.applicationelb.httpcode_elb_4xx(count every 60 seconds)\n(beta) Number of HTTP 4XX client error codes generated by the load balancer.shown as response\n\n\n\n\naws.applicationelb.httpcode_elb_5xx(count every 60 seconds)\n(beta) Number of HTTP 5XX client error codes generated by the load balancer.shown as response\n\n\n\n\naws.applicationelb.httpcode_target_2xx(count every 60 seconds)\n(beta) Number of HTTP 2XX response codes generated by registered instances.shown as response\n\n\n\n\naws.applicationelb.httpcode_target_3xx(count every 60 seconds)\n(beta) Number of HTTP 3XX response codes generated by registered instances.shown as response\n\n\n\n\naws.applicationelb.httpcode_target_4xx(count every 60 seconds)\n(beta) Number of HTTP 4XX response codes generated by registered instances.shown as response\n\n\n\n\naws.applicationelb.httpcode_target_5xx(count every 60 seconds)\n(beta) Number of HTTP 5XX response codes generated by registered instances.shown as response\n\n\n\n\naws.applicationelb.request_count(count every 60 seconds)\n(beta) Total number of completed requests that were received and routed to the registered instances.shown as request\n\n\n\n\naws.applicationelb.target_connection_error_count(count every 60 seconds)\n(beta) Number of connections that were not successfully established between the load balancer and the registered instances.shown as error\n\n\n\n\naws.applicationelb.healthy_host_count(gauge every 60 seconds)\n(beta) Average number of healthy instances in each Availability Zone.shown as host\n\n\n\n\naws.applicationelb.healthy_host_count.minimum(gauge every 60 seconds)\n(beta) Minimum number of healthy instances in each Availability Zone.shown as host\n\n\n\n\naws.applicationelb.healthy_host_count.maximum(gauge every 60 seconds)\n(beta) Maximum number of healthy instances in each Availability Zone.shown as host\n\n\n\n\naws.applicationelb.un_healthy_host_count(gauge every 60 seconds)\n(beta) Average number of unhealthy instances in each Availability Zone.shown as host\n\n\n\n\naws.applicationelb.un_healthy_host_count.minimum(gauge every 60 seconds)\n(beta) Minimium number of unhealthy instances in each Availability Zone.shown as host\n\n\n\n\naws.applicationelb.un_healthy_host_count.maximum(gauge every 60 seconds)\n(beta) Maximum number of unhealthy instances in each Availability Zone.shown as host\n\n\n\n\naws.applicationelb.healthy_host_count_deduped(gauge every 60 seconds)\n(beta) Deduped number of healthy instances in each Availability Zone.shown as host\n\n\n\n\naws.applicationelb.unhealthy_host_count_deduped(gauge every 60 seconds)\n(beta) Deduped number of unhealthy instances in each Availability Zone.shown as host\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awselb/"},{"title":"Datadog-AWS Elastic Map Reduce Integration","text":"\n\nOverview\n\nAmazon Elastic MapReduce (Amazon EMR) is a web service that makes it easy to quickly and cost-effectively process vast amounts of data.\n\nEnable this integration to see in Datadog all your EMR metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that EMR is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.elasticmapreduce.apps_completed(gauge)\nThe number of applications submitted to YARN that have completed.\n\n\n\n\naws.elasticmapreduce.apps_failed(gauge)\nThe number of applications submitted to YARN that have failed to complete.\n\n\n\n\naws.elasticmapreduce.apps_killed(gauge)\nThe number of applications submitted to YARN that have been killed.\n\n\n\n\naws.elasticmapreduce.apps_pending(gauge)\nThe number of applications submitted to YARN that are in a pending state.\n\n\n\n\naws.elasticmapreduce.apps_running(gauge)\nThe number of applications submitted to YARN that are running.\n\n\n\n\naws.elasticmapreduce.apps_submitted(gauge)\nThe number of applications submitted to YARN.\n\n\n\n\naws.elasticmapreduce.capacity_remaining_gb(gauge)\nThe amount of remaining HDFS disk capacity.shown as byte\n\n\n\n\naws.elasticmapreduce.container_allocated(gauge)\nThe number of resource containers allocated by the ResourceManager.\n\n\n\n\naws.elasticmapreduce.container_pending(gauge)\nThe number of containers in the queue that have not yet been allocated.\n\n\n\n\naws.elasticmapreduce.container_pending_ratio(gauge)\nThe percentage of containers in the queue that have not yet been allocated.shown as percent\n\n\n\n\naws.elasticmapreduce.container_reserved(gauge)\nThe number of containers reserved.\n\n\n\n\naws.elasticmapreduce.core_nodes_pending(gauge)\nThe number of core nodes waiting to be assigned. All of the core nodes requested may not be immediately available; this metric reports the pending requests. Data points for this metric are reported only when a corresponding instance group exists.shown as node\n\n\n\n\naws.elasticmapreduce.core_nodes_running(gauge)\nThe number of core nodes working. Data points for this metric are reported only when a corresponding instance group exists.shown as node\n\n\n\n\naws.elasticmapreduce.corrupt_blocks(gauge)\nThe number of blocks that HDFS reports as corrupted.shown as block\n\n\n\n\naws.elasticmapreduce.dfs_fsnamesystem_pending_replication_blocks(gauge)\nThe status of block replication: blocks being replicated, age of replication requests, and unsuccessful replication requests.\n\n\n\n\naws.elasticmapreduce.hbase_backup_failed(gauge)\nWhether the last backup failed. This is set to 0 by default and updated to 1 if the previous backup attempt failed. This metric is only reported for HBase clusters.\n\n\n\n\naws.elasticmapreduce.hbase_most_recent_backup_duration(gauge)\nThe amount of time it took the previous backup to complete. This metric is set regardless of whether the last completed backup succeeded or failed. While the backup is ongoing, this metric returns the number of minutes after the backup started. This metric is only reported for HBase clusters.shown as minute\n\n\n\n\naws.elasticmapreduce.hbase_time_since_last_successful_backup(gauge)\nThe number of elapsed minutes after the last successful HBase backup started on your cluster. This metric is only reported for HBase clusters.shown as minute\n\n\n\n\naws.elasticmapreduce.hdfsbytes_read(gauge)\nThe number of bytes read from HDFS.shown as byte\n\n\n\n\naws.elasticmapreduce.hdfsbytes_written(gauge)\nThe number of bytes written to HDFS.shown as byte\n\n\n\n\naws.elasticmapreduce.hdfsutilization(gauge)\nThe percentage of HDFS storage currently used.shown as percent\n\n\n\n\naws.elasticmapreduce.is_idle(gauge)\nIndicates that a cluster is no longer performing work, but is still alive and accruing charges. It is set to 1 if no tasks are running and no jobs are running, and set to 0 otherwise. This value is checked at five-minute intervals and a value of 1 indicates only that the cluster was idle when checked, not that it was idle for the entire five minutes.\n\n\n\n\naws.elasticmapreduce.jobs_failed(gauge)\nThe number of jobs in the cluster that have failed.\n\n\n\n\naws.elasticmapreduce.jobs_running(gauge)\nThe number of jobs in the cluster that are currently running.\n\n\n\n\naws.elasticmapreduce.live_data_nodes(gauge)\nThe percentage of data nodes that are receiving work from Hadoop.shown as percent\n\n\n\n\naws.elasticmapreduce.live_task_trackers(gauge)\nThe percentage of task trackers that are functional.shown as percent\n\n\n\n\naws.elasticmapreduce.map_slots_open(gauge)\nThe unused map task capacity. This is calculated as the maximum number of map tasks for a given cluster, less the total number of map tasks currently running in that cluster.\n\n\n\n\naws.elasticmapreduce.memory_allocated_mb(gauge)\nThe amount of memory allocated to the cluster.shown as byte\n\n\n\n\naws.elasticmapreduce.memory_available_mb(gauge)\nThe amount of memory available to be allocated.shown as byte\n\n\n\n\naws.elasticmapreduce.memory_reserved_mb(gauge)\nThe amount of memory reserved.shown as byte\n\n\n\n\naws.elasticmapreduce.memory_total_mb(gauge)\nThe total amount of memory in the cluster.shown as byte\n\n\n\n\naws.elasticmapreduce.missing_blocks(gauge)\nThe number of blocks in which HDFS has no replicas. These might be corrupt blocks.shown as block\n\n\n\n\naws.elasticmapreduce.mractive_nodes(gauge)\nThe number of nodes presently running MapReduce tasks or jobs.shown as node\n\n\n\n\naws.elasticmapreduce.mrdecommissioned_nodes(gauge)\nThe number of nodes allocated to MapReduce applications that have been marked in a DECOMMISSIONED state.\n\n\n\n\naws.elasticmapreduce.mrlost_nodes(gauge)\nThe number of nodes allocated to MapReduce that have been marked in a LOST state.shown as node\n\n\n\n\naws.elasticmapreduce.mrrebooted_nodes(gauge)\nThe number of nodes available to MapReduce that have been rebooted and marked in a REBOOTED state.shown as node\n\n\n\n\naws.elasticmapreduce.mrtotal_nodes(gauge)\nThe number of nodes presently available to MapReduce jobs.shown as node\n\n\n\n\naws.elasticmapreduce.mrunhealthy_nodes(gauge)\nThe number of nodes available to MapReduce jobs marked in an UNHEALTHY state.shown as node\n\n\n\n\naws.elasticmapreduce.no_of_black_listed_task_trackers(gauge)\nThe number of blackisted TaskTracker nodes.shown as node\n\n\n\n\naws.elasticmapreduce.no_of_gray_listed_task_trackers(gauge)\nThe number of graylisted TaskTracker nodes.shown as node\n\n\n\n\naws.elasticmapreduce.pending_deletion_blocks(gauge)\nThe number of blocks marked for deletion.shown as block\n\n\n\n\naws.elasticmapreduce.reduce_slots_open(gauge)\nUnused reduce task capacity. This is calculated as the maximum reduce task capacity for a given cluster, less the number of reduce tasks currently running in that cluster.\n\n\n\n\naws.elasticmapreduce.remaining_map_tasks(gauge)\nThe number of remaining map tasks for each job. If you have a scheduler installed and multiple jobs running, multiple graphs are generated. A remaining map task is one that is not in any of the following states: Running, Killed, or Completed.shown as task\n\n\n\n\naws.elasticmapreduce.remaining_map_tasks_per_slot(gauge)\nThe ratio of the total map tasks remaining to the total map slots available in the cluster.\n\n\n\n\naws.elasticmapreduce.remaining_reduce_tasks(gauge)\nThe number of remaining reduce tasks for each job. If you have a scheduler installed and multiple jobs running, multiple graphs are generated.shown as task\n\n\n\n\naws.elasticmapreduce.running_map_tasks(gauge)\nThe number of running map tasks for each job. If you have a scheduler installed and multiple jobs running, multiple graphs are generated.shown as task\n\n\n\n\naws.elasticmapreduce.running_reduce_tasks(gauge)\nThe number of running reduce tasks for each job. If you have a scheduler installed and multiple jobs running, multiple graphs are generated.shown as task\n\n\n\n\naws.elasticmapreduce.s_3bytes_read(gauge)\nThe number of bytes read from Amazon S3.shown as byte\n\n\n\n\naws.elasticmapreduce.s_3bytes_written(gauge)\nThe number of bytes written to Amazon S3.shown as byte\n\n\n\n\naws.elasticmapreduce.task_nodes_pending(gauge)\nThe number of task nodes waiting to be assigned. All of the task nodes requested may not be immediately available; this metric reports the pending requests. Data points for this metric are reported only when a corresponding instance group exists.shown as node\n\n\n\n\naws.elasticmapreduce.task_nodes_running(gauge)\nThe number of task nodes working. Data points for this metric are reported only when a corresponding instance group exists.shown as node\n\n\n\n\naws.elasticmapreduce.total_load(gauge)\nThe total number of concurrent data transfers.\n\n\n\n\naws.elasticmapreduce.total_map_tasks(gauge)\nThe total number of map tasks.shown as task\n\n\n\n\naws.elasticmapreduce.total_reduce_tasks(gauge)\nThe total number of reduce tasks.shown as task\n\n\n\n\naws.elasticmapreduce.under_replicated_blocks(gauge)\nThe number of blocks that need to be replicated one or more times.shown as block\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsemr/"},{"title":"Datadog-AWS ES Integration","text":"\n\nOverview\n\nAmazon Elasticsearch Service is a managed service that makes it easy to deploy, operate, and scale Elasticsearch in the AWS Cloud.\n\nEnable this integration to see custom tags and metrics for your ES clusters in Datadog.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. This integration requires the permissions es:ListTags, es:ListDomainNames  and es:DescribeElasticsearchDomains to be fully enabled.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that ES is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.es.automated_snapshot_failure(gauge)\nThe number of failed automated snapshots for the cluster.\n\n\n\n\naws.es.cluster_statusgreen(gauge)\nIndicates whether all index shards are allocated to nodes in the cluster.\n\n\n\n\naws.es.cluster_statusred(gauge)\nIndicates whether both primary and replica shards of at least one index are not allocated to nodes in a cluster.\n\n\n\n\naws.es.cluster_statusyellow(gauge)\nIndicates whether replica shards are not allocated to nodes in a cluster.\n\n\n\n\naws.es.cluster_used_space(gauge)\nThe total used space in megabytes for a cluster.shown as mebibyte\n\n\n\n\naws.es.cpucredit_balance(gauge)\nThe remaining CPU credits available for data nodes in the cluster.\n\n\n\n\naws.es.cpuutilization(gauge)\nThe average percentage of CPU resources used across all nodes in the cluster.shown as percent\n\n\n\n\naws.es.cpuutilization.minimum(gauge)\nThe minimum percentage of CPU resources used by any node in the cluster.shown as percent\n\n\n\n\naws.es.cpuutilization.maximum(gauge)\nThe maximum percentage of CPU resources used by any node in the cluster.shown as percent\n\n\n\n\naws.es.deleted_documents(gauge)\nThe total number of deleted documents across all indices in the cluster.\n\n\n\n\naws.es.disk_queue_depth(gauge)\nThe average number of pending input and output (I/O) requests for an EBS volume. across all nodes in the cluster\n\n\n\n\naws.es.disk_queue_depth.minimum(gauge)\nThe minimum number for any node in the cluster of pending input and output (I/O) requests for an EBS volume.\n\n\n\n\naws.es.disk_queue_depth.maximum(gauge)\nThe maximum number for any node in the cluster of pending input and output (I/O) requests for an EBS volume.\n\n\n\n\naws.es.free_storage_space(gauge)\nThe average free space, in megabytes, across all the data nodes in a cluster.shown as mebibyte\n\n\n\n\naws.es.free_storage_space.minimum(gauge)\nThe free space, in megabytes, for the single data node with the least available free space in a cluster.shown as mebibyte\n\n\n\n\naws.es.free_storage_space.maximum(gauge)\nThe free space, in megabytes, for the single data node with the most available free space in a cluster.shown as mebibyte\n\n\n\n\naws.es.free_storage_space.sum(gauge)\nThe free space, in megabytes, for all data nodes in the cluster.shown as mebibyte\n\n\n\n\naws.es.jvmmemory_pressure(gauge)\nThe average percentage of the Java heap used for all data nodes in the cluster.shown as percent\n\n\n\n\naws.es.jvmmemory_pressure.minimum(gauge)\nThe minimum percentage of the Java heap used by any data node in the cluster.shown as percent\n\n\n\n\naws.es.jvmmemory_pressure.maximum(gauge)\nThe maximum percentage of the Java heap used by any data node in the cluster.shown as percent\n\n\n\n\naws.es.master_cpuutilization(gauge)\nThe maximum percentage of CPU resources used by the dedicated master nodes.shown as percent\n\n\n\n\naws.es.master_free_storage_space(gauge)\nThis metric is not relevant and can be ignored. The service does not use master nodes as data nodes.shown as mebibyte\n\n\n\n\naws.es.master_jvmmemory_pressure(gauge)\nThe maximum percentage of the Java heap used for all dedicated master nodes in the cluster.shown as percent\n\n\n\n\naws.es.master_cpucredit_balance(gauge)\nThe remaining CPU credits available for dedicated master nodes in the cluster.\n\n\n\n\naws.es.nodes(gauge)\nThe number of nodes in the Amazon ES cluster.\n\n\n\n\naws.es.read_iops(gauge)\nThe number of input and output (I/O) operations per second for read operations on EBS volumes.shown as operation/second\n\n\n\n\naws.es.read_iops.minimum(gauge)\nThe minimum number for any node of input and output (I/O) operations per second for read operations on EBS volumes.shown as operation/second\n\n\n\n\naws.es.read_iops.maximum(gauge)\nThe maximum number for any node of input and output (I/O) operations per second for read operations on EBS volumes.shown as operation/second\n\n\n\n\naws.es.read_latency(gauge)\nThe latency, in seconds, for read operations on EBS volumes.shown as second\n\n\n\n\naws.es.read_latency.minimum(gauge)\nThe minimum latency for any node, in seconds, for read operations on EBS volumes.shown as second\n\n\n\n\naws.es.read_latency.maximum(gauge)\nThe maximum latency for any node, in seconds, for read operations on EBS volumes.shown as second\n\n\n\n\naws.es.read_throughput(gauge)\nThe throughput, in bytes per second, for read operations on EBS volumes.shown as byte/second\n\n\n\n\naws.es.read_throughput.minimum(gauge)\nThe minimum throughput for any node, in bytes per second, for read operations on EBS volumes.shown as byte/second\n\n\n\n\naws.es.read_throughput.maximum(gauge)\nThe maximum throughput for any node, in bytes per second, for read operations on EBS volumes.shown as byte/second\n\n\n\n\naws.es.searchable_documents(gauge)\nThe total number of searchable documents across all indices in the cluster.\n\n\n\n\naws.es.write_iops(gauge)\nThe number of input and output (I/O) operations per second for write operations on EBS volumes.shown as operation/second\n\n\n\n\naws.es.write_iops.minimum(gauge)\nThe minimum number for any node of input and output (I/O) operations per second for write operations on EBS volumes.shown as operation/second\n\n\n\n\naws.es.write_iops.maximum(gauge)\nThe maximum number for any node of input and output (I/O) operations per second for write operations on EBS volumes.shown as operation/second\n\n\n\n\naws.es.write_latency(gauge)\nThe latency, in seconds, for write operations on EBS volumes.shown as second\n\n\n\n\naws.es.write_latency.minimum(gauge)\nThe minimum latency for any node, in seconds, for write operations on EBS volumes.shown as second\n\n\n\n\naws.es.write_latency.maximum(gauge)\nThe maximum latency for any node, in seconds, for write operations on EBS volumes.shown as second\n\n\n\n\naws.es.write_throughput(gauge)\nThe throughput, in bytes per second, for write operations on EBS volumes.shown as byte/second\n\n\n\n\naws.es.write_throughput.minimum(gauge)\nThe minimum throughput for any node, in bytes per second, for write operations on EBS volumes.shown as byte/second\n\n\n\n\naws.es.write_throughput.maximum(gauge)\nThe maximum throughput for any node, in bytes per second, for write operations on EBS volumes.shown as byte/second\n\n\n\n\n()\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awses/"},{"title":"Datadog-AWS Firehose Integration","text":"\n\nOverview\n\nAmazon Kinesis Firehose is the easiest way to load streaming data into AWS.\n\nEnable this integration to see in Datadog all your Firehose metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that Firehose is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.firehose.delivery_to_elasticsearch_bytes(count)\nThe total number of bytes indexed to Amazon ElasticSearch.shown as byte\n\n\n\n\naws.firehose.delivery_to_elasticsearch_records(count)\nThe total number of records indexed to Amazon ElasticSearch.\n\n\n\n\naws.firehose.delivery_to_elasticsearch_success(gauge)\nFraction of records successfully indexed to Amazon ElasticSearch.shown as fraction\n\n\n\n\naws.firehose.delivery_to_elasticsearch_success.sum(count every 60 seconds)\nTotal number of records successfully indexed to Amazon ElasticSearch.\n\n\n\n\naws.firehose.delivery_to_redshift_bytes(gauge)\nThe average number of bytes copied to Amazon Redshift per delivery.shown as byte\n\n\n\n\naws.firehose.delivery_to_redshift_bytes.sum(count every 60 seconds)\nThe total number of bytes copied to Amazon Redshift.shown as byte\n\n\n\n\naws.firehose.delivery_to_redshift_records(count every 60 seconds)\nThe total number of records copied to Amazon Redshift.\n\n\n\n\naws.firehose.delivery_to_redshift_records.average(gauge)\nThe average number of records copied to Amazon Redshift per delivery.\n\n\n\n\naws.firehose.delivery_to_redshift_success(gauge)\nFraction of successful Redshift COPY commandsshown as fraction\n\n\n\n\naws.firehose.delivery_to_redshift_success.sum(count every 60 seconds)\nTotal number of successful Redshift COPY commands\n\n\n\n\naws.firehose.delivery_to_s_3bytes(gauge)\nThe average number of bytes delivered to Amazon S3 per delivery.shown as byte\n\n\n\n\naws.firehose.delivery_to_s_3bytes.sum(count every 60 seconds)\nThe total number of bytes delivered to Amazon S3.shown as byte\n\n\n\n\naws.firehose.delivery_to_s_3data_freshness(gauge)\nAge (from getting into Firehose to now) of the oldest record in Firehose. Any record older than this age has been delivered to the S3 bucket.shown as second\n\n\n\n\naws.firehose.delivery_to_s_3records(count every 60 seconds)\nThe total number of records delivered to Amazon S3.\n\n\n\n\naws.firehose.delivery_to_s_3records.average(gauge)\nThe average number of records delivered to Amazon S3 per delivery.\n\n\n\n\naws.firehose.delivery_to_s_3success(gauge)\nFraction of successful deliveries to S3shown as fraction\n\n\n\n\naws.firehose.delivery_to_s_3success.sum(count every 60 seconds)\nSum of successful deliveries to S3\n\n\n\n\naws.firehose.describe_delivery_stream_latency(gauge)\nThe average time taken per DescribeDeliveryStream operation.shown as millisecond\n\n\n\n\naws.firehose.describe_delivery_stream_latency.maximum(gauge)\nThe maximum time taken per DescribeDeliveryStream operation.shown as millisecond\n\n\n\n\naws.firehose.describe_delivery_stream_requests(count every 60 seconds)\nTotal number of DescribeDeliveryStream requests.\n\n\n\n\naws.firehose.incoming_bytes(gauge)\nThe number of bytes ingested into the Firehose delivery stream.shown as byte\n\n\n\n\naws.firehose.incoming_records(count every 60 seconds)\nThe number of records ingested into the Firehose delivery stream.\n\n\n\n\naws.firehose.list_delivery_stream_latency(gauge)\nThe average time taken per ListDeliveryStream operation.shown as millisecond\n\n\n\n\naws.firehose.list_delivery_stream_latency.maximum(gauge)\nThe maximum time taken per ListDeliveryStream operation.shown as millisecond\n\n\n\n\naws.firehose.list_delivery_stream_requests(count every 60 seconds)\nTotal number of ListDeliveryStream requests.\n\n\n\n\naws.firehose.list_delivery_streams_latency(gauge)\nThe average time taken per ListDeliveryStreams operation.shown as millisecond\n\n\n\n\naws.firehose.list_delivery_streams_latency.maximum(gauge)\nThe maximum time taken per ListDeliveryStreams operation.shown as millisecond\n\n\n\n\naws.firehose.list_delivery_streams_requests(count every 60 seconds)\nTotal number of ListDeliveryStreams requests.\n\n\n\n\naws.firehose.put_record_bytes(count every 60 seconds)\nThe total number of bytes put to the Firehose delivery stream using PutRecord.shown as byte\n\n\n\n\naws.firehose.put_record_bytes.average(gauge)\nThe average number of bytes per PutRecord requestshown as byte\n\n\n\n\naws.firehose.put_record_latency(gauge)\nThe average time taken per PutRecord operation.shown as millisecond\n\n\n\n\naws.firehose.put_record_latency.maximum(gauge)\nThe maximum time taken per PutRecord operation.shown as millisecond\n\n\n\n\naws.firehose.put_record_requests(count every 60 seconds)\nTotal number of PutRecord requests.\n\n\n\n\naws.firehose.put_record_batch_bytes(count every 60 seconds)\nThe total number of bytes put to the Firehose delivery stream using PutRecordBatch.shown as byte\n\n\n\n\naws.firehose.put_record_batch_bytes.average(gauge)\nThe average number of bytes per PutRecordBatch request.shown as byte\n\n\n\n\naws.firehose.put_record_batch_latency(gauge)\nThe average time taken per PutRecordBatch operation.shown as millisecond\n\n\n\n\naws.firehose.put_record_batch_latency.maximum(gauge)\nThe maximum time taken per PutRecordBatch operation.shown as millisecond\n\n\n\n\naws.firehose.put_record_batch_records(count every 60 seconds)\nTotal number of records from PutRecordBatch operations.\n\n\n\n\naws.firehose.put_record_batch_records.average(gauge)\nAverage number of records per PutRecordBatch operation.\n\n\n\n\naws.firehose.put_record_batch_requests(count every 60 seconds)\nTotal number of PutRecordBatch requests.\n\n\n\n\naws.firehose.update_delivery_stream_latency(gauge)\nThe average time taken per UpdateDeliveryStream operation.shown as millisecond\n\n\n\n\naws.firehose.update_delivery_stream_latency.maximum(gauge)\nThe maximum time taken per UpdateDeliveryStream operation.shown as millisecond\n\n\n\n\naws.firehose.update_delivery_stream_requests(count every 60 seconds)\nTotal number of UpdateDeliveryStream requests.\n\n\n\n\naws.firehose.update_firehose_latency(gauge)\nThe average time taken per UpdateFirehose operation.shown as millisecond\n\n\n\n\naws.firehose.update_firehose_latency.maximum(gauge)\nThe maximum time taken per UpdateFirehose operation.shown as millisecond\n\n\n\n\naws.firehose.update_firehose_requests(count every 60 seconds)\nTotal number of UpdateFirehose requests.\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsfirehose/"},{"title":"Datadog-AWS Internet of Things Integration","text":"\n\nOverview\n\nAWS IoT is a managed cloud platform that lets connected devices easily and securely interact with cloud applications and other devices.\n\nEnable this integration to see in Datadog all your IOT metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that IOT is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.iot.connect_auth_error(count every 60 seconds)\nAWS IoT could not authorize a connect request from a client on an MQTT topic.shown as error\n\n\n\n\naws.iot.connect_client_error(count every 60 seconds)\nAWS IoT rejected a connect request from a client on an MQTT topic because the MQTT message did not meet the requirements defined in AWS IoT Limits.shown as error\n\n\n\n\naws.iot.connect_server_error(count every 60 seconds)\nAWS IoT failed to process a client connect request on an MQTT topic because an internal error occurred.shown as error\n\n\n\n\naws.iot.connect_success(count every 60 seconds)\nAWS IoT successfully processed a client connect request on an MQTT topic.\n\n\n\n\naws.iot.connect_throttle(count every 60 seconds)\nAWS IoT did not process a client connect request on an MQTT topic because the client exceeded the allowed connect request rate.\n\n\n\n\naws.iot.deletethingshadow_accepted(count every 60 seconds)\nAWS IoT received a DeleteThingShadow request.\n\n\n\n\naws.iot.getthingshadow_accepted(count every 60 seconds)\nAWS IoT received a GetThingShadow request.\n\n\n\n\naws.iot.ping_success(count every 60 seconds)\nAWS IoT received a ping message.\n\n\n\n\naws.iot.publishin_auth_error(count every 60 seconds)\nAWS IoT could not authorize a publish request from a client.shown as error\n\n\n\n\naws.iot.publishin_client_error(count every 60 seconds)\nAWS IoT rejected a publish request from a client because the MQTT message did not meet the requirements defined in AWS IoT Limits.shown as error\n\n\n\n\naws.iot.publishin_server_error(count every 60 seconds)\nAWS IoT failed to process a client publish request because an internal error occurred.shown as error\n\n\n\n\naws.iot.publishin_success(count every 60 seconds)\nA client successfully published an MQTT message.\n\n\n\n\naws.iot.publishin_throttle(count every 60 seconds)\nAWS IoT did not process a client publish request because the client exceeded the allowed inbound message rate.\n\n\n\n\naws.iot.publishout_auth_error(count every 60 seconds)\nAWS IoT could not authorize the publish request from the message broker.shown as error\n\n\n\n\naws.iot.publishout_client_error(count every 60 seconds)\nAWS IoT rejected the publish out request from the message broker because the MQTT message did not meet the requirements defined in AWS IoT Limits.shown as error\n\n\n\n\naws.iot.publishout_success(count every 60 seconds)\nAWS IoT successfully published a message to the connected client.\n\n\n\n\naws.iot.rules_executed(count every 60 seconds)\nAWS IoT executed a rule.\n\n\n\n\naws.iot.subscribe_auth_error(count every 60 seconds)\nAWS IoT could not authorize a subscribe request from a client on an MQTT topic.shown as error\n\n\n\n\naws.iot.subscribe_client_error(count every 60 seconds)\nAWS IoT rejected a subscribe request from a client on an MQTT topic because the MQTT message did not meet the requirements defined in AWS IoT Limits.shown as error\n\n\n\n\naws.iot.subscribe_server_error(count every 60 seconds)\nAWS IoT failed to process a client subscribe request on an MQTT topic because an internal error occurred.shown as error\n\n\n\n\naws.iot.subscribe_success(count every 60 seconds)\nAWS IoT successfully processed a client subscribe request on an MQTT topic.\n\n\n\n\naws.iot.subscribe_throttle(count every 60 seconds)\nAWS IoT did not process a client subscribe request on an MQTT topic because the client exceeded the allowed subscribe request rate.\n\n\n\n\naws.iot.unsubscribe_client_error(count every 60 seconds)\nAWS IoT rejected an unsubscribe request from a client on an MQTT topic because the MQTT message did not meet the requirements defined in AWS IoT Limits.shown as error\n\n\n\n\naws.iot.unsubscribe_server_error(count every 60 seconds)\nAWS IoT failed to process a client unsubscribe request on an MQTT topic because an internal error occurred.shown as error\n\n\n\n\naws.iot.unsubscribe_success(count every 60 seconds)\nAWS IoT successfully processed a client unsubscribe request on an MQTT topic.\n\n\n\n\naws.iot.unsubscribe_throttle(count every 60 seconds)\nAWS IoT did not process a client unsubscribe request on an MQTT topic because the client exceeded the allowed unsubscribe request rate.\n\n\n\n\naws.iot.updatethingshadow_accepted(count every 60 seconds)\nAWS IoT received a UpdateThingShadow request.\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsiot/"},{"title":"Datadog-AWS Kinesis Integration","text":"\n\nOverview\n\nAmazon Kinesis is a fully managed, cloud-based service for real-time processing of large, distributed data streams.\n\nEnable this integration to see in Datadog all your Kinesis metrics, and collect custom Kinesis tags.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that Kinesis is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.kinesis.get_records_bytes(gauge every 60 seconds)\nAverage number of bytes per GetRecords operationshown as byte/operation\n\n\n\n\naws.kinesis.get_records_bytes.minimum(gauge every 60 seconds)\nMinimum number of bytes per GetRecords operationshown as byte\n\n\n\n\naws.kinesis.get_records_bytes.maximum(gauge every 60 seconds)\nMaximum number of bytes per GetRecords operationshown as byte\n\n\n\n\naws.kinesis.get_records_bytes.sum(count every 60 seconds)\nTotal number of bytes returned over all GetRecords operationsshown as byte\n\n\n\n\naws.kinesis.get_records_records(gauge every 60 seconds)\nAverage number of records per GetRecords operationshown as record/operation\n\n\n\n\naws.kinesis.get_records_records.minimum(gauge every 60 seconds)\nMinimum number of records per GetRecords operationshown as record\n\n\n\n\naws.kinesis.get_records_records.maximum(gauge every 60 seconds)\nMaximum number of records per GetRecords operationshown as record\n\n\n\n\naws.kinesis.get_records_records.sum(count every 60 seconds)\nTotal number of records returned over all GetRecords operationsshown as record\n\n\n\n\naws.kinesis.get_records_iterator_age(gauge every 60 seconds)\nAverage Difference between the current time and when the last record of a GetRecords call was written to the stream.shown as second\n\n\n\n\naws.kinesis.get_records_iterator_age.maximum(gauge every 60 seconds)\nMaximum Difference between the current time and when the last record of a GetRecords call was written to the stream.shown as second\n\n\n\n\naws.kinesis.get_records_iterator_age_milliseconds(gauge every 60 seconds)\nDifference between the current time and when the last record of a GetRecords call was written to the stream.shown as millisecond\n\n\n\n\naws.kinesis.get_records_iterator_age_milliseconds.maximum(gauge every 60 seconds)\nDifference between the current time and when the last record of a GetRecords call was written to the stream.shown as millisecond\n\n\n\n\naws.kinesis.get_records_latency(gauge every 60 seconds)\nAverage time taken per GetRecords operation.shown as millisecond/operation\n\n\n\n\naws.kinesis.get_records_latency.maximum(gauge every 60 seconds)\nMaximum time taken per GetRecords operation.shown as millisecond\n\n\n\n\naws.kinesis.get_records_success(count every 60 seconds)\nNumber of successful GetRecords operations per stream.shown as event\n\n\n\n\naws.kinesis.incoming_bytes(gauge every 60 seconds)\nAverage number of bytes successfully put to the Amazon Kinesis stream per operation.shown as byte/operation\n\n\n\n\naws.kinesis.incoming_bytes.sum(count every 60 seconds)\nTotal number of bytes successfully put to the Amazon Kinesis stream.shown as byte\n\n\n\n\naws.kinesis.incoming_records(count every 60 seconds)\nTotal number of records sucessfully put to the Amazon Kinesis stream.shown as record\n\n\n\n\naws.kinesis.incoming_records.average(gauge every 60 seconds)\nAverage number of records sucessfully put to the Amazon Kinesis stream per operation.shown as record/operation\n\n\n\n\naws.kinesis.put_record_bytes(gauge every 60 seconds)\nAverage number of bytes per PutRecord operationshown as byte/operation\n\n\n\n\naws.kinesis.put_record_bytes.minimum(gauge every 60 seconds)\nMinimum number of bytes per PutRecord operationshown as byte\n\n\n\n\naws.kinesis.put_record_bytes.maximum(gauge every 60 seconds)\nMaximum number of bytes per PutRecord operationshown as byte\n\n\n\n\naws.kinesis.put_record_bytes.sum(count every 60 seconds)\nTotal number of bytes for all PutRecord operationshown as byte\n\n\n\n\naws.kinesis.put_record_latency(gauge every 60 seconds)\nAverage time taken per PutRecord operation.shown as millisecond/operation\n\n\n\n\naws.kinesis.put_record_latency.maximum(gauge every 60 seconds)\nMaximum time taken per PutRecord operation.shown as millisecond\n\n\n\n\naws.kinesis.put_record_success(count every 60 seconds)\nNumber of successful PutRecord operations per Amazon Kinesis stream.shown as event\n\n\n\n\naws.kinesis.put_records_bytes.sum(count every 60 seconds)\nTotal number of bytes for all PutRecords operation.shown as byte\n\n\n\n\naws.kinesis.put_records_bytes.maximum(gauge every 60 seconds)\nMaximum number of bytes per PutRecords operation.shown as byte/operation\n\n\n\n\naws.kinesis.put_records_bytes.minimum(gauge every 60 seconds)\nMinimum number of bytes per PutRecords operation.shown as byte/operation\n\n\n\n\naws.kinesis.put_records_bytes(gauge every 60 seconds)\nAverage number of bytes per PutRecords operation.shown as byte/operation\n\n\n\n\naws.kinesis.put_records_latency(gauge every 60 seconds)\nAverage time taken per PutRecords operation.shown as millisecond/operation\n\n\n\n\naws.kinesis.put_records_latency.maximum(gauge every 60 seconds)\nMaximum time taken for all PutRecords operation.shown as millisecond\n\n\n\n\naws.kinesis.put_records_success(count every 60 seconds)\nNumber of successful PutRecords operations per Amazon Kinesis stream.shown as event\n\n\n\n\naws.kinesis.put_records_records(gauge every 60 seconds)\nAverage number of records per PutRecords operationshown as record/operation\n\n\n\n\naws.kinesis.put_records_records.maximum(gauge every 60 seconds)\nMaximum number of records for PutRecords operationsshown as record\n\n\n\n\naws.kinesis.put_records_records.minimum(gauge every 60 seconds)\nMinimum number of records for PutRecords operationsshown as record\n\n\n\n\naws.kinesis.put_records_records.sum(count every 60 seconds)\nTotal number of records for PutRecords operationsshown as record\n\n\n\n\naws.kinesis.write_provisioned_throughput_exceeded(count every 60 seconds)\nNumber of records rejected due to throttling for the streamshown as record\n\n\n\n\naws.kinesis.write_provisioned_throughput_exceeded.average(count every 60 seconds)\nAverage of records rejected due to throttling for the streamshown as record\n\n\n\n\naws.kinesis.write_provisioned_throughput_exceeded.minimum(count every 60 seconds)\nMinimum number of records rejected due to throttling for the streamshown as record\n\n\n\n\naws.kinesis.write_provisioned_throughput_exceeded.maximum(count every 60 seconds)\nMaximum number of records rejected due to throttling for the streamshown as record\n\n\n\n\naws.kinesis.read_provisioned_throughput_exceeded(count every 60 seconds)\nNumber of GetRecords calls throttled for the streamshown as record\n\n\n\n\naws.kinesis.read_provisioned_throughput_exceeded.average(count every 60 seconds)\nAverage of GetRecords calls throttled for the streamshown as record\n\n\n\n\naws.kinesis.read_provisioned_throughput_exceeded.minimum(count every 60 seconds)\nMinimum number of GetRecords calls throttled for the streamshown as record\n\n\n\n\naws.kinesis.read_provisioned_throughput_exceeded.maximum(count every 60 seconds)\nMaximum number of GetRecords calls throttled for the streamshown as record\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awskinesis/"},{"title":"Datadog-AWS Key Management Service Integration","text":"\n\nOverview\n\nAWS Key Management Service (KMS) is a managed service that makes it easy for you to create and control the encryption keys used to encrypt your data.\n\nEnable this integration to see in Datadog all your KMS metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that KMS is checked under metric collection.\n\n\nMetrics\n\n\n\naws.kms.seconds_until_key_material_expiration(gauge every 60 seconds)\nThis metric tracks the number of seconds remaining until imported key material expires.shown as second\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awskms/"},{"title":"Datadog-AWS Lambda Integration","text":"\n\nOverview\n\nAmazon Lambda is a compute service that runs code in response to events and automatically manages the compute resources required by that code.\n\nEnable this integration to begin collecting Cloudwatch & custom metrics from your Lambda functions.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that Lambda is checked under metric collection.\n\nTo send custom metrics to Datadog, you must print a log line from your Lambda, using the following format:\nMONITORING|unix_epoch_timestamp|value|metric_type|my.metric.name|#tag1:value,tag2\n\nPlease ensure the unix_epoch_timestamp is in seconds (not milliseconds).\n\nFor example, here is sample snippet for printing a valid custom metric, from your Lambda function (in Python):\n\nunix_epoch_timestamp = int(time.time())\nvalue = 42\nmetric_type = 'count'\nmetric_name = 'my.metric.name'\ntags = ['tag1:value', 'tag2']\nprint('MONITORING|{0}|{1}|{2}|{3}|#{4}'.format(\n    unix_epoch_timestamp, value, metric_type, metric_name, ','.join(tags)\n))\n\n\nNote: This integration requires the AWS permissions logs:DescribeLogGroups, logs:DescribeLogStreams, and logs:FilterLogEvents to be fully enabled. Also, counts and gauges are the only metrics types currently supported.\n\n\nMetrics\n\n\n\n\naws.lambda.duration(gauge)\nMeasures the average elapsed wall clock time from when the function code starts executing as a result of an invocation to when it stops executing.shown as millisecond\n\n\n\n\naws.lambda.duration.maximum(gauge)\nMeasures the maximum elapsed wall clock time from when the function code starts executing as a result of an invocation to when it stops executing.shown as millisecond\n\n\n\n\naws.lambda.duration.minimum(gauge)\nMeasures the minimum elapsed wall clock time from when the function code starts executing as a result of an invocation to when it stops executing.shown as millisecond\n\n\n\n\naws.lambda.duration.sum(gauge)\nMeasures the total execution time of the lambda function executing.shown as millisecond\n\n\n\n\naws.lambda.errors(count every 60 seconds)\nMeasures the number of invocations that failed due to errors in the function (response code 4XX).\n\n\n\n\naws.lambda.invocations(count every 60 seconds)\nMeasures the number of times a function is invoked in response to an event or invocation API call.\n\n\n\n\naws.lambda.throttles(count every 60 seconds)\nMeasures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customer’s concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds.\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awslambda/"},{"title":"Datadog-AWS Machine Learning Integration","text":"\n\nOverview\n\nAmazon Machine Learning is a service that makes it easy for developers of all skill levels to use machine learning technology.\n\nEnable this integration to see in Datadog all your Machine Learning metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that Machine Learning is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.ml.predict_count(count every 60 seconds)\nThe number of observations received by Amazon ML.\n\n\n\n\naws.ml.predict_failure_count(count every 60 seconds)\nThe number of invalid or malformed observations received by Amazon ML.\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsml/"},{"title":"Datadog-AWS OpsWorks Integration","text":"\n\nOverview\n\nAWS OpsWorks is an application management service that makes it easy to deploy and operate applications of all shapes and sizes.\n\nEnable this integration to see in Datadog all your OpsWorks metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that OpsWorks is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.opsworks.cpusystem(gauge)\nThe percentage of time that the CPU is handling system operations.shown as percent\n\n\n\n\naws.opsworks.cpuuser(gauge)\nThe percentage of time that the CPU is handling user operations.shown as percent\n\n\n\n\naws.opsworks.cpuwaitio(gauge)\nThe percentage of time that the CPU is waiting for input/output operations.shown as percent\n\n\n\n\naws.opsworks.load_1(gauge)\nThe load averaged over a 1-minute window.\n\n\n\n\naws.opsworks.load_1_5(gauge)\nThe load averaged over a 15-minute window.\n\n\n\n\naws.opsworks.load_5(gauge)\nThe load averaged over a 5-minute window.\n\n\n\n\naws.opsworks.memorybuffers(gauge)\nThe amount of buffered memory.shown as kibibyte\n\n\n\n\naws.opsworks.memorycached(gauge)\nThe amount of cached memory.shown as kibibyte\n\n\n\n\naws.opsworks.memoryfree(gauge)\nThe amount of free memory.shown as kibibyte\n\n\n\n\naws.opsworks.memoryswap(gauge)\nThe amount of swap space.shown as kibibyte\n\n\n\n\naws.opsworks.memorytotal(gauge)\nThe total amount of memory.shown as kibibyte\n\n\n\n\naws.opsworks.memoryused(gauge)\nThe amount of memory in use.shown as kibibyte\n\n\n\n\naws.opsworks.procs(gauge)\nThe number of active processes.shown as process\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsopsworks/"},{"title":"Datadog-AWS Polly Integration","text":"\n\nOverview\n\nAmazon Polly is a service that turns text into lifelike speech.\n\nEnable this integration to see in Datadog all your Polly metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that Polly is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.polly.request_characters(gauge every 60 seconds)\nThe average number of characters in the request. This is billable characters only and does not include SSML tags.\n\n\n\n\naws.polly.request_characters.sum(count every 60 seconds)\nThe total number of characters in the request. This is billable characters only and does not include SSML tags.\n\n\n\n\naws.polly.request_characters.maximum(gauge every 60 seconds)\nThe maximum number of characters in the request. This is billable characters only and does not include SSML tags.\n\n\n\n\naws.polly.request_characters.minimum(gauge every 60 seconds)\nThe minimum number of characters in the request. This is billable characters only and does not include SSML tags.\n\n\n\n\naws.polly.response_latency(gauge every 60 seconds)\nThe average latency between when the request was made and the start of the streaming response.shown as millisecond\n\n\n\n\naws.polly.response_latency.minimum(gauge every 60 seconds)\nThe minimum latency between when the request was made and the start of the streaming response.shown as millisecond\n\n\n\n\naws.polly.response_latency.maximum(gauge every 60 seconds)\nThe minimum latency between when the request was made and the start of the streaming response.shown as millisecond\n\n\n\n\naws.polly.response_latency.sum(count every 60 seconds)\nThe sum of the latency between when the request was made and the start of the streaming response.shown as millisecond\n\n\n\n\naws.polly.response_latency.samplecount(count every 60 seconds)\nThe total number of successful responsesshown as response\n\n\n\n\naws.polly.2xx_count(count every 60 seconds)\nTotal number of HTTP 200 level code returned upon a successful response.shown as response\n\n\n\n\naws.polly.4xx_count(count every 60 seconds)\nTotal number of HTTP 400 level code returned upon a successful response. For each successful response, a zero (0) is emitted.shown as response\n\n\n\n\naws.polly.5xx_count(count every 60 seconds)\nTotal number of HTTP 500 level code returned upon a successful response. For each successful response, a zero (0) is emitted.shown as response\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awspolly/"},{"title":"Datadog-AWS RDS Integration","text":"\n\nOverview\n\n\n\nAmazon Relational Database Service (RDS) is a web service that makes it easy to setup, operate, and scale a relational database in the cloud. Enable this integration to see all your RDS metrics in Datadog\n\n\nHow this works\n\nThere are 3 options for monitoring RDS instances. You can choose to use standard or enhanced, and then optionally turn on the native database integration as well if you wish.\n\n\n  \n    Standard RDS Integration - The standard integration requires selecting RDS on the left side of the AWS integration tile. You will receive metrics about your instance as often as your Cloudwatch integration allows. All RDS Engine types are supported.\n  \n  \n    Enhanced RDS Integration - The enhanced integration requires additional configuration and is only available for MySQL, Aurora, and MariaDB engines. Additional metrics are available but an AWS Lambda is required to submit the metrics to Datadog. The higher granularity and additional required services may result in additional AWS charges.\n  \n  \n    RDS + Native Database Integration - You can also choose to turn on the Native Database Integration. This is available for MySQL, Aurora, MariaDB, SQL Server, and Postgres engine types. To get the metrics from RDS and the ones from the native integration to match up, you will need to use the dbinstanceidentifier tag on the native integration based on the identifier you assign to the RDS instance. The RDS instances will automatically have the tag assigned.\n  \n\n\n\nInstallation\n\n\n  \n    Standard RDS Integration\n\n    If you haven’t already, set up the Amazon Web Services integration first.\n  \n  \n    Enhanced RDS Integration\n\n    \n      Enable Enhanced Monitoring for your RDS instance. This can either be done during instance creation or afterwards by choosing Modify under Instance Actions. We recommend choosing 15 for Monitoring Granularity.\n\n\n      From the IAM Management Console, click on Encryption Keys. Click the Create Key button.\n      Enter an Alias for the key, such as lambda-datadog-key.\n      Add the appropriate administrators and then users for the key. Ensure that you select yourself at least as a user.\n      \n        Encrypt the key you just created by using the AWS CLI:\n\n        aws kms encrypt --key-id alias/<KMS key name> --plaintext '{\"api_key\":\"<datadog_api_key>\", \"app_key\":\"<datadog_app_key>\"}'\n\n\n        The KMS key name should be replaced by the alias of the key you just created. The datadog api and app keys should be replaced by the api and app keys found here.\n\n        The output of this command will include two parts: a ciphertext blob followed by the key ID that starts with something similar to arn:aws:kms.\n      \n      From the IAM Management Console, create a new role. Enter a name for the role, such as lambda-datadog-post-execution.\n      Select AWS Lambda from the AWS Service Roles list. You do not need to attach any policies at this time. Press the appropriate buttons to complete the role creation.\n      Click on the role you just created. Expand the Inline Policies section and click the link to create a policy. Choose Custom Policy and press the button to continue.\n      \n        Enter a policy name, such as lambda-datadog-policy. For Policy Document, enter the following, replacing <ENCRYPTION_KEY ARN> with the ARN of the Encryption Key:\n\n        {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"kms:Decrypt\"\n            ],\n            \"Resource\": [\n                \"<ENCRYPTION_KEY ARN>\"\n            ]\n        }\n    ]\n}\n\n      \n      From the Lambda Management Console, create a new Lambda Function.\n      On the Select blueprint screen, select the datadog-process-rds-metrics blueprint.\n      Choose RDSOSMetrics from the Log Group dropdown.\n      Enter anything for the Filter Name and click Next.\n      Enter a name for your function, such as lambda-datadog-post-function.\n      In the Lambda function code area, replace <KMS_ENCRYPTED_KEYS> with the ciphertext blob part of the CLI command output above.\n      Under Lambda function handler and role, choose the role you created above. Click Next.\n      Choose the Enable Now radio button.\n      Click the Create Function button.\n    \n  \n  \n    Native Database Integration\n\n    \n      Navigate to the AWS Console and open the RDS section to find the instance you want to monitor.\n\n\n      Copy the endpoint URL (e.g. mysqlrds.blah.us-east1.rds.amazonaws.com:3306); You will need it when you configure the agent. Also make a note of the DB Instance identifier (e.g. mysqlrds). You will need it to create graphs and dashboards.\n    \n  \n\n\n\nConfiguration\n\n\n  \n    Standard RDS Integration\n\n    \n      Ensure RDS is checked in the AWS Integration tile.\n    \n  \n  \n    Enhanced RDS Integration\n\n    \n      Ensure RDS is checked in the AWS Integration tile.\n    \n  \n  \n    Native Database Integration\n\n    \n      \n        Configure an agent and connect to your RDS instance by editing the appropriate yaml file in your conf.d directory.\na.  If you are using MySQL, MariaDB, or Aurora, then edit mysql.yaml:\n\n        init_config:\n\ninstances:\n  - server: mysqlrds.blah.us-east1-rds.amazonaws.com # The endpoint URL from the AWS console\n    user: my_username\n    pass: my_password\n    port: 3306\n    tags:\n      - dbinstanceidentifier:my_own_instance\n\n\n        b.  If you are using PostgreSQL, then edit postgres.yaml:\n\n        init_config:\n\ninstances:\n  - host: mysqlrds.blah.us-east1-rds.amazonaws.com\n    port: 5432\n    username: my_username\n    password: my_password\n    dbname: db_name\n    tags:\n      - dbinstanceidentifier:my_own_instance\n\n\n        c.  If you are using Microsoft SQL Server, then edit sqlserver.yaml\n\n        init_config:\n\ninstances:\n  - host: mysqlrds.blah.us-east1-rds.amazonaws.com,1433\n    username: my_username\n    password: my_password\n    tags:\n      - dbinstanceidentifier:my_own_instance\n\n      \n      \n        Restart the agent.\n      \n    \n  \n\n\n\nValidation\n\nTo validate that the native database integration is working, run datadog-agent info. You should see something like the following:\n\nChecks\n======\n\n  [...]\n\n  mysql\n  -----\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\n\nUsage\n\nAfter a few minutes, RDS metrics and metrics from MySQL, Aurora, MariaDB, SQL Server, or PostgreSQL will be accessible in Datadog in the Metrics Explorer, in Graphs and in Alerts. Here’s an example of an Aurora dashboard displaying a number of metrics from both RDS and the MySQL integration. Metrics from both integrations on the instance quicktestrds are unified using the dbinstanceidentifier tag. \n\nHere is the default dashboard for MySQL on Amazon RDS:\n\n\nLearn more about how to monitor MySQL on Amazon RDS performance metrics thanks to our series of posts. We detail the key performance metrics, how to collect them, and how to use Datadog to monitor MySQL on Amazon RDS.\n\n\nMetrics\n\nIn addition to the metrics you get from the database engines you will also get the following RDS metrics:\n\n\n\n\naws.rds.bin_log_disk_usage(gauge every 60 seconds)\nAmount of disk space occupied by binary logs on the master. (Standard)shown as byte\n\n\n\n\naws.rds.cpuutilization(gauge every 60 seconds)\nPercentage of CPU utilization. (Standard)shown as percent\n\n\n\n\naws.rds.cpucredit_usage(gauge every 60 seconds)\nNumber of CPU credits consumed. (Standard)\n\n\n\n\naws.rds.cpucredit_balance(gauge every 60 seconds)\nNumber of CPU credits that an instance has accumulated. (Standard)\n\n\n\n\naws.rds.database_connections(gauge every 60 seconds)\nNumber of database connections in use. (Standard)shown as connection\n\n\n\n\naws.rds.disk_queue_depth(gauge every 60 seconds)\nNumber of outstanding IOs (read/write requests) waiting to access the disk. (Standard)shown as request\n\n\n\n\naws.rds.freeable_memory(gauge every 60 seconds)\nAmount of available random access memory. (Standard)shown as byte\n\n\n\n\naws.rds.free_storage_space(gauge every 60 seconds)\nAmount of available storage space. (Standard)shown as byte\n\n\n\n\naws.rds.replica_lag(gauge every 60 seconds)\nAmount of time a Read Replica DB Instance lags behind the source DB Instance.(Standard)shown as second\n\n\n\n\naws.rds.swap_usage(gauge every 60 seconds)\nAmount of swap space used on the DB Instance. (Standard)shown as byte\n\n\n\n\naws.rds.read_iops(rate every 60 seconds)\nAverage number of disk read I/O operations. (Standard)shown as operation/second\n\n\n\n\naws.rds.write_iops(rate every 60 seconds)\nAverage number of disk write I/O operations per second. (Standard)shown as operation/second\n\n\n\n\naws.rds.read_latency(gauge every 60 seconds)\nAverage amount of time taken per disk read I/O operation. (Standard)shown as second\n\n\n\n\naws.rds.write_latency(gauge every 60 seconds)\nAverage amount of time taken per disk write I/O operation. (Standard)shown as second\n\n\n\n\naws.rds.read_throughput(rate every 60 seconds)\nAverage number of bytes read from disk. (Standard)shown as byte/second\n\n\n\n\naws.rds.write_throughput(rate every 60 seconds)\nAverage number of bytes written to  (Standard)shown as byte/second\n\n\n\n\naws.rds.network_receive_throughput(rate every 60 seconds)\nIncoming (Receive) network traffic on the DB instance. (Standard)shown as byte/second\n\n\n\n\naws.rds.network_transmit_throughput(rate every 60 seconds)\nOutgoing (Transmit) network traffic on the DB instance.  (Standard)shown as byte/second\n\n\n\n\naws.rds.update_throughput(rate every 60 seconds)\nThe average rate of update queries. (Enhanced, Aurora only)shown as query/second\n\n\n\n\naws.rds.update_latency(gauge every 60 seconds)\nThe average latency for update queries. (Enhanced, Aurora only)shown as millisecond\n\n\n\n\naws.rds.transaction_logs_disk_usage(gauge every 60 seconds)\nAmount of disk space occupied by transaction logs. (Enhanced, Postgres Only)shown as byte\n\n\n\n\naws.rds.total_storage_space(gauge every 60 seconds)\nTotal amount of storage available on an instance. (Standard)shown as byte\n\n\n\n\naws.rds.select_throughput(rate every 60 seconds)\nThe average rate of select queries. (Enhanced, Aurora only)shown as query/second\n\n\n\n\naws.rds.select_latency(gauge every 60 seconds)\nThe average latency for select queries. (Enhanced, Aurora only)shown as millisecond\n\n\n\n\naws.rds.result_set_cache_hit_ratio(gauge every 60 seconds)\nThe percentage of requests that are served by the Resultset cache. (Enhanced, Aurora only)shown as percent\n\n\n\n\naws.rds.queries(rate every 60 seconds)\nThe average rate of queries. (Enhanced)shown as query/second\n\n\n\n\naws.rds.network_throughput(rate every 60 seconds)\nThe rate of network throughput sent and received from clients by each instance in the DB cluster. (Standard)shown as byte/second\n\n\n\n\naws.rds.login_failures(count every 60 seconds)\nThe average number of failed login attempts per second (Enhanced, Aurora only)shown as operation/second\n\n\n\n\naws.rds.insert_throughput(rate every 60 seconds)\nThe average rate of insert queries. (Enhanced, Aurora only)shown as query/second\n\n\n\n\naws.rds.insert_latency(gauge every 60 seconds)\nThe amount of latency for insert queries. (Enhanced, Aurora only)shown as millisecond\n\n\n\n\naws.rds.free_local_storage(gauge every 60 seconds)\nThe amount of local storage that is free on an instance. (Enhanced, Aurora only)shown as byte\n\n\n\n\naws.rds.engine_uptime(gauge every 60 seconds)\nThe amount of time that the DB instance has been active. (Enhanced)shown as second\n\n\n\n\naws.rds.dmlthroughput(rate every 60 seconds)\nThe average rate of inserts and updates and deletes. (Enhanced, Aurora only)shown as operation/second\n\n\n\n\naws.rds.dmllatency(gauge every 60 seconds)\nThe average latency for inserts and updates and deletes. (Enhanced, Aurora only)shown as millisecond\n\n\n\n\naws.rds.delete_throughput(rate every 60 seconds)\nThe average rate of delete queries. (Enhanced, Aurora only)shown as query/second\n\n\n\n\naws.rds.delete_latency(gauge every 60 seconds)\nThe average latency for delete queries. (Enhanced, Aurora only)shown as millisecond\n\n\n\n\naws.rds.deadlocks(count every 60 seconds)\nThe average number of deadlocks in the database per second. (Enhanced, Aurora only)shown as lock\n\n\n\n\naws.rds.ddlthroughput(rate every 60 seconds)\nThe average rate of DDL requests per second. (Enhanced, Aurora only)shown as request/second\n\n\n\n\naws.rds.ddllatency(gauge every 60 seconds)\nThe amount of latency for DDL requests (create/alter/drop). (Enhanced, Aurora only)shown as millisecond\n\n\n\n\naws.rds.commit_throughput(rate every 60 seconds)\nThe average rate of committed transactions. (Enhanced, Aurora only)shown as transaction/second\n\n\n\n\naws.rds.commit_latency(gauge every 60 seconds)\nThe amount of latency for committed transactions. (Enhanced, Aurora only)shown as millisecond\n\n\n\n\naws.rds.buffer_cache_hit_ratio(gauge every 60 seconds)\nThe percentage of requests that are served by the Buffer cache. (Enhanced, Aurora only)shown as percent\n\n\n\n\naws.rds.blocked_transactions(count every 60 seconds)\nThe average rate of transactions in the database that are blocked. (Enhanced, Aurora only)shown as transaction/second\n\n\n\n\naws.rds.aurora_replica_lag_minimum(gauge every 60 seconds)\nThe minimum amount of lag between the primary instance and each Aurora instance in the DB cluster. (Enhanced, Aurora only)shown as millisecond\n\n\n\n\naws.rds.aurora_replica_lag_maximum(gauge every 60 seconds)\nThe maximum amount of lag between the primary instance and each Aurora instance in the DB cluster. (Enhanced, Aurora only)shown as millisecond\n\n\n\n\naws.rds.aurora_replica_lag(gauge every 60 seconds)\nThe average lag when replicating updates from the primary instance. (Enhanced, Aurora only)shown as millisecond\n\n\n\n\naws.rds.active_transactions(gauge every 60 seconds)\nThe average rate of current transactions executing on a DB instance. (Enhanced, Aurora only)shown as transaction/second\n\n\n\n\naws.rds.volume_bytes_used(gauge every 60 seconds)\nThe amount of storage in bytes used by your Aurora database. (Enhanced, Aurora, only)shown as byte\n\n\n\n\naws.rds.volume_read_iops(count every 60 seconds)\nThe number of billed read I/O operations from a cluster volume, reported at 5-minute intervals (Enhanced, Aurora only)shown as operation/minute\n\n\n\n\naws.rds.volume_write_iops(count every 60 seconds)\nThe average number of write disk I/O operations to the cluster volume reported at 5-minute intervals (Enhanced, Aurora only)shown as operation/minute\n\n\n\n\naws.rds.uptime(gauge)\nRDS instance uptime. (Enhanced)shown as second\n\n\n\n\naws.rds.cpuutilization.guest(gauge)\nThe percentage of CPU in use by guest programs. (Enhanced)shown as percent\n\n\n\n\naws.rds.cpuutilization.idle(gauge)\nThe percentage of CPU that is idle. (Enhanced)shown as percent\n\n\n\n\naws.rds.cpuutilization.irq(gauge)\nThe percentage of CPU in use by software interrupts. (Enhanced)shown as percent\n\n\n\n\naws.rds.cpuutilization.nice(gauge)\nThe percentage of CPU in use by programs running at lowest priority. (Enhanced)shown as percent\n\n\n\n\naws.rds.cpuutilization.steal(gauge)\nThe percentage of CPU in use by other virtual machines. (Enhanced)shown as percent\n\n\n\n\naws.rds.cpuutilization.system(gauge)\nThe percentage of CPU in use by the kernel. (Enhanced)shown as percent\n\n\n\n\naws.rds.cpuutilization.total(gauge)\nThe total percentage of the CPU in use. This value excludes the nice value. (Enhanced)shown as percent\n\n\n\n\naws.rds.cpuutilization.user(gauge)\nThe percentage of CPU in use by user programs. (Enhanced)shown as percent\n\n\n\n\naws.rds.cpuutilization.wait(gauge)\nThe percentage of CPU unused while waiting for I/O access. (Enhanced)shown as percent\n\n\n\n\naws.rds.load.1(gauge)\nThe number of processes requesting CPU time over the last minute. (Enhanced)shown as process\n\n\n\n\naws.rds.load.15(gauge)\nThe number of processes requesting CPU time over the last 15 minutes. (Enhanced)shown as process\n\n\n\n\naws.rds.load.5(gauge)\nThe number of processes requesting CPU time over the last 5 minutes. (Enhanced)shown as process\n\n\n\n\naws.rds.memory.active(gauge)\nThe amount of assigned memory. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.buffers(gauge)\nThe amount of memory used for buffering I/O requests prior to writing to the storage device. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.cached(gauge)\nThe amount of memory used for caching file systemâ€“based I/O. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.dirty(gauge)\nThe amount of memory pages in RAM that have been modified but not written to their related data block in storage. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.free(gauge)\nThe amount of unassigned memory. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.hugePagesFree(gauge)\nThe number of free huge pages. (Enhanced)shown as page\n\n\n\n\naws.rds.memory.hugePagesRsvd(gauge)\nThe number of committed huge pages. (Enhanced)shown as page\n\n\n\n\naws.rds.memory.hugePagesSize(gauge)\nThe size for each huge pages unit. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.hugePagesSurp(gauge)\nThe number of available surplus huge pages over the total. (Enhanced)shown as page\n\n\n\n\naws.rds.memory.hugePagesTotal(gauge)\nThe total number of huge pages for the system. (Enhanced)shown as page\n\n\n\n\naws.rds.memory.inactive(gauge)\nThe amount of inactive memory (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.mapped(gauge)\nThe total amount of file-system contents that is memory mapped inside a process address space. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.pageTables(gauge)\nThe amount of memory used by page tables. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.slab(gauge)\nThe amount of reusable kernel data structures. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.total(gauge)\nThe total amount of memory. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.memory.writeback(gauge)\nThe amount of dirty pages in RAM that are still being written to the backing storage. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.process.cpuUsedPc(gauge)\nThe percentage of CPU used by the process. (Enhanced)shown as percent\n\n\n\n\naws.rds.process.memoryUsedPc(gauge)\nThe amount of memory used by the process. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.process.parentID(gauge)\nThe process identifier for the parent proces of the process. (Enhanced)\n\n\n\n\naws.rds.process.rss(gauge)\nThe amount of RAM allocated to the process. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.process.tgid(gauge)\nThe thread group identifier which is a number representing the process ID to which a thread belongs. This identifier is used to group threads from the same process. (Enhanced)\n\n\n\n\naws.rds.process.vss(gauge)\nThe amount of virtual memory allocated to the process. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.diskio.avgQueueLen(gauge)\nThe number of requests waiting in the I/O device's queue. This metric is not available for Amazon Aurora. (Enhanced)shown as request\n\n\n\n\naws.rds.diskio.avgReqSz(gauge)\nThe average request size. This metric is not available for Amazon Aurora. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.diskio.await(gauge)\nThe number of milliseconds required to respond to requests including queue time and service time. This metric is not available for Amazon Aurora. (Enhanced)shown as millisecond\n\n\n\n\naws.rds.diskio.readIOsPS(rate)\nThe rate of read operations. (Enhanced)shown as operation/second\n\n\n\n\naws.rds.diskio.readKb(gauge)\nThe total amount of data read. This metric is not available for Amazon Aurora. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.diskio.readKbPS(rate)\nThe rate that data is read. This metric is not available for Amazon Aurora. (Enhanced)shown as kibibyte/second\n\n\n\n\naws.rds.diskio.rrqmPS(rate)\nThe rate of merged read requests queue. This metric is not available for Amazon Aurora. (Enhanced)shown as request/second\n\n\n\n\naws.rds.diskio.tps(rate)\nThe rate of I/O transactions. This metric is not available for Amazon Aurora. (Enhanced)shown as transaction/second\n\n\n\n\naws.rds.diskio.util(gauge)\nThe percentage of CPU time during which requests were issued. The percentage of CPU time during which requests were issued. (Enhanced)shown as percent\n\n\n\n\naws.rds.diskio.writeIOsPS(rate)\nThe rate of write operations. (Enhanced)shown as operation/second\n\n\n\n\naws.rds.diskio.writeKb(gauge)\nThe total amount of data written. This metric is not available for Amazon Aurora. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.diskio.writeKbPS(rate)\nThe rate that data is written. This metric is not available for Amazon Aurora. (Enhanced)shown as kibibyte/second\n\n\n\n\naws.rds.diskio.wrqmPS(rate)\nThe rate of merged write requests queue. This metric is not available for Amazon Aurora. (Enhanced)shown as request/second\n\n\n\n\naws.rds.filesystem.maxFiles(gauge)\nThe maximum number of files that can be created for the file system. (Enhanced)shown as file\n\n\n\n\naws.rds.filesystem.total(gauge)\nThe total amount of disk space available for the file system. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.filesystem.used(gauge)\nThe amount of disk space used by files in the file system. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.filesystem.usedFilePercent(gauge)\nThe percentage of available files in use. (Enhanced)shown as percent\n\n\n\n\naws.rds.filesystem.usedFiles(gauge)\nThe number of files in the file system. (Enhanced)shown as file\n\n\n\n\naws.rds.filesystem.usedPercent(gauge)\nThe percentage of the file-system disk space in use. (Enhanced)shown as percent\n\n\n\n\naws.rds.network.rx(gauge)\nThe number of packets received. (Enhanced)shown as packet\n\n\n\n\naws.rds.network.tx(gauge)\nThe number of packets uploaded. (Enhanced)shown as packet\n\n\n\n\naws.rds.swap.cached(gauge)\nThe amount of swap memory used as cache memory. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.swap.free(gauge)\nThe total amount of swap memory free. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.swap.total(gauge)\nThe total amount of swap memory available. (Enhanced)shown as kibibyte\n\n\n\n\naws.rds.tasks.blocked(gauge)\nThe number of tasks that are blocked. (Enhanced)shown as task\n\n\n\n\naws.rds.tasks.running(gauge)\nThe number of tasks that are running. (Enhanced)shown as task\n\n\n\n\naws.rds.tasks.sleeping(gauge)\nThe number of tasks that are sleeping. (Enhanced)shown as task\n\n\n\n\naws.rds.tasks.stopped(gauge)\nThe number of tasks that are stopped. (Enhanced)shown as task\n\n\n\n\naws.rds.tasks.total(gauge)\nThe total number of tasks. (Enhanced)shown as task\n\n\n\n\naws.rds.tasks.zombie(gauge)\nThe number of child tasks that are inactive with an active parent task. (Enhanced)shown as task\n\n\n\n\naws.rds.virtual_cpus(gauge)\nThe number of virtual CPUs for the DB instance. (Enhanced)shown as cpu\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n\n","tags":"","loc":"/integrations/awsrds/"},{"title":"Datadog-AWS Redshift Integration","text":"\n\nOverview\n\nAmazon Redshift is a fast, fully managed, petabyte-scale data warehouse service that makes it simple and cost-effective to efficiently analyze all your data.\n\nEnable this integration to see all your Redshift metrics in Datadog.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that Redshift is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.redshift.cpuutilization(gauge)\nThe percentage of CPU utilization. For clusters, this metric represents an aggregation of all nodes (leader and compute) CPU utilization values.shown as percent\n\n\n\n\naws.redshift.database_connections(gauge)\nThe number of database connections to a cluster.shown as connection\n\n\n\n\naws.redshift.health_status(gauge)\nIndicates the health of the cluster. 1 indicates healthy, and 0 indicates unhealthy.\n\n\n\n\naws.redshift.maintenance_mode(gauge)\nIndicates whether the cluster is in maintenance mode. 1 indicates on, and 0 indicates off.\n\n\n\n\naws.redshift.network_receive_throughput(rate every 60 seconds)\nThe rate at which the node or cluster receives data.shown as byte/second\n\n\n\n\naws.redshift.network_transmit_throughput(rate every 60 seconds)\nThe rate at which the node or cluster writes data.shown as byte/second\n\n\n\n\naws.redshift.percentage_disk_space_used(gauge)\nThe percent of disk space used.shown as percent\n\n\n\n\naws.redshift.read_iops(rate every 60 seconds)\nThe average number of disk read operations per second.shown as operation/second\n\n\n\n\naws.redshift.read_latency(gauge)\nThe average amount of time taken for disk read I/O operations.shown as second\n\n\n\n\naws.redshift.read_throughput(rate every 60 seconds)\nThe average number of bytes read from disk per second.shown as byte/second\n\n\n\n\naws.redshift.write_iops(rate every 60 seconds)\nThe average number of write operations per second.shown as operation/second\n\n\n\n\naws.redshift.write_latency(gauge)\nThe average amount of time taken for disk write I/O operations.shown as second\n\n\n\n\naws.redshift.write_throughput(rate every 60 seconds)\nThe average number of bytes written to disk per second.shown as byte/second\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsredshift/"},{"title":"Datadog-AWS Route 53 Integration","text":"\n\nOverview\n\nAWS Route 53 provides DNS and traffic management along with availability and performance monitoring via health checks. You can view the health check information in Datadog to provide context around other metrics and events in your environments. Here’s an example dashboard of Route 53’s health check status graph:\n\n\n\nFor information about the rest of the AWS services, see the AWS tile\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first.\n\nConfigure Route 53 on AWS and ensure that the policy you created has the route53:List* action allowed. Here is an example policy to give access to Route 53 health checks.\n\n{\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"route53:List*\"\n      ],\n      \"Resource\": [\n        \"*\"\n      ]\n    }\n  ]\n}\n\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that Route53 is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.route53.health_check_percentage_healthy(gauge)\nThe percentage of Amazon Route 53 health checkers that consider the selected endpoint to be healthy.shown as percent\n\n\n\n\naws.route53.health_check_status(gauge)\nThe status of the health check endpoint that CloudWatch is checking. 1 indicates healthy, and 0 indicates unhealthy.\n\n\n\n\naws.route53.connection_time(gauge)\nThe average time that it took Amazon Route 53 health checkers to establish a TCP connection with the endpoint.shown as millisecond\n\n\n\n\naws.route53.time_to_first_byte(gauge)\nThe average time that it took Amazon Route 53 health checkers to receive the first byte of the response to an HTTP or HTTPS request.shown as millisecond\n\n\n\n\naws.route53.sslhandshake_time(gauge)\nThe average time that it took Amazon Route 53 health checkers to complete the SSL handshake.\n\n\n\n\naws.route53.child_health_check_healthy_count(gauge)\nFor a calculated health check, the number of health checks that are healthy among the health checks that Amazon Route 53 is monitoring.\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n\n","tags":"","loc":"/integrations/awsroute53/"},{"title":"Datadog-AWS S3 Integration","text":"\n\nOverview\n\n\n\nAmazon Simple Storage Service (S3) is a highly available and scalable cloud storage service.\n\nEnable this integration to see in Datadog all your S3 metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first.\n\n\n  \n    Daily Storage Metrics\n\n    The only requirement to monitor daily metrics is the permission s3:GetBucketTagging.\n  \n  \n    Request Metrics\n\n    Enable Requests metrics on your Amazon S3 buckets from the AWS console.\n  \n\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that S3 is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.s3.bucket_size_bytes(gauge)\nThe amount of data in bytes stored in a bucket in the Standard storage class, Standard - Infrequent Access (Standard_IA) storage class, or the Reduced Redundancy Storage (RRS) class.shown as byte\n\n\n\n\naws.s3.number_of_objects(gauge)\nThe total number of objects stored in a bucket for all storage classes except for the GLACIER storage class.\n\n\n\n\naws.s3.all_requests(count every 60 seconds)\nThe total number of HTTP requests made to a bucket, regardless of type.\n\n\n\n\naws.s3.get_requests(count every 60 seconds)\nThe number of HTTP GET requests made for objects in a bucket. This doesn't include list operations.\n\n\n\n\naws.s3.put_requests(count every 60 seconds)\nThe number of HTTP PUT requests made for objects in a bucket.\n\n\n\n\naws.s3.delete_requests(count every 60 seconds)\nThe number of HTTP DELETE requests made for objects in a bucket. This also includes Delete Multiple Objects requests.\n\n\n\n\naws.s3.head_requests(count every 60 seconds)\nThe number of HTTP HEAD requests made to a bucket.\n\n\n\n\naws.s3.post_requests(count every 60 seconds)\nThe number of HTTP POST requests made to a bucket.\n\n\n\n\naws.s3.list_requests(count every 60 seconds)\nThe number of HTTP requests that list the contents of a bucket.\n\n\n\n\naws.s3.bytes_downloaded(count every 60 seconds)\nThe total number bytes downloaded from the bucket.shown as byte\n\n\n\n\naws.s3.bytes_uploaded(count every 60 seconds)\nThe total number bytes uploaded to the bucket.shown as byte\n\n\n\n\naws.s3.4xx_errors(count every 60 seconds)\nThe total number of HTTP 4xx server error status code requests made to a bucket\n\n\n\n\naws.s3.5xx_errors(count every 60 seconds)\nThe total number of HTTP 5xx server error status code requests made to a bucket\n\n\n\n\naws.s3.first_byte_latency(gauge every 60 seconds)\nThe average per-request time from the complete request being received by a bucket to when the response starts to be returned.shown as millisecond\n\n\n\n\naws.s3.first_byte_latency.minimum(gauge every 60 seconds)\nThe minimum per-request time from the complete request being received by a bucket to when the response starts to be returned.shown as millisecond\n\n\n\n\naws.s3.first_byte_latency.maximum(gauge every 60 seconds)\nThe maximum per-request time from the complete request being received by a bucket to when the response starts to be returned.shown as millisecond\n\n\n\n\naws.s3.total_request_latency(gauge every 60 seconds)\nThe average elapsed per-request time from the first byte received to the last byte sent to a bucketshown as millisecond\n\n\n\n\naws.s3.total_request_latency.minimum(gauge every 60 seconds)\nThe minimum elapsed per-request time from the first byte received to the last byte sent to a bucketshown as millisecond\n\n\n\n\naws.s3.total_request_latency.maximum(gauge every 60 seconds)\nThe maximum elapsed per-request time from the first byte received to the last byte sent to a bucketshown as millisecond\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n\n","tags":"","loc":"/integrations/awss3/"},{"title":"Datadog-AWS SES Integration","text":"\n\nOverview\n\nAmazon Simple Email Service (SES) is a cost-effective, outbound-only email-sending service.\n\nEnable this integration to see in Datadog all your SES metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. The only requirement for this integration is the permission ses:get.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that SES is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.ses.max_24_hour_send(gauge)\nThe maximum number of emails that can be sent in a 24-hour periodshown as event\n\n\n\n\naws.ses.sent_last_24_hours(gauge)\nThe total number of emails sent in the past 24 hoursshown as event\n\n\n\n\naws.ses.bounces(gauge)\nThe number of bounces (hard bounces only)shown as response\n\n\n\n\naws.ses.complaints(gauge)\nThe number of complaintsshown as message\n\n\n\n\naws.ses.deliveryattempts(gauge)\nThe number of delivery attemptsshown as event\n\n\n\n\naws.ses.rejects(gauge)\nRejected send attempts (a rejected email is an email that Amazon SES initially accepted, but later rejected because the email contained a virus. Amazon SES notifies you by email and does not send the message.)shown as response\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n\n","tags":"","loc":"/integrations/awsses/"},{"title":"Datadog-AWS SNS Integration","text":"\n\nOverview\n\n\n\nConnect SNS to Datadog in order to:\n\n\n  See SNS messages as events in your stream\n  Send alert and event notifications to SNS\n\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first.\n\n\nReceiving SNS Messages In the Event Stream\n\n\n  On the Topics section of the SNS Management console, select the desired topic and click Create Subscription\n  \n    Select https and enter the following webhook url:\n\n    https://app.datadoghq.com/intake/webhook/sns?api_key=<API KEY>\n\n  \n\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that SNS is checked under metric collection.\n\n\nSending SNS Notifications from Datadog\n\n\n  Configure the AWS account that is associated with an SNS service on the AWS integration tile\n  Install the SNS integration\n  Datadog will detect your configured SNS topics and demonstrate the @ notifications you can use below (e.g., “@sns-topic-name”)\n\n\n\nMetrics\n\n\n\n\naws.sns.number_of_messages_published(count every 60 seconds)\nNumber of messages published.shown as message\n\n\n\n\naws.sns.publish_size(gauge)\nSize of messages published.shown as byte\n\n\n\n\naws.sns.number_of_notifications_delivered(count every 60 seconds)\nNumber of messages successfully delivered.shown as message\n\n\n\n\naws.sns.number_of_notifications_failed(count every 60 seconds)\nNumber of messages that SNS failed to deliver.shown as message\n\n\n\n\naws.sns.dwell_time(gauge)\nTime waited by a message before it was delivered.shown as second\n\n\n\n\naws.sns.smssuccess_rate(gauge)\nThe percentage of successfully delivered sms.shown as percent\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awssns/"},{"title":"Datadog-AWS SQS Integration","text":"\n\nOverview\n\n\n\nAmazon Simple Queue Service (SQS) is a fast, reliable, scalable, fully managed message queuing service.\n\nEnable this integration to see all your SQS metrics in Datadog.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that SQS is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.sqs.approximate_age_of_oldest_message(gauge)\nThe approximate age of the oldest non-deleted message in the queue.shown as second\n\n\n\n\naws.sqs.approximate_number_of_messages_delayed(gauge)\nThe number of messages in the queue that are delayed and not available for reading immediately. This can happen when the queue is configured as a delay queue or when a message has been sent with a delay parameter.shown as message\n\n\n\n\naws.sqs.approximate_number_of_messages_not_visible(gauge)\nThe number of messages that are in flight. Messages are considered in flight if they have been sent to a client but have not yet been deleted or have not yet reached the end of their visibility window.shown as message\n\n\n\n\naws.sqs.approximate_number_of_messages_visible(gauge)\nThe number of messages available for retrieval from the queue.shown as message\n\n\n\n\naws.sqs.number_of_empty_receives(count every 60 seconds)\nThe number of ReceiveMessage API calls that did not return a message.shown as message\n\n\n\n\naws.sqs.number_of_messages_deleted(count every 60 seconds)\nThe number of messages deleted from the queue.shown as message\n\n\n\n\naws.sqs.number_of_messages_received(count every 60 seconds)\nThe number of messages returned by calls to the ReceiveMessage API action.shown as message\n\n\n\n\naws.sqs.number_of_messages_sent(count every 60 seconds)\nThe number of messages added to a queue.shown as message\n\n\n\n\naws.sqs.sent_message_size(gauge)\nThe size of messages added to a queue.shown as byte\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n\n","tags":"","loc":"/integrations/awssqs/"},{"title":"Datadog-AWS Storage Gateway Integration","text":"\n\nOverview\n\nAWS Storage Gateway provides seamless and secure integration between an organization’s IT environment and AWS’s storage infrastructure.\n\nEnable this integration to see in Datadog all your Storage Gateway metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that Storage Gateway is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.storagegateway.cache_hit_percent(gauge)\nPercent of application reads served from the cache.shown as percent\n\n\n\n\naws.storagegateway.cache_percent_dirty(gauge)\nPercent of the gateway's cache that has not been persisted to AWS.shown as percent\n\n\n\n\naws.storagegateway.cache_percent_used(gauge)\nPercent use of the gateway's cache storage.shown as percent\n\n\n\n\naws.storagegateway.cloud_bytes_downloaded(count every 60 seconds)\nThe total number of compressed bytes that the gateway downloaded from AWS.shown as byte\n\n\n\n\naws.storagegateway.cloud_bytes_uploaded(count every 60 seconds)\nThe total number of compressed bytes that the gateway uploaded to AWS.shown as byte\n\n\n\n\naws.storagegateway.cloud_download_latency(gauge)\nThe total number of milliseconds spent reading data from AWS.shown as millisecond\n\n\n\n\naws.storagegateway.queued_writes(count every 60 seconds)\nThe number of bytes waiting to be written to AWS. These bytes are kept in your gateway's working storage.shown as byte\n\n\n\n\naws.storagegateway.read_bytes(count every 60 seconds)\nThe total number of bytes read from your on-premises applications in the reporting period for all volumes in the gateway.shown as byte\n\n\n\n\naws.storagegateway.read_time(gauge)\nThe total number of milliseconds spent to do read operations from your on-premises applications for all volumes in the gateway.shown as millisecond\n\n\n\n\naws.storagegateway.time_since_last_recovery_point(gauge)\nThe time since the last available recovery point.shown as second\n\n\n\n\naws.storagegateway.total_cache_size(gauge)\nThe total size of the cache in bytes. This metric applies only to the gateway-cached volume setup.shown as byte\n\n\n\n\naws.storagegateway.upload_buffer_free(gauge)\nThe total amount of unused space in the gateway's upload buffer.shown as byte\n\n\n\n\naws.storagegateway.upload_buffer_percent_used(gauge)\nPercent use of the gateway's upload buffer.shown as percent\n\n\n\n\naws.storagegateway.upload_buffer_used(gauge)\nThe total number of bytes being used in the gateway's upload buffer.shown as byte\n\n\n\n\naws.storagegateway.working_storage_free(gauge)\nThe total amount of unused space in the gateway's working storage.shown as byte\n\n\n\n\naws.storagegateway.working_storage_percent_used(gauge)\nPercent use of the gateway's upload buffer.shown as percent\n\n\n\n\naws.storagegateway.working_storage_used(gauge)\nThe total number of bytes being used in the gateway's upload buffer.shown as byte\n\n\n\n\naws.storagegateway.write_bytes(count every 60 seconds)\nThe total number of bytes written to your on-premises applications for all volumes in the gateway.shown as byte\n\n\n\n\naws.storagegateway.write_time(gauge)\nThe total number of milliseconds spent to do write operations from your on-premises applications for all volumes in the gateway.shown as millisecond\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsstoragegateway/"},{"title":"Datadog-AWS Simple Workflow Service Integration","text":"\n\nOverview\n\nAmazon SWF helps developers build, run, and scale background jobs that have parallel or sequential steps.\n\nEnable this integration to see in Datadog all your SWF metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that SWF is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.swf.activity_tasks_canceled(count every 60 seconds)\nThe count of activity tasks that were canceled.\n\n\n\n\naws.swf.activity_task_schedule_to_close_time(gauge)\nThe time interval, in milliseconds, between the time when the activity was scheduled to when it closed.shown as millisecond\n\n\n\n\naws.swf.activity_task_schedule_to_start_time(gauge)\nThe time interval, in milliseconds, between the time when the activity task was scheduled and when it started.shown as millisecond\n\n\n\n\naws.swf.activity_tasks_completed(count every 60 seconds)\nThe count of activity tasks that completed.\n\n\n\n\naws.swf.activity_tasks_failed(count every 60 seconds)\nThe count of activity tasks that failed.\n\n\n\n\naws.swf.activity_task_start_to_close_time(gauge)\nThe time interval, in milliseconds, between the time that the decision task was started and the time it was closed.shown as millisecond\n\n\n\n\naws.swf.decision_task_schedule_to_start_time(gauge)\nThe time interval, in milliseconds, between the time that the decision task was scheduled and the time it was picked up by a worker and started.shown as millisecond\n\n\n\n\naws.swf.decision_tasks_completed(count every 60 seconds)\nThe count of decision tasks that have been completed.\n\n\n\n\naws.swf.decision_task_start_to_close_time(gauge)\nThe time interval, in milliseconds, between the time that the decision task was started and the time it was closed.\n\n\n\n\naws.swf.scheduled_activity_tasks_timed_out_on_close(count every 60 seconds)\nThe count of activity tasks that were scheduled but timed out on close.\n\n\n\n\naws.swf.scheduled_activity_tasks_timed_out_on_start(count every 60 seconds)\nThe count of activity tasks that were scheduled but timed out on start.\n\n\n\n\naws.swf.started_activity_tasks_timed_out_on_close(count every 60 seconds)\nThe count of activity tasks that were started but timed out on close.\n\n\n\n\naws.swf.started_activity_tasks_timed_out_on_heartbeat(count every 60 seconds)\nThe count of activity tasks that were started but timed out due to a heartbeat timeout.\n\n\n\n\naws.swf.started_decision_tasks_timed_out_on_close(count every 60 seconds)\nThe count of decision tasks that started but timed out on closing.\n\n\n\n\naws.swf.workflows_canceled(count every 60 seconds)\nThe count of workflows that were canceled.\n\n\n\n\naws.swf.workflows_completed(count every 60 seconds)\nThe count of workflows that were completed.\n\n\n\n\naws.swf.workflows_continued_as_new(count every 60 seconds)\nThe count of workflows that continued as new.\n\n\n\n\naws.swf.workflows_failed(count every 60 seconds)\nThe count of workflows that failed.\n\n\n\n\naws.swf.workflow_start_to_close_time(gauge)\nThe time, in milliseconds, between the time the workflow started and the time it closed.shown as millisecond\n\n\n\n\naws.swf.workflows_terminated(count every 60 seconds)\nThe count of workflows that were terminated.\n\n\n\n\naws.swf.workflows_timed_out(count every 60 seconds)\nThe count of workflows that timed out, for any reason.\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsswf/"},{"title":"Datadog-AWS Web Application Firewall Integration","text":"\n\nOverview\n\nAWS WAF is a web application firewall that helps protect your web applications from common web exploits.\n\nEnable this integration to see in Datadog all your WAF metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that WAF is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.waf.allowed_requests(count every 60 seconds)\nThe number of allowed web requests.shown as request\n\n\n\n\naws.waf.blocked_requests(count every 60 seconds)\nThe number of blocked web requests.shown as request\n\n\n\n\naws.waf.counted_requests(count every 60 seconds)\nThe number of counted web requests.shown as request\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awswaf/"},{"title":"Datadog-AWS Workspaces Integration","text":"\n\nOverview\n\nAmazon WorkSpaces is a fully managed, secure desktop computing service which runs on the AWS cloud.\n\nEnable this integration to see in Datadog all your Workspaces metrics.\n\n\nInstallation\n\nIf you haven’t already, set up the Amazon Web Services integration first. There are no other installation steps that need to be performed.\n\n\nConfiguration\n\nIn the Amazon Web Services integration tile, ensure that Workspaces is checked under metric collection.\n\n\nMetrics\n\n\n\n\naws.workspaces.available(gauge)\nThe number of WorkSpaces that returned a healthy status.\n\n\n\n\naws.workspaces.connection_attempt(count every 60 seconds)\nThe number of connection attempts.\n\n\n\n\naws.workspaces.connection_failure(count every 60 seconds)\nThe number of failed connections.\n\n\n\n\naws.workspaces.connection_success(count every 60 seconds)\nThe number of successful connections.\n\n\n\n\naws.workspaces.in_session_latency(gauge)\nThe round trip time between the WorkSpaces client and the WorkSpace.shown as millisecond\n\n\n\n\naws.workspaces.session_disconnect(count every 60 seconds)\nThe number of connections that were closed, including user-initiated and failed connections.\n\n\n\n\naws.workspaces.session_launch_time(gauge)\nThe amount of time it takes to initiate a WorkSpaces session.shown as second\n\n\n\n\naws.workspaces.unhealthy(gauge)\nThe number of WorkSpaces that returned an unhealthy status.\n\n\n\n\naws.workspaces.user_connected(gauge)\nThe number of WorkSpaces that have a user connected.\n\n\n\n\naws.workspaces.stopped(gauge)\nThe number of WorkSpaces that are stopped.\n\n\n\n\naws.workspaces.maintenance(gauge)\nThe number of WorkSpaces that are under maintenance.\n\n\n\n\nEach of the metrics retrieved from AWS will be assigned the same tags that appear in the AWS console, including but not limited to host name, security-groups, and more.\n","tags":"","loc":"/integrations/awsworkspaces/"},{"title":"Datadog-Microsoft Azure Integration","text":"\n\nOverview\n\nConnect to Microsoft Azure in order to:\n\n\n  Get metrics from Azure VMs with or without installing the Agent\n  Tag your Azure VMs with Azure-specific information (e.g. location)\n  Get metrics for other services: Application Gateway, App Service (Web & Mobile), Batch Service, Event Hub, IOT Hub, Logic App, Redis Cache, Server Farm (App Service Plan), SQL Database, SQL Elastic Pool, and Virtual Machine Scale Set\n\n\nRelated integrations include:\n\n\n  \n    \n      App Service\n      easy-to-use service for deploying and scaling web, mobile, API and business logic applications\n    \n    \n      Batch Service\n      managed task scheduler and processor\n    \n    \n      Event Hub\n      large scale data stream managed service\n    \n    \n      IOT Hub\n      connect, monitor, and manage billions of IOT assets\n    \n    \n      Logic App\n      quickly build powerful integration solutions\n    \n    \n      Redis Cache\n      managed data cache\n    \n    \n      Storage\n      blob, file, queue, and table storage\n    \n    \n      SQL Database\n      highly scalable relational database in the cloud\n    \n    \n      SQL Database Elastic Pool\n      manage the performance of multiple databases\n    \n    \n      Virtual Machine\n      virtual machine management service\n    \n    \n      Virtual Machine Scale Set\n      deploy, manage, and autoscale a set of identical VMs\n    \n  \n\n\n\nInstallation\n\nYou can integrate your Microsoft Azure account with Datadog using the Azure CLI tool or the Azure portal.\n\n\nIntegrating through the Azure CLI\n\nTo integrate Datadog with Azure using the Azure CLI, make sure you have Azure CLI installed. \n\nFirst, login to the Azure account you want to integrate with Datadog\n\nFor Azure CLI 2.0\n\naz login\n\n\nRun the account show command and copy & paste the Tenant ID value into the form on the Azure setup tile under “Tenant Name/ID”\n\naz account show\n\n\n\n  Create an application as a service principal using the format below. \n  Grant the Service Principal the “reader” role for the subscription(s) you would like to monitor.\n  The appID generated from this command must be pasted into the “Client ID” text box in the Azure installation form in Datadog.\n  NOTE, you may add  --name {some-name} to use a hand-picked name. Otherwise Azure will generate a unique one. The Name will not be used in any way in the setup process.\n  NOTE, you may add  --password {some-password} to use a hand-picked password. Otherwise Azure will generate a unique one. This password must be copied and pasted into the “Client Secret” text box in the Azure installation form in Datadog.\n\n\naz ad sp create-for-rbac --role reader --scopes /subscriptions/{subscription_id}\n\n\nFor Azure CLI 1.0\n\nazure login\n\n\nRun the account show command and copy & paste the Tenant ID value into the form on the Azure setup tile under “Tenant Name/ID”\n\nazure account show\n\n\n\n  Create an application as a service principal using the format below. The name is NOT used in any way and is simply required as part of the setup process.\n  The password you choose must be copied and pasted into the form on the Azure setup tile under “Client Secret”.\n  You must also pass the “Client ID” of the application into Datadog. The “Client ID” is the unique ID generated from this command, shown under Service Principal Name. It is not the Object ID. \n\n\nazure ad sp create -n {name} -p {password}\n\n\n\n  Grant the Service Principal the “Reader” role for the subscription you are interested in monitoring.\n  Use the Object Id returned from the previous command to fill in {object-Id}.\n{subscription-Id} is the azure subscription you would like to monitor, and is listed as ID in azure account show or through the portal\n\n\nazure role assignment create --objectId {object-Id} -o Reader -c /subscriptions/{subscription-Id}/\n\n\nFor Azure CLI < 1.0\n\nazure login\n\n\nRun the account show command and copy & paste the Tenant ID value into the form on the Azure setup tile under “Tenant Name/ID”\n\nazure account show\n\n\n\n  Create an Active Directory application using the format below.\n  The name, home-page, and identifiter-uris will be NOT used in any way and are simply required as part of the setup process. \n  The password you choose must be copied and pasted into the form on the Azure setup tile under “Client Secret”\n\n\nazure ad app create --name \"DatadogAuth\" --home-page \"http://app.datadoghq.com\" --identifier-uris \"http://app.datadoghq.com\" --password \"SomePassword\"\n\n\n\n  Create a Service Principal using the AppId returned from the last command.\n  Copy and paste this AppId into the form on the Azure setup tile under “Client ID”\n\n\nazure cli <0.10.2:\n\nazure ad sp create {app-id}\n\n\nazure cli >= 0.10.2:\n\nazure ad sp create -a {app-id}\n\n\n\n  Grant the Service Principal the “Reader” role for the subscription you are interested in monitoring.\n  Use the Object Id returned from the previous command to fill in {object-Id}\n{subscription-Id} is the azure subscription you would like to monitor, and is listed as ID in azure account show or through the portal\n\n\nazure role assignment create --objectId {object-Id} --roleName Reader --subscription {subscription-Id}\n\n\n\nIntegrating through the Azure Portals\n\n\n  \nGet your tenant name and pass it to Datadog. \n  \nCreate a web application in your Active Directory and pass the correct credentials to Datadog.\n  \nGive this application read-access to any subscriptions you would like to monitor.\n\n\n\nGetting your Tenant Name\n\n\n  Navigate to portal.azure.com\n\n  In the leftmost blade, select “Azure Active Directory”\n  \n    Under properties, copy the Directory ID Value\n\n    \n  \n  \n    Paste the ID under “Tenant Name/ID” in the form on the Azure setup tile \n\n    \n  \n\n\n\nCreating the Web Application\n\n\n  Navigate to the “App Registrations” tab within your Azure Active Directory.\n  Press “Add”\n  Enter a name and Sign-on URL for this app. \n    \n      These will NOT be used in any way and are simply required as part of the setup process. \n      Leave Application “Type as Web app/ API”\n    \n  \n  \n    Press “Create”\n\n    \n  \n  Once it is created, select the App from the list of App Registrations\n  \n    Copy the “Application ID” and paste the value into “Client ID” in the form on the Azure setup tile\n\n    \n\n    \n  \n  For the same app, go to “All settings”\n  Go to “Keys”\n  Enter a new Client Secret key and press Save\n    \n      Make sure to note when the key will expire!\n    \n  \n  \n    When the Secret Key is shown, copy and paste it in “Client Secret” in the form on the Azure setup tile\n\n    \n\n    \n  \n  Click “Install Integration” to complete the application creation process\n\n\n\nGiving Read Permissions to the Application\n\n\n  \n    Navigate to “Subscriptions” on the left hand menu\n\n    \n  \n  Click on the subscription you would like to monitor\n  \n    Click on “Access control (IAM)” in the lefthand menu \n\n    \n  \n  \n    Click “Add” \n\n    \n  \n  \n    Select “Reader” as a role \n\n    \n  \n  Search/select for the name of the Application you just created (i.e. Datadog Auth)\n  Click Select\n  Click OK\n  Repeat this process for any other subscriptions you would like to monitor\n  Please note that Diagnostics must be enabled for ARM deployed VMs to collect metrics. See the instructions below\n\n\nIn a few minutes, metrics from applications under that subscription will begin to appear!\n\n\nNaviate to the Azure VM Default Dashboard to see this dashboard populate with your infrastructure’s data\n\nLearn more about how to monitor Azure VM performance metrics with our series of posts. We detail the key performance metrics, how to collect them, and how to use Datadog to monitor Azure VMs.\n\n\nConfiguration\n\nOptionally, you can limit the Azure VMs that are pulled into Datadog by entering tags in the “Optionally filter to VMs with tag” textbox. This comma separated list of tags (in the form ‘key:value’) defines a filter that we will use when collecting metrics from Azure VMs. Wildcards, such as ‘?’ (for single characters) and ‘*’ (for multiple characters) can also be used. Only VMs that match one of the defined tags will be imported into Datadog. The rest will be ignored.\n\nVMs matching a given tag can also be excluded by adding ‘!’ before the tag. For example:\n\ndatadog:monitored,env:production,!env:staging,instance-type:c1.*\n\n\n\n\n\nDeploy Agents\n\n\n  Navigate to your VM in the Azure Portal > Settings > Extenstions > Add > Select Datadog Agent. Use an API key found here \n  Manually deploy Agents by following the instructions here\n\n  Install based on operating system or CICD tool  using these instructions\n\n\n\n\nMetrics\n\nView the specific metrics we collect for each Azure service integration:\n\n\n  \nApp Service \n  \nBatch Service \n  \nEvent Hub \n  \nIOT Hub \n  Logic App\n  Redis Cache\n  SQL Database\n  SQL Database Elastic Pool\n  Virtual Machine\n  Virtual Machine Scale Set\n\n\n\nTroubleshooting\nHere are some common issues you might be seeing.\n\n\nI don’t know my tenant name\n\n\n  Navigate to portal.azure.com\n\n  In the leftmost blade, select “Azure Active Directory”\n  \n    Under properties, it is the Directory ID\n\n    \n  \n\n\nYour tenant name is also available from the URL after navigating to the classic portal. It is the text in between (not including) the @ and # symbol\n\n\n\n\nUnable to login\nIf you have experienced an error logging in while trying to install the integration, please reach out to support@datadoghq.com. When possible, please attach a screenshot.\n\n\nNo Metrics Are Showing Up\nPlease ensure you completed step three of the installation process, which entails giving read permissions to the Azure application (created in step two) for the subscriptions you want to monitor. \n\nFor ARM deployed virtual machines, you must also turn on Diagnostics and select the VM metrics you would like to collect. See Enable Diagnostics below for instructions.\n\n\nMissing Metrics?\nFor ARM virtual machines, ensure you have enabled diagnostics and selected the metrics you would like to collect using the instructions below. \n\nFor other missing metrics, please reach out to support@datadoghq.com.  \n\n\nEnable diagnostics\nTurning on Diagnostics allows ARM deployed VMs to collect logging information which includes metrics for CPU, Network, etc. To do this, first go to Azure Portal then follow the instructions below.\n\nAfter locating your VM:\n\n\n  Click on Diagnostics settings under the Monitoring section\n  Shift the status to On \n  Select the metrics you would like to collect (note: we recommend “Basic metrics”, “Network and web metrics”, and “.Net metrics”. Un-checking logs collection could save you some storage space. Linux Virtual Machines only collect “Basic” and “Boot” diagnostics)\n  \n    Click Save to save your changes\n\n    \n\n  \n\n","tags":"","loc":"/integrations/azure/"},{"title":"Datadog-Microsoft Azure App Service Integration","text":"\n\nOverview\nAzure App Service is a platform-as-a-service that runs web, mobile, API and business logic applications and automatically manages the resources required by those apps.\n\nGet metrics from Azure App Service to:\n\n\n  Visualize your app performance\n  Correlate the performance of your Azure Apps with the rest of your apps\n\n\n\nInstallation\n\nIf you haven’t already, set up the Microsoft Azure integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\nazure.app_services.bytes_sent(gauge)\nAverage number of bytes sentshown as byte\n\n\n\n\nazure.app_services.http2xx(count)\nTotal number of 2xx requests served by the appshown as request\n\n\n\n\nazure.app_services.http3xx(count)\nTotal number of 3xx requests served by the appshown as request\n\n\n\n\nazure.app_services.http401(count)\nTotal number of 401 requests served by the appshown as request\n\n\n\n\nazure.app_services.http403(count)\nTotal number of 403 requests served by the appshown as request\n\n\n\n\nazure.app_services.http404(count)\nTotal number of 404 requests served by the appshown as request\n\n\n\n\nazure.app_services.http406(count)\nTotal number of 406 requests served by the appshown as request\n\n\n\n\nazure.app_services.http4xx(count)\nTotal number of 4xx requests served by the appshown as request\n\n\n\n\nazure.app_services.http5xx(count)\nTotal number of 5xx requests served by the appshown as request\n\n\n\n\nazure.app_services.cpu_time(gauge)\nAverage cpu time of the appshown as second\n\n\n\n\nazure.app_services.requests(count)\nTotal number of requests served by the appshown as request\n\n\n\n\nazure.app_services.bytes_received(gauge)\nAverage number of bytes receivedshown as byte\n\n\n\n\nazure.app_services.memory_working_set(gauge)\nAverage memory used by the appshown as byte\n\n\n\n\nazure.app_services.average_response_time(gauge)\nAverage response time of the appshown as second\n\n\n\n\nazure.app_services.average_memory_working_set(gauge)\nAverage memory used by the appshown as byte\n\n\n\n\n","tags":"","loc":"/integrations/azure_app_services/"},{"title":"Datadog-Microsoft Azure Batch Integration","text":"\n\nOverview\nAzure Batch Service is a managed task scheduler and processor for your Azure applications.\n\nGet metrics from Azure Batch Service to:\n\n\n  Visualize the performance of your Batch Accounts\n  Correlate the performance of your Batch Accounts with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Microsoft Azure integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\nazure.batch_batchaccounts.core_count(gauge)\nAverage number of cores in the batch accountshown as core\n\n\n\n\nazure.batch_batchaccounts.creating_node_count(gauge)\nNumber of nodes being createdshown as node\n\n\n\n\nazure.batch_batchaccounts.idle_node_count(gauge)\nNumber of idle nodesshown as node\n\n\n\n\nazure.batch_batchaccounts.leaving_pool_node_count(gauge)\nNumber of nodes leaving the Poolshown as node\n\n\n\n\nazure.batch_batchaccounts.offline_node_count(gauge)\nNumber of offline nodesshown as node\n\n\n\n\nazure.batch_batchaccounts.pool_create_event(count)\nTotal number of pools that have been createdshown as event\n\n\n\n\nazure.batch_batchaccounts.pool_delete_complete_event(count)\nTotal number of pool deletes that have completedshown as event\n\n\n\n\nazure.batch_batchaccounts.pool_delete_start_event(count)\nTotal number of pool deletes that have startedshown as event\n\n\n\n\nazure.batch_batchaccounts.pool_resize_complete_event(count)\nTotal number of pool resizes that have completedshown as event\n\n\n\n\nazure.batch_batchaccounts.pool_resize_start_event(count)\nTotal number of pool resizes that have startedshown as event\n\n\n\n\nazure.batch_batchaccounts.rebooting_node_count(gauge)\nNumber of rebooting nodesshown as node\n\n\n\n\nazure.batch_batchaccounts.reimaging_node_count(gauge)\nNumber of reimaging nodesshown as node\n\n\n\n\nazure.batch_batchaccounts.running_node_count(gauge)\nNumber of running nodesshown as node\n\n\n\n\nazure.batch_batchaccounts.start_task_failed_node_count(gauge)\nNumber of nodes where the Start Task has failedshown as node\n\n\n\n\nazure.batch_batchaccounts.starting_node_count(gauge)\nNumber of nodes startingshown as node\n\n\n\n\nazure.batch_batchaccounts.task_complete_event(count)\nTotal number of tasks that have completedshown as event\n\n\n\n\nazure.batch_batchaccounts.task_fail_event(count)\nTotal number of tasks that have completed in a failed stateshown as event\n\n\n\n\nazure.batch_batchaccounts.task_start_event(count)\nTotal number of tasks that have startedshown as event\n\n\n\n\nazure.batch_batchaccounts.total_node_count(gauge)\nAverage number of nodes in the batch accountshown as node\n\n\n\n\nazure.batch_batchaccounts.unusable_node_count(gauge)\nNumber of unusable nodesshown as node\n\n\n\n\nazure.batch_batchaccounts.waiting_for_start_task_node_count(gauge)\nNumber of nodes waiting for the Start Task to completeshown as node\n\n\n\n","tags":"","loc":"/integrations/azure_batch/"},{"title":"Datadog-Microsoft Azure Event Hub Integration","text":"\n\nOverview\nAzure Event Hub is a large scale data stream managed service.\n\nGet metrics from Azure Event Hub to:\n\n\n  Visualize the performance of your Event Hubs\n  Correlate the performance of your Event Hubs with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Microsoft Azure integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\nazure.eventhub_namespaces.archive_backlog_messages(count every 60 seconds)\nEvent Hub archive messages in backlog for a namespaceshown as message\n\n\n\n\nazure.eventhub_namespaces.archive_message_throughput(rate every 60 seconds)\nEvent Hub archived message throughput in a namespaceshown as byte/second\n\n\n\n\nazure.eventhub_namespaces.archive_messages(count every 60 seconds)\nEvent Hub archived messages in a namespaceshown as message\n\n\n\n\nazure.eventhub_namespaces.incoming_bytes_per_sec(rate every 60 seconds)\nEvent Hub incoming message throughput for a namespaceshown as byte/second\n\n\n\n\nazure.eventhub_namespaces.outgoing_bytes_per_sec(rate every 60 seconds)\nEvent Hub outgoing message throughput for a namespaceshown as byte/second\n\n\n\n\nazure.eventhub_namespaces.failed_requests(count every 60 seconds)\nTotal failed requests for a namespaceshown as request\n\n\n\n\nazure.eventhub_namespaces.incoming_messages(count every 60 seconds)\nTotal incoming messages for a namespaceshown as message\n\n\n\n\nazure.eventhub_namespaces.incoming_requests(count every 60 seconds)\nTotal incoming requests for a namespaceshown as request\n\n\n\n\nazure.eventhub_namespaces.internal_server_errors(count every 60 seconds)\nTotal internal server errors for a namespaceshown as error\n\n\n\n\nazure.eventhub_namespaces.other_errors(count every 60 seconds)\nTotal other errors for a namespaceshown as error\n\n\n\n\nazure.eventhub_namespaces.outgoing_messages(count every 60 seconds)\nTotal outgoing messages for a namespaceshown as message\n\n\n\n\nazure.eventhub_namespaces.successful_requests(count every 60 seconds)\nTotal successful requests for a namespaceshown as request\n\n\n\n\nazure.eventhub_namespaces.server_busy_errors(count every 60 seconds)\nTotal server busy errors for a namespaceshown as error\n\n\n\n\n","tags":"","loc":"/integrations/azure_event_hub/"},{"title":"Datadog-Microsoft Azure IOT Hub Integration","text":"\n\nOverview\nAzure IOT Hub is a fully managed service that enables reliable and secure bidirectional communications between millions of IoT devices.\n\nGet metrics from Azure IOT Hub to:\n\n\n  Visualize the performance of your IOT Hubs\n  Correlate the performance of your IOT Hubs with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Microsoft Azure integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\nazure.devices_iothubs.c2d.commands.egress.abandon.success(count)\nNumber of Cloud to Device commands abandoned by the deviceshown as command\n\n\n\n\nazure.devices_iothubs.c2d.commands.egress.complete.success(count)\nNumber of Cloud to Device commands completed successfully by the deviceshown as command\n\n\n\n\nazure.devices_iothubs.c2d.commands.egress.reject.success(count)\nNumber of Cloud to Device commands rejected by the deviceshown as command\n\n\n\n\nazure.devices_iothubs.c2d.methods.failure(count)\nNumber of Cloud to Device method invocation failuresshown as method\n\n\n\n\nazure.devices_iothubs.c2d.methods.request_size(gauge)\nRequest size of Cloud to Device method invocationsshown as byte\n\n\n\n\nazure.devices_iothubs.c2d.methods.response_size(gauge)\nResponse size of Cloud to Device method invocationsshown as byte\n\n\n\n\nazure.devices_iothubs.c2d.methods.success(count)\nNumber of Cloud to Device method invocation successesshown as method\n\n\n\n\nazure.devices_iothubs.c2d.twin.read.failure(count)\nNumber of failed backend-initiated twin readsshown as read\n\n\n\n\nazure.devices_iothubs.c2d.twin.read.size(gauge)\nResponse size of backend-initiated twin readsshown as byte\n\n\n\n\nazure.devices_iothubs.c2d.twin.read.success(count)\nNumber of successful backend-initiated twin readsshown as read\n\n\n\n\nazure.devices_iothubs.c2d.twin.update.failure(count)\nNumber of failed device-initiated twin updatesshown as update\n\n\n\n\nazure.devices_iothubs.c2d.twin.update.size(gauge)\nResponse size of device-initiated twin updatesshown as byte\n\n\n\n\nazure.devices_iothubs.c2d.twin.update.success(count)\nNumber of successful device-initiated twin updatesshown as update\n\n\n\n\nazure.devices_iothubs.d2c.endpoints.egress.built_in.events(count)\nNumber of messages successfully written to the built-in endpointshown as message\n\n\n\n\nazure.devices_iothubs.d2c.endpoints.egress.event_hubs(count)\nNumber of messages successfully written to the Event Hub endpointsshown as message\n\n\n\n\nazure.devices_iothubs.d2c.endpoints.egress.service_bus_queues(count)\nNumber of messages successfully written to the Service Bus Queues endpointsshown as message\n\n\n\n\nazure.devices_iothubs.d2c.endpoints.egress.service_bus_topics(count)\nNumber of messages successfully written to the Service Bus Topics endpointsshown as message\n\n\n\n\nazure.devices_iothubs.d2c.endpoints.latency.built_in.events(gauge)\nThe average latency between message ingress to the IoT hub and message ingress into the built-in endpointshown as millisecond\n\n\n\n\nazure.devices_iothubs.d2c.endpoints.latency.event_hubs(gauge)\nThe average latency between message ingress to the IoT hub and message ingress into a Event Hub endpointshown as millisecond\n\n\n\n\nazure.devices_iothubs.d2c.endpoints.latency.service_bus_queues(gauge)\nThe average latency between message ingress to the IoT hub and message ingress into a Service Bus Queue endpointshown as millisecond\n\n\n\n\nazure.devices_iothubs.d2c.endpoints.latency.service_bus_topics(gauge)\nThe average latency between message ingress to the IoT hub and message ingress into a Service Bus Topic endpointshown as millisecond\n\n\n\n\nazure.devices_iothubs.d2c.telemetry.egress.dropped(count)\nNumber of messages dropped because they did not match any routes and the fallback route was disabledshown as message\n\n\n\n\nazure.devices_iothubs.d2c.telemetry.egress.fallback(count)\nNumber of messages written to the fallback endpointshown as message\n\n\n\n\nazure.devices_iothubs.d2c.telemetry.egress.invalid(count)\nThe count of messages not delivered due to incompatibility with the endpointshown as message\n\n\n\n\nazure.devices_iothubs.d2c.telemetry.egress.orphaned(count)\nThe count of messages not matching any routes including the fallback routeshown as message\n\n\n\n\nazure.devices_iothubs.d2c.telemetry.egress.success(count)\nNumber of times messages were successfully written to endpointsshown as message\n\n\n\n\nazure.devices_iothubs.d2c.telemetry.ingress.all_protocol(count)\nNumber of Device to Cloud telemetry messages attempted to be sent to IOT Hubshown as message\n\n\n\n\nazure.devices_iothubs.d2c.telemetry.ingress.success(count)\nNumber of Device to Cloud telemetry messages successfully sent to IOT Hubshown as message\n\n\n\n\nazure.devices_iothubs.d2c.twin.read.failure(count)\nNumber of failed device-initiated twin readsshown as read\n\n\n\n\nazure.devices_iothubs.d2c.twin.read.size(gauge)\nResponse size of device-initiated twin readsshown as byte\n\n\n\n\nazure.devices_iothubs.d2c.twin.read.success(count)\nNumber of successful device-initiated twin readsshown as read\n\n\n\n\nazure.devices_iothubs.d2c.twin.update.failure(count)\nNumber of failed device-initiated twin updatesshown as update\n\n\n\n\nazure.devices_iothubs.d2c.twin.update.size(gauge)\nResponse size of device-initiated twin updatesshown as byte\n\n\n\n\nazure.devices_iothubs.d2c.twin.update.success(count)\nNumber of successful device-initiated twin updatesshown as update\n\n\n\n\nazure.devices_iothubs.devices.connected_devices.all_protocol(gauge)\nNumber of devices connected to your IoT hubshown as device\n\n\n\n\nazure.devices_iothubs.devices.total_devices(gauge)\nNumber of devices registered to your IoT hubshown as device\n\n\n\n\nazure.devices_iothubs.jobs.cancel_job.failure(count)\nNumber of failed calls to cancel a jobshown as operation\n\n\n\n\nazure.devices_iothubs.jobs.cancel_job.success(count)\nNumber of successful calls to cancel a jobshown as operation\n\n\n\n\nazure.devices_iothubs.jobs.completed(count)\nNumber of completed jobsshown as job\n\n\n\n\nazure.devices_iothubs.jobs.create_direct_method_job.failure(count)\nNumber of failed creations of direct method invocation jobsshown as operation\n\n\n\n\nazure.devices_iothubs.jobs.create_direct_method_job.success(count)\nNumber of successful creations of direct method invocation jobsshown as operation\n\n\n\n\nazure.devices_iothubs.jobs.create_twin_update_job.failure(count)\nNumber of failed creations of twin update jobsshown as operation\n\n\n\n\nazure.devices_iothubs.jobs.create_twin_update_job.success(count)\nNumber of successful creations of twin update jobsshown as operation\n\n\n\n\nazure.devices_iothubs.jobs.failed(count)\nNumber of failed jobsshown as job\n\n\n\n\nazure.devices_iothubs.jobs.list_jobs.failure(count)\nNumber of failed calls to list jobsshown as operation\n\n\n\n\nazure.devices_iothubs.jobs.list_jobs.success(count)\nNumber of successful calls to list jobsshown as operation\n\n\n\n\nazure.devices_iothubs.jobs.query_jobs.failure(count)\nNumber of failed calls to query jobsshown as query\n\n\n\n\nazure.devices_iothubs.jobs.query_jobs.success(count)\nNumber of successful calls to query jobsshown as query\n\n\n\n\nazure.devices_iothubs.twin_queries.failure(count)\nNumber of failed twin queriesshown as query\n\n\n\n\nazure.devices_iothubs.twin_queries.result_size(gauge)\nAverage result size of successful twin queriesshown as byte\n\n\n\n\nazure.devices_iothubs.twin_queries.success(gauge)\nNumber of successful twin queriesshown as query\n\n\n\n","tags":"","loc":"/integrations/azure_iot_hub/"},{"title":"Datadog-Microsoft Azure Logic App Integration","text":"\n\nOverview\nLogic App allows developers to design workflows that articulate intent via a trigger and series of steps.\n\nGet metrics from Azure Logc App to:\n\n\n  Visualize the performance of your Logic App workflows\n  Correlate the performance of your Logic App workflows with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Microsoft Azure integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\nazure.logic_workflows.action_latency(gauge)\nLatency of completed workflow actionsshown as second\n\n\n\n\nazure.logic_workflows.action_success_latency(gauge)\nLatency of succeeded workflow actionsshown as second\n\n\n\n\nazure.logic_workflows.action_throttled_events(count)\nNumber of workflow action throttled eventsshown as event\n\n\n\n\nazure.logic_workflows.actions_completed(count)\nNumber of workflow actions completedshown as event\n\n\n\n\nazure.logic_workflows.actions_failed(count)\nNumber of workflow actions failedshown as event\n\n\n\n\nazure.logic_workflows.actions_skipped(count)\nNumber of workflow actions skippedshown as event\n\n\n\n\nazure.logic_workflows.actions_started(count)\nNumber of workflow actions startedshown as event\n\n\n\n\nazure.logic_workflows.actions_succeeded(count)\nNumber of workflow actions succeededshown as event\n\n\n\n\nazure.logic_workflows.billable_action_executions(count)\nNumber of workflow action executions getting billedshown as event\n\n\n\n\nazure.logic_workflows.billable_trigger_executions(count)\nNumber of workflow trigger executions getting billedshown as event\n\n\n\n\nazure.logic_workflows.total_billable_executions(count)\nNumber of workflow executions getting billedshown as event\n\n\n\n\nazure.logic_workflows.run_failure_percentage(gauge)\nPercentage of workflow runs failedshown as percent\n\n\n\n\nazure.logic_workflows.run_latency(gauge)\nLatency of completed workflow runsshown as second\n\n\n\n\nazure.logic_workflows.run_success_latency(gauge)\nLatency of succeeded workflow runsshown as second\n\n\n\n\nazure.logic_workflows.run_throttled_events(count)\nNumber of workflow action or trigger throttled eventsshown as event\n\n\n\n\nazure.logic_workflows.runs_cancelled(count)\nNumber of workflow runs cancelledshown as event\n\n\n\n\nazure.logic_workflows.runs_completed(count)\nNumber of workflow runs completed.shown as event\n\n\n\n\nazure.logic_workflows.runs_failed(count)\nNumber of workflow runs failedshown as event\n\n\n\n\nazure.logic_workflows.runs_started(count)\nNumber of workflow runs startedshown as event\n\n\n\n\nazure.logic_workflows.runs_succeeded(count)\nNumber of workflow runs succeededshown as event\n\n\n\n\nazure.logic_workflows.trigger_fire_latency(gauge)\nLatency of fired workflow triggersshown as second\n\n\n\n\nazure.logic_workflows.trigger_latency(gauge)\nLatency of completed workflow triggersshown as second\n\n\n\n\nazure.logic_workflows.trigger_success_latency(gauge)\nLatency of succeeded workflow triggersshown as second\n\n\n\n\nazure.logic_workflows.trigger_throttled_events(count)\nNumber of workflow trigger throttled eventsshown as event\n\n\n\n\nazure.logic_workflows.triggers_completed(count)\nNumber of workflow triggers completedshown as event\n\n\n\n\nazure.logic_workflows.triggers_failed(count)\nNumber of workflow triggers failedshown as event\n\n\n\n\nazure.logic_workflows.triggers_fired(count)\nNumber of workflow triggers firedshown as event\n\n\n\n\nazure.logic_workflows.triggers_skipped(count)\nNumber of workflow triggers skippedshown as event\n\n\n\n\nazure.logic_workflows.triggers_started(count)\nNumber of workflow triggers startedshown as event\n\n\n\n\nazure.logic_workflows.triggers_succeeded(count)\nNumber of workflow triggers succeededshown as event\n\n\n\n\n","tags":"","loc":"/integrations/azure_logic_app/"},{"title":"Datadog-Microsoft Azure Redis Cache Integration","text":"\n\nOverview\nAzure Redis Cache is a managed data cache for your Azure applications.\n\nGet metrics from Azure Redis Cache to:\n\n\n  Visualize the performance of your Redis Caches\n  Correlate the performance of your Redis Caches with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Microsoft Azure integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\nazure.cache_redis.cache_read(rate)\nThe amount of data read from the cache in bytes per secondshown as byte/second\n\n\n\n\nazure.cache_redis.cache_write(rate)\nThe amount of data written to the cache in bytes per secondshown as byte/second\n\n\n\n\nazure.cache_redis.cachehits(count)\nThe number of successful key lookupsshown as hit\n\n\n\n\nazure.cache_redis.cachemisses(count)\nThe number of failed key lookupsshown as miss\n\n\n\n\nazure.cache_redis.connectedclients(count)\nThe number of client connections to the cacheshown as connection\n\n\n\n\nazure.cache_redis.evictedkeys(count)\nThe number of items evicted from the cacheshown as key\n\n\n\n\nazure.cache_redis.expiredkeys(count)\nThe number of items expired from the cacheshown as key\n\n\n\n\nazure.cache_redis.getcommands(count)\nThe number of get operations from the cacheshown as get\n\n\n\n\nazure.cache_redis.percent_processor_time(gauge)\nThe CPU utilization of the Azure Redis Cache server as a percentageshown as percent\n\n\n\n\nazure.cache_redis.server_load(gauge)\nThe percentage of cycles in which the Redis server is busy processing and not waiting idle for messagesshown as percent\n\n\n\n\nazure.cache_redis.setcommands(count)\nThe number of set operations to the cacheshown as set\n\n\n\n\nazure.cache_redis.totalcommandsprocessed(count)\nThe total number of commands processed by the cache servershown as operation\n\n\n\n\nazure.cache_redis.totalkeys(count)\nThe total number of keys in the cacheshown as key\n\n\n\n\nazure.cache_redis.usedmemory(gauge)\nThe amount of cache memory used for key/value pairs in the cache in bytesshown as byte\n\n\n\n\nazure.cache_redis.usedmemory_rss(gauge)\nThe amount of cache memory used in bytes during the specified reporting interval, including fragmentation and metadatashown as byte\n\n\n\n\n","tags":"","loc":"/integrations/azure_redis_cache/"},{"title":"Datadog-Microsoft Azure SQL Database Integration","text":"\n\nOverview\nAzure SQL Database gives you a robust datastore with the flexibility to scale to meet demand.\n\nGet metrics from Azure SQL Database to:\n\n\n  Visualize the performance of your SQL Database\n  Correlate the performance of your SQL Database with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Microsoft Azure integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\nazure.sql_servers_databases.blocked_by_firewall(count every 60 seconds)\nCount of connection attempts blocked by the firewallshown as connection\n\n\n\n\nazure.sql_servers_databases.connection_failed(count every 60 seconds)\nCount of failed connectionsshown as connection\n\n\n\n\nazure.sql_servers_databases.connection_successful(count every 60 seconds)\nCount of successful connectionsshown as connection\n\n\n\n\nazure.sql_servers_databases.deadlock(count every 60 seconds)\nCount of deadlocks\n\n\n\n\nazure.sql_servers_databases.dtu_limit(gauge)\nDatabase throughput units utilization limitshown as unit\n\n\n\n\nazure.sql_servers_databases.dtu_used(gauge)\nDatabase throughput units usedshown as unit\n\n\n\n\nazure.sql_servers_databases.sessions_percent(gauge)\n\nshown as percent\n\n\n\n\nazure.sql_servers_databases.storage_percent(gauge)\nPercent of the maximum size for the database usedshown as percent\n\n\n\n\nazure.sql_servers_databases.storage(gauge)\nTotal size of the databaseshown as byte\n\n\n\n\nazure.sql_servers_databases.workers_percent(gauge)\n\nshown as percent\n\n\n\n\nazure.sql_servers_databases.cpu_percent(gauge)\nAverage CPU utilizationshown as percent\n\n\n\n\nazure.sql_servers_databases.physical_data_read_percent(gauge)\nAverage IO utilizationshown as percent\n\n\n\n\nazure.sql_servers_databases.log_write_percent(gauge)\nAverage log utilizationshown as percent\n\n\n\n\nazure.sql_servers_databases.xtp_storage_percent(gauge)\nIn-Memory OLTP storage percentshown as percent\n\n\n\n\nazure.sql_servers_databases.dtu_consumption_percent(gauge)\nDatabase throughput units utilizationshown as percent\n\n\n\n\nazure.sql_servers_databases.dwu_consumption_percent(gauge)\nData warehouse units utilizationshown as percent\n\n\n\n\nazure.sql_servers_databases.dwu_limit(gauge)\nData warehouse units utilization limitshown as unit\n\n\n\n\nazure.sql_servers_databases.dwu_used(gauge)\nData warehouse units usedshown as unit\n\n\n\n\n","tags":"","loc":"/integrations/azure_sql_database/"},{"title":"Datadog-Microsoft Azure SQL Elastic Pool Integration","text":"\n\nOverview\nElastic pools provide a simple and cost effective solution for managing the performance of multiple databases.\n\nGet metrics from Azure SQL Elastic Pool to:\n\n\n  Visualize the performance of your SQL Elastic Pools\n  Correlate the performance of your SQL Elastic Pools with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Microsoft Azure integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\nazure.sql_servers_elasticpools.cpu_percent(gauge)\nAverage compute utilization in percentage of the limit of the poolshown as percent\n\n\n\n\nazure.sql_servers_elasticpools.dtu_consumption_percent(gauge)\nAverage eDTU utilization in percentage of eDTU limit for the poolshown as percent\n\n\n\n\nazure.sql_servers_elasticpools.e_dtu_limit(gauge)\nCurrent max elastic pool DTU setting for this elastic poolshown as unit\n\n\n\n\nazure.sql_servers_elasticpools.e_dtu_used(gauge)\nAverage eDTUs used by the poolshown as unit\n\n\n\n\nazure.sql_servers_elasticpools.log_write_percent(gauge)\nAverage write resource utilization in percentage of the limit of the poolshown as percent\n\n\n\n\nazure.sql_servers_elasticpools.physical_data_read_percent(gauge)\nAverage I/O utilization in percentage based on the limit of the poolshown as percent\n\n\n\n\nazure.sql_servers_elasticpools.sessions_percent(gauge)\nMaximum concurrent sessions in percentage based on the limit of the poolshown as percent\n\n\n\n\nazure.sql_servers_elasticpools.storage_limit(gauge)\nCurrent max elastic pool storage limit setting for this elastic pool in megabytes during this intervalshown as byte\n\n\n\n\nazure.sql_servers_elasticpools.storage_percent(gauge)\nCurrent max elastic pool storage limit setting for this elastic poolshown as percent\n\n\n\n\nazure.sql_servers_elasticpools.storage_used(gauge)\nAverage storage used by the pool in this interval in bytesshown as byte\n\n\n\n\nazure.sql_servers_elasticpools.workers_percent(gauge)\nMaximum concurrent workers (requests) in percentage based on the limit of the poolshown as percent\n\n\n\n\n","tags":"","loc":"/integrations/azure_sql_elastic_pool/"},{"title":"Datadog-Microsoft Azure Storage Integration","text":"\n\nOverview\n\nAzure Storage is the cloud storage solution for modern applications that rely on durability, availability, and scalability to meet the needs of their customers. It provides the following four services: Blob storage, Table storage, Queue storage, and File storage\n\nEnable this integration to see capacity and transaction metrics from Azure Storage in Datadog. Note that capacity metrics are only available for Blob storage.\n\n\n\n\nInstallation\n\n\n  If you haven’t already, set up the Main Azure Integration.\n  For each storage account that you want to monitor, create the required monitoring tables and generate the SAS token with the Azure Storage integration setup CLI. Instructions and a script for completing this step can be found here\n\n  \n    Paste the storage account name and SAS token generated from the CLI tool into the form in the Azure Storage Tile\n\n    \n  \n  Once you have done this for each Storage Account you wish to monitor, click Update Configuration.\n\n\nNOTE: It may take up to an hour for Azure to generate and populate the minute-metric table for a Storage Account. This delay will occur when first adding a Storage Account to monitor in Datadog\n\n\nMetrics\n\n\n\nazure.storage.anonymous_authorization_error(count every 60 seconds)\nThe number of anonymous requests to a storage service or the specified API operation that returned an AnonymousAuthorizationError. shown as error\n\n\n\n\nazure.storage.anonymous_client_other_error(count every 60 seconds)\nThe number of anonymous requests to a storage service or the specified API operation that returned an AnonymousClientOtherError. shown as error\n\n\n\n\nazure.storage.anonymous_client_timeout_error(count every 60 seconds)\nThe number of anonymous requests to a storage service or the specified API operation that returned an AnonymousClientTimeoutError. shown as error\n\n\n\n\nazure.storage.anonymous_network_error(count every 60 seconds)\nThe number of anonymous requests to a storage service or the specified API operation that returned an AnonymousNetworkError.shown as error\n\n\n\n\nazure.storage.anonymous_server_other_error(count every 60 seconds)\nThe number of anonymous requests to a storage service or the specified API operation that returned an AnonymousServerOtherError. shown as error\n\n\n\n\nazure.storage.anonymous_server_timeout_error(count every 60 seconds)\nThe number of anonymous requests to a storage service or the specified API operation that returned an AnonymousServerTimeoutError. shown as error\n\n\n\n\nazure.storage.anonymous_success(count every 60 seconds)\nThe number of successful anonymous requests made to a storage service or the specified API operation.shown as request\n\n\n\n\nazure.storage.anonymous_throttling_error(count every 60 seconds)\nThe number of anonymous requests to a storage service or the specified API operation that returned an AnonymousThrottlingError.shown as error\n\n\n\n\nazure.storage.authorization_error(count every 60 seconds)\nThe number of authenticated requests to a storage service or the specified API operation that returned an AuthorizationError. shown as error\n\n\n\n\nazure.storage.availability(gauge every 60 seconds)\nThe percentage of availability for the storage service or the specified API operation. shown as percent\n\n\n\n\nazure.storage.average_e2_e_latency(gauge every 60 seconds)\nThe average end-to-end latency of successful requests made to a storage service or the specified API operation in millisecondsshown as millisecond\n\n\n\n\nazure.storage.average_server_latency(gauge every 60 seconds)\nThe average latency used by Azure Storage to process a successful request in milliseconds.shown as millisecond\n\n\n\n\nazure.storage.capacity(gauge every 60 seconds)\nThe amount of storage used by the storage account’s Blob service in bytes.shown as byte\n\n\n\n\nazure.storage.client_other_error(count every 60 seconds)\nThe number of authenticated requests to a storage service or the specified API operation that returned a ClientOtherError.shown as error\n\n\n\n\nazure.storage.client_timeout_error(count every 60 seconds)\nThe number of authenticated requests to a storage service or the specified API operation that returned a ClientTimeoutError. shown as error\n\n\n\n\nazure.storage.container_count(count every 60 seconds)\nThe number of blob containers in the storage account’s Blob service.shown as container\n\n\n\n\nazure.storage.network_error(count every 60 seconds)\nThe number of authenticated requests to a storage service or the specified API operation that returned a NetworkError.shown as error\n\n\n\n\nazure.storage.object_count(count every 60 seconds)\nThe number of committed and uncommitted blobs in the storage account’s Blob service.shown as object\n\n\n\n\nazure.storage.percent_authorization_error(gauge every 60 seconds)\nThe percentage of requests that failed with an AuthorizationError.shown as percent\n\n\n\n\nazure.storage.percent_client_other_error(gauge every 60 seconds)\nThe percentage of requests that failed with a ClientOtherError. shown as percent\n\n\n\n\nazure.storage.percent_network_error(gauge every 60 seconds)\nThe percentage of requests that failed with a NetworkError.shown as percent\n\n\n\n\nazure.storage.percent_server_other_error(gauge every 60 seconds)\nThe percentage of requests that failed with a ServerOtherError. shown as percent\n\n\n\n\nazure.storage.percent_success(gauge every 60 seconds)\nThe percentage of successful requests.shown as percent\n\n\n\n\nazure.storage.percent_throttling_error(gauge every 60 seconds)\nThe percentage of requests that failed with a throttling error.shown as percent\n\n\n\n\nazure.storage.percent_timeout_error(gauge every 60 seconds)\nThe percentage of requests that failed with a timeout error. This number includes both client and server timeouts.shown as percent\n\n\n\n\nazure.storage.sas_authorization_error(count every 60 seconds)\nThe number of SAS requests to a storage service or the specified API operation that returned an SASAuthorizationError.shown as error\n\n\n\n\nazure.storage.sas_client_other_error(count every 60 seconds)\nThe number of SAS requests to a storage service or the specified API operation that returned an SASClientOtherError.shown as error\n\n\n\n\nazure.storage.sas_client_timeout_error(count every 60 seconds)\nThe number of SAS requests to a storage service or the specified API operation that returned an SASClientTimeoutError.shown as error\n\n\n\n\nazure.storage.sas_network_error(count every 60 seconds)\nThe number of SAS requests to a storage service or the specified API operation that returned a SASNetworkError. shown as error\n\n\n\n\nazure.storage.sas_server_other_error(count every 60 seconds)\nThe number of SAS requests to a storage service or the specified API operation that returned an SASServerOtherError.shown as error\n\n\n\n\nazure.storage.sas_server_timeout_error(count every 60 seconds)\nThe number of SAS requests to a storage service or the specified API operation that returned an SASServerTimeoutError.shown as error\n\n\n\n\nazure.storage.sas_success(count every 60 seconds)\nThe number of successful Shared Access Signature (SAS) requests made to a storage service or the specified API operation.shown as request\n\n\n\n\nazure.storage.sas_throttling_error(count every 60 seconds)\nThe number of SAS requests to a storage service or the specified API operation that returned a SASThrottlingError. shown as error\n\n\n\n\nazure.storage.server_other_error(count every 60 seconds)\nThe number of authenticated requests to a storage service or the specified API operation that returned a ServerOtherError. shown as error\n\n\n\n\nazure.storage.server_timeout_error(count every 60 seconds)\nThe number of authenticated requests to a storage service or the specified API operation that returned a ServerTimeoutError. shown as error\n\n\n\n\nazure.storage.success(count every 60 seconds)\nThe number of successful requests made to a storage service or the specified API operation.shown as request\n\n\n\n\nazure.storage.throttling_error(count every 60 seconds)\nThe number of authenticated requests to a storage service or the specified API operation that returned a ThrottlingErrorshown as error\n\n\n\n\nazure.storage.total_billable_requests(count every 60 seconds)\nThe number of billable requestsshown as request\n\n\n\n\nazure.storage.total_egress(count every 60 seconds)\nThe amount of egress data in bytes.shown as byte\n\n\n\n\nazure.storage.total_ingress(count every 60 seconds)\nThe amount of ingress data in bytes.shown as byte\n\n\n\n\nazure.storage.total_requests(count every 60 seconds)\nThe number of requests made to a storage service or the specified API operation. This number includes successful and failed requests as well as requests which produced errors.shown as request\n\n\n\n\n","tags":"","loc":"/integrations/azure_storage/"},{"title":"Datadog-Microsoft Azure VM Integration","text":"\n\nOverview\nAzure Virtual Machine allows you to flexibly run virtualized environments with the ability to scale on-demand.\n\nGet metrics from Azure VM to:\n\n\n  Visualize the performance of your VMs\n  Correlate the performance of your VMs with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Microsoft Azure integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\nazure.vm.asp.net_applications_running(gauge)\nNumber of applications running concurrently on the server computer\n\n\n\n\nazure.vm.asp.net_applications_total_errors_total_per_sec(gauge)\nRate of errors that occur during the execution of HTTP requestsshown as error/second\n\n\n\n\nazure.vm.asp.net_applications_total_pipeline_instance_count(gauge)\nNumber of active request pipeline instances for the specified ASP.NET application.\n\n\n\n\nazure.vm.asp.net_applications_total_requests_executing(gauge)\nNumber of requests currently executingshown as request\n\n\n\n\nazure.vm.asp.net_applications_total_requests_in_application_queue(gauge)\nNumber of requests waiting for service from the queueshown as request\n\n\n\n\nazure.vm.asp.net_applications_total_requests_per_sec(gauge)\nRate of requests executed per secondshown as request/second\n\n\n\n\nazure.vm.asp.net_request_execution_time(gauge)\nTime to execute the last requestshown as millisecond\n\n\n\n\nazure.vm.asp.net_requests_queued(gauge)\nNumber of requests waiting for service from the queueshown as request\n\n\n\n\nazure.vm.asp.net_requests_rejected(gauge)\nTotal number of requests not executed because of insufficient server resources to process themshown as request\n\n\n\n\nazure.vm.asp.net_request_wait_time(gauge)\nTime that the most recent request waited in the queue for processingshown as millisecond\n\n\n\n\nazure.vm.memory_available_bytes(gauge)\nPool size of available pages in RAM that the system uses to satisfy requests for new pagesshown as byte\n\n\n\n\nazure.vm.memory_available_swap(gauge)\nAvailable swapshown as byte\n\n\n\n\nazure.vm.memory_cache_faults_per_sec(gauge)\nRate at which pages sought in the cache were not found there and had to be obtained elsewhere in memory or on the disshown as page/second\n\n\n\n\nazure.vm.memory_committed_bytes(gauge)\nAmount of committed virtual memoryshown as byte\n\n\n\n\nazure.vm.memory_page_faults_per_sec(gauge)\nOverall rate at which the processor handles both hard and soft page faults.shown as page\n\n\n\n\nazure.vm.memory_page_reads_per_sec(gauge)\nRate at which the disk is read to resolve hard page faultshown as page\n\n\n\n\nazure.vm.memory_pages_per_sec(gauge)\nRate at which pages are read from or written to disk to resolve hard page faultsshown as page\n\n\n\n\nazure.vm.memory_pages_read_per_sec(gauge)\nRate of pages read to resolve hard page faultshown as page/second\n\n\n\n\nazure.vm.memory_pages_written_per_sec(gauge)\nRate of pages writesshown as page/second\n\n\n\n\nazure.vm.memory_pct_committed_bytes_in_use(gauge)\nRatio of Memory \\ Committed Bytes to the Memory \\ Commit Limit.shown as percent\n\n\n\n\nazure.vm.memory_percent_available_memory(gauge)\nPercentage of available memory availableshown as percent\n\n\n\n\nazure.vm.memory_percent_available_swap(gauge)\nPercentage of available swap availableshown as percent\n\n\n\n\nazure.vm.memory_percent_used_by_cache(gauge)\n\nshown as percent\n\n\n\n\nazure.vm.memory_percent_used_memory(gauge)\nPercentage of available memory usedshown as percent\n\n\n\n\nazure.vm.memory_percent_used_swap(gauge)\nPercentage of available swap usedshown as percent\n\n\n\n\nazure.vm.memory_pool_nonpaged_bytes(gauge)\nSize of the nonpaged poolshown as byte\n\n\n\n\nazure.vm.memory_pool_paged_bytes(gauge)\nSize of the paged poolshown as byte\n\n\n\n\nazure.vm.memory_transition_faults_per_sec(gauge)\nRate at which page faults are resolved by recovering pages without incurring additional disk activityshown as fault/second\n\n\n\n\nazure.vm.memory_used_memory(gauge)\nUsed memoryshown as byte\n\n\n\n\nazure.vm.memory_used_swap(gauge)\nUsed swapshown as byte\n\n\n\n\nazure.vm.net_clr_exceptions_global_of_exceps_thrown_per_sec(gauge)\n\nshown as error/second\n\n\n\n\nazure.vm.net_clr_interop_global_of_marshalling(gauge)\n\nshown as operation\n\n\n\n\nazure.vm.net_clr_jit_global_pct_time_in_jit(gauge)\n\nshown as percent\n\n\n\n\nazure.vm.net_clr_loading_global_pct_time_loading(gauge)\n\nshown as percent\n\n\n\n\nazure.vm.net_clr_locks_and_threads_global_contention_rate_per_sec(gauge)\nRate at which threads in the runtime attempt to acquire a managed lock unsuccessfully.shown as time/second\n\n\n\n\nazure.vm.net_clr_locks_and_threads_global_current_queue_length(gauge)\nNumber of threads that are currently waiting to acquire a managed lock in the applicationshown as thread\n\n\n\n\nazure.vm.net_clr_locks_and_threads_global_of_current_logical_threads(gauge)\nNumber of current managed thread objects in the application.shown as thread\n\n\n\n\nazure.vm.net_clr_locks_and_threads_global_of_current_physical_threads(gauge)\nNumber of native operating system threads created and owned by the common language runtime to act as underlying threads for managed thread objectsshown as thread\n\n\n\n\nazure.vm.net_clr_memory_global_allocated_bytes_per_sec(gauge)\nRate of bytes allocated on the garbage collection heapshown as byte/second\n\n\n\n\nazure.vm.net_clr_memory_global_bytes_in_all_heaps(gauge)\nCurrent memory allocated in bytes on the garbage collection heaps.shown as byte\n\n\n\n\nazure.vm.net_clr_memory_global_gen_0_heap_size(gauge)\nMaximum bytes that can be allocated in generation 0shown as byte\n\n\n\n\nazure.vm.net_clr_memory_global_gen_1_heap_size(gauge)\nCurrent number of bytes in generation 1shown as byte\n\n\n\n\nazure.vm.net_clr_memory_global_gen_2_heap_size(gauge)\nCurrent number of bytes in generation 2.shown as byte\n\n\n\n\nazure.vm.net_clr_memory_global_large_object_heap_size(gauge)\nCurrent size of the Large Object Heapshown as byte\n\n\n\n\nazure.vm.net_clr_memory_global_pct_time_in_gc(gauge)\nPercentage of elapsed time that was spent performing a garbage collection since the last garbage collection cycleshown as percent\n\n\n\n\nazure.vm.net_clr_networking_global_connections_established(gauge)\nThe cumulative total number of Socket objects for stream sockets that were ever connected within the AppDomain since the process started.shown as connection\n\n\n\n\nazure.vm.net_clr_remoting_global_remote_calls_per_sec(gauge)\nNumber of remote procedure calls invoked per secondshown as operation/second\n\n\n\n\nazure.vm.network_interface_bytes_received(gauge)\nRate at which bytes are received over each network adapteshown as byte/second\n\n\n\n\nazure.vm.network_interface_bytes_total(gauge)\nRate at which bytes are sent and received on the network interfaceshown as byte/second\n\n\n\n\nazure.vm.network_interface_bytes_transmitted(gauge)\nRate at which bytes are sent over each network adapteshown as byte/second\n\n\n\n\nazure.vm.network_interface_packets_received(gauge)\nRate at which packets are received on the network interfaceshown as packet/second\n\n\n\n\nazure.vm.network_interface_packets_transmitted(gauge)\nRate at which packets are transmitted on the network interface.shown as packet/second\n\n\n\n\nazure.vm.network_interface_total_collisions(gauge)\nRate of collisions/second\n\n\n\n\nazure.vm.network_interface_total_rx_errors(gauge)\nRate of errors when receiving packetsshown as error/second\n\n\n\n\nazure.vm.network_interface_total_tx_errors(gauge)\nRate of errors when sending packetsshown as error/second\n\n\n\n\nazure.vm.physical_disk_average_disk_queue_length(gauge)\nNumber of requests that are queued and waiting for a disk during the sample interva\n\n\n\n\nazure.vm.physical_disk_average_read_time(gauge)\nPercentage of time that the selected disk drive is busy servicing read requests.shown as percent\n\n\n\n\nazure.vm.physical_disk_average_transfer_time(gauge)\nThe average disk transfer timeshown as percent\n\n\n\n\nazure.vm.physical_disk_average_write_time(gauge)\nPercentage of time that the selected disk drive is busy servicing write requests.shown as percent\n\n\n\n\nazure.vm.physical_disk_bytes_per_second(gauge)\nRate of bytesshown as byte/second\n\n\n\n\nazure.vm.physical_disk_read_bytes_per_second(gauge)\nRate at which bytes are readshown as byte/second\n\n\n\n\nazure.vm.physical_disk_reads_per_second(gauge)\nRate of readsshown as read/second\n\n\n\n\nazure.vm.physical_disk_total_disk_read_bytes_per_sec(gauge)\nRate at which bytes are read on all disksshown as byte/second\n\n\n\n\nazure.vm.physical_disk_total_disk_write_bytes_per_sec(gauge)\nRate at which bytes are written on all disksshown as byte/second\n\n\n\n\nazure.vm.physical_disk_transfers_per_second(gauge)\nRate of transfers/second\n\n\n\n\nazure.vm.physical_disk_write_bytes_per_second(gauge)\nRate at which bytes are writtenshown as byte/second\n\n\n\n\nazure.vm.physical_disk_writes_per_second(gauge)\nRate of writesshown as write/second\n\n\n\n\nazure.vm.processor_percent_dpc_time(gauge)\nPercentage of the time in which the system was executing in Deferred Procedure Callshown as percent\n\n\n\n\nazure.vm.processor_percent_interrupt_time(gauge)\nPercentage of the time the processor spends receiving and servicing hardware interruptsshown as percent\n\n\n\n\nazure.vm.processor_percent_io_wait_time(gauge)\nPercentage of the time the processor spends on IO waitshown as percent\n\n\n\n\nazure.vm.processor_percent_nice_time(gauge)\nPercentage of time occupied by user level processes with a positive nice valueshown as percent\n\n\n\n\nazure.vm.processor_percent_privileged_time(gauge)\nPercentage of the time in which the system was executing in Privileged modeshown as percent\n\n\n\n\nazure.vm.processor_percent_processor_time(gauge)\nPercentage of elapsed time that the processor spends to execute a non-Idle threadshown as percent\n\n\n\n\nazure.vm.processor_percent_user_time(gauge)\nPercentage of the time that the system is executing in User mode.shown as percent\n\n\n\n\nazure.vm.processor_total_pct_interrupt_time(gauge)\n\n\n\n\nazure.vm.processor_total_pct_privileged_time(gauge)\n\n\n\n\nazure.vm.processor_total_pct_processor_time(gauge)\n\n\n\n\nazure.vm.processor_total_pct_user_time(gauge)\n\n\n\n\nazure.vm.process_total_handle_count(gauge)\n\n\n\n\nazure.vm.process_total_page_faults_per_sec(gauge)\n\nshown as fault/second\n\n\n\n\nazure.vm.process_total_pct_processor_time(gauge)\n\nshown as percent\n\n\n\n\nazure.vm.process_total_private_bytes(gauge)\n\nshown as byte\n\n\n\n\nazure.vm.process_total_working_set(gauge)\n\n\n\n\nazure.vm.process_total_working_set_private(gauge)\n\n\n\n\nazure.vm.sql_server_general_statistics_user_connections(gauge)\n\nshown as connection\n\n\n\n\nazure.vm.sql_server_memory_manager_total_server_memory_kb(gauge)\n\nshown as kibibyte\n\n\n\n\nazure.vm.sql_server_sql_statistics_batch_requests_per_sec(gauge)\n\nshown as request/second\n\n\n\n\nazure.vm.sql_server_sql_statistics_sql_attention_rate(gauge)\n\n\n\n\nazure.vm.sql_server_sql_statistics_sql_re_compilations_per_sec(gauge)\n/second\n\n\n\nazure.vm.status(gauge)\n\n\n\n\nazure.vm.system_processes(gauge)\n\nshown as process\n\n\n\n\nazure.vm.system_threads(gauge)\n\nshown as thread\n\n\n\n\nazure.vm.tcpv4.connections.established(gauge)\n\nshown as connection\n\n\n\n\nazure.vm.tcpv4.connections.failures(gauge)\n\nshown as connection\n\n\n\n\nazure.vm.tcpv4.connections.reset(gauge)\n\nshown as connection\n\n\n\n\nazure.vm.tcpv4.segments.received_per_sec(gauge)\nRate at which TCP segments are received by using the TCP protocolshown as segment/second\n\n\n\n\nazure.vm.tcpv4.segments.retransmitted_per_sec(gauge)\nRate at which segments are transmitted that contain one or more bytes that TCP recognizes as having been transmitted before.shown as segment/second\n\n\n\n\nazure.vm.tcpv4.segments.sent_per_sec(gauge)\nRate at which TCP segments are sent by using the TCP protocol.shown as segment/second\n\n\n\n\nazure.vm.thread_total_context_switches_per_sec(gauge)\nRate of context switches generated by all threads.shown as occurrence/second\n\n\n\n\nazure.vm.web_service_total_bytes_total_per_sec(gauge)\nSum of bytes sent/sec and bytes received/secshown as byte/second\n\n\n\n\nazure.vm.web_service_total_connection_attempts_per_sec(gauge)\nRate of attempted connections to the WWW service since service startupshown as connection/second\n\n\n\n\nazure.vm.web_service_total_current_connections(gauge)\nCurrent number of active connections to the WWW serviceshown as connection\n\n\n\n\nazure.vm.web_service_total_get_requests_per_sec(gauge)\nRate at which requests using the GET method are made to the WWW serviceshown as request/second\n\n\n\n\nazure.vm.web_service_total_isapi_extension_requests_per_sec(gauge)\nRate of ISAPI extension requests that are processed simultaneously by the WWW service,shown as request/second\n\n\n\n\nazure.vm.web_service_total_post_requests_per_sec(gauge)\nRate at which requests using the POST method are made to the WWW serviceshown as request/second\n\n\n\n\nazure.vm.disk_read_bytes(count)\n(ARM VM only) Amount of bytes readshown as byte\n\n\n\n\nazure.vm.disk_read_bytes_sec(gauge)\n(Classic VM only) Amount of bytes read per secondshown as byte/second\n\n\n\n\nazure.vm.disk_read_operations_sec(gauge)\n(ARM VM only) Amount of read operations per secondshown as operation/second\n\n\n\n\nazure.vm.disk_write_bytes(count)\n(ARM VM only) Amount of bytes writtenshown as byte\n\n\n\n\nazure.vm.disk_write_bytes_sec(gauge)\n(Classic VM only) Amount of bytes writtenshown as byte/second\n\n\n\n\nazure.vm.disk_write_operations_sec(gauge)\n(ARM VM only) Amount of write operations per secondshown as operation/second\n\n\n\n\nazure.vm.network_in(gauge)\nNumber of bytes received on all network interfaces by the instance.shown as byte\n\n\n\n\nazure.vm.network_out(gauge)\nNumber of bytes sent out on all network interfaces by the instance.shown as byte\n\n\n\n\nazure.vm.percentage_cpu(gauge)\nPercentage of CPU resources usedshown as percent\n\n\n\n\n","tags":"","loc":"/integrations/azure_vm/"},{"title":"Datadog-Microsoft Azure Virtual Machine Scale Set Integration","text":"\n\nOverview\nVirtual machine scale sets are an Azure Compute resource you can use to deploy, manage, and autoscale a set of identical VMs.\n\nGet metrics from Azure Virtaul Machine Scale Set to:\n\n\n  Visualize the performance of your Virtual Machine Scale Sets\n  Correlate the performance of your Virtual Machine Scale Sets with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Microsoft Azure integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\nazure.compute_virtualmachinescalesets.disk_read_bytes(gauge)\nTotal bytes read from diskshown as byte\n\n\n\n\nazure.compute_virtualmachinescalesets.disk_read_operations_sec(gauge)\nDisk Read IOPSshown as read/second\n\n\n\n\nazure.compute_virtualmachinescalesets.disk_write_bytes(gauge)\nTotal bytes written to diskshown as byte\n\n\n\n\nazure.compute_virtualmachinescalesets.disk_write_operations_sec(gauge)\nDisk Write IOPSshown as write/second\n\n\n\n\nazure.compute_virtualmachinescalesets.network_in(gauge)\nThe number of bytes received on all network interfaces by the Virtual Machine(s) (Incoming Traffic)shown as byte\n\n\n\n\nazure.compute_virtualmachinescalesets.network_out(gauge)\nThe number of bytes out on all network interfaces by the Virtual Machine(s) (Outgoing Traffic)shown as byte\n\n\n\n\nazure.compute_virtualmachinescalesets.percentage_cpu(gauge)\nThe percentage of allocated compute units that are currently in use by the Virtual Machine(s)shown as percent\n\n\n\n\n","tags":"","loc":"/integrations/azure_vm_scale_set/"},{"title":"Datadog-Bitbucket Integration","text":"\n\nOverview\n\nCapture commits and pull requests events directly from your bitbucket to:\n\n\n  Keep track of code changes in real time\n  Add code change markers on all of your dashboards\n  Discuss code changes with your team\n\n\nWe’ve written extensively about the Bitbucket integration on our blog.\n\n\nOnce the integration is complete, whatever you select (commits and/or pull requests) will populate\ninto your Datadog Event Stream.\n\n\n  When commits are made\n  When a PR is created\n  When a comment is made/deleted on a PR\n\n\nIf you view a dashboard, in the top left search bar you can type sources:bitbucket to see bitbucket events overlayed over your the graphs on that dashboard.\n\n\nInstallation\n\nOn the Bitbucket website, create a new user that has Read access to the repo you want to monitor. This is the user that Datadog will use to collect information on the repository.\n\n\nConfiguration\n\n\n  Login to the Datadog application and add the Bitbucket integration here.\n  Enter the username and password you created above in the Installation section. Click the Install Integration button. If the username or password is not correct you will get a error message.\n  Open the Bitbucket integration again and enter the full name of the repository you want to monitor. If the url for your repository is https://bitbucket.org/groupname/reponame, then enter groupname/reponame in the Repo full name textbox.\n  Decide what type of events you would like to collect and click Update Configuration.\n\n\n\nValidation\n\nEach entry in the integration tile is validated when you enter it. There is nothing else you need to do.\n\n","tags":"","loc":"/integrations/bitbucket/"},{"title":"Datadog-btrfs Integration","text":"\nCapture Btrfs metrics into Datadog to:\n\n\n  Visualize your file system performance.\n  Correlate the performance of Btrfs file system with the rest of your applications.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nbtrfs YAML example\nbtrfs checks.d\n\n\n\nMetrics\n\n\n\n\nsystem.disk.btrfs.total(gauge)\nThe total amount of space on a deviceshown as byte\n\n\n\n\nsystem.disk.btrfs.used(gauge)\nThe used space on a deviceshown as byte\n\n\n\n\nsystem.disk.btrfs.free(gauge)\nThe free space on a deviceshown as byte\n\n\n\n\nsystem.disk.btrfs.usage(gauge)\nThe amount of space used on a device as a fraction of the totalshown as fraction\n\n\n\n","tags":"","loc":"/integrations/btrfs/"},{"title":"Datadog-Bugsnag Integration","text":"\n\nOverview\n\nBugsnag provides software teams with an automated crash detection platform for their web and mobile applications. Bugsnag automatically captures and alerts you of errors as they happen. Integrating Datadog with Bugsnag will send error notifications to your Datadog event stream.\n\nWith this integration:\n\n\n  Get a summary of the error in your Datadog event stream\n  Get notified when a project has a spike in error rates\n  Filter notifications by severity and release stage\n\n\n\nInstallation\n\nNo installation is required.\n\n\nConfiguration\n\nTo integrate Bugsnag with Datadog:\n\n\n  In Bugsnag go to Settings for the project you would like to configure to send notifications to Datadog\n  Select Team Notifications and then Datadog\n\n  Customize the notifications you’ll see in Datadog by selecting error notification triggers.\n  Apply custom filters to your notification triggers to see errors from specific release stages and severities.\n  Enter your Datadog API key.\n  Select Test Notification to test the configuration. A test error from Bugsnag will appear in Datadog’s event stream.\n  \nSave your settings.\n  Add more streams from the same project to see error events based on a different set of notification criteria.\n\n\n\nMetrics\n\nThis integration does not include metrics at this time.\n\n\nEvents\n\nThis integration will push configured Bugsnag errors and alerts to your Datadog event stream.\n","tags":"","loc":"/integrations/bugsnag/"},{"title":"Datadog-Cacti Integration","text":"\n\nOverview\n\nConnect Cacti to Datadog to:\n\n\n  Visualize Cacti metrics in Datadog.\n  Correlate metrics captured by Cacti with the rest of your applications.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nCacti YAML example\nCacti checks.d\n\n\n\nMetrics\n\n\n\n\ncacti.hosts.count(gauge)\nThe number of hosts monitored by Cactishown as host\n\n\n\n\ncacti.metrics.count(gauge)\nThe number of metrics collected from Cacti\n\n\n\n\ncacti.rrd.count(gauge)\nThe number of Cacti RRD filesshown as file\n\n\n\n\nsystem.disk.free.last(gauge)\nThe amount of disk space that is free - last polling valueshown as byte\n\n\n\n\nsystem.disk.free.max(gauge)\nThe amount of disk space that is free - max polling valueshown as byte\n\n\n\n\nsystem.disk.free.min(gauge)\nThe amount of disk space that is free - min polling valueshown as byte\n\n\n\n\nsystem.disk.used.last(gauge)\nThe amount of disk space that is used - last polling valueshown as byte\n\n\n\n\nsystem.disk.used.max(gauge)\nThe amount of disk space that is used - max polling valueshown as byte\n\n\n\n\nsystem.disk.used.min(gauge)\nThe amount of disk space that is used - min polling valueshown as byte\n\n\n\n\nsystem.load.1.last(gauge)\nThe average system load over one minute - last polling value\n\n\n\n\nsystem.load.1.max(gauge)\nThe average system load over one minute - max polling value\n\n\n\n\nsystem.load.1.min(gauge)\nThe average system load over one minute - min polling value\n\n\n\n\nsystem.load.15.last(gauge)\nThe average system load over 15 minute - last polling value\n\n\n\n\nsystem.load.15.max(gauge)\nThe average system load over 15 minute - max polling value\n\n\n\n\nsystem.load.15.min(gauge)\nThe average system load over 15 minute - min polling value\n\n\n\n\nsystem.load.5.last(gauge)\nThe average system load over five minute - last polling value\n\n\n\n\nsystem.load.5.max(gauge)\nThe average system load over five minute - max polling value\n\n\n\n\nsystem.load.5.min(gauge)\nThe average system load over five minute - min polling value\n\n\n\n\nsystem.mem.buffered.last(gauge)\nThe amount of physical RAM used for file buffers - last polling valueshown as byte\n\n\n\n\nsystem.mem.buffered.max(gauge)\nThe amount of physical RAM used for file buffers - max polling valueshown as byte\n\n\n\n\nsystem.mem.buffered.min(gauge)\nThe amount of physical RAM used for file buffers - min polling valueshown as byte\n\n\n\n\nsystem.ping.latency(gauge)\nThe system ping latency - avg polling valueshown as millisecond\n\n\n\n\nsystem.ping.latency.max(gauge)\nThe system ping latency - max polling valueshown as millisecond\n\n\n\n\nsystem.proc.running.last(gauge)\nThe number of processes running - last polling valueshown as process\n\n\n\n\nsystem.proc.running.max(gauge)\nThe number of processes running - max polling valueshown as process\n\n\n\n\nsystem.proc.running.min(gauge)\nThe number of processes running - min polling valueshown as process\n\n\n\n\nsystem.swap.free.max(gauge)\nThe amount of free swap space - max polling valueshown as byte\n\n\n\n\nsystem.users.current.last(gauge)\nThe number of logged in users - last polling value\n\n\n\n\nsystem.users.current.max(gauge)\nThe number of logged in users - max polling value\n\n\n\n\nsystem.users.current.min(gauge)\nThe number of logged in users - min polling value\n\n\n\n","tags":"","loc":"/integrations/cacti/"},{"title":"Datadog-Campfire Integration","text":"\nIntegrate with Campfire to:\n\n\n  be notified when someone posts on your stream\n  be notified when a metric alert is triggered\n\n","tags":"","loc":"/integrations/campfire/"},{"title":"Datadog-Capistrano Integration","text":"\n\nOverview\n\nCapistrano is a remote server automation and deployment tool written in Ruby.\n\nInstall the Capistrano Datadog integration to:\n\n\n  Capture and search for deploy events in your event stream\n  Overlay deploy events with other metrics within dashboards to identify which deploys affect your application’s performance\n\n\nOnce you enable this integration for a given Capfile, each Capistrano task that completes will be submitted as an event to Datadog. Role information and logging output are submitted, too.\n\n\nInstallation\n\nInstall the dogapi Ruby gem:\n\n    sudo gem install dogapi --version \">=1.10.0\"\n\n\n\nConfiguration\n\nAdd the following to the beginning of any Capfile whose tasks you want to send to Datadog:\n\n    require \"capistrano/datadog\"\n    set :datadog_api_key, \"${your_api_key}\"\n\n\n\nValidation\n\nAfter you’ve configured your Capfile and have run at least one Capistrano task:\n\n\n  Navigate to your events stream.\n  Either enter sources:capistrano in the Search bar, or click ‘Capistrano’ in the FROM list of integrations on the left.\n  Either enter priority:all in the Search bar, or click ‘All’ in the PRIORITY list on the left. Capistrano tasks are submitted with Low priority by default, so if you’re only viewing Normal priority events - which you will be, by default - you won’t see your Capistrano tasks in the event stream.\n\n\n\n\n","tags":"","loc":"/integrations/capistrano/"},{"title":"Datadog-Cassandra Integration","text":"\n\n\nLearn more about how to monitor Cassandra performance metrics thanks to our series of posts. We detail the key performance metrics, how to collect them, and how to use Datadog to monitor Cassandra.\n\nFor information on JMX Checks, please see here.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\nCassandra YAML example\n\n\nMetrics\n\n\n\n\ncassandra.active_tasks(gauge every 10 seconds)\nThe number of tasks that the thread pool is actively executing.shown as task\n\n\n\n\ncassandra.bloom_filter_disk_space_used(gauge every 10 seconds)\nDisk space used by the Bloom filters.shown as byte\n\n\n\n\ncassandra.bloom_filter_false_positives(gauge every 10 seconds)\nThe number of Bloom filter false positives.shown as event\n\n\n\n\ncassandra.bloom_filter_false_ratio(gauge every 10 seconds)\nThe ratio of Bloom filter false positives to total checks.shown as fraction\n\n\n\n\ncassandra.capacity(gauge every 10 seconds)\nThe capacity of the caches, such as the key cache and row cache.shown as byte\n\n\n\n\ncassandra.completed_tasks(gauge every 10 seconds)\nThe number of tasks that the thread pool has completed.shown as task\n\n\n\n\ncassandra.compression_ratio(gauge every 10 seconds)\nThe compression ratio for all SSTables in a column family.shown as fraction\n\n\n\n\ncassandra.currently_blocked_tasks.count(gauge every 10 seconds)\nThe number of currently blocked tasks for the thread pool.shown as task\n\n\n\n\ncassandra.exceptions.count(gauge every 10 seconds)\nThe number of exceptions thrown.shown as error\n\n\n\n\ncassandra.hits.count(gauge every 10 seconds)\nThe number of hits to a cache.shown as hit\n\n\n\n\ncassandra.latency.count(gauge every 10 seconds)\nThe number of client requests.shown as request\n\n\n\n\ncassandra.latency.one_minute_rate(gauge every 10 seconds)\nRecent rate of client requests, as an exponentially weighted moving average over a one-minute interval.shown as request/second\n\n\n\n\ncassandra.live_disk_space_used.count(gauge every 10 seconds)\nDisk space used by \"live\" SSTables (only counts non-obsolete files).shown as byte\n\n\n\n\ncassandra.live_ss_table_count(gauge every 10 seconds)\nNumber of \"live\" (non-obsolete) SSTables.shown as file\n\n\n\n\ncassandra.load.count(gauge every 10 seconds)\nDisk space used on a node.shown as byte\n\n\n\n\ncassandra.max_row_size(gauge every 10 seconds)\nSize of the largest compacted row.shown as byte\n\n\n\n\ncassandra.mean_row_size(gauge every 10 seconds)\nAverage size of compacted rows.shown as byte\n\n\n\n\ncassandra.memtable_columns_count(gauge every 10 seconds)\nNumber of columns in memtable.shown as column\n\n\n\n\ncassandra.memtable_live_data_size(gauge every 10 seconds)\nSize of data stored in memtable.shown as byte\n\n\n\n\ncassandra.memtable_switch_count.count(gauge every 10 seconds)\nNumber of times a full memtable has been switched out for an empty one due to flushing.shown as event\n\n\n\n\ncassandra.min_row_size(gauge every 10 seconds)\nSize of the smallest compacted row.shown as byte\n\n\n\n\ncassandra.pending_tasks(gauge every 10 seconds)\nThe number of pending tasks for the thread pool.shown as task\n\n\n\n\ncassandra.requests.count(gauge every 10 seconds)\nThe number of requests to a cache.shown as request\n\n\n\n\ncassandra.size(gauge every 10 seconds)\nSize of cache.shown as byte\n\n\n\n\ncassandra.timeouts.count(gauge every 10 seconds)\nCount of requests not acknowledged within configurable timeout window.shown as timeout\n\n\n\n\ncassandra.timeouts.one_minute_rate(gauge every 10 seconds)\nRecent timeout rate, as an exponentially weighted moving average over a one-minute interval.shown as timeout/second\n\n\n\n\ncassandra.total_disk_space_used.count(gauge every 10 seconds)\nDisk space used by a column family.shown as byte\n\n\n\n\ncassandra.total_latency.count(gauge every 10 seconds)\nTotal latency for all client requests.shown as microsecond\n\n\n\n\ncassandra.unavailables.count(gauge every 10 seconds)\nCount of requests for which the required number of nodes was unavailable.shown as error\n\n\n\n\ncassandra.unavailables.one_minute_rate(gauge every 10 seconds)\nRecent rate of unavailable exceptions, as an exponentially weighted moving average over a one-minute interval. shown as error/second\n\n\n\n\ncassandra.db.update_interval(gauge every 10 seconds)\nThe configurable update interval for the dynamic snitch, which monitors read latency to route requests away from slow nodes. shown as millisecond\n\n\n\n\ncassandra.db.write_count(gauge every 10 seconds)\nThe number of local write requests for a column family. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.latency.count instead)shown as write\n\n\n\n\ncassandra.db.read_count(gauge every 10 seconds)\nThe number of local read requests for a column family. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.latency.count instead)shown as read\n\n\n\n\ncassandra.db.live_ss_table_count(gauge every 10 seconds)\nNumber of \"live\" (non-obsolete) SSTables. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.live_ss_table_count instead)shown as file\n\n\n\n\ncassandra.db.total_disk_space_used(gauge every 10 seconds)\nDisk space used by a column family. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.total_disk_space_used.count instead)shown as byte\n\n\n\n\ncassandra.db.memtable_data_size(gauge every 10 seconds)\nSize of data stored in memtable. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.memtable_live_data_size instead)shown as byte\n\n\n\n\ncassandra.internal.currently_blocked_tasks(gauge every 10 seconds)\nThe number of currently blocked tasks for the thread pool. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.currently_blocked_tasks.count instead)shown as task\n\n\n\n\ncassandra.db.max_row_size(gauge every 10 seconds)\nSize of the largest compacted row. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.max_row_size instead)shown as byte\n\n\n\n\ncassandra.db.live_disk_space_used(gauge every 10 seconds)\nDisk space used by \"live\" SSTables (only counts non-obsolete files). (Metric may not be available for Cassandra versions > 2.2. Use cassandra.live_disk_space_used.count instead)shown as byte\n\n\n\n\ncassandra.internal.active_count(gauge every 10 seconds)\nThe number of tasks that the thread pool is actively executing. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.active_tasks instead)shown as task\n\n\n\n\ncassandra.internal.completed_tasks(gauge every 10 seconds)\nThe number of tasks that the thread pool has completed. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.completed_tasks instead)shown as task\n\n\n\n\ncassandra.db.total_write_latency_micros(gauge every 10 seconds)\nTotal latency for all write requests. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.total_latency.count instead)shown as microsecond\n\n\n\n\ncassandra.db.total_read_latency_micros(gauge every 10 seconds)\nTotal latency for all read requests. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.total_latency.count instead)shown as microsecond\n\n\n\n\ncassandra.internal.total_blocked_tasks(gauge every 10 seconds)\nThe cumulative total of currently blocked tasks for the thread pool. (Metric may not be available for Cassandra versions > 2.2.)shown as task\n\n\n\n\ncassandra.db.mean_row_size(gauge every 10 seconds)\nAverage size of compacted rows. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.mean_row_size instead)shown as byte\n\n\n\n\ncassandra.db.compression_ratio(gauge every 10 seconds)\nThe compression ratio for all SSTables in a column family. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.compression_ratio instead)shown as fraction\n\n\n\n\ncassandra.db.memtable_switch_count(gauge every 10 seconds)\nNumber of times a full memtable has been switched out for an empty one due to flushing. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.memtable_switch_count.count instead)shown as event\n\n\n\n\ncassandra.db.memtable_columns_count(gauge every 10 seconds)\nNumber of columns in memtable. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.memtable_columns_count instead)shown as column\n\n\n\n\ncassandra.db.min_row_size(gauge every 10 seconds)\nSize of the smallest compacted row. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.min_row_size instead)shown as byte\n\n\n\n\ncassandra.db.bloom_filter_false_positives(gauge every 10 seconds)\nThe number of Bloom filter false positives. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.bloom_filter_false_positives instead)shown as event\n\n\n\n\ncassandra.db.bloom_filter_disk_space_used(gauge every 10 seconds)\nDisk space used by the Bloom filters. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.bloom_filter_disk_space_used instead)shown as byte\n\n\n\n\ncassandra.db.bloom_filter_false_ratio(gauge every 10 seconds)\nThe ratio of Bloom filter false positives to total checks. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.bloom_filter_false_ratio instead)shown as fraction\n\n\n\n\ncassandra.net.total_timeouts(gauge every 10 seconds)\nCount of requests not acknowledged within configurable timeout window. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.timeouts.count instead)shown as timeout\n\n\n\n\ncassandra.db.completed_tasks(gauge every 10 seconds)\nCompleted compaction or commitlog tasks. (Metric may not be available for Cassandra versions > 2.2.)shown as task\n\n\n\n\ncassandra.db.pending_tasks(gauge every 10 seconds)\nPending compaction, commitlog, or column family tasks. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.pending_tasks instead)shown as task\n\n\n\n\ncassandra.db.load(gauge every 10 seconds)\nDisk space used on a node. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.load.count instead)shown as byte\n\n\n\n\ncassandra.db.exception_count(gauge every 10 seconds)\nThe number of exceptions thrown. (Metric may not be available for Cassandra versions > 2.2. Use cassandra.exceptions.count instead)shown as error\n\n\n\n\ncassandra.db.recent_read_latency_micros(gauge every 10 seconds)\nThe latency of reads since the last time this attribute was read. (Metric may not be available for Cassandra versions > 2.2.)shown as microsecond\n\n\n\n\ncassandra.db.recent_write_latency_micros(gauge every 10 seconds)\nThe latency of writes since the last time this attribute was read. (Metric may not be available for Cassandra versions > 2.2.)shown as microsecond\n\n\n\n\ncassandra.db.key_cache_recent_hit_rate(gauge every 10 seconds)\nRatio of key cache hits to key cache requests since the last time this attribute was read. (Metric may not be available for Cassandra versions > 2.2.)shown as fraction\n\n\n\n\ncassandra.db.recent_range_latency_micros(gauge every 10 seconds)\nThe latency of range scans since the last time this attribute was read. (Metric may not be available for Cassandra versions > 2.2.)shown as microsecond\n\n\n\n\ncassandra.db.total_range_latency_micros(gauge every 10 seconds)\nTotal latency for all range scans. (Metric may not be available for Cassandra versions > 2.2.)shown as microsecond\n\n\n\n\ncassandra.db.write_operations(gauge every 10 seconds)\nCount of write operations. (Metric may not be available for Cassandra versions > 2.2.)shown as operation\n\n\n\n\ncassandra.db.read_operations(gauge every 10 seconds)\nCount of read operations. (Metric may not be available for Cassandra versions > 2.2.)shown as operation\n\n\n\n\ncassandra.db.range_operations(gauge every 10 seconds)\nCount of range scan operations. (Metric may not be available for Cassandra versions > 2.2.)shown as operation\n\n\n\n","tags":"","loc":"/integrations/cassandra/"},{"title":"Datadog-Catchpoint Integration","text":"\n\nOverview\n\nCatchpoint is a Digital Performance Analytics platform that gives you the power to deliver amazing user experiences.\n\nConnect Catchpoint and Datadog to:\n\n\n  Configure comprehensive alerts in your event stream\n  Direct links to Analysis Charts in the Catchpoint Portal\n  Alert Type tags for easy filtering\n\n\n\nInstallation\n\nNo installation is required.\n\n\nConfiguration\n\nTo get Catchpoint alerts into your stream, login into the Catchpoint Portal and goto Settings > API.\n\n\n  In the Alerts API select Enable\n  Enter the DataDog Endpoint URL. You will also need the DataDog API Key which can be created in the DataDog portal.\n  Set Status to Active\n  Select Template for Format\n  Add a new template\n  Enter the template Name e.g. DataDog and set the Format to JSON.\n  \n    Use the following JSON Template and Save it.\n\n     {\n     \"title\": \"${TestName} [${TestId}] - ${switch(${notificationLevelId},'0','WARNING','1','CRITICAL','3','OK')}\",\n     \"text\": \"${TestName} - http://portal.catchpoint.com/ui/Content/Charts/Performance.aspx?tList=${testId}&uts=${alertProcessingTimestampUtc}&z=&chartView=1\",\n     \"priority\": \"normal\",\n     \"tags\": [\"alertType:${Switch(${AlertTypeId},'0', 'Unknown','2', 'Byte Length','3','Content Match','4', 'Host Failure','7', 'Timing','9', 'Test Failure', '10',Insight', '11','Javascript Failure', '12', 'Ping',13, 'Requests')}\"],\n     \"alert_type\": \"${switch(${notificationLevelId},'0','warning','1','error','3','success')}\",\n     \"source_type_name\": \"catchpoint\"\n }\n\n  \n\n\nCatchpoint will now send any alerts directly to the Events stream in DataDog.\n\n\nMetrics\n\nThis integration does not include metrics at this time.\n\n\nEvents\n\nThis integration will push Catchpoint events to your Datadog event stream.\n","tags":"","loc":"/integrations/catchpoint/"},{"title":"Datadog-Ceph Integration","text":"\n\nOverview\n\nEnable the Datadog-Ceph integration to:\n\n\n  Track disk usage across storage pools\n  Receive service checks in case of issues\n  Monitor I/O performance metrics\n\n\n\nInstallation\n\nThe integration is meant to be enabled on each Ceph monitor host.\n\n\nConfiguration\n\nAdjust the configuration file to match your environment. By default the check will use /usr/bin/ceph to retrieve metrics; this can be overriden by using the ceph_cmd option. If sudo access is required to run it, please enable the use_sudo flag.\n\nAny extra tags specific to the cluster can be specified under tags, as usual.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nCeph YAML example\nCeph checks.d\n\n\n\nValidation\n\nExecute the info command /etc/init.d/datadog-agent info and verify that the integration check was successful. The output should contain a section similar to the following:\n\n    Checks\n    ======\n\n      [...]\n\n      ceph\n      ----\n          - instance #0 [OK]\n          - Collected 19 metrics, 0 events & 2 service checks\n\n\n\nMetrics\n\n\n\n\nceph.commit_latency_ms(gauge)\nTime taken to commit an operation to the journalshown as millisecond\n\n\n\n\nceph.apply_latency_ms(gauge)\nTime taken to flush an update to disksshown as millisecond\n\n\n\n\nceph.op_per_sec(gauge)\nIO operations per second for given poolshown as operation/second\n\n\n\n\nceph.read_bytes_sec(gauge)\nBytes/second being readshown as byte\n\n\n\n\nceph.write_bytes_sec(gauge)\nBytes/second being writtenshown as byte\n\n\n\n\nceph.num_osds(gauge)\nNumber of known storage daemonsshown as item\n\n\n\n\nceph.num_in_osds(gauge)\nNumber of participating storage daemonsshown as item\n\n\n\n\nceph.num_up_osds(gauge)\nNumber of online storage daemonsshown as item\n\n\n\n\nceph.num_pgs(gauge)\nNumber of placement groups availableshown as item\n\n\n\n\nceph.num_mons(gauge)\nNumber of monitor daemonsshown as item\n\n\n\n\nceph.aggregate_pct_used(gauge)\nOverall capacity usage metricshown as percent\n\n\n\n\nceph.total_objects(gauge)\nObject count from the underlying object storeshown as item\n\n\n\n\nceph.num_objects(gauge)\nObject count for a given poolshown as item\n\n\n\n\nceph.read_bytes(rate)\nPer-pool read bytesshown as byte\n\n\n\n\nceph.write_bytes(rate)\nPer-pool write bytesshown as byte\n\n\n\n\nceph.num_pools(gauge)\nNumber of poolsshown as item\n\n\n\n\nceph.pgstate.active_clean(gauge)\nNumber of active+clean placement groupsshown as item\n\n\n\n\nceph.read_op_per_sec(gauge)\nPer-pool read operations/secondshown as operation/second\n\n\n\n\nceph.write_op_per_sec(gauge)\nPer-pool write operations/secondshown as operation/second\n\n\n\n\nceph.num_near_full_osds(gauge)\nNumber of nearly full osdsshown as item\n\n\n\n\nceph.num_full_osds(gauge)\nNumber of full osdsshown as item\n\n\n\n\nceph.osd.pct_used(gauge)\nPercentage used of full/near full osdsshown as percent\n\n\n\n","tags":"","loc":"/integrations/ceph/"},{"title":"Datadog-Chatwork Integration","text":"\nIntegrate with ChatWork to:\n\n\n  be notified when someone posts on your stream\n  be notified when a metric alert is triggered\n\n","tags":"","loc":"/integrations/chatwork/"},{"title":"Datadog-Chef Integration","text":"\n\nOverview\n\n\n\nChef is a popular configuration management tool written in Ruby and Erlang. If you manage your compute instances with Chef and want to use it to install the Datadog agent, check out our guide for that. This page is about sending Chef metrics to Datadog.\n\nConnect Chef to Datadog in order to:\n\n\n  Get real-time reports on Chef client runs\n  Track key Chef performance metrics across all your servers\n  Quickly identify and discuss failed Chef runs with your team\n\n\n\nInstallation\n\n\n  \n    If you are using Berkshelf, add the cookbook to your Berksfile:\n\n    cookbook 'datadog'\n\n\n    Otherwise, install the cookbook in to your repository using Knife:\n\n    knife cookbook site install datadog\n\n  \n  \n    Set the Datadog-specific attributes in either a role, environment or another recipe:\n\n    # Make sure you replace the API and application key below\n# with the ones for your account\n\nnode.default['datadog']['api_key'] = \"9775a026f1ca7d1c6c5af9d94d9595a4\"\n\n# Use an existing application key or create a new one for Chef\nnode.default['datadog']['application_key'] =\"87ce4a24b5553d2e482ea8a8500e71b8ad4554ff\"\n\n  \n  \n    Upload the updated cookbook to your Chef server\n\n    berks upload\n# or\nknife cookbook upload datadog\n\nknife cookbook list | grep datadog && \\\necho -e \"\\033[0;32mdatadog cookbook - OK\\033[0m\" || \\\necho -e \"\\033[0;31mmissing datadog cookbook - OK\\033[0m\"\n\n\n    The cookbook is now ready to be applied to your nodes.\n  \n  \n    Once uploaded, add it to your node’s run_list or role:\n\n    \"run_list\": [\n  \"recipe[datadog::dd-handler]\"\n]\n\n  \n  \n    Wait for the next scheduled chef-client run.\n  \n\n\n\nValidation\n\nFrom your events stream, enter sources:chef in the search bar. Your Chef runs should appear.\n\n\nMetrics\n\n\n\n\nchef.resources.elapsed_time(gauge)\nTotal time elapsed during the Chef Client Run.shown as second\n\n\n\n\nchef.resources.total(gauge)\nTotal count of resources managed by Chef.shown as resource\n\n\n\n\nchef.resources.updated(gauge)\nTotal count of resources updated in the Chef Client Run.shown as resource\n\n\n\n","tags":"","loc":"/integrations/chef/"},{"title":"Datadog-Consul Integration","text":"\n\nOverview\n\nConnect Consul to Datadog in order to:\n\n\n  Correlate the performance of Consul with the rest of your applications\n  Monitor the health of your Consul cluster\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nConsul YAML example\nConsul checks.d\n\n\n\nMetrics\n\n\n\n\nconsul.catalog.nodes_critical(gauge)\nNumber of nodes with service status `critical` from those registeredshown as node\n\n\n\n\nconsul.catalog.nodes_passing(gauge)\nNumber of nodes with service status `passing` from those registeredshown as node\n\n\n\n\nconsul.catalog.nodes_up(gauge)\nNumber of nodesshown as node\n\n\n\n\nconsul.catalog.nodes_warning(gauge)\nNumber of nodes with service status `warning` from those registeredshown as node\n\n\n\n\nconsul.catalog.services_critical(gauge)\nTotal critical services on nodesshown as service\n\n\n\n\nconsul.catalog.services_passing(gauge)\nTotal passing services on nodesshown as service\n\n\n\n\nconsul.catalog.services_up(gauge)\nTotal services registered on nodesshown as service\n\n\n\n\nconsul.catalog.services_warning(gauge)\nTotal warning services on nodesshown as service\n\n\n\n\nconsul.net.node.latency.min(gauge)\nminimum latency from this node to all othersshown as millisecond\n\n\n\n\nconsul.net.node.latency.p25(gauge)\np25 latency from this node to all othersshown as millisecond\n\n\n\n\nconsul.net.node.latency.median(gauge)\nmedian latency from this node to all othersshown as millisecond\n\n\n\n\nconsul.net.node.latency.p75(gauge)\np75 latency from this node to all othersshown as millisecond\n\n\n\n\nconsul.net.node.latency.p90(gauge)\np90 latency from this node to all othersshown as millisecond\n\n\n\n\nconsul.net.node.latency.p95(gauge)\np95 latency from this node to all othersshown as millisecond\n\n\n\n\nconsul.net.node.latency.p99(gauge)\np99 latency from this node to all othersshown as millisecond\n\n\n\n\nconsul.net.node.latency.max(gauge)\nmaximum latency from this node to all othersshown as millisecond\n\n\n\n\nconsul.runtime.num_goroutines(gauge every 10 seconds)\nNumber of running goroutines\n\n\n\n\nconsul.runtime.alloc_bytes(gauge every 10 seconds)\nCurrent bytes allocated by the Consul processshown as byte\n\n\n\n\nconsul.runtime.heap_objects(gauge every 10 seconds)\nNumber of objects allocated on the heapshown as object\n\n\n\n\nconsul.runtime.sys_bytes(gauge every 10 seconds)\nTotal size of the virtual address space reserved by the Go runtimeshown as byte\n\n\n\n\nconsul.runtime.malloc_count(gauge every 10 seconds)\nCumulative count of heap objects allocatedshown as object\n\n\n\n\nconsul.runtime.free_count(gauge every 10 seconds)\nCumulative count of heap objects freedshown as object\n\n\n\n\nconsul.runtime.heap_objects(gauge every 10 seconds)\nBytes of allocated heap objectsshown as byte\n\n\n\n\nconsul.runtime.total_gc_pause_ns(gauge every 10 seconds)\nCumulative nanoseconds in GC stop-the-world pauses since Consul startedshown as nanosecond\n\n\n\n\nconsul.runtime.total_gc_runs(gauge every 10 seconds)\nNumber of completed GC cycles\n\n\n\n\nconsul.raft.state.leader(rate every 10 seconds)\nNumber of completed leader electionsshown as event\n\n\n\n\nconsul.raft.state.candidate(rate every 10 seconds)\nNumber of initiated leader electionsshown as event\n\n\n\n\nconsul.raft.apply(rate every 10 seconds)\nNumber of raft transactions occurringshown as transaction\n\n\n\n\nconsul.raft.commitTime.avg(gauge every 10 seconds)\nThe average time it takes to commit a new entry to the raft log on the leadershown as millisecond\n\n\n\n\nconsul.raft.commitTime.count(rate every 10 seconds)\nThe number of samples of raft.commitTime\n\n\n\n\nconsul.raft.commitTime.max(gauge every 10 seconds)\nThe max time it takes to commit a new entry to the raft log on the leadershown as millisecond\n\n\n\n\nconsul.raft.commitTime.median(gauge every 10 seconds)\nThe median time it takes to commit a new entry to the raft log on the leadershown as millisecond\n\n\n\n\nconsul.raft.commitTime.95percentile(gauge every 10 seconds)\nThe p95 time it takes to commit a new entry to the raft log on the leadershown as millisecond\n\n\n\n\nconsul.raft.leader.dispatchLog.avg(gauge every 10 seconds)\nThe average time it takes for the leader to write log entries to diskshown as millisecond\n\n\n\n\nconsul.raft.leader.dispatchLog.count(rate every 10 seconds)\nThe number of samples of raft.leader.dispatchLog\n\n\n\n\nconsul.raft.leader.dispatchLog.max(gauge every 10 seconds)\nThe max time it takes for the leader to write log entries to diskshown as millisecond\n\n\n\n\nconsul.raft.leader.dispatchLog.median(gauge every 10 seconds)\nThe median time it takes for the leader to write log entries to diskshown as millisecond\n\n\n\n\nconsul.raft.leader.dispatchLog.95percentile(gauge every 10 seconds)\nThe p95 time it takes for the leader to write log entries to diskshown as millisecond\n\n\n\n\nconsul.raft.leader.lastContact.avg(gauge every 10 seconds)\nAverage time elapsed since the leader was last able to check its lease with followersshown as millisecond\n\n\n\n\nconsul.raft.leader.lastContact.count(rate every 10 seconds)\nThe number of samples of raft.leader.lastContact\n\n\n\n\nconsul.raft.leader.lastContact.max(gauge every 10 seconds)\nMax time elapsed since the leader was last able to check its lease with followersshown as millisecond\n\n\n\n\nconsul.raft.leader.lastContact.median(gauge every 10 seconds)\nMedian time elapsed since the leader was last able to check its lease with followersshown as millisecond\n\n\n\n\nconsul.raft.leader.lastContact.95percentile(gauge every 10 seconds)\nP95 time elapsed since the leader was last able to check its lease with followersshown as millisecond\n\n\n\n\nconsul.memberlist.msg.suspect(rate every 10 seconds)\nNumber of times an agent suspects another as failed while probing during gossip protocol\n\n\n\n\nconsul.serf.member.flap(rate every 10 seconds)\nNumber of times an agent is marked dead and then quickly recovers\n\n\n\n\nconsul.serf.events(rate every 10 seconds)\nIncremented when an agent processes a serf eventshown as event\n\n\n\n\nconsul.serf.member.join(rate every 10 seconds)\nIncremented when an agent processes a join eventshown as event\n\n\n\n\nFor each service that you’re monitoring we’ll create the consul.catalog.nodes_up gauge metric tagged by consul_service_id that will let you know how many Consul nodes are running each service. We’ll also collect consul.catalog.service_u tagged by consul_node_id that measures how many services a node is running.\nFinally, we perform a service check consul.check that will report on the state of each service.\n\nThe other consul metrics collected are not service bound but node bound, and only consul.peers is tagged with mode:leader or mode:follower.\n\n","tags":"","loc":"/integrations/consul/"},{"title":"Datadog-Couchbase Integration","text":"\n\nOverview\n\nGet metrics from Couchbase in real time to\n\n\n  Visualize key Couchbase metrics\n  Correlate Couchbase performance with the rest of your applications\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nCouchbase YAML example\nCouchbase checks.d\n\n\n\nMetrics\n\n\n\n\ncouchbase.hdd.free(gauge)\nFree hard disk spaceshown as byte\n\n\n\n\ncouchbase.hdd.used(gauge)\nUsed hard disk spaceshown as byte\n\n\n\n\ncouchbase.hdd.total(gauge)\nTotal hard disk spaceshown as byte\n\n\n\n\ncouchbase.hdd.quota_total(gauge)\nHard disk quotashown as byte\n\n\n\n\ncouchbase.hdd.used_by_data(gauge)\nHard disk used for datashown as byte\n\n\n\n\ncouchbase.ram.used(gauge)\nRAM in useshown as byte\n\n\n\n\ncouchbase.ram.total(gauge)\nTotal RAMshown as byte\n\n\n\n\ncouchbase.ram.quota_total(gauge)\nRAM quotashown as byte\n\n\n\n\ncouchbase.ram.used_by_data(gauge)\nRAM used for datashown as byte\n\n\n\n\ncouchbase.by_bucket.avg_bg_wait_time(gauge)\nAverage background wait timeshown as second\n\n\n\n\ncouchbase.by_bucket.avg_disk_commit_time(gauge)\nAverage disk commit timeshown as second\n\n\n\n\ncouchbase.by_bucket.bytes_read(gauge)\nBytes readshown as byte\n\n\n\n\ncouchbase.by_bucket.bytes_written(gauge)\nBytes writtenshown as byte\n\n\n\n\ncouchbase.by_bucket.cas_hits(gauge)\nCompare and Swap hitsshown as hit\n\n\n\n\ncouchbase.by_bucket.cas_misses(gauge)\nCompare and Swap missesshown as miss\n\n\n\n\ncouchbase.by_bucket.cmd_get(gauge)\nCompare and Swap getsshown as get\n\n\n\n\ncouchbase.by_bucket.cmd_set(gauge)\nCompare and swap setsshown as set\n\n\n\n\ncouchbase.by_bucket.couch_docs_actual_disk_size(gauge)\nCouch docs total size on disk in bytesshown as byte\n\n\n\n\ncouchbase.by_bucket.couch_docs_data_size(gauge)\nCouch docs data size in bytesshown as byte\n\n\n\n\ncouchbase.by_bucket.couch_docs_disk_size(gauge)\nCouch docs total size in bytesshown as byte\n\n\n\n\ncouchbase.by_bucket.couch_docs_fragmentation(gauge)\nCouch docs fragmentationshown as percent\n\n\n\n\ncouchbase.by_bucket.couch_total_disk_size(gauge)\nCouch total disk sizeshown as byte\n\n\n\n\ncouchbase.by_bucket.couch_views_fragmentation(gauge)\nView fragmentationshown as percent\n\n\n\n\ncouchbase.by_bucket.couch_views_ops(gauge)\nView operationsshown as operation\n\n\n\n\ncouchbase.by_bucket.cpu_idle_ms(gauge)\nCPU idle millisecondsshown as millisecond\n\n\n\n\ncouchbase.by_bucket.cpu_utilization_rate(gauge)\nCPU utilization percentageshown as percent\n\n\n\n\ncouchbase.by_bucket.curr_connections(gauge)\nCurrent bucket connectionsshown as connection\n\n\n\n\ncouchbase.by_bucket.curr_items(gauge)\nNumber of active items in memoryshown as item\n\n\n\n\ncouchbase.by_bucket.curr_items_tot(gauge)\nTotal number of itemsshown as item\n\n\n\n\ncouchbase.by_bucket.decr_hits(gauge)\nDecrement hitsshown as hit\n\n\n\n\ncouchbase.by_bucket.decr_misses(gauge)\nDecrement missesshown as miss\n\n\n\n\ncouchbase.by_bucket.delete_hits(gauge)\nDelete hitsshown as hit\n\n\n\n\ncouchbase.by_bucket.delete_misses(gauge)\nDelete missesshown as miss\n\n\n\n\ncouchbase.by_bucket.disk_commit_count(gauge)\nDisk commitsshown as operation\n\n\n\n\ncouchbase.by_bucket.disk_update_count(gauge)\nDisk updatesshown as operation\n\n\n\n\ncouchbase.by_bucket.disk_write_queue(gauge)\nDisk write queue depthshown as operation\n\n\n\n\ncouchbase.by_bucket.ep_bg_fetched(gauge)\nDisk reads per secondshown as fetch/second\n\n\n\n\ncouchbase.by_bucket.ep_cache_miss_rate(gauge)\nCache miss rateshown as miss\n\n\n\n\ncouchbase.by_bucket.ep_cache_miss_ratio(gauge)\nCache miss ratioshown as percent\n\n\n\n\ncouchbase.by_bucket.ep_diskqueue_drain(gauge)\nTotal Drained items on disk queueshown as item\n\n\n\n\ncouchbase.by_bucket.ep_diskqueue_fill(gauge)\nTotal enqueued items on disk queueshown as item\n\n\n\n\ncouchbase.by_bucket.ep_flusher_todo(gauge)\nNumber of items currently being writtenshown as item\n\n\n\n\ncouchbase.by_bucket.ep_item_commit_failed(gauge)\nNumber of times a transaction failed to commit due to storage errorsshown as error\n\n\n\n\ncouchbase.by_bucket.ep_max_size(gauge)\nThe maximum amount of memory this bucket can useshown as byte\n\n\n\n\ncouchbase.by_bucket.ep_mem_high_wat(gauge)\nMem usage high water mark for auto-evictionsshown as byte\n\n\n\n\ncouchbase.by_bucket.ep_mem_low_wat(gauge)\nMem usage low water mark for auto-evictionsshown as byte\n\n\n\n\ncouchbase.by_bucket.ep_num_non_resident(gauge)\nNumber of non-resident itemsshown as item\n\n\n\n\ncouchbase.by_bucket.ep_num_value_ejects(gauge)\nNumber of times item values got ejected from memory to diskshown as item\n\n\n\n\ncouchbase.by_bucket.ep_oom_errors(gauge)\nNumber of times unrecoverable OOMs happened while processing operationsshown as error\n\n\n\n\ncouchbase.by_bucket.ep_ops_create(gauge)\nCreate operationsshown as operation\n\n\n\n\ncouchbase.by_bucket.ep_ops_update(gauge)\nUpdate operationsshown as operation\n\n\n\n\ncouchbase.by_bucket.ep_overhead(gauge)\nExtra memory used by transient data like persistence queues or checkpointsshown as byte\n\n\n\n\ncouchbase.by_bucket.ep_queue_size(gauge)\nNumber of items queued for storageshown as item\n\n\n\n\ncouchbase.by_bucket.ep_resident_items_rate(gauge)\nNumber of resident itemsshown as item\n\n\n\n\ncouchbase.by_bucket.ep_tap_replica_queue_drain(gauge)\nTotal drained items in the replica queueshown as item\n\n\n\n\ncouchbase.by_bucket.ep_tap_total_queue_drain(gauge)\nTotal drained items in the queueshown as item\n\n\n\n\ncouchbase.by_bucket.ep_tap_total_queue_fill(gauge)\nTotal enqueued items in the queueshown as item\n\n\n\n\ncouchbase.by_bucket.ep_tap_total_total_backlog_size(gauge)\nNumber of remaining items for replicationshown as item\n\n\n\n\ncouchbase.by_bucket.ep_tmp_oom_errors(gauge)\nNumber of times recoverable OOMs happened while processing operationsshown as error\n\n\n\n\ncouchbase.by_bucket.evictions(gauge)\nNumber of evictionsshown as eviction\n\n\n\n\ncouchbase.by_bucket.get_hits(gauge)\nNumber of get hitsshown as hit\n\n\n\n\ncouchbase.by_bucket.get_misses(gauge)\nNumber of get missesshown as miss\n\n\n\n\ncouchbase.by_bucket.hit_ratio(gauge)\nHit ratioshown as percent\n\n\n\n\ncouchbase.by_bucket.incr_hits(gauge)\nNumber of increment hitsshown as hit\n\n\n\n\ncouchbase.by_bucket.incr_misses(gauge)\nNumber of increment missesshown as miss\n\n\n\n\ncouchbase.by_bucket.mem_free(gauge)\nFree memoryshown as byte\n\n\n\n\ncouchbase.by_bucket.mem_total(gauge)\nTotal available memoryshown as byte\n\n\n\n\ncouchbase.by_bucket.mem_used(gauge)\nEngine's total memory usage (deprecated)shown as byte\n\n\n\n\ncouchbase.by_bucket.misses(gauge)\nTotal number of missesshown as miss\n\n\n\n\ncouchbase.by_bucket.ops(gauge)\nTotal number of operationsshown as operation\n\n\n\n\ncouchbase.by_bucket.page_faults(gauge)\nNumber of page faultsshown as page\n\n\n\n\ncouchbase.by_bucket.replication_docs_rep_queue(gauge)\n\nshown as item\n\n\n\n\ncouchbase.by_bucket.replication_meta_latency_aggr(gauge)\n\nshown as second\n\n\n\n\ncouchbase.by_bucket.vb_active_num(gauge)\nNumber of active itemsshown as item\n\n\n\n\ncouchbase.by_bucket.vb_active_queue_drain(gauge)\nTotal drained items in the queueshown as item\n\n\n\n\ncouchbase.by_bucket.vb_active_queue_size(gauge)\nNumber of active items in the queueshown as item\n\n\n\n\ncouchbase.by_bucket.vb_active_resident_items_ratio(gauge)\nNumber of resident itemsshown as item\n\n\n\n\ncouchbase.by_bucket.vb_avg_total_queue_age(gauge)\nAverage age of items in the queueshown as second\n\n\n\n\ncouchbase.by_bucket.vb_pending_ops_create(gauge)\nNumber of pending create operationsshown as operation\n\n\n\n\ncouchbase.by_bucket.vb_pending_queue_fill(gauge)\nTotal enqueued items on disk queueshown as item\n\n\n\n\ncouchbase.by_bucket.vb_replica_curr_items(gauge)\nNumber of in memory itemsshown as item\n\n\n\n\ncouchbase.by_bucket.vb_replica_meta_data_memory(gauge)\nTotal metadata memoryshown as byte\n\n\n\n\ncouchbase.by_bucket.vb_replica_num(gauge)\nNumber of replica vBucketsshown as item\n\n\n\n\ncouchbase.by_bucket.vb_replica_queue_size(gauge)\nReplica items in disk queueshown as item\n\n\n\n\ncouchbase.by_bucket.xdc_ops(gauge)\nNumber of cross-datacenter replication operationsshown as operation\n\n\n\n\ncouchbase.by_node.curr_items(gauge)\nNumber of active items in memoryshown as item\n\n\n\n\ncouchbase.by_node.curr_items_tot(gauge)\nTotal number of itemsshown as item\n\n\n\n\ncouchbase.by_node.couch_docs_data_size(gauge)\nCouch docs data size in bytesshown as byte\n\n\n\n\ncouchbase.by_node.couch_docs_actual_disk_size(gauge)\nCouch docs total size on disk in bytesshown as byte\n\n\n\n\ncouchbase.by_node.couch_views_data_size(gauge)\nCouch views data size on disk in bytesshown as byte\n\n\n\n\ncouchbase.by_node.couch_views_actual_disk_size(gauge)\nCouch views total size on disk in bytesshown as byte\n\n\n\n\ncouchbase.by_node.vb_replica_curr_items(gauge)\nNumber of in memory itemsshown as item\n\n\n\n","tags":"","loc":"/integrations/couchbase/"},{"title":"Datadog-CouchDB Integration","text":"\n\nOverview\n\nCapture CouchDB data in Datadog to:\n\n\n  Visualize key CouchDB metrics.\n  Correlate CouchDB performance with the rest of your applications.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nCouchDB YAML example\nCouchDB checks.d\n\n\n\nMetrics\n\n\n\n\ncouchdb.by_db.disk_size(gauge)\nDisk size per databaseshown as byte\n\n\n\n\ncouchdb.by_db.doc_count(gauge)\nDocument count per databaseshown as document\n\n\n\n\ncouchdb.httpd.requests(gauge)\nNumber of HTTP requestsshown as request\n\n\n\n\ncouchdb.httpd.view_reads(gauge)\nNumber of view readsshown as read\n\n\n\n\ncouchdb.couchdb.auth_cache_hits(gauge)\nNumber of authentication cache hitsshown as hit\n\n\n\n\ncouchdb.couchdb.auth_cache_misses(gauge)\nNumber of authentication cache missesshown as miss\n\n\n\n\ncouchdb.couchdb.database_reads(gauge)\nNumber of times a document was read from a databaseshown as read\n\n\n\n\ncouchdb.couchdb.database_writes(gauge)\nNumber of times a document was changedshown as write\n\n\n\n\ncouchdb.couchdb.open_databases(gauge)\nNumber of open databasesshown as item\n\n\n\n\ncouchdb.couchdb.open_os_files(gauge)\nNumber of file descriptors CouchDB has openshown as file\n\n\n\n\ncouchdb.couchdb.request_time(gauge)\nLength of a request inside CouchDB without MochiWebshown as second\n\n\n\n\ncouchdb.httpd.bulk_requests(gauge)\nNumber of bulk requestsshown as request\n\n\n\n\ncouchdb.httpd.clients_requesting_changes(gauge)\nNumber of clients requesting a changeshown as connection\n\n\n\n\ncouchdb.httpd_request_methods.DELETE(gauge)\nNumber of HTTP DELETE requestsshown as request\n\n\n\n\ncouchdb.httpd_request_methods.GET(gauge)\nNumber of HTTP GET requestsshown as request\n\n\n\n\ncouchdb.httpd_request_methods.HEAD(gauge)\nNumber of HTTP HEAD requestsshown as request\n\n\n\n\ncouchdb.httpd_request_methods.POST(gauge)\nNumber of HTTP POST requestsshown as request\n\n\n\n\ncouchdb.httpd_request_methods.PUT(gauge)\nNumber of HTTP PUT requestsshown as request\n\n\n\n\ncouchdb.httpd_status_codes.200(gauge)\nNumber of HTTP 200 OK responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.201(gauge)\nNumber of HTTP 201 Created responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.202(gauge)\nNumber of HTTP 202 Accepted responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.301(gauge)\nNumber of HTTP 301 Moved Permanently responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.304(gauge)\nNumber of HTTP 304 Not Modified responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.400(gauge)\nNumber of HTTP 400 Bad Request responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.401(gauge)\nNumber of HTTP 401 Unauthorized responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.403(gauge)\nNumber of HTTP 403 Forbidden responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.404(gauge)\nNumber of HTTP 404 Not Found responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.405(gauge)\nNumber of HTTP 405 Method Not Allowed responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.409(gauge)\nNumber of HTTP 409 Conflict responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.412(gauge)\nNumber of HTTP 412 Precondition Failed responsesshown as request\n\n\n\n\ncouchdb.httpd_status_codes.500(gauge)\nNumber of HTTP 500 Internal Server Error responsesshown as request\n\n\n\n","tags":"","loc":"/integrations/couchdb/"},{"title":"Datadog-Desk Integration","text":"\n\nOverview\n\nConnect Desk to Datadog to:\n\n\n  Receive new case events in the event stream\n  Visualize case stats by user and status\n  View trends in support tickets alongside DevOps issues\n\n\n\nConfiguration\n\nFrom your Desk account, add an API application on the Settings -> API -> My Applications page (you made need administrator privileges.\nFill out the form as shown, leaving the latter two URL fields blank. Desk should then generate an application key, application secret, API access token, and API access token secret.\n\n\n\nThen from your Datadog account, enter the corresponding information on the Desk tile. You will also need to enter your company’s unique Desk domain name.\nHit the install button, and then you’re all set! You will soon be able to select desk.* metrics on a custom dashboard or view them on the provided Desk dashboard. (You can also read about this integration on our blog.)\n\n\nMetrics\n\n\n\n\ndesk.all_open_cases(gauge)\nThe total number of open cases.\n\n\n\n\ndesk.cases(gauge)\nThe number of cases opened during the current day.\n\n\n\n","tags":"","loc":"/integrations/desk/"},{"title":"Directory check","text":"\n\nOverview\n\nCapture metrics from the files in given directories:\n\n\n  number of files\n  file size\n  age of the last modification\n  age of the creation\n\n\n\nConfiguration\n\nTo capture Directory metrics you need to install the Datadog Agent.\n\n\n  Ensure the user account running the Agent (typically dd-agent) has read access to the monitored directory and files.\n  \n    Configure the Agent to connect to your directories. Edit directory.yaml in your conf.d directory.\n\n    init_config:\n\ninstances:\n    # For each instance, the 'directory' parameter is required, all others are optional.\n    #\n    # Instances take the following parameters:\n    # \"directory\" - string, the directory to monitor. Required.\n    # \"name\" - string, tag metrics with specified name. defaults to the \"directory\"\n    # \"pattern\" - string, the `fnmatch` pattern to use when reading the \"directory\"'s files.\n    #                     default \"*\"\n    # \"recursive\" - boolean, when true the stats will recurse into directories. default False\n    # \"countonly\" - boolean, when true the stats will only count the number of files matching the pattern. Useful for very large directories.\n\n\n    -  directory: \"/path/to/directory\"\n       name: \"tag_name\"\n       pattern: \"*.log\"\n       recursive: True\n\n  \n  Restart the Agent\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nDirectory Check YAML example\nDirectory Check checks.d\n\n\n\nValidation\n\nTo validate that the check has passed run the agent info command. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n[...]\n\ndirectory\n---------\n    - instance #0 [OK]\n    - Collected 8 metrics & 0 events\n\n\n","tags":"","loc":"/integrations/directory/"},{"title":"Datadog-Disk Integration","text":"\n\nOverview\n\nGet metrics related to disk usage and IO metrics.\n\n\nInstallation\n\nIncluded by default with the Datadog agent installation.\n\n\nConfiguration\n\nThis configuration does not require any explicit configuration to begin monititoring your storage devices.  One however can override the default settings to adjust how disks are monitored.\n\ninit_config:\n\ninstances:\n  # The use_mount parameter will instruct the check to collect disk\n  # and fs metrics using mount points instead of volumes\n  - use_mount: no\n  # The (optional) excluded_filesystems parameter will instruct the check to\n  # ignore disks using these filesystems\n  # excluded_filesystems:\n  #   - tmpfs\n\n  # The (optional) excluded_disks parameter will instruct the check to\n  # ignore this list of disks\n  # excluded_disks:\n  #   - /dev/sda1\n  #   - /dev/sda2\n  #\n  # The (optional) excluded_disk_re parameter will instruct the check to\n  # ignore all disks matching this regex\n  # excluded_disk_re: /dev/sde.*\n  #\n  # The (optional) tag_by_filesystem parameter will instruct the check to\n  # tag all disks with their filesystem (for ex: filesystem:nfs)\n  # tag_by_filesystem: no\n  #\n  # The (optional) excluded_mountpoint_re parameter will instruct the check to\n  # ignore all mountpoints matching this regex\n  # excluded_mountpoint_re: /mnt/somebody-elses-problem.*\n  #\n  # The (optional) all_partitions parameter will instruct the check to\n  # get metrics for all partitions. use_mount should be set to yes (to avoid\n  # collecting empty device names) when using this option.\n  # all_partitions: no\n\n\n\nValidation\n\nTo ensure the integration is installed correctly, run the agent info command.\n\nsudo /etc/init.d/datadog-agent info\n\n\nYou should see something similar to the following if everything is working correctly:\n\nChecks\n======\n\n  [...]\n\n  disk\n  ------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\nsystem.disk.free(gauge)\nThe amount of disk space that is free.shown as byte\n\n\n\n\nsystem.disk.in_use(gauge)\nThe amount of disk space in use as a fraction of the total.shown as fraction\n\n\n\n\nsystem.disk.read_time_pct **Windows only(gauge)\nPercent of time spent reading from disk.shown as percent\n\n\n\n\nsystem.disk.total(gauge)\nThe total amount of disk space.shown as byte\n\n\n\n\nsystem.disk.used(gauge)\nThe amount of disk space in use.shown as byte\n\n\n\n\nsystem.disk.write_time_pct **Windows only(gauge)\nPercent of time spent writing to disk.shown as percent\n\n\n\n\nsystem.fs.inodes.free(gauge)\nThe number of free inodes.shown as inode\n\n\n\n\nsystem.fs.inodes.in_use(gauge)\nThe number of inodes in use as a fraction of the total.shown as fraction\n\n\n\n\nsystem.fs.inodes.total(gauge)\nThe total number of inodes.shown as inode\n\n\n\n\nsystem.fs.inodes.used(gauge)\nThe number of inodes in use.shown as inode\n\n\n\n\n","tags":"","loc":"/integrations/disk/"},{"title":"Datadog-DNS Service Check","text":"\n\nOverview\n\nThe DNS Service Check allows you to monitor the resolution of host names against a specified DNS server. This will allow you to monitor the availability and response times of your DNS infrastructure, as well as validate that key host names are resolvable.\n\n\nConfiguration\n\nTo configure the DNS Service Check, edit the dns_check.yaml file in your conf.d directory.\n\ninit_config:\n  default_timeout: 4\n\ninstances:\n  - hostname: www.example.org\n    nameserver: 127.0.0.1\n    timeout: 8\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nDNS Service Check YAML example\nDNS Service Check checks.d\n\n\n\nValidation\n\nTo validate that the DNS Service Check is working, run datadog-agent info. You should see something like the following:\n\nChecks\n======\n\n  [...]\n  dns_check\n  ---------\n    - instance #0 [OK]\n    - Collected 1 metric, 0 events & 2 service checks\n\n\n\nUsage\n\nWhen the data has been submitted to Datadog, you will have one new metric: dns.response_time. This will have the tags nameserver:<nameserver_in_yaml_file> and resolved_hostname:<hostname_in_yaml>.\n","tags":"","loc":"/integrations/dnscheck/"},{"title":"Datadog-Docker Integration","text":"\n\nOverview\n\nGet metrics from Docker in real time to:\n\n\n  Visualize your containers’ performance.\n  Correlate the performance of containers with the applications running inside them.\n\n\n\n\n\nInstallation\n\nThere are three ways to setup the Docker integration: install the agent on the host, on a single privileged container, and on each individual container.\n\nWhichever you choose, your system will need to have cgroup memory management enabled for the check to succeed. Check out our Docker agent repository for how to enable it.\n\n\nHost Installation\n\n\n  Ensure Docker is running on the host.\n  Install the agent as described in the agent installation instructions for your host OS.\n  Enable the Docker integration tile in the application.\n  Add the agent user to the docker group: usermod -a -G docker dd-agent\n\n  Create a docker_daemon.yaml file by copying the example file in the agent conf.d directory. If you have a standard install of Docker on your host, there shouldn’t be anything you need to change to get the integration to work.\n  To enable other integrations, use docker ps to identify the ports used by the corresponding applications.\n \n\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nDocker YAML example\nDocker checks.d\n\n\nNote: docker_daemon has replaced the older docker integration.\n\n\nSingle Container Installation\n\n\n  Ensure Docker is running on the host.\n  \n    As per the docker container installation instructions, run:\n\n     docker run -d --name dd-agent \\\n   -v /var/run/docker.sock:/var/run/docker.sock:ro \\\n   -v /proc/:/host/proc/:ro \\\n   -v /sys/fs/cgroup/:/host/sys/fs/cgroup:ro \\\n   -e API_KEY={YOUR API KEY} \\\n   datadog/docker-dd-agent:latest\n\n  \n\n\n\nEnvironment variables\n\nNote that in the command above, you are able to pass your API key to the Datadog Agent using Docker’s -e environment variable flag. Some other variables you can pass include:\n\n\n  \n    \n      Variable\n      Description\n    \n  \n  \n    \n      API_KEY\n      Sets your Datadog API key.\n    \n    \n      DD_HOSTNAME\n      Sets the hostname in the Agent container’s datadog.conf file. If this variable is not set, the Agent container will default to using the Name field (as reported by the docker info command) as the Agent container hostname.\n    \n    \n      DD_URL\n      Sets the Datadog intake server URL where the Agent will send data. This is useful when using an agent as a proxy.\n    \n    \n      LOG_LEVEL\n      Sets logging verbosity (CRITICAL, ERROR, WARNING, INFO, DEBUG). For example, -e LOG_LEVEL=DEBUG will set logging to debug mode.\n    \n    \n      TAGS\n      Sets host tags as a comma delimited string. You can pass both simple tags and key-value tags. For example, -e TAGS=\"simple-tag, tag-key:tag-value\".\n    \n    \n      EC2_TAGS\n      Enabling this feature allows the agent to query and capture custom tags set using the EC2 API during startup. To enable, set the value to “yes”, for example, -e EC2_TAGS=yes. Note that this feature requires an IAM role associated with the instance.\n    \n    \n      NON_LOCAL_TRAFFIC\n      Enabling this feature will allow statsd reporting from any external IP. For example, -e NON_LOCAL_TRAFFIC=yes. This can be used to report metrics from other containers or systems. See network configuration for more details.\n    \n    \n      PROXY_HOST, PROXY_PORT, PROXY_USER, PROXY_PASSWORD\n      Sets proxy configuration details. For more information, see the Agent proxy documentation\n\n    \n    \n      SD_BACKEND, SD_CONFIG_BACKEND, SD_BACKEND_HOST, SD_BACKEND_PORT, SD_TEMPLATE_DIR, SD_CONSUL_TOKEN\n      Enables and configures Autodiscovery. For more information, please see the Autodiscovery guide.\n    \n  \n\n\n\nRunning the agent container on Amazon Linux\n\nTo run the Datadog Agent container on Amazon Linux, you’ll need to make one small change to the cgroup volume mount location:\n\ndocker run -d --name dd-agent \\\n  -v /var/run/docker.sock:/var/run/docker.sock:ro \\\n  -v /proc/:/host/proc/:ro \\\n  -v /cgroup/:/host/sys/fs/cgroup:ro \\\n  -e API_KEY={YOUR API KEY} \\\n  datadog/docker-dd-agent:latest\n\n\n\nAlpine Linux based container\n\nOur standard Docker image is based on Debian Linux, but as of version 5.7 of the Datadog Agent, we also offer an Alpine Linux based image. The Alpine Linux image is considerably smaller in size than the traditional Debian-based image. It also inherits Alpine’s security-oriented design.\n\nTo use the Alpine Linux image, simply append -alpine to the version tag. For example:\n\ndocker run -d --name dd-agent \\\n  -v /var/run/docker.sock:/var/run/docker.sock:ro \\\n  -v /proc/:/host/proc/:ro \\\n  -v /sys/fs/cgroup/:/host/sys/fs/cgroup:ro \\\n  -e API_KEY={YOUR API KEY} \\\n  datadog/docker-dd-agent:latest-alpine\n\n\n\nImage versioning\nStarting with version 5.5.0 of the Datadog Agent, the docker image follows a new versioning pattern. This allows us to release changes to the Docker image of the Datadog Agent but with the same version of the Agent.\n\nThe Docker image version will have the following pattern: X.Y.Z where X is the major version of the Docker Image, Y is the minor version, Z will represent the Agent version.\n\nFor example, the first version of the Docker image that will bundle the Datadog Agent 5.5.0 will be: 10.0.550\n\n\nCustom containers and additional information\n\nFor more information about building custom Docker containers with the Datadog Agent, the Alpine Linux based image, versioning, and more, please reference our docker-dd-agent project on Github.\n\n\nEach Container Installation\n\n\n  Ensure Docker is running on the host.\n  \n    Add a RUN command to the Dockerfile as listed in the agent installation instructions in the app for the OS used in the container. For instance, if the container is based on an Ubuntu image, the Dockerfile would look similar to the following:\n\n     FROM ubuntu:16.04\n RUN DD_API_KEY={YOUR API KEY} \\\n   bash -c \"$(curl -L https://raw.githubusercontent.com/DataDog/dd-agent/.../install_agent.sh)\"\n\n\n    NOTE: Always refer to the instructions in the app for the latest version of the install command.\n  \n\n\n\nValidate Installation\n\n\n  Restart the agent.\n  \n    Execute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\n     Checks\n ======\n\n   [...]\n   docker_daemon\n   -------------\n     - instance #0 [OK]\n     - Collected 50 metrics, 0 events & 2 service checks\n\n  \n  In the application on the Infrastructure List, you should see the host with the blue docker pill next to it indicating that the app is receiving the data correctly.\n\n\n\nMetrics\n\n\n\n\ndocker.cpu.system(gauge)\nThe percent of time the CPU is executing system calls on behalf of processes of this containershown as percent\n\n\n\n\ndocker.cpu.system.95percentile(gauge)\n95th percentile of docker.cpu.systemshown as percent\n\n\n\n\ndocker.cpu.system.avg(gauge)\nAverage value of docker.cpu.systemshown as percent\n\n\n\n\ndocker.cpu.system.count(rate)\nThe rate that the value of docker.cpu.system was sampledshown as sample/second\n\n\n\n\ndocker.cpu.system.max(gauge)\nMax value of docker.cpu.systemshown as percent\n\n\n\n\ndocker.cpu.system.median(gauge)\nMedian value of docker.cpu.systemshown as percent\n\n\n\n\ndocker.cpu.user(gauge)\nThe percent of time the CPU is under direct control of processes of this containershown as percent\n\n\n\n\ndocker.cpu.user.95percentile(gauge)\n95th percentile of docker.cpu.usershown as percent\n\n\n\n\ndocker.cpu.user.avg(gauge)\nAverage value of docker.cpu.usershown as percent\n\n\n\n\ndocker.cpu.user.count(rate)\nThe rate that the value of docker.cpu.user was sampledshown as sample/second\n\n\n\n\ndocker.cpu.user.max(gauge)\nMax value of docker.cpu.usershown as percent\n\n\n\n\ndocker.cpu.user.median(gauge)\nMedian value of docker.cpu.usershown as percent\n\n\n\n\ndocker.cpu.usage(gauge)\nThe percent of CPU time obtained by this containershown as percent\n\n\n\n\ndocker.cpu.throttled(gauge)\nNumber of times the cgroup has been throttled\n\n\n\n\ndocker.mem.cache(gauge)\nThe amount of memory that is being used to cache data from disk (e.g. memory contents that can be associated precisely with a block on a block device)shown as byte\n\n\n\n\ndocker.mem.cache.95percentile(gauge)\n95th percentile value of docker.mem.cacheshown as byte\n\n\n\n\ndocker.mem.cache.avg(gauge)\nAverage value of docker.mem.cacheshown as byte\n\n\n\n\ndocker.mem.cache.count(rate)\nThe rate that the value of docker.mem.cache was sampledshown as sample/second\n\n\n\n\ndocker.mem.cache.max(gauge)\nMax value of docker.mem.cacheshown as byte\n\n\n\n\ndocker.mem.cache.median(gauge)\nMedian value of docker.mem.cacheshown as byte\n\n\n\n\ndocker.mem.rss(gauge)\nThe amount of non-cache memory that belongs to the container's processes. Used for stacks, heaps, etc.shown as byte\n\n\n\n\ndocker.mem.rss.95percentile(gauge)\n95th percentile value of docker.mem.rssshown as byte\n\n\n\n\ndocker.mem.rss.avg(gauge)\nAverage value of docker.mem.rssshown as byte\n\n\n\n\ndocker.mem.rss.count(rate)\nThe rate that the value of docker.mem.rss was sampledshown as sample/second\n\n\n\n\ndocker.mem.rss.max(gauge)\nMax value of docker.mem.rssshown as byte\n\n\n\n\ndocker.mem.rss.median(gauge)\nMedian value of docker.mem.rssshown as byte\n\n\n\n\ndocker.mem.swap(gauge)\nThe amount of swap currently used by the containershown as byte\n\n\n\n\ndocker.mem.swap.95percentile(gauge)\n95th percentile value of docker.mem.swapshown as byte\n\n\n\n\ndocker.mem.swap.avg(gauge)\nAverage value of docker.mem.swapshown as byte\n\n\n\n\ndocker.mem.swap.count(rate)\nThe rate that the value of docker.mem.swap was sampledshown as sample/second\n\n\n\n\ndocker.mem.swap.max(gauge)\nMax value of docker.mem.swapshown as byte\n\n\n\n\ndocker.mem.swap.median(gauge)\nMedian value of docker.mem.swapshown as byte\n\n\n\n\ndocker.container.size_rw(gauge)\nTotal size of all the files in the container which have been created or changed by processes running in the containershown as byte\n\n\n\n\ndocker.container.size_rw.95percentile(gauge)\n95th percentile of docker.container.size_rwshown as byte\n\n\n\n\ndocker.container.size_rw.avg(gauge)\nAverage value of docker.container.size_rwshown as byte\n\n\n\n\ndocker.container.size_rw.count(rate)\nThe rate that the value of docker.container.size_rw was sampledshown as sample/second\n\n\n\n\ndocker.container.size_rw.max(gauge)\nMax value of docker.container.size_rwshown as byte\n\n\n\n\ndocker.container.size_rw.median(gauge)\nMedian value of docker.container.size_rwshown as byte\n\n\n\n\ndocker.container.size_rootfs(gauge)\nTotal size of all the files in the containershown as byte\n\n\n\n\ndocker.container.size_rootfs.95percentile(gauge)\n95th percentile of docker.container.size_rootfsshown as byte\n\n\n\n\ndocker.container.size_rootfs.avg(gauge)\nAverage value of docker.container.size_rootfsshown as byte\n\n\n\n\ndocker.container.size_rootfs.count(rate)\nThe rate that the value of docker.container.size_rw was sampledshown as sample/second\n\n\n\n\ndocker.container.size_rootfs.max(gauge)\nMax value of docker.container.size_rootfsshown as byte\n\n\n\n\ndocker.container.size_rootfs.median(gauge)\nMedian value of docker.container.size_rootfsshown as byte\n\n\n\n\ndocker.containers.running(gauge)\nThe number of containers running on this host\n\n\n\n\ndocker.containers.stopped(gauge)\nThe number of containers stopped on this host\n\n\n\n\ndocker.images.available(gauge)\nThe number of top-level images\n\n\n\n\ndocker.images.intermediate(gauge)\nThe number of intermediate images, which are intermediate layers that make up other images\n\n\n\n\ndocker.mem.limit(gauge)\nThe memory limit for the container, if setshown as byte\n\n\n\n\ndocker.mem.limit.95percentile(gauge)\n95th percentile of docker.mem.limit. Ordinarily this value will not changeshown as byte\n\n\n\n\ndocker.mem.limit.avg(gauge)\nAverage value of docker.mem.limit. Ordinarily this value will not changeshown as byte\n\n\n\n\ndocker.mem.limit.count(rate)\nThe rate that the value of docker.mem.limit was sampledshown as sample/second\n\n\n\n\ndocker.mem.limit.max(gauge)\nMax value of docker.mem.limit. Ordinarily this value will not changeshown as byte\n\n\n\n\ndocker.mem.limit.median(gauge)\nMedian value of docker.mem.limit. Ordinarily this value will not changeshown as byte\n\n\n\n\ndocker.mem.sw_limit(gauge)\nThe swap + memory limit for the container, if setshown as byte\n\n\n\n\ndocker.mem.sw_limit.95percentile(gauge)\n95th percentile of docker.mem.sw_limit. Ordinarily this value will not changeshown as byte\n\n\n\n\ndocker.mem.sw_limit.avg(gauge)\nAverage value of docker.mem.sw_limit. Ordinarily this value will not changeshown as byte\n\n\n\n\ndocker.mem.sw_limit.count(rate)\nThe rate that the value of docker.mem.sw_limit was sampledshown as sample/second\n\n\n\n\ndocker.mem.sw_limit.max(gauge)\nMax value of docker.mem.sw_limit. Ordinarily this value will not changeshown as byte\n\n\n\n\ndocker.mem.sw_limit.median(gauge)\nMedian value of docker.mem.sw_limit. Ordinarily this value will not changeshown as byte\n\n\n\n\ndocker.mem.in_use(gauge)\nThe fraction of used memory to available memory, if the limit is setshown as fraction\n\n\n\n\ndocker.mem.in_use.95percentile(gauge)\n95th percentile of docker.mem.in_useshown as fraction\n\n\n\n\ndocker.mem.in_use.avg(gauge)\nAverage value of docker.mem.in_useshown as fraction\n\n\n\n\ndocker.mem.in_use.count(rate)\nThe rate that the value of docker.mem.in_use was sampledshown as sample/second\n\n\n\n\ndocker.mem.in_use.max(gauge)\nMax value of docker.container.mem.in_useshown as fraction\n\n\n\n\ndocker.mem.in_use.median(gauge)\nMedian value of docker.container.mem.in_useshown as fraction\n\n\n\n\ndocker.mem.sw_in_use(gauge)\nThe fraction of used swap + memory to available swap + memory, if the limit is setshown as fraction\n\n\n\n\ndocker.mem.sw_in_use.95percentile(gauge)\n95th percentile of docker.mem.sw_in_useshown as fraction\n\n\n\n\ndocker.mem.sw_in_use.avg(gauge)\nAverage value of docker.mem.sw_in_useshown as fraction\n\n\n\n\ndocker.mem.sw_in_use.count(rate)\nThe rate that the value of docker.mem.sw_in_use was sampledshown as sample/second\n\n\n\n\ndocker.mem.sw_in_use.max(gauge)\nMax value of docker.container.mem.sw_in_useshown as fraction\n\n\n\n\ndocker.mem.sw_in_use.median(gauge)\nMedian value of docker.container.mem.sw_in_useshown as fraction\n\n\n\n\ndocker.io.read_bytes(gauge)\nBytes read per second from disk by the processes of the containershown as byte/second\n\n\n\n\ndocker.io.read_bytes.95percentile(gauge)\n95th percentile of docker.io.read_bytesshown as byte/second\n\n\n\n\ndocker.io.read_bytes.avg(gauge)\nAverage value of docker.io.read_bytesshown as byte/second\n\n\n\n\ndocker.io.read_bytes.count(rate)\nThe rate that the value of docker.io.read_bytes was sampledshown as sample/second\n\n\n\n\ndocker.io.read_bytes.max(gauge)\nMax value of docker.container.io.read_bytesshown as byte/second\n\n\n\n\ndocker.io.read_bytes.median(gauge)\nMedian value of docker.container.io.read_bytesshown as byte/second\n\n\n\n\ndocker.io.write_bytes(gauge)\nBytes written per second to disk by the processes of the containershown as byte/second\n\n\n\n\ndocker.io.write_bytes.95percentile(gauge)\n95th percentile of docker.io.write_bytesshown as byte/second\n\n\n\n\ndocker.io.write_bytes.avg(gauge)\nAverage value of docker.io.write_bytesshown as byte/second\n\n\n\n\ndocker.io.write_bytes.count(rate)\nThe rate that the value of docker.io.write_bytes was sampledshown as sample/second\n\n\n\n\ndocker.io.write_bytes.max(gauge)\nMax value of docker.container.io.write_bytesshown as byte/second\n\n\n\n\ndocker.io.write_bytes.median(gauge)\nMedian value of docker.container.io.write_bytesshown as byte/second\n\n\n\n\ndocker.image.virtual_size(gauge)\nSize of all layers of the image on diskshown as byte\n\n\n\n\ndocker.image.size(gauge)\nSize of all layers of the image on diskshown as byte\n\n\n\n\ndocker.net.bytes_rcvd(gauge)\nBytes received per second from the networkshown as byte/second\n\n\n\n\ndocker.net.bytes_rcvd.95percentile(gauge)\n95th percentile of docker.net.bytes_rcvdshown as byte/second\n\n\n\n\ndocker.net.bytes_rcvd.avg(gauge)\nAverage value of docker.net.bytes_rcvdshown as byte/second\n\n\n\n\ndocker.net.bytes_rcvd.count(rate)\nThe rate that the value of docker.net.bytes_rcvd was sampledshown as sample/second\n\n\n\n\ndocker.net.bytes_rcvd.max(gauge)\nMax value of docker.container.net.bytes_rcvdshown as byte/second\n\n\n\n\ndocker.net.bytes_rcvd.median(gauge)\nMedian value of docker.container.net.bytes_rcvdshown as byte/second\n\n\n\n\ndocker.net.bytes_sent(gauge)\nBytes sent per second to the networkshown as byte/second\n\n\n\n\ndocker.net.bytes_sent_bytes.95percentile(gauge)\n95th percentile of docker.net.bytes_sent_bytesshown as byte/second\n\n\n\n\ndocker.net.bytes_sent_bytes.avg(gauge)\nAverage value of docker.net.bytes_sent_bytesshown as byte/second\n\n\n\n\ndocker.net.bytes_sent_bytes.count(rate)\nThe rate that the value of docker.net.bytes_sent_bytes was sampledshown as sample/second\n\n\n\n\ndocker.net.bytes_sent_bytes.max(gauge)\nMax value of docker.container.net.bytes_sent_bytesshown as byte/second\n\n\n\n\ndocker.net.bytes_sent_bytes.median(gauge)\nMedian value of docker.container.net.bytes_sent_bytesshown as byte/second\n\n\n\n\ndocker.data.used(gauge)\nStorage pool disk space usedshown as byte\n\n\n\n\ndocker.data.free(gauge)\nStorage pool disk space freeshown as byte\n\n\n\n\ndocker.data.total(gauge)\nStorage pool disk space totalshown as byte\n\n\n\n\ndocker.data.percent(gauge)\nThe percent of storage pool usedshown as percent\n\n\n\n\ndocker.metadata.used(gauge)\nStorage pool metadata space usedshown as byte\n\n\n\n\ndocker.metadata.free(gauge)\nStorage pool metadata space freeshown as byte\n\n\n\n\ndocker.metadata.total(gauge)\nStorage pool metadata space totalshown as byte\n\n\n\n\ndocker.metadata.percent(gauge)\nThe percent of storage pool metadata usedshown as percent\n\n\n\n\n\nDeprecated metrics\n\nThe following metrics are reported by a deprecated check and will be eventually removed from the catalog:\n\n\n  docker.mem.active_anon\n  docker.mem.inactive_anon\n  docker.mem.active_file\n  docker.mem.inactive_file\n  docker.mem.mapped_file\n  docker.mem.pgfault\n  docker.mem.pgmajfault\n  docker.mem.pgpgin\n  docker.mem.pgpgout\n  docker.mem.unevictable\n\n\nThe following metrics are now reported with a different name and will be eventually removed from the catalog:\n\n\n  \ndocker.disk.used (now reported as docker.data.used)\n  \ndocker.disk.free (now reported as docker.data.free)\n  \ndocker.disk.total (now reported as docker.data.total)\n\n\n\nCompose and the Datadog Agent\n\nCompose is a Docker tool that simplifies building applications on Docker by allowing you to define, build and run multiple containers as a single application.\n\nWhile the Single Container Installation instructions above will get the stock Datadog Agent container running, you will most likely want to enable integrations for other containerized services that are part of your Compose application. To do this, you’ll need to combine integration YAML files with the base Datadog Agent image to create your Datadog Agent container. Then you’ll need to add your container to the Compose YAML.\n\n\nExample: Monitoring Redis\n\nLet’s look at how you would monitor a Redis container using Compose. Our example file structure is:\n\n|- docker-compose.yml\n|- datadog\n    |- Dockerfile\n    |- conf.d\n       |-redisdb.yaml\n\n\nFirst we’ll take a look at the docker-compose.yml that describes how our containers work together and sets some of the configuration details for the containers.\n\nversion: \"2\"\nservices:\n  # Redis container\n  redis:\n    image: redis\n  # Agent container\n  datadog:\n    build: datadog\n    links:\n     - redis # Ensures datadog container can connect to redis container\n    environment:\n     - API_KEY=__your_datadog_api_key_here__\n    volumes:\n     - /var/run/docker.sock:/var/run/docker.sock\n     - /proc/mounts:/host/proc/mounts:ro\n     - /sys/fs/cgroup:/host/sys/fs/cgroup:ro\n\n\nIn this file, we can see that Compose will run the Docker image redis and it will also build and run a datadog container. By default it will look for a matching directory called datadog and run the Dockerfile in that directory.\n\nOur Dockerfile simply takes the standard Datadog docker image and places a copy of the redisdb.yaml integration configuration into the appropriate directory:\n\nFROM datadog/docker-dd-agent\nADD conf.d/redisdb.yaml /etc/dd-agent/conf.d/redisdb.yaml\n\n\nFinally our redisdb.yaml is patterned after the redisdb.yaml.example file and tells the Datadog agent to look for Redis on the host named redis (defined in our docker-compose.yaml above) and the standard Redis port 6379:\n\ninit_config:\n\ninstances:\n  - host: redis\n    port: 6379\n\n\nFor a more complete example, please see our Docker Compose example project on Github.\n\n\nDogStatsD and Docker\n\nDatadog has a huge number of integrations with common applications, but it can also be used to instrument your custom applications. This is typically using one of the many Datadog libraries.\n\nLibraries that communicate over HTTP using the Datadog API don’t require any special configuration with regard to Docker. However, applications using libraries that integrate with DogStatsD or StatsD will need to configure the library to connect to the Agent. Note that each library will handle this configuration differently, so please refer to the individual library’s documentation for more details.\n\nAfter your code is configured you can run your custom application container using the --link option to create a network connection between your application container and the Datadog Agent container.\n\n\nExample: Monitoring a basic Python application\n\nTo start monitoring our application, we first need to run the Datadog container using the Single Container Installation instructions above. Note that the docker run command sets the name of the container to dd-agent.\n\nNext, we’ll need to instrument our code. Here’s a basic Flask-based web application:\n\nfrom flask import Flask\nfrom datadog import initialize, statsd\n\n# Initialize DogStatsD and set the host.\ninitialize(statsd_host = 'dd-agent')\n\napp = Flask(__name__)\n\n@app.route('/')\ndef hello():\n    # Increment a Datadog counter.\n    statsd.increment('my_webapp.page.views')\n\n    return \"Hello World!\"\n\nif __name__ == \"__main__\"\n    app.run()\n\n\nIn our example code above, we set the DogStatsD host to match the Datadog Agent container name, dd-agent.\n\nAfter we build our web application container, we can run it and use the --link argument to setup a network connection to the Datadog Agent container:\n\ndocker run -d --name my-web-app \\\n  --link dd-agent:dd-agent\n  my-web-app\n\n\nFor another example using DogStatsD, see our Docker Compose example project on Github.\n\n\nAdditional resources\n\nLearn more about how to monitor Docker performance metrics thanks to our series of posts. We detail the challenges when monitoring Docker, its key performance metrics, how to collect them, and lastly how the largest TV and radio outlet in the U.S. monitors Docker using Datadog.\n\nWe’ve also written several other in-depth blog posts to help you get the most out of Datadog and Docker:\n\n\n  How to Monitor Docker Resource Metrics\n  How to Collect Docker Metrics\n  8 Surprising Facts about Real Docker Adoption\n  Monitor Docker on AWS ECS\n  Dockerize Datadog\n  Monitor Docker with Datadog\n\n","tags":"","loc":"/integrations/docker_daemon/"},{"title":"Datadog-Dyn Integration","text":"\nMonitor your zones with advanced graphs and events.\n\n\n  Keep track of the changes made when a zone is updated\n  Analyze the QPS made by zone or record type thanks to advanced graphing tools\n\n\n\nMetrics\n\n\n\n\ndyn.qps(gauge)\nThe number of DNS queries to a given zone.shown as query/second\n\n\n\n\ndyn.changes(gauge)\nThe number of DNS zone note changes.shown as event/second\n\n\n\n","tags":"","loc":"/integrations/dyn/"},{"title":"Datadog-AWS ECS Integration","text":"\n\nOverview\nAmazon EC2 Container Service (ECS) is a highly scalable, high performance container management service for Docker containers running on EC2 instances.\n\n\nInstallation\nTo monitor your ECS containers and tasks with Datadog, run the Agent as a container on every EC2 instance in your ECS cluster. As detailed below, there are a few setup steps:\n\n\n  Add an ECS Task\n  Create or Modify your IAM Policy\n  Create a new Instance with a User Script\n\n\nThis documentation assume you already have a working EC2 Container Service cluster configured. If not, review the Getting Started section in the ECS documentation.\n\n\nCreate an ECS Task\n\nThis task will launch the Datadog container. When you need to modify the configuration, you will update this Task Definition as described further down in this guide.\n\nYou may either configure the task using the AWS CLI tools or using the Amazon Web Console.\n\n\nAWS CLI\n\n\n  Download dd-agent-ecs.json.\n  Edit dd-agent-ecs.json and update it with the API_KEY for your account.\n  Execute the following command:\n    aws ecs register-task-definition –cli-input-json file://path/to/dd-agent-ecs.json\n\n\n\nWeb UI\n\n\n  Log in to your AWS Console and navigate to the EC2 Container Service section.\n  Click on the cluster you wish to add Datadog to.\n  Click on Task Definitions on the left side and click the button Create new Task Definition.\n  Enter a Task Definition Name, such as dd-agent-task.\n  Click on the Add volume link.\n  For Name enter docker_sock. For Source Path, enter /var/run/docker.sock. Click Add.\n  Add another volume with the name proc and source path of /proc/.\n  Add another volume with the name cgroup and source path of /cgroup/.\n  Click the large Add container button.\n  For Container name enter dd-agent.\n  For Image enter datadog/docker-dd-agent:latest.\n  For Maximum memory enter 128.\n  Scroll down to the Advanced container configuration section and enter 10 in CPU units.\n  For Env Variables, add a Key of API_KEY and enter your Datadog API Key in the value. If you feel more comfortable storing secrets like this in s3, take a look at the ECS Configuration guide.\n\n  Add another Environment Variable for any tags you want to add using the key TAGS.\n  Scroll down to the Storage and Logging section.\n  In Mount points select the docker_sock source volume and enter /var/run/docker.sock in the Container path. Leave the Read only checkbox un-checked.\n  Add another mount point for proc and enter /host/proc/ in the Container path. Check the Read only checkbox.\n  Add a third mount point for cgroup and enter /host/sys/fs/cgroup in the Container path. Check the Read only checkbox.\n\n\n\nCreate or Modify your IAM Policy\n\nIf you are modifying the IAM Policy you created for your cluster, you may only need to add one Action: ecs:StartTask.\n\n\n  Using the Identity and Access Management (IAM) console, create a new role called dd-agent-ecs.\n  Select Amazon EC2 Role for EC2 Container Service. On the next screen do not check any checkboxes and click Next Step.\n  Click Create Role.\n  Click on the newly created role.\n  Expand the Inline Policies section. Click the link to create a new inline policy.\n  Choose Custom Policy and press the button.\n  \n    For Policy Name enter dd-agent-policy. Copy the following text into the Policy Document:\n\n    {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"ecs:RegisterContainerInstance\",\n                \"ecs:DeregisterContainerInstance\",\n                \"ecs:DiscoverPollEndpoint\",\n                \"ecs:Submit*\",\n                \"ecs:Poll\",\n                \"ecs:StartTask\",\n                \"ecs:StartTelemetrySession\"\n            ],\n            \"Resource\": [\n                \"*\"\n            ]\n        }\n    ]\n}\n\n  \n  Click Create Policy\n\n\n\n\nCreate a new instance including a startup script\n\nIdeally you want the Datadog agent to load on one container on each EC2 instance. The easiest way to achieve this is to have a startup script on each instance used. Unfortunately there is no way to add a script to an existing instance. So you need to create a new instance and add it to your ECS cluster.\n\n\nCreate a new Amazon Linux instance\n\n\n  Log in to the AWS console and navigate to the EC2 section.\n  Create a new instance by clicking the Launch Instance button.\n  Click on Community AMIs. Visit this page to see a list of current ECS optimized instances. Choose the appropriate AMI for your region and copy the ID into the search box. Choose the AMI that comes up as a result of the  search.\n  Follow the prompts as you normally would when setting up an instance.\n  On the third dialog, select the IAM role you created above.\n  \n    Expand the Advanced Details section and copy the following script into the User Data section. Change cluster name to your cluster’s name and task definition to the name you gave your task definition.\n\n    #!/bin/bash\ncluster=\"cluster_name\"\ntask_def=\"dd-agent-task\"\necho ECS_CLUSTER=$cluster >> /etc/ecs/ecs.config\nstart ecs\nyum install -y aws-cli jq\ninstance_arn=$(curl -s http://localhost:51678/v1/metadata \\\n  | jq -r '. | .ContainerInstanceArn' | awk -F/ '{print $NF}' )\naz=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone)\nregion=${az:0:${#az} - 1}\necho \"\ncluster=$cluster\naz=$az\nregion=$region\naws ecs start-task --cluster $cluster --task-definition $task_def \\\n  --container-instances $instance_arn --region $region\" >> /etc/rc.local\n\n\n    This user script above will:\n\n    \n      Start the task defined with the right parameters\n      Add a few lines to /etc/rc.local so that the rebooted instance starts the task\n    \n  \n\n\n\nCreate a new CoreOS instance\n\n\n  Log in to the AWS console and navigate to the EC2 section.\n  Create a new instance  as described in the instructions for a simple CoreOS ECS instance here).\n  When you get to the Configure Instance Details step, select the IAM role you created above.\n  \n    Paste the following block in User Data under Advanced Details, replace CLUSTER_NAME and YOUR_API_KEY with the ECS cluster that instance will join and your Datadog API key. This block declares two units with cloud-config, one for the ecs-agent container, used by Amazon ECS to administrate the ECS instance, and one for the dd-agent container, used by Datadog to collect metrics about the system and the tasks running on this ECS instance. Of course it can be modified to include your own tasks as well.\n\n    #cloud-config\n\ncoreos:\n  units:\n    - name: amazon-ecs-agent.service\n      command: start\n      runtime: true\n      content: |\n        [Unit]\n        Description=Amazon ECS Agent\n        After=docker.service\n        Requires=docker.service\n        Requires=network-online.target\n        After=network-online.target\n\n        [Service]\n        Environment=ECS_CLUSTER=CLUSTER_NAME\n        Environment=ECS_LOGLEVEL=warn\n        Environment=ECS_CHECKPOINT=true\n        ExecStartPre=-/usr/bin/docker kill ecs-agent\n        ExecStartPre=-/usr/bin/docker rm ecs-agent\n        ExecStartPre=/usr/bin/docker pull amazon/amazon-ecs-agent\n        ExecStart=/usr/bin/docker run --name ecs-agent --env=ECS_CLUSTER=${ECS_CLUSTER} --env=ECS_LOGLEVEL=${ECS_LOGLEVEL} --env=ECS_CHECKPOINT=${ECS_CHECKPOINT} --publish=127.0.0.1:51678:51678 --volume=/var/run/docker.sock:/var/run/docker.sock --volume=/var/lib/aws/ecs:/data amazon/amazon-ecs- agent\n        ExecStop=/usr/bin/docker stop ecs-agent\n    - name: dd-agent.service\n      command: start\n      runtime: true\n      content: |\n        [Unit]\n        Description=Datadog Agent\n        After=amazon-ecs-agent.service\n        After=docker.service\n        After=network-online.target\n        Requires=amazon-ecs-agent.service\n        Requires=docker.service\n        Requires=network-online.target\n\n        [Service]\n        Environment=API_KEY=YOUR_API_KEY\n        Environment=TAGS=simple-tag-0\n        ExecStartPre=/usr/bin/docker pull datadog/docker-dd-agent:latest\n        ExecStart=/usr/bin/docker run --name dd-agent --env=API_KEY=${API_KEY} --volume=/var/run/docker.sock:/var/run/docker.sock --volume=/proc/:/host/proc/:ro --volume=/sys/fs/cgroup/:/host/sys/fs/cgroup:ro datadog/docker-dd-agent:latest\n        ExecStop=/usr/bin/docker stop dd-agent\n\n  \n\n\n\nThat’s all!\n\nThe Datadog agent is now running on your new ECS instance. Use this user script with every new ECS instance deployment to monitor your cluster’s health with Datadog.\n\n\nDynamic detection and monitoring of running services\n\nDatadog’s Autodiscovery can be used in conjunction with ECS and Docker to automatically discovery and monitor running tasks in your environment.\n\n\nMetrics\n\n\n\n\naws.ecs.cpuutilization(gauge)\nAverage percentage of CPU units that are used in the cluster or service.shown as percent\n\n\n\n\naws.ecs.cpuutilization.minimum(gauge)\nMinimum percentage of CPU units that are used in the cluster or service.shown as percent\n\n\n\n\naws.ecs.cpuutilization.maximum(gauge)\nMaximum percentage of CPU units that are used in the cluster or service.shown as percent\n\n\n\n\naws.ecs.memory_utilization(gauge)\nAverage percentage of memory that is used in the cluster or service.shown as fraction\n\n\n\n\naws.ecs.memory_utilization.minimum(gauge)\nMinimum percentage of memory that is used in the cluster or service.shown as fraction\n\n\n\n\naws.ecs.memory_utilization.maximum(gauge)\nMaximum percentage of memory that is used in the cluster or service.shown as fraction\n\n\n\n\naws.ecs.service.cpuutilization(gauge)\nAverage percentage of CPU units that are used in the service.shown as percent\n\n\n\n\naws.ecs.service.cpuutilization.minimum(gauge)\nMinimum percentage of CPU units that are used in the service.shown as percent\n\n\n\n\naws.ecs.service.cpuutilization.maximum(gauge)\nMaximum percentage of CPU units that are used in the service.shown as percent\n\n\n\n\naws.ecs.service.memory_utilization(gauge)\nAverage percentage of memory that is used in the service.shown as fraction\n\n\n\n\naws.ecs.service.memory_utilization.minimum(gauge)\nMinimum percentage of memory that is used in the service.shown as fraction\n\n\n\n\naws.ecs.service.memory_utilization.maximum(gauge)\nMaximum percentage of memory that is used in the service.shown as fraction\n\n\n\n\naws.ecs.cluster.cpuutilization(gauge)\nAverage percentage of CPU units that are used in the cluster.shown as percent\n\n\n\n\naws.ecs.cluster.cpuutilization.minimum(gauge)\nMinimum percentage of CPU units that are used in the cluster.shown as percent\n\n\n\n\naws.ecs.cluster.cpuutilization.maximum(gauge)\nMaximum percentage of CPU units that are used in the cluster.shown as percent\n\n\n\n\naws.ecs.cluster.memory_utilization(gauge)\nAverage percentage of memory that is used in the cluster.shown as fraction\n\n\n\n\naws.ecs.cluster.memory_utilization.minimum(gauge)\nMinimum percentage of memory that is used in the cluster.shown as fraction\n\n\n\n\naws.ecs.cluster.memory_utilization.maximum(gauge)\nMaximum percentage of memory that is used in the cluster.shown as fraction\n\n\n\n\naws.ecs.cpureservation(gauge)\nAverage percentage of CPU units that are reserved by running tasks in the cluster.shown as percent\n\n\n\n\naws.ecs.cpureservation.maximum(gauge)\nMaximum percentage of CPU units that are reserved by running tasks in the cluster.shown as percent\n\n\n\n\naws.ecs.cpureservation.minimum(gauge)\nMinimum percentage of CPU units that are reserved by running tasks in the cluster.shown as percent\n\n\n\n\naws.ecs.memory_reservation(gauge)\nAverage percentage of memory that is reserved by running tasks in the cluster.shown as percent\n\n\n\n\naws.ecs.memory_reservation.minimum(gauge)\nMinimum percentage of memory that is reserved by running tasks in the cluster.shown as percent\n\n\n\n\naws.ecs.memory_reservation.maximum(gauge)\nMaximum percentage of memory that is reserved by running tasks in the cluster.shown as percent\n\n\n\n\naws.ecs.running_tasks_count(gauge)\nThe number of tasks on the container instance that are in the RUNNING status.\n\n\n\n\naws.ecs.pending_tasks_count(gauge)\nThe number of tasks on the container instance that are in the PENDING status.\n\n\n\n\naws.ecs.registered_cpu(gauge)\nThe number of CPU units registered on the container instance\n\n\n\n\naws.ecs.remaining_cpu(gauge)\nThe number of CPU units remaining on the container instance\n\n\n\n\naws.ecs.registered_memory(gauge)\nThe number of Memory units registered on the container instance\n\n\n\n\naws.ecs.remaining_memory(gauge)\nThe number of Memory units remaining on the container instance\n\n\n\n\naws.ecs.services(gauge)\nThe number of services running per cluster\n\n\n\n\naws.ecs.service.pending(gauge)\nThe number of containers pending per service\n\n\n\n\naws.ecs.service.desired(gauge)\nThe number of containers desired per service\n\n\n\n\naws.ecs.service.running(gauge)\nThe number of containers running per service\n\n\n\n\n()\n\n\n\n","tags":"","loc":"/integrations/ecs/"},{"title":"Datadog-Elasticsearch Integration","text":"\n\nOverview\n\n\n\nConnect Elasticsearch to Datadog in order to:\n\n\n  Visualize Elasticsearch performance.\n  Correlate Elasticsearch performance with the rest of your applications.\n\n\n\nInstallation\n\nNo installation steps are required for this integration\n\n\nConfiguration\n\n\n  \n    Edit your conf.d/elastic.yaml file as follows:\n\n    init_config:\n\ninstances:\n  - url: http://elastic:9200\n    # The format for the url entry is url: http://servername:port\n\n  \n  \n    Restart the agent\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nElasticsearch YAML example\nElasticsearch checks.d\n\n\n\nValidation\n\nTo validate that the integration is working, run datadog-agent info. You should see results similar to the following:\n\nChecks\n======\n\n    ntp\n    ---\n      - instance #0 [OK]\n      - Collected 1 metric, 0 events & 2 service checks\n\n    disk\n    ----\n      - instance #0 [OK]\n      - Collected 32 metrics, 0 events & 1 service check\n\n    elastic\n    -------\n      - instance #0 [OK]\n      - Collected 97 metrics, 0 events & 3 service checks\n\n\n\nMetrics\n\n\n\n\nelasticsearch.active_primary_shards(gauge)\nThe number of active primary shards in the cluster.shown as shard\n\n\n\n\nelasticsearch.active_shards(gauge)\nThe number of active shards in the cluster.shown as shard\n\n\n\n\nelasticsearch.breakers.fielddata.estimated_size_in_bytes(gauge)\nThe estimated size in bytes of the field data circuit breaker.shown as byte\n\n\n\n\nelasticsearch.breakers.fielddata.overhead(gauge)\nThe constant multiplier for byte estimations of the field data circuit breaker.\n\n\n\n\nelasticsearch.breakers.fielddata.tripped(gauge)\nThe number of times the field data circuit breaker has tripped.\n\n\n\n\nelasticsearch.breakers.parent.estimated_size_in_bytes(gauge)\nThe estimated size in bytes of the parent circuit breaker.shown as byte\n\n\n\n\nelasticsearch.breakers.parent.overhead(gauge)\nThe constant multiplier for byte estimations of the parent circuit breaker.\n\n\n\n\nelasticsearch.breakers.parent.tripped(gauge)\nThe number of times the parent circuit breaker has tripped.\n\n\n\n\nelasticsearch.breakers.request.estimated_size_in_bytes(gauge)\nThe estimated size in bytes of the request circuit breaker.shown as byte\n\n\n\n\nelasticsearch.breakers.request.overhead(gauge)\nThe constant multiplier for byte estimations of the request circuit breaker.\n\n\n\n\nelasticsearch.breakers.request.tripped(gauge)\nThe number of times the request circuit breaker has tripped.\n\n\n\n\nelasticsearch.cache.field.evictions(gauge)\nThe total number of evictions from the field data cache.shown as eviction\n\n\n\n\nelasticsearch.cache.field.size(gauge)\nThe size of the field cache.shown as byte\n\n\n\n\nelasticsearch.cache.filter.count(gauge)\nThe number of items in the filter cache.shown as item\n\n\n\n\nelasticsearch.cache.filter.evictions(gauge)\nThe total number of evictions from the filter cache.shown as eviction\n\n\n\n\nelasticsearch.cache.filter.size(gauge)\nThe size of the filter cache.shown as byte\n\n\n\n\nelasticsearch.cluster_status(gauge)\nThe elasticsearch cluster health as a number: red = 0, yellow = 1, green = 2\n\n\n\n\nelasticsearch.docs.count(gauge)\nThe total number of documents in the cluster across all shards.shown as document\n\n\n\n\nelasticsearch.docs.deleted(gauge)\nThe total number of documents deleted from the cluster across all shards.shown as document\n\n\n\n\nelasticsearch.fielddata.evictions(gauge)\nThe total  number of evictions from the fielddata cache.shown as eviction\n\n\n\n\nelasticsearch.fielddata.size(gauge)\nThe size of the fielddata cache.shown as byte\n\n\n\n\nelasticsearch.flush.total(gauge)\nThe total number of index flushes to disk since start.shown as flush\n\n\n\n\nelasticsearch.flush.total.time(gauge)\nThe total time spent flushing the index to disk.shown as second\n\n\n\n\nelasticsearch.fs.total.available_in_bytes(gauge)\nThe total number of bytes available to this Java virtual machine on this file store.shown as byte\n\n\n\n\nelasticsearch.fs.total.disk_io_op(gauge)\nThe total I/O operations on the file store.shown as operation\n\n\n\n\nelasticsearch.fs.total.disk_io_size_in_bytes(gauge)\nTotal bytes used for all I/O operations on the file store.shown as byte\n\n\n\n\nelasticsearch.fs.total.disk_read_size_in_bytes(gauge)\nThe total bytes read from the file store.shown as byte\n\n\n\n\nelasticsearch.fs.total.disk_reads(gauge)\nThe total number of reads from the file store.shown as read\n\n\n\n\nelasticsearch.fs.total.disk_write_size_in_bytes(gauge)\nThe total bytes written to the file store.shown as byte\n\n\n\n\nelasticsearch.fs.total.disk_writes(gauge)\nThe total number of writes to the file store.shown as write\n\n\n\n\nelasticsearch.fs.total.free_in_bytes(gauge)\nThe total number of unallocated bytes in the file store.shown as byte\n\n\n\n\nelasticsearch.fs.total.total_in_bytes(gauge)\nThe total size in bytes of the file store.shown as byte\n\n\n\n\nelasticsearch.get.current(gauge)\nThe number of get requests currently running.shown as request\n\n\n\n\nelasticsearch.get.exists.time(gauge)\nThe total time spent on get requests where the document existed.shown as second\n\n\n\n\nelasticsearch.get.exists.total(gauge)\nThe total number of get requests where the document existed.shown as request\n\n\n\n\nelasticsearch.get.missing.time(gauge)\nThe total time spent on get requests where the document was missing.shown as second\n\n\n\n\nelasticsearch.get.missing.total(gauge)\nThe total number of get requests where the document was missing.shown as request\n\n\n\n\nelasticsearch.get.time(gauge)\nThe total time spent on get requests.shown as second\n\n\n\n\nelasticsearch.get.total(gauge)\nThe total number of get requests.shown as request\n\n\n\n\nelasticsearch.http.current_open(gauge)\nThe number of current open HTTP connections.shown as connection\n\n\n\n\nelasticsearch.http.total_opened(gauge)\nThe total number of opened HTTP connections.shown as connection\n\n\n\n\nelasticsearch.id_cache.size(gauge)\nThe size of the id cacheshown as byte\n\n\n\n\nelasticsearch.indexing.delete.current(gauge)\nThe number of documents currently being deleted from an index.shown as document\n\n\n\n\nelasticsearch.indexing.delete.time(gauge)\nThe total time spent deleting documents from an index.shown as second\n\n\n\n\nelasticsearch.indexing.delete.total(gauge)\nThe total number of documents deleted from an index.shown as document\n\n\n\n\nelasticsearch.indexing.index.current(gauge)\nThe number of documents currently being indexed to an index.shown as document\n\n\n\n\nelasticsearch.indexing.index.time(gauge)\nThe total time spent indexing documents to an index.shown as second\n\n\n\n\nelasticsearch.indexing.index.total(gauge)\nThe total number of documents indexed to an index.shown as document\n\n\n\n\nelasticsearch.indices.indexing.index_failed(gauge)\nThe number of failed indexing operations.\n\n\n\n\nelasticsearch.indices.indexing.throttle_time(gauge)\nThe total time indexing waited due to throttling.shown as millisecond\n\n\n\n\nelasticsearch.indices.query_cache.evictions(gauge)\nThe number of query cache evictions.shown as eviction\n\n\n\n\nelasticsearch.indices.query_cache.hit_count(gauge)\nThe number of query cache hits.shown as hit\n\n\n\n\nelasticsearch.indices.query_cache.memory_size_in_bytes(gauge)\nThe memory used by the query cache.shown as byte\n\n\n\n\nelasticsearch.indices.query_cache.miss_count(gauge)\nThe number of query cache misses.shown as miss\n\n\n\n\nelasticsearch.indices.recovery.current_as_source(gauge)\nThe number of ongoing recoveries for which a shard serves as a source.\n\n\n\n\nelasticsearch.indices.recovery.current_as_target(gauge)\nThe number of ongoing recoveries for which a shard serves as a target.\n\n\n\n\nelasticsearch.indices.recovery.throttle_time(gauge)\nThe total time recoveries waited due to throttling.shown as millisecond\n\n\n\n\nelasticsearch.indices.request_cache.evictions(gauge)\nThe number of request cache evictions.shown as eviction\n\n\n\n\nelasticsearch.indices.request_cache.hit_count(gauge)\nThe number of request cache hits.shown as hit\n\n\n\n\nelasticsearch.indices.request_cache.memory_size_in_bytes(gauge)\nThe memory used by the request cache.shown as byte\n\n\n\n\nelasticsearch.indices.request_cache.miss_count(gauge)\nThe number of request cache misses.shown as miss\n\n\n\n\nelasticsearch.indices.segments.count(gauge)\nThe number of segments in an index shard.shown as segment\n\n\n\n\nelasticsearch.indices.segments.doc_values_memory_in_bytes(gauge)\nThe memory used by doc values.shown as byte\n\n\n\n\nelasticsearch.indices.segments.fixed_bit_set_memory_in_bytes(gauge)\nThe memory used by fixed bit set.shown as byte\n\n\n\n\nelasticsearch.indices.segments.index_writer_max_memory_in_bytes(gauge)\nThe maximum memory used by the index writer.shown as byte\n\n\n\n\nelasticsearch.indices.segments.index_writer_memory_in_bytes(gauge)\nThe memory used by the index writer.shown as byte\n\n\n\n\nelasticsearch.indices.segments.memory_in_bytes(gauge)\nThe memory used by index segments.shown as byte\n\n\n\n\nelasticsearch.indices.segments.norms_memory_in_bytes(gauge)\nThe memory used by norms.shown as byte\n\n\n\n\nelasticsearch.indices.segments.stored_fields_memory_in_bytes(gauge)\nThe memory used by stored fields.shown as byte\n\n\n\n\nelasticsearch.indices.segments.term_vectors_memory_in_bytes(gauge)\nThe memory used by term vectors.shown as byte\n\n\n\n\nelasticsearch.indices.segments.terms_memory_in_bytes(gauge)\nThe memory used by terms.shown as byte\n\n\n\n\nelasticsearch.indices.segments.version_map_memory_in_bytes(gauge)\nThe memory used by the segment version map.shown as byte\n\n\n\n\nelasticsearch.indices.translog.operations(gauge)\nThe number of operations in the transaction log.shown as operation\n\n\n\n\nelasticsearch.indices.translog.size_in_bytes(gauge)\nThe size of the transaction log.shown as byte\n\n\n\n\nelasticsearch.initializing_shards(gauge)\nThe number of shards that are currently initializing.shown as shard\n\n\n\n\nelasticsearch.merges.current(gauge)\nThe number of currently active segment merges.shown as merge\n\n\n\n\nelasticsearch.merges.current.docs(gauge)\nThe number of documents across segments currently being merged.shown as document\n\n\n\n\nelasticsearch.merges.current.size(gauge)\nThe size of the segments currently being merged.shown as byte\n\n\n\n\nelasticsearch.merges.total(gauge)\nThe total number of segment merges.shown as merge\n\n\n\n\nelasticsearch.merges.total.docs(gauge)\nThe total number of documents across all merged segments.shown as document\n\n\n\n\nelasticsearch.merges.total.size(gauge)\nThe total size of all merged segments.shown as byte\n\n\n\n\nelasticsearch.merges.total.time(gauge)\nThe total time spent on segment merging.shown as second\n\n\n\n\nelasticsearch.number_of_data_nodes(gauge)\nThe number of data nodes in the cluster.shown as node\n\n\n\n\nelasticsearch.number_of_nodes(gauge)\nThe total number of nodes in the cluster.shown as node\n\n\n\n\nelasticsearch.pending_tasks_priority_high(gauge)\nThe number of high priority pending tasks.shown as task\n\n\n\n\nelasticsearch.pending_tasks_priority_urgent(gauge)\nThe number of urgent priority pending tasks.shown as task\n\n\n\n\nelasticsearch.pending_tasks_total(gauge)\nThe total number of pending tasks.shown as task\n\n\n\n\nelasticsearch.primaries.docs.count(gauge)\nThe total number of documents in the primary shards.shown as document\n\n\n\n\nelasticsearch.primaries.docs.deleted(gauge)\nThe total number of documents deleted from the primary shards.shown as document\n\n\n\n\nelasticsearch.primaries.flush.total(gauge)\nThe total number of index flushes to disk from the primary shards since start.shown as flush\n\n\n\n\nelasticsearch.primaries.flush.total.time(gauge)\nThe total time spent flushing the index to disk from the primary shards.shown as second\n\n\n\n\nelasticsearch.primaries.get.current(gauge)\nThe number of get requests currently running on the primary shards.shown as request\n\n\n\n\nelasticsearch.primaries.get.exists.time(gauge)\nThe total time spent on get requests from the primary shards where the document existed.shown as request\n\n\n\n\nelasticsearch.primaries.get.exists.total(gauge)\nThe total number of get requests on primary shards where the document existed.shown as request\n\n\n\n\nelasticsearch.primaries.get.missing.time(gauge)\nThe total time spent on get requests from the primary shards where the document was missing.shown as second\n\n\n\n\nelasticsearch.primaries.get.missing.total(gauge)\nThe total number of get requests from the primary shards where the document was missing.shown as request\n\n\n\n\nelasticsearch.primaries.get.time(gauge)\nThe total time spent on get requests from the primary shards.shown as second\n\n\n\n\nelasticsearch.primaries.get.total(gauge)\nThe total number of get requests from the primary shards.shown as request\n\n\n\n\nelasticsearch.primaries.indexing.delete.current(gauge)\nThe number of documents currently being deleted from an index on the primary shards.shown as document\n\n\n\n\nelasticsearch.primaries.indexing.delete.time(gauge)\nThe total time spent deleting documents from an index on the primary shards.shown as second\n\n\n\n\nelasticsearch.primaries.indexing.delete.total(gauge)\nThe total number of documents deleted from an index on the primary shards.shown as document\n\n\n\n\nelasticsearch.primaries.indexing.index.current(gauge)\nThe number of documents currently being indexed to an index on the primary shards.shown as document\n\n\n\n\nelasticsearch.primaries.indexing.index.time(gauge)\nThe total time spent indexing documents to an index on the primary shards.shown as second\n\n\n\n\nelasticsearch.primaries.indexing.index.total(gauge)\nThe total number of documents indexed to an index on the primary shards.shown as document\n\n\n\n\nelasticsearch.primaries.merges.current(gauge)\nThe number of currently active segment merges on the primary shards.shown as merge\n\n\n\n\nelasticsearch.primaries.merges.current.docs(gauge)\nThe number of documents across segments currently being merged on the primary shards.shown as document\n\n\n\n\nelasticsearch.primaries.merges.current.size(gauge)\nThe size of the segments currently being merged on the primary shards.shown as byte\n\n\n\n\nelasticsearch.primaries.merges.total(gauge)\nThe total number of segment merges on the primary shards.shown as merge\n\n\n\n\nelasticsearch.primaries.merges.total.docs(gauge)\nThe total number of documents across all merged segments on the primary shards.shown as document\n\n\n\n\nelasticsearch.primaries.merges.total.size(gauge)\nThe total size of all merged segments on the primary shards.shown as byte\n\n\n\n\nelasticsearch.primaries.merges.total.time(gauge)\nThe total time spent on segment merging on the primary shards.shown as second\n\n\n\n\nelasticsearch.primaries.refresh.total(gauge)\nThe total number of index refreshes on the primary shards.shown as refresh\n\n\n\n\nelasticsearch.primaries.refresh.total.time(gauge)\nThe total time spent on index refreshes on the primary shards.shown as second\n\n\n\n\nelasticsearch.primaries.search.fetch.current(gauge)\nThe number of query fetches currently running on the primary shards.shown as fetch\n\n\n\n\nelasticsearch.primaries.search.fetch.time(gauge)\nThe total time spent on query fetches on the primary shards.shown as second\n\n\n\n\nelasticsearch.primaries.search.fetch.total(gauge)\nThe total number of query fetches on the primary shards.shown as fetch\n\n\n\n\nelasticsearch.primaries.search.query.current(gauge)\nThe number of currently active queries on the primary shards.shown as query\n\n\n\n\nelasticsearch.primaries.search.query.time(gauge)\nThe total time spent querying on the primary shards.shown as second\n\n\n\n\nelasticsearch.primaries.search.query.total(gauge)\nThe total number of queries to the primary shards.shown as query\n\n\n\n\nelasticsearch.primaries.store.size(gauge)\nThe total size of all the primary shards.shown as byte\n\n\n\n\nelasticsearch.process.open_fd(gauge)\nThe number of opened file descriptors associated with the current process, or -1 if not supported.shown as file\n\n\n\n\nelasticsearch.refresh.total(gauge)\nThe total number of index refreshes.shown as refresh\n\n\n\n\nelasticsearch.refresh.total.time(gauge)\nThe total time spent on index refreshes.shown as second\n\n\n\n\nelasticsearch.relocating_shards(gauge)\nThe number of shards that are reloacting from one node to another.shown as shard\n\n\n\n\nelasticsearch.search.fetch.current(gauge)\nThe number of search fetches currently running.shown as fetch\n\n\n\n\nelasticsearch.search.fetch.open_contexts(gauge)\nThe number of active searches.shown as query\n\n\n\n\nelasticsearch.search.fetch.time(gauge)\nThe total time spent on the search fetch.shown as second\n\n\n\n\nelasticsearch.search.fetch.total(gauge)\nThe total number of search fetches.shown as fetch\n\n\n\n\nelasticsearch.search.query.current(gauge)\nThe number of currently active queries.shown as query\n\n\n\n\nelasticsearch.search.query.time(gauge)\nThe total time spent on queries.shown as second\n\n\n\n\nelasticsearch.search.query.total(gauge)\nThe total number of queries.shown as query\n\n\n\n\nelasticsearch.store.size(gauge)\nThe total size in bytes of the store.shown as byte\n\n\n\n\nelasticsearch.thread_pool.bulk.active(gauge)\nThe number of active threads in the bulk pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.bulk.queue(gauge)\nThe number of queued threads in the bulk pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.bulk.threads(gauge)\nThe total number of threads in the bulk pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.bulk.rejected(gauge)\nThe number of rejected threads in the bulk pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.fetch_shard_started.active(gauge)\nThe number of active threads in the fetch shard started pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.fetch_shard_started.threads(gauge)\nThe total number of threads in the fetch shard started pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.fetch_shard_started.queue(gauge)\nThe number of queued threads in the fetch shard started pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.fetch_shard_started.rejected(gauge)\nThe number of rejected threads in the fetch shard started pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.fetch_shard_store.active(gauge)\nThe number of active threads in the fetch shard store pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.fetch_shard_store.threads(gauge)\nThe total number of threads in the fetch shard store pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.fetch_shard_store.queue(gauge)\nThe number of queued threads in the fetch shard store pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.fetch_shard_store.rejected(gauge)\nThe number of rejected threads in the fetch shard store pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.flush.active(gauge)\nThe number of active threads in the flush queue.shown as thread\n\n\n\n\nelasticsearch.thread_pool.flush.queue(gauge)\nThe number of queued threads in the flush pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.flush.threads(gauge)\nThe total number of threads in the flush pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.flush.rejected(gauge)\nThe number of rejected threads in the flush pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.force_merge.active(gauge)\nThe number of active threads for force merge operations.shown as thread\n\n\n\n\nelasticsearch.thread_pool.force_merge.threads(gauge)\nThe total number of threads for force merge operations.shown as thread\n\n\n\n\nelasticsearch.thread_pool.force_merge.queue(gauge)\nThe number of queued threads for force merge operations.shown as thread\n\n\n\n\nelasticsearch.thread_pool.force_merge.rejected(gauge)\nThe number of rejected threads for force merge operations.shown as thread\n\n\n\n\nelasticsearch.thread_pool.generic.active(gauge)\nThe number of active threads in the generic pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.generic.queue(gauge)\nThe number of queued threads in the generic pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.generic.threads(gauge)\nThe total number of threads in the generic pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.generic.rejected(gauge)\nThe number of rejected threads in the generic pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.get.active(gauge)\nThe number of active threads in the get pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.get.queue(gauge)\nThe number of queued threads in the get pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.get.threads(gauge)\nThe total number of threads in the get pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.get.rejected(gauge)\nThe number of rejected threads in the get pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.index.active(gauge)\nThe number of active threads in the index pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.index.queue(gauge)\nThe number of queued threads in the index pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.index.threads(gauge)\nThe total number of threads in the index pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.index.rejected(gauge)\nThe number of rejected threads in the index pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.listener.active(gauge)\nThe number of active threads in the listener pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.listener.queue(gauge)\nThe number of queued threads in the listener pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.listener.threads(gauge)\nThe total number of threads in the listener pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.listener.rejected(gauge)\nThe number of rejected threads in the listener pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.management.active(gauge)\nThe number of active threads in the management pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.management.queue(gauge)\nThe number of queued threads in the management pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.management.threads(gauge)\nThe total number of threads in the management pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.management.rejected(gauge)\nThe number of rejected threads in the management pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.merge.active(gauge)\nThe number of active threads in the merge pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.merge.queue(gauge)\nThe number of queued threads in the merge pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.merge.threads(gauge)\nThe total number of threads in the merge pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.merge.rejected(gauge)\nThe number of rejected threads in the merge pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.percolate.active(gauge)\nThe number of active threads in the percolate pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.percolate.queue(gauge)\nThe number of queued threads in the percolate pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.percolate.threads(gauge)\nThe total number of threads in the percolate pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.percolate.rejected(gauge)\nThe number of rejected threads in the percolate pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.refresh.active(gauge)\nThe number of active threads in the refresh pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.refresh.queue(gauge)\nThe number of queued threads in the refresh pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.refresh.threads(gauge)\nThe total number of threads in the refresh pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.refresh.rejected(gauge)\nThe number of rejected threads in the refresh pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.search.active(gauge)\nThe number of active threads in the search pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.search.queue(gauge)\nThe number of queued threads in the search pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.search.threads(gauge)\nThe total number of threads in the search pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.search.rejected(gauge)\nThe number of rejected threads in the search pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.snapshot.active(gauge)\nThe number of active threads in the snapshot pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.snapshot.queue(gauge)\nThe number of queued threads in the snapshot pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.snapshot.threads(gauge)\nThe total number of threads in the snapshot pool.shown as thread\n\n\n\n\nelasticsearch.thread_pool.snapshot.rejected(gauge)\nThe number of rejected threads in the snapshot pool.shown as thread\n\n\n\n\nelasticsearch.transport.rx_count(gauge)\nThe total number of packets received in cluster communication.shown as packet\n\n\n\n\nelasticsearch.transport.rx_size(gauge)\nThe total size of data received in cluster communication.shown as byte\n\n\n\n\nelasticsearch.transport.server_open(gauge)\nThe number of connections opened for cluster communication.shown as connection\n\n\n\n\nelasticsearch.transport.tx_count(gauge)\nThe total number of packets sent in cluster communication.shown as packet\n\n\n\n\nelasticsearch.transport.tx_size(gauge)\nThe total size of data sent in cluster communication.shown as byte\n\n\n\n\nelasticsearch.unassigned_shards(gauge)\nThe number of shards that are unassigned to a node.shown as shard\n\n\n\n\njvm.gc.collection_count(gauge)\nThe total number of garbage collections run by the JVM.shown as garbage collection\n\n\n\n\njvm.gc.collection_time(gauge)\nThe total time spent on garbage collection in the JVM.shown as second\n\n\n\n\njvm.gc.collectors.old.collection_time(gauge)\nThe total time spent in major GCs in the JVM that collect old generation objects.shown as second\n\n\n\n\njvm.gc.collectors.old.count(gauge)\nThe total count of major GCs in the JVM that collect old generation objects.shown as garbage collection\n\n\n\n\njvm.gc.collectors.young.collection_time(gauge)\nThe total time spent in minor GCs in the JVM that collects young generation objects.shown as second\n\n\n\n\njvm.gc.collectors.young.count(gauge)\nThe total count of minor GCs in the JVM that collects young generation objects.shown as garbage collection\n\n\n\n\njvm.gc.concurrent_mark_sweep.collection_time(gauge)\nThe total time spent on \"concurrent mark & sweep\" GCs in the JVM.shown as second\n\n\n\n\njvm.gc.concurrent_mark_sweep.count(gauge)\nThe total count of \"concurrent mark & sweep\" GCs in the JVM.shown as garbage collection\n\n\n\n\njvm.gc.par_new.collection_time(gauge)\nThe total time spent on \"parallel new\" GCs in the JVM.shown as second\n\n\n\n\njvm.gc.par_new.count(gauge)\nThe total count of \"parallel new\" GCs in the JVM.shown as garbage collection\n\n\n\n\njvm.mem.heap_committed(gauge)\nThe amount of memory guaranteed to be available to the JVM heap.shown as byte\n\n\n\n\njvm.mem.heap_in_use(gauge)\nThe amount of memory currently used by the JVM heap as a value between 0 and 1.\n\n\n\n\njvm.mem.heap_max(gauge)\nThe maximum amount of memory that can be used by the JVM heap.shown as byte\n\n\n\n\njvm.mem.heap_used(gauge)\nThe amount of memory in bytes currently used by the JVM heap.shown as byte\n\n\n\n\njvm.mem.non_heap_committed(gauge)\nThe amount of memory guaranteed to be available to JVM non-heap.shown as byte\n\n\n\n\njvm.mem.non_heap_used(gauge)\nThe amount of memory in bytes currently used by the JVM non-heap.shown as byte\n\n\n\n\njvm.threads.count(gauge)\nThe number of active threads in the JVM.shown as thread\n\n\n\n\njvm.threads.peak_count(gauge)\nThe peak number of threads used by the JVM.shown as thread\n\n\n\n\n","tags":"","loc":"/integrations/elasticsearch/"},{"title":"Datadog-etcd Integration","text":"\n\nOverview\n\nCapture etcd metrics in Datadog to:\n\n\n  Monitor the health of your etcd cluster.\n  Know when host configurations may be out of sync.\n  Correlate the performance of etcd with the rest of your applications.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\netcd YAML example\netcd checks.d\n\n\n\nMetrics\n\n\n\n\netcd.store.gets.success(gauge)\nRate of successful get requestsshown as request/second\n\n\n\n\netcd.store.gets.fail(gauge)\nRate of failed get requestsshown as request/second\n\n\n\n\netcd.store.sets.success(gauge)\nRate of successful set requestsshown as request/second\n\n\n\n\netcd.store.sets.fail(gauge)\nRate of failed set requestsshown as request/second\n\n\n\n\netcd.store.delete.success(gauge)\nRate of successful delete requestsshown as request/second\n\n\n\n\netcd.store.delete.fail(gauge)\nRate of failed delete requestsshown as request/second\n\n\n\n\netcd.store.update.success(gauge)\nRate of successful update requestsshown as request/second\n\n\n\n\netcd.store.update.fail(gauge)\nRate of failed update requestsshown as request/second\n\n\n\n\netcd.store.create.success(gauge)\nRate of successful create requestsshown as request/second\n\n\n\n\netcd.store.create.fail(gauge)\nRate of failed create requestsshown as request/second\n\n\n\n\netcd.store.compareandswap.success(gauge)\nRate of compare and swap requests successshown as request/second\n\n\n\n\netcd.store.compareandswap.fail(gauge)\nRate of compare and swap requests failureshown as request/second\n\n\n\n\netcd.store.compareanddelete.success(gauge)\nRate of compare and delete requests successshown as request/second\n\n\n\n\netcd.store.compareanddelete.fail(gauge)\nRate of compare and delete requests failureshown as request/second\n\n\n\n\netcd.store.expire.count(gauge)\nRate of expired keysshown as eviction/second\n\n\n\n\netcd.store.watchers(gauge)\nRate of watchers\n\n\n\n\netcd.self.send.pkgrate(gauge)\nRate of packets receivedshown as packet/second\n\n\n\n\netcd.self.send.bandwidthrate(gauge)\nRate of bytes receivedshown as byte/second\n\n\n\n\netcd.self.recv.pkgrate(gauge)\nRate of packets sentshown as packet/second\n\n\n\n\netcd.self.recv.bandwidthrate(gauge)\nRate of bytes sentshown as byte/second\n\n\n\n\netcd.self.recv.appendrequest.count(gauge)\nRate of append requests this node has processedshown as request/second\n\n\n\n\netcd.self.send.appendrequest.count(gauge)\nRate of append requests this node has sentshown as request/second\n\n\n\n\netcd.leader.counts.fail(gauge)\nRate of failed Raft RPC requestsshown as request/second\n\n\n\n\netcd.leader.counts.success(gauge)\nRate of successful Raft RPC requestsshown as request/second\n\n\n\n\netcd.leader.latency.current(gauge)\nCurrent latency to each peer in the clustershown as millisecond\n\n\n\n\netcd.leader.latency.avg(gauge)\nAverage latency to each peer in the clustershown as millisecond\n\n\n\n\netcd.leader.latency.min(gauge)\nMinimum latency to each peer in the clustershown as millisecond\n\n\n\n\netcd.leader.latency.max(gauge)\nMaximum latency to each peer in the clustershown as millisecond\n\n\n\n\netcd.leader.latency.stddev(gauge)\nStandard deviation latency to each peer in the clustershown as millisecond\n\n\n\n\nFurthermore, etcd metrics are tagged with etcd_state:leader or etcd_state:follower, depending on the node status, so you can easily aggregate metrics by status.\n","tags":"","loc":"/integrations/etcd/"},{"title":"Datadog-Event Viewer Integration","text":"\n\nOverview\n\nConnect Event Viewer to Datadog in order to:\n\n\n  Track system and application events in Datadog.\n  Correlate system and application events with the rest of your application.\n\n\n\nConfiguration\n\nUse the Windows Event Viewer GUI to list all the event logs you can capture with this integration.\n\nTo determine the exact values you can set your filters to, use the following PowerShell\ncommand:\n\nGet-WmiObject -Class Win32_NTLogEvent\n\n\nFor instance, to see the latest event logged in the Security LogFile, use:\n\nGet-WmiObject -Class Win32_NTLogEvent -Filter \"LogFile='Security'\" | select -First 1\n\n\nThe values listed in the output of the command are the ones you can set in win32_event_log.yaml\nto capture the same kind of events.\n\nNote: the information given by the Get-EventLog PowerShell command or the Windows Event Viewer\nGUI may slightly differ from Get-WmiObject, so we recommend you to double-check your filters’ values\nwith Get-WmiObject if the integration does not capture the events you set up.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nEvent Viewer YAML example\nEvent Viewer checks.d\n\n\n","tags":"","loc":"/integrations/eventviewer/"},{"title":"Datadog-ExpressJS Integration","text":"\nAdd the connect-datadog middleware to your application to:\n\n\n  Alert on your response times\n  Monitor your response code\n\n\n\nMetrics\n\n\n\n\nnode.express.router.response_code.100(rate every 10 seconds)\nThe rate of requests that generate responses with a 100 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.101(rate every 10 seconds)\nThe rate of requests that generate responses with a 101 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.102(rate every 10 seconds)\nThe rate of requests that generate responses with a 102 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.200(rate every 10 seconds)\nThe rate of requests that generate responses with a 200 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.201(rate every 10 seconds)\nThe rate of requests that generate responses with a 201 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.202(rate every 10 seconds)\nThe rate of requests that generate responses with a 202 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.203(rate every 10 seconds)\nThe rate of requests that generate responses with a 203 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.204(rate every 10 seconds)\nThe rate of requests that generate responses with a 204 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.205(rate every 10 seconds)\nThe rate of requests that generate responses with a 205 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.206(rate every 10 seconds)\nThe rate of requests that generate responses with a 206 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.207(rate every 10 seconds)\nThe rate of requests that generate responses with a 207 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.208(rate every 10 seconds)\nThe rate of requests that generate responses with a 208 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.226(rate every 10 seconds)\nThe rate of requests that generate responses with a 226 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.300(rate every 10 seconds)\nThe rate of requests that generate responses with a 300 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.301(rate every 10 seconds)\nThe rate of requests that generate responses with a 301 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.302(rate every 10 seconds)\nThe rate of requests that generate responses with a 302 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.303(rate every 10 seconds)\nThe rate of requests that generate responses with a 303 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.304(rate every 10 seconds)\nThe rate of requests that generate responses with a 304 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.305(rate every 10 seconds)\nThe rate of requests that generate responses with a 305 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.306(rate every 10 seconds)\nThe rate of requests that generate responses with a 306 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.307(rate every 10 seconds)\nThe rate of requests that generate responses with a 307 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.308(rate every 10 seconds)\nThe rate of requests that generate responses with a 308 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.400(rate every 10 seconds)\nThe rate of requests that generate responses with a 400 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.401(rate every 10 seconds)\nThe rate of requests that generate responses with a 401 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.402(rate every 10 seconds)\nThe rate of requests that generate responses with a 402 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.403(rate every 10 seconds)\nThe rate of requests that generate responses with a 403 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.404(rate every 10 seconds)\nThe rate of requests that generate responses with a 404 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.405(rate every 10 seconds)\nThe rate of requests that generate responses with a 405 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.406(rate every 10 seconds)\nThe rate of requests that generate responses with a 406 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.407(rate every 10 seconds)\nThe rate of requests that generate responses with a 407 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.408(rate every 10 seconds)\nThe rate of requests that generate responses with a 408 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.409(rate every 10 seconds)\nThe rate of requests that generate responses with a 409 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.410(rate every 10 seconds)\nThe rate of requests that generate responses with a 410 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.411(rate every 10 seconds)\nThe rate of requests that generate responses with a 411 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.412(rate every 10 seconds)\nThe rate of requests that generate responses with a 412 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.413(rate every 10 seconds)\nThe rate of requests that generate responses with a 413 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.414(rate every 10 seconds)\nThe rate of requests that generate responses with a 414 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.415(rate every 10 seconds)\nThe rate of requests that generate responses with a 415 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.416(rate every 10 seconds)\nThe rate of requests that generate responses with a 416 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.417(rate every 10 seconds)\nThe rate of requests that generate responses with a 417 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.421(rate every 10 seconds)\nThe rate of requests that generate responses with a 421 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.422(rate every 10 seconds)\nThe rate of requests that generate responses with a 422 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.423(rate every 10 seconds)\nThe rate of requests that generate responses with a 423 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.424(rate every 10 seconds)\nThe rate of requests that generate responses with a 424 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.425(rate every 10 seconds)\nThe rate of requests that generate responses with a 425 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.426(rate every 10 seconds)\nThe rate of requests that generate responses with a 426 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.428(rate every 10 seconds)\nThe rate of requests that generate responses with a 428 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.429(rate every 10 seconds)\nThe rate of requests that generate responses with a 429 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.431(rate every 10 seconds)\nThe rate of requests that generate responses with a 431 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.451(rate every 10 seconds)\nThe rate of requests that generate responses with a 451 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.500(rate every 10 seconds)\nThe rate of requests that generate responses with a 500 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.501(rate every 10 seconds)\nThe rate of requests that generate responses with a 501 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.502(rate every 10 seconds)\nThe rate of requests that generate responses with a 502 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.503(rate every 10 seconds)\nThe rate of requests that generate responses with a 503 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.504(rate every 10 seconds)\nThe rate of requests that generate responses with a 504 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.505(rate every 10 seconds)\nThe rate of requests that generate responses with a 505 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.506(rate every 10 seconds)\nThe rate of requests that generate responses with a 506 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.507(rate every 10 seconds)\nThe rate of requests that generate responses with a 507 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.508(rate every 10 seconds)\nThe rate of requests that generate responses with a 508 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.510(rate every 10 seconds)\nThe rate of requests that generate responses with a 510 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.511(rate every 10 seconds)\nThe rate of requests that generate responses with a 511 status code.shown as response/second\n\n\n\n\nnode.express.router.response_code.all(rate every 10 seconds)\nThe rate of all requests that receive a response.shown as response/second\n\n\n\n\nnode.express.router.response_time.95percentile(gauge every 10 seconds)\nThe 95th percentile of response time.shown as millisecond\n\n\n\n\nnode.express.router.response_time.avg(gauge every 10 seconds)\nThe average response time.shown as millisecond\n\n\n\n\nnode.express.router.response_time.count(rate every 10 seconds)\nThe rate of responses received.shown as response/second\n\n\n\n\nnode.express.router.response_time.max(gauge every 10 seconds)\nThe maximum response time.shown as millisecond\n\n\n\n\nnode.express.router.response_time.median(gauge every 10 seconds)\nThe median response time.shown as millisecond\n\n\n\n","tags":"","loc":"/integrations/expressjs/"},{"title":"Datadog-Fabric Integration","text":"\n\nOverview\n\nConnect Fabric to Datadog in order to:\n\n\n  Capture and search for deploy events in the event stream.\n  Correlate deploy events with metric changes on dashboards.\n\n\n","tags":"","loc":"/integrations/fabric/"},{"title":"Datadog-Fastly Integration","text":"\n\nOverview\n\n\n\nConnect to Fastly to see key Fastly metrics (like cache coverage and header size) in context with the rest of your Datadog metrics.\n\n\nInstallation\n\nNo installation steps required.\n\n\nConfiguration\n\nCreate a Read-only access API Token on Fastly’s token management page, get your Service ID from the Dashboard and enter them in the Fastly integration tile.\n\nNote: The ServiceID is the alphanumerical code, e.g. 5VqE6MOOy1QFJbgmCK41pY (example from https://docs.fastly.com/api/auth).\n\nIf using multiple Service IDs from one account, please enter an API token on each line.\n\n\nMetrics\n\n\n\n\nfastly.attack_block(gauge every 60 seconds)\n\n\n\n\nfastly.attack_body_size(gauge every 60 seconds)\n\nshown as byte\n\n\n\n\nfastly.attack_header_size(gauge every 60 seconds)\n\nshown as byte\n\n\n\n\nfastly.attack_synth(gauge every 60 seconds)\n\n\n\n\nfastly.bandwidth(gauge every 60 seconds)\nBandwidth sent.shown as byte/minute\n\n\n\n\nfastly.body_size(gauge every 60 seconds)\nRequest body bandwidth sent.shown as byte/minute\n\n\n\n\nfastly.errors(gauge every 60 seconds)\nNumber of Errors.shown as request/minute\n\n\n\n\nfastly.header_size(gauge every 60 seconds)\nRequest header bandwidth sent.shown as byte/minute\n\n\n\n\nfastly.hit_ratio(gauge every 60 seconds)\nRatio of cache hits to cache misses.shown as percent\n\n\n\n\nfastly.hits(gauge every 60 seconds)\nNumber of cache hits.shown as request/minute\n\n\n\n\nfastly.hits_time(gauge every 60 seconds)\nAmount of time spent processing cache hits.shown as millisecond\n\n\n\n\nfastly.miss(gauge every 60 seconds)\nNumber of cache misses.shown as request/minute\n\n\n\n\nfastly.miss_time(gauge every 60 seconds)\nAmount of time spent processing cache misses.shown as millisecond\n\n\n\n\nfastly.pass(gauge every 60 seconds)\nNumber of requests passed through the CDN without being cached.shown as request/minute\n\n\n\n\nfastly.pipe(gauge every 60 seconds)\nNumber of pipe operations performed.shown as operation/minute\n\n\n\n\nfastly.requests(gauge every 60 seconds)\nNumber of Requests Processed.shown as request/minute\n\n\n\n\nfastly.status_1xx(gauge every 60 seconds)\nNumber of responses sent with an Informational status code.shown as response/minute\n\n\n\n\nfastly.status_200(gauge every 60 seconds)\nNumber of responses sent with status code 200 (Success).shown as response/minute\n\n\n\n\nfastly.status_204(gauge every 60 seconds)\nNumber of responses sent with status code 204 (No Content).shown as response/minute\n\n\n\n\nfastly.status_2xx(gauge every 60 seconds)\nNumber of responses sent with a Success status code.shown as response/minute\n\n\n\n\nfastly.status_301(gauge every 60 seconds)\nNumber of responses sent with status code 301 (Moved Permanently).shown as response/minute\n\n\n\n\nfastly.status_302(gauge every 60 seconds)\nNumber of responses sent with status code 302 (Found).shown as response/minute\n\n\n\n\nfastly.status_304(gauge every 60 seconds)\nNumber of responses sent with status code 304 (Not Modified).shown as response/minute\n\n\n\n\nfastly.status_3xx(gauge every 60 seconds)\nNumber of responses sent with a Redirection status code.shown as response/minute\n\n\n\n\nfastly.status_4xx(gauge every 60 seconds)\nNumber of responses sent with a Client Error status code.shown as response/minute\n\n\n\n\nfastly.status_503(gauge every 60 seconds)\nNumber of responses sent with status code 503 (Service Unavailable).shown as response/minute\n\n\n\n\nfastly.status_5xx(gauge every 60 seconds)\nNumber of responses sent with a Server Error status code.shown as response/minute\n\n\n\n\nfastly.synth(gauge every 60 seconds)\n\n\n\n\nfastly.uncacheable(gauge every 60 seconds)\nNumber of requests that were denoted uncachable.shown as request\n\n\n\n","tags":"","loc":"/integrations/fastly/"},{"title":"Datadog-Flowdock Integration","text":"\nIntegrate with FlowDock to:\n\n\n  be notified when someone posts on your stream\n  get monitor alerts, integration status changes (and much more) directly in your flows\n\n\nDatadog takes advantage on Flowdock’s Threads to avoid polluting your flows with notifications: for a given flow, every notification will go in it’s own Thread, further related notifications will go in that same thread (for instance if a given monitor alert is triggered and then resolved, the corresponding notifications will be grouped in Flowdock).\n\n\nHands-off integration\n\nIntegrating flowdock is really straightforward. You just have to log into Flowdock on the Configuration tab. It will fetch all your opened flows. If you don’t want to post to all of them, you can delete the ones you don’t want to appear in the autocomplete list. You can then use @flowdock handles in any user message or monitor to post messages to your flows.\n\nUser messages and snapshots will go in the main thread of your flow while each alert will be posted in its own Flowdock thread. It prevents the main thread from being overpolluted with alerts and keeps your team chat clean and organized. On the other hand, you always have an immediate glance at the statuses of the monitors which reported recently on the Inbox view.\n","tags":"","loc":"/integrations/flowdock/"},{"title":"Datadog-Fluentd Integration","text":"\n\nOverview\nGet metrics from Fluentd in real time to\n\n\n  Visualize Fluentd performance.\n  Correlate the performance of Fluentd with the rest of your applications.\n\n\n\n\n\nInstallation\n\nConfigure your fluentd to use a monitor agent and plugin id (see doc), for instance:\n\n<source>\n  type monitor_agent\n  bind 0.0.0.0\n  port 24220\n</source>\n<match test>\n  id   plg1\n  type forward\n  <server>\n    host localhost\n  </server>\n</match>\n\n<match **>\n  id   plg2\n  type forward\n  <server>\n    host localhost\n  </server>\n</match>\n\n\n\nConfiguration\n\nConfigure the Agent to connect to fluentd, and set the plugins id you want to monitor\nEdit conf.d/fluentd.yaml\n\ninit_config:\n\ninstances:\n    # For every instance, you have an `monitor_agent_url`\n    # and (optionally) a list of tags.\n    -  monitor_agent_url: http://example.com:24220/api/plugins.json\n       plugin_ids:\n         - plg1\n         - plg2\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nFluentd YAML example\nFluentd checks.d\n\n\n\nValidation\n\n\n  Restart the Agent\n  \n    Execute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\n    Checks\n======\n\n  [...]\n\n  fluentd\n  -------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n  \n\n\nNot sure how to execute the last two steps? Visit the Agent Usage Guide for more detailed instructions.\n\n\nMetrics\n\n\n\n\nfluentd.retry_count(gauge)\nThe number of retries for this plugin.shown as time\n\n\n\n\nfluentd.buffer_queue_length(gauge)\nThe length of the buffer queue for this plugin.shown as buffer\n\n\n\n\nfluentd.buffer_total_queued_size(gauge)\nThe size of the buffer queue for this plugin.shown as byte\n\n\n\n","tags":"","loc":"/integrations/fluentd/"},{"title":"Datadog-Gearman Integration","text":"\n\nOverview\n\nBring Gearman metrics to Datadog to:\n\n\n  Visualize Gearman performance.\n  Know how many tasks are queued or running.\n  Correlate the performance of Gearman with the rest of your applications.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nGearman YAML example\nGearman checks.d\n\n\n\nMetrics\n\n\n\n\ngearman.unique_tasks(gauge)\nThe number of all functions registered with Gearman.shown as task\n\n\n\n\ngearman.running(gauge)\nThe total number of running Gearman jobs.shown as task\n\n\n\n\ngearman.queued(gauge)\nThe total number of jobs in the queue.shown as task\n\n\n\n\ngearman.workers(gauge)\nThe total number of capable Gearman workers.shown as process\n\n\n\n\ngearman.running_by_task(gauge)\nThe number of running Gearman jobs by task.shown as task\n\n\n\n\ngearman.queued_by_task(gauge)\nThe number of jobs in the queue by task.shown as task\n\n\n\n\ngearman.workers_by_task(gauge)\nThe number of capable Gearman workers by task.shown as process\n\n\n\n","tags":"","loc":"/integrations/gearman/"},{"title":"Datadog-Git Integration","text":"\n\nOverview\n\nCapture Git commits directly from your Git server to:\n\n\n  Keep track of code changes in real time.\n  Add code change markers on all your dashboards.\n  Discuss code changes with your team.\n\n\n","tags":"","loc":"/integrations/git/"},{"title":"Datadog-Github Integration","text":"\n\nOverview\n\nCapture GitHub commits in Datadog to:\n\n\n  Track new features from code changes\n  Identify when new code changes lead to system alerts or build failures\n  Discuss code changes with your team in the Datadog Event Stream\n\n\n\nConfiguration\n\nSelect ‘Github’ on the account settings screen and link your account. You can then select which repos you would like to integrate, which branches, and if you’d like to receive commits and/or issues.\n\n\nWhat to Expect\n\nOnce the integration is complete, whatever you select (commits and/or issues) will populate into your Datadog Event Stream. If you view a dashboard, in the top left search bar you can type sources:github to see github events overlayed over your the graphs on that dashboard.\n\n","tags":"","loc":"/integrations/github/"},{"title":"Datadog-Go Expvar Integration","text":"\nUse the Datadog Expvar Agent check to:\n\n\n  Get information and monitor into your application memory usage\n  Instrument your own metrics\n  An example configration file for GO Expvar can be found here\n\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nGo Expvar YAML example\nGo Expvar checks.d\n\n\n\nMetrics\n\n\n\n\ngo_expvar.memstats.alloc(gauge)\nBytes allocated and not yet freedshown as byte\n\n\n\n\ngo_expvar.memstats.frees(gauge)\nNumber of freesshown as operation\n\n\n\n\ngo_expvar.memstats.heap_alloc(gauge)\nBytes allocated and not yet freedshown as byte\n\n\n\n\ngo_expvar.memstats.heap_idle(gauge)\nBytes in idle spansshown as byte\n\n\n\n\ngo_expvar.memstats.heap_inuse(gauge)\nBytes in non-idle spansshown as byte\n\n\n\n\ngo_expvar.memstats.heap_objects(gauge)\nTotal number of allocated objectsshown as item\n\n\n\n\ngo_expvar.memstats.heap_released(gauge)\nBytes released to the OSshown as byte\n\n\n\n\ngo_expvar.memstats.heap_sys(gauge)\nBytes obtained from systemshown as byte\n\n\n\n\ngo_expvar.memstats.lookups(gauge)\nNumber of pointer lookupsshown as operation\n\n\n\n\ngo_expvar.memstats.mallocs(gauge)\nNumber of mallocsshown as operation\n\n\n\n\ngo_expvar.memstats.num_gc(gauge)\nNumber of garbage collectionsshown as garbage collection\n\n\n\n\ngo_expvar.memstats.pause_ns.95percentile(gauge)\n95th percentile of recent GC pause durationsshown as nanosecond\n\n\n\n\ngo_expvar.memstats.pause_ns.avg(gauge)\nAverage of recent GC pause durationsshown as nanosecond\n\n\n\n\ngo_expvar.memstats.pause_ns.count(rate)\nNumber of submitted GC pause durationsshown as sample/second\n\n\n\n\ngo_expvar.memstats.pause_ns.max(gauge)\nMax GC pause durationshown as nanosecond\n\n\n\n\ngo_expvar.memstats.pause_ns.median(gauge)\nMedian GC pause durationshown as nanosecond\n\n\n\n\ngo_expvar.memstats.pause_total_ns(gauge)\nTotal GC pause duration over lifetime of processshown as nanosecond\n\n\n\n\ngo_expvar.memstats.total_alloc(gauge)\nBytes allocated (even if freed)shown as byte\n\n\n\n","tags":"","loc":"/integrations/goexpvar/"},{"title":"Datadog-Google App Engine Integration","text":"\n\nOverview\n\nInstall the Google App Engine integration in your Python project to:\n\n\n  See your Google App Engine services metrics: memcache, task queues, datastores\n  See metrics about requests: display percentiles, latency, cost\n  Tag Google App Engine metrics by version and compare the performance of different versions\n\n\nYou can also send custom metrics to Datadog.\n\n\nInstallation\n\nEnsure that Billing is enabled on your Google App Engine project to collect all metrics\n\n\n  Change directory into to your project’s application directory.\n  \n    Clone our Google App Engine module\n\n     git clone https://github.com/DataDog/gae_datadog\n\n  \n\n\n\n  \n    Edit your project’s app.yaml file\n\n    a. Add the Datadog handler to your app.yaml file:\n\n     handlers:\n   # Should probably be at the beginning of the list\n   # so it's not clobbered by a catchall route\n   - url: /datadog\n     script: gae_datadog.datadog.app\n\n\n    b. Set your API key. This should be at the top level of the file and not in the handler section.\n\n     env_variables:\n   DATADOG_API_KEY: 'YOUR_API_KEY_HERE'\n\n\n    c. Since the dogapi module sends metrics and events through a secure TLS connection, add the ssl module in the app.yaml:\n\n     libraries:\n   - name: ssl\n     version: \"latest\"\n\n  \n  \n    Add dogapi to the requirements.txt file.\n\n     echo dogapi >> requirements.txt\n\n  \n  \n    Ensure the requirements are installed.\n\n     pip install -r requirements.txt -t lib/\n\n  \n  \n    Deploy your application. Refer to the Google App Engine documentation for language specific deployment command. For Python apps, it’s:\n\n     appcfg.py -A <project id> update app.yaml\n\n  \n  \n    Enter the URL for your application in the first text box on the integration configuration screen. If you are using Task queues in the Google Developers Console, you can add them here as well.\n  \n\n\nAt this point you will get a number of metrics for your environment. You can also choose to further instrument your app using the library for whatever language your app is written in.\n\nFor Python apps, you might use the dogapi library. Here is the Getting Started Flask-based Python app, modified to increment a counter each time the main page has been hit:\n\n\"\"\"`main` is the top level module for your Flask application.\"\"\"\nimport os\n\n# Import the Flask Framework\nfrom flask import Flask\napp = Flask(__name__)\n# Note: We don't need to call run() since our application is embedded within\n# the App Engine WSGI application server.\n\nfrom dogapi import dog_stats_api as dog\ndog.start(\n    api_key=os.environ['DATADOG_API_KEY'],\n    flush_in_thread=False\n)\n\n@app.route('/')\ndef hello():\n    \"\"\"Return a friendly HTTP greeting.\"\"\"\n    dog.increment('testapp.metric', 1)\n    dog.flush()\n    return 'Hello World dd!'\n\n@app.errorhandler(404)\ndef page_not_found(e):\n    \"\"\"Return a custom 404 error.\"\"\"\n    return 'Sorry, Nothing at this URL.', 404\n\n\n@app.errorhandler(500)\ndef application_error(e):\n    \"\"\"Return a custom 500 error.\"\"\"\n    return 'Sorry, unexpected error: {}'.format(e), 500\n\n\n\nMetrics\n\n\n\n\ngcp.gae.memcache.byte_hits(gauge)\nSum of key and value bytes in successful get() and contains()shown as byte\n\n\n\n\ngcp.gae.memcache.bytes(gauge)\nSum of key and value sizes for all live entries currently in cacheshown as byte\n\n\n\n\ngcp.gae.memcache.hits(gauge)\nThe counter of \"successful\" MemcacheService.get(Object) or MemcacheService.contains(Object) operationsshown as hit\n\n\n\n\ngcp.gae.memcache.items(gauge)\nNumber of entries currently \"alive\" in the cacheshown as item\n\n\n\n\ngcp.gae.memcache.misses(gauge)\nThe counter of \"unsuccessful\" MemcacheService.get(Object) or MemcacheService.contains(Object) operationsshown as miss\n\n\n\n\ngcp.gae.memcache.oldest_item_age(gauge)\nMilliseconds since last access of least-recently-used live entryshown as millisecond\n\n\n\n\ngcp.gae.requests.cost.95percentile(gauge)\nThe 95th percentile estimated fractional dollar cost of this requestshown as dollar\n\n\n\n\ngcp.gae.requests.cost.avg(gauge)\nThe average estimated fractional dollar cost of this requestshown as dollar\n\n\n\n\ngcp.gae.requests.cost.count(count)\nThe number of times the cost metric was sampledshown as request\n\n\n\n\ngcp.gae.requests.cost.max(gauge)\nThe maximum estimated fractional dollar cost of this requestshown as dollar\n\n\n\n\ngcp.gae.requests.cost.min(gauge)\nThe minimum estimated fractional dollar cost of this requestshown as dollar\n\n\n\n\ngcp.gae.requests.latency.95percentile(gauge)\nThe 95th percentile of time required to process request in secondsshown as second\n\n\n\n\ngcp.gae.requests.latency.avg(gauge)\nThe Average time required to process request in secondsshown as second\n\n\n\n\ngcp.gae.requests.latency.count(count)\nThe number of times the request latency metric was sampledshown as request\n\n\n\n\ngcp.gae.requests.latency.max(gauge)\nThe maximum time required to process request in secondsshown as second\n\n\n\n\ngcp.gae.requests.latency.min(gauge)\nThe minimum time required to process request in secondsshown as second\n\n\n\n\ngcp.gae.requests.mcycles.95percentile(gauge)\nThe 95th percentile of machine cycles used to process request\n\n\n\n\ngcp.gae.requests.mcycles.avg(gauge)\nThe average number of machine cycles used to process request\n\n\n\n\ngcp.gae.requests.mcycles.count(count)\nThe number of times the mcycles metric was sampled\n\n\n\n\ngcp.gae.requests.mcycles.max(gauge)\nThe maximum number of machine cycles used to process request\n\n\n\n\ngcp.gae.requests.mcycles.min(gauge)\nThe minimum number of machine cycles used to process request\n\n\n\n\ngcp.gae.requests.pending_time.95percentile(gauge)\nThe 95th percentile of time this request spent in the pending request queueshown as second\n\n\n\n\ngcp.gae.requests.pending_time.avg(gauge)\nThe Average time this request spent in the pending request queueshown as second\n\n\n\n\ngcp.gae.requests.pending_time.count(count)\nThe number of times the pending request metric was sampledshown as request\n\n\n\n\ngcp.gae.requests.pending_time.max(gauge)\nThe maximum time this request spent in the pending request queueshown as second\n\n\n\n\ngcp.gae.requests.pending_time.min(gauge)\nThe minimum time this request spent in the pending request queueshown as second\n\n\n\n\ngcp.gae.requests.response_size.95percentile(gauge)\nThe 95th percentile of size in bytes sent back to client by requestshown as byte\n\n\n\n\ngcp.gae.requests.response_size.avg(gauge)\nThe Average size in bytes sent back to client by requestshown as byte\n\n\n\n\ngcp.gae.requests.response_size.count(count)\nThe number of times the response size metric was sampledshown as request\n\n\n\n\ngcp.gae.requests.response_size.max(gauge)\nThe maximum size in bytes sent back to client by requestshown as byte\n\n\n\n\ngcp.gae.requests.response_size.min(gauge)\nThe minimum size in bytes sent back to client by requestshown as byte\n\n\n\n\ngcp.gae.task_queue.tasks(gauge)\nThe number of tasks remaining in the queueshown as task\n\n\n\n\ngcp.gae.http.server.dos_intercept_count(count)\nInterceptions performed to prevent DoS attacks.shown as occurrence\n\n\n\n\ngcp.gae.http.server.quota_denial_count(count)\nFailed requests due to the app being over quota.shown as request\n\n\n\n\ngcp.gae.http.server.response_count(count)\nHTTP responses.shown as response\n\n\n\n\ngcp.gae.http.server.response_style_count(count)\nNumber of HTTP responses by serve style.shown as response\n\n\n\n\ngcp.gae.memcache.centi_mcu_count(count)\nMemcache utilization as 1/100th Memcache Compute Units.shown as unit\n\n\n\n\ngcp.gae.memcache.operation_count(count)\nCount of memcache key operations.shown as operation\n\n\n\n\ngcp.gae.memcache.received_bytes_count(count)\nNumber of bytes received by app from the memcache API.shown as byte\n\n\n\n\ngcp.gae.memcache.sent_bytes_count(count)\nNumber of bytes sent by app through the memcache API.shown as byte\n\n\n\n\ngcp.gae.system.cpu.usage(gauge)\nCPU usage.shown as megahertz\n\n\n\n\ngcp.gae.system.instance_count(gauge)\nNumber of App Engine instances.shown as instance\n\n\n\n\ngcp.gae.system.memory.usage(gauge)\nTotal memory used by running instances.shown as byte\n\n\n\n\ngcp.gae.system.network.received_bytes_count(count)\nIncoming network traffic.shown as byte\n\n\n\n\ngcp.gae.system.network.sent_bytes_count(count)\nOutgoing network traffic.shown as byte\n\n\n\n\ngcp.cloudtasks.api.request_count(count)\nNumber of Cloud Tasks API calls.shown as request\n\n\n\n\ngcp.cloudtasks.queue.task_attempt_count(count)\nNumber of task attempts.shown as attempt\n\n\n\n\ngcp.gae.http.server.response_latencies.avg(gauge)\nAverage HTTP response latency.shown as millisecond\n\n\n\n\ngcp.gae.http.server.response_latencies.samplecount(count)\nSample Count for HTTP response latency.shown as millisecond\n\n\n\n\ngcp.gae.http.server.response_latencies.max(gauge)\nMaximum HTTP response latency.shown as millisecond\n\n\n\n\ngcp.gae.http.server.response_latencies.min(gauge)\nMinimum HTTP response latency.shown as millisecond\n\n\n\n\ngcp.gae.http.server.response_latencies.sumsqdev(gauge)\nSum of Squared Deviation for HTTP response latency.shown as millisecond\n\n\n\n\ngcp.cloudtasks.queue.task_attempt_delays.avg(gauge)\nAverage delay between each scheduled and actual attempt times.shown as millisecond\n\n\n\n\ngcp.cloudtasks.queue.task_attempt_delays.samplecount(count)\nSample Count for delay between each scheduled and actual attempt times.shown as millisecond\n\n\n\n\ngcp.cloudtasks.queue.task_attempt_delays.max(gauge)\nMaximum delay between each scheduled and actual attempt times.shown as millisecond\n\n\n\n\ngcp.cloudtasks.queue.task_attempt_delays.min(gauge)\nMinimum delay between each scheduled and actual attempt times.shown as millisecond\n\n\n\n\ngcp.cloudtasks.queue.task_attempt_delays.sumsqdev(gauge)\nSum of Squared Deviation for delay between each scheduled and actual attempt times.shown as millisecond\n\n\n\n\ngcp.gae.flex.cpu.reserved_cores(gauge)\nTotal number of CPU cores allocated to an App Engine flexible environment version.shown as core\n\n\n\n\ngcp.gae.flex.cpu.utilization(gauge)\nThe percentage of allocated CPU in use across an App Engine flexible environment version. Note that some machine types allow bursting above 100%.shown as percent\n\n\n\n\ngcp.gae.flex.disk.read_bytes_count(count)\nCount of bytes read from disk across an App Engine flexible environment version.shown as byte\n\n\n\n\ngcp.gae.flex.disk.write_bytes_count(count)\nDelta count of bytes written from disk across an App Engine flexible environment version.shown as byte\n\n\n\n\ngcp.gae.flex.network.received_bytes_count(count)\nCount of incoming network bytes across all VMs in an App Engine flexible environment versionshown as byte\n\n\n\n\ngcp.gae.flex.network.sent_bytes_count(count)\nCount of outgoing network bytes across all VMs in an App Engine flexible environment versionshown as byte\n\n\n\n\n\n\nThis documentation verified on November 3, 2015\n","tags":"","loc":"/integrations/google_app_engine/"},{"title":"Datadog-Google BigQuery Integration","text":"\n\nOverview\nBigQuery is Google’s fully managed, petabyte scale, low cost enterprise data warehouse for analytics.\n\nGet metrics from Google BigQuery to:\n\n\n  Visualize the performance of your BigQuery queries\n  Correlate the performance of your BigQuery queries with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.bigquery.query.count(count)\nQueries in flight.shown as query\n\n\n\n\ngcp.bigquery.query.execution_times.avg(gauge)\nAverage of query execution times.shown as second\n\n\n\n\ngcp.bigquery.query.execution_times.samplecount(count)\nSample Count of query execution times.shown as second\n\n\n\n\ngcp.bigquery.query.execution_times.max(gauge)\nMaximum of query execution times.shown as second\n\n\n\n\ngcp.bigquery.query.execution_times.min(gauge)\nMinimum of query execution times.shown as second\n\n\n\n\ngcp.bigquery.query.execution_times.sumsqdev(gauge)\nSum of Squared Deviation for query execution times.shown as second\n\n\n\n\ngcp.bigquery.query.scanned_bytes(rate)\nNumber of scanned bytes. Note: this metric is available with a 12h delayshown as byte/minute\n\n\n\n\ngcp.bigquery.query.scanned_bytes_billed(rate)\nNumber of scanned bytes billed. Note: this metric is available with a 12h delayshown as byte/minute\n\n\n\n\ngcp.bigquery.slots.allocated_for_project(gauge)\nNumber of BigQuery slots currently allocated for the project.shown as resource\n\n\n\n\ngcp.bigquery.slots.allocated_for_reservation(gauge)\nNumber of BigQuery slots currently allocated for the reservation.shown as resource\n\n\n\n\ngcp.bigquery.slots.total_available(gauge)\nTotal number of BigQuery slots available for the project.shown as resource\n\n\n\n\ngcp.bigquery.storage.stored_bytes(gauge)\nNumber of bytes stored. Note: this metric is available with a 12h delayshown as byte\n\n\n\n\ngcp.bigquery.storage.table_count(gauge)\nNumber of tables. Note: this metric is available with a 12h delayshown as table\n\n\n\n\ngcp.bigquery.storage.uploaded_bytes(rate)\nNumber of uploaded bytes. Note: this metric is available with a 12h delayshown as byte/minute\n\n\n\n\ngcp.bigquery.storage.uploaded_bytes_billed(rate)\nNumber of uploaded bytes billed. Note: this metric is available with a 12h delayshown as byte/minute\n\n\n\n\ngcp.bigquery.storage.uploaded_row_count(rate)\nNumber of uploaded rows. Note: this metric is available with a 12h delayshown as byte/minute\n\n\n\n","tags":"","loc":"/integrations/google_cloud_big_query/"},{"title":"Datadog-Google Datastore Integration","text":"\n\nOverview\nCloud Datastore is a highly-scalable NoSQL database for your web and mobile applications.\n\nGet metrics from Google Datastore to:\n\n\n  Visualize the performance of your Datastores\n  Correlate the performance of your Datastores with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.datastore.api.request_count(count)\nDatastore API calls.shown as request\n\n\n\n\ngcp.datastore.index.write_count(count)\nDatastore index writes.shown as write\n\n\n\n\ngcp.datastore.entity.read_sizes.avg(gauge)\nAverage of sizes of read entities.shown as byte\n\n\n\n\ngcp.datastore.entity.read_sizes.samplecount(count)\nSample Count for sizes of read entities.shown as byte\n\n\n\n\ngcp.datastore.entity.read_sizes.max(gauge)\nMaximum of sizes of read entities.shown as byte\n\n\n\n\ngcp.datastore.entity.read_sizes.min(gauge)\nMinimum of sizes of read entities.shown as byte\n\n\n\n\ngcp.datastore.entity.read_sizes.sumsqdev(gauge)\nSum of Squared Deviation for sizes of read entities.shown as byte\n\n\n\n\ngcp.datastore.entity.write_sizes.avg(gauge)\nAverage of sizes of written entities.shown as byte\n\n\n\n\ngcp.datastore.entity.write_sizes.samplecount(gauge)\nSample Count for sizes of written entities.shown as byte\n\n\n\n\ngcp.datastore.entity.write_sizes.max(gauge)\nMaximum of sizes of written entities.shown as byte\n\n\n\n\ngcp.datastore.entity.write_sizes.min(gauge)\nMinimum of sizes of written entities.shown as byte\n\n\n\n\ngcp.datastore.entity.write_sizes.sumsqdev(gauge)\nSum of Squared Deviation for sizes of written entities.shown as byte\n\n\n\n\n","tags":"","loc":"/integrations/google_cloud_datastore/"},{"title":"Datadog-Google Cloud Firebase Integration","text":"\n\nOverview\nFirebase is a mobile platform that helps you quickly develop high-quality apps, grow your user base, and earn more money.\n\nGet metrics from Google Firebase to:\n\n\n  Visualize the performance of your Firebase databases and hosting services \n  Correlate the performance of your Firebase tools with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.firebasedatabase.io.utilization(gauge)\nPercentage of io utilizationshown as percent\n\n\n\n\ngcp.firebasedatabase.network.active_connections(gauge)\nNumber of outstanding connectionsshown as connection\n\n\n\n\ngcp.firebasedatabase.network.operations_count(count)\nNumber of operationsshown as operation\n\n\n\n\ngcp.firebasedatabase.network.sent_bytes_count(count)\nOutgoing bandwidth usage for Firebase databaseshown as byte\n\n\n\n\ngcp.firebasedatabase.storage.total_bytes(gauge)\nTotal size of the Firebase database storage.shown as byte\n\n\n\n\ngcp.firebasehosting.network.sent_bytes_count(count)\nOutgoing bandwidth usage for Firebase Hostingshown as byte\n\n\n\n\ngcp.firebasehosting.storage.total_bytes(gauge)\nTotal size of the Firebase Hosting storage.shown as byte\n\n\n\n\ngcp.firebasedatabase.network.disabled_for_overages(gauge)\nIndicates if the Firebase database has been disabled for network overages\n\n\n\n\ngcp.firebasedatabase.network.monthly_sent(gauge)\nThe total outgoing bytes sent aggregated and reset monthlyshown as byte\n\n\n\n\ngcp.firebasedatabase.network.monthly_sent_limit(gauge)\nThe monthly network limit for the Firebase databaseshown as byte\n\n\n\n\ngcp.firebasedatabase.status.disabled_for_overages(gauge)\nIndicates if the Firebase database has been disabled for overages\n\n\n\n\ngcp.firebasedatabase.storage.disabled_for_overages(gauge)\nIndicates if the Firebase database has been disabled for storage overages\n\n\n\n\ngcp.firebasedatabase.storage.limit(gauge)\nThe storage limit for the Firebase databaseshown as byte\n\n\n\n\n","tags":"","loc":"/integrations/google_cloud_firebase/"},{"title":"Datadog-Google Cloud Functions Integration","text":"\n\nOverview\nGoogle Cloud Functions is a lightweight, event-based, asynchronous compute solution that allows you to create small, single-purpose functions.\n\nGet metrics from Google Functions to:\n\n\n  Visualize the performance of your Functions\n  Correlate the performance of your Functions with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.cloudfunctions.function.execution_times.avg(gauge)\nAverage of functions execution times.shown as nanosecond\n\n\n\n\ngcp.cloudfunctions.function.execution_times.samplecount(count)\nSample Count for functions execution times.shown as occurrence\n\n\n\n\ngcp.cloudfunctions.function.execution_times.max(gauge)\nMaximum of functions execution times.shown as nanosecond\n\n\n\n\ngcp.cloudfunctions.function.execution_times.min(gauge)\nMinimum of functions execution times.shown as nanosecond\n\n\n\n\ngcp.cloudfunctions.function.execution_times.sumsqdev(gauge)\nSum of Squared Deviation for functions execution times.shown as nanosecond\n\n\n\n\ngcp.cloudfunctions.function.execution_count(count)\nNumber of function exceptions.shown as occurrence\n\n\n\n","tags":"","loc":"/integrations/google_cloud_functions/"},{"title":"Datadog-Google Machine Learning Integration","text":"\n\nOverview\nGoogle Cloud Machine Learning is a managed service that enables you to easily build machine learning models, that work on any type of data, of any size.\n\nGet metrics from Google Machine Learning to:\n\n\n  Visualize the performance of your ML Services\n  Correlate the performance of your ML Services with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\nLook for gcp.ml.* metrics within the Datadog App\n\n","tags":"","loc":"/integrations/google_cloud_ml/"},{"title":"Datadog-Google Cloud Platform Integration","text":"\n\nOverview\n\nConnect to Google Cloud Platform to:\n\n\n  See your Google Compute Engine hosts in the infrastructure overview\n  Import your Google Compute Engine host tags\n  Tag your Google Compute Engine hosts with additional compute-specific metadata (e.g. zone)\n\n\nRelated integrations include:\n\n\n  \n    \n      App Engine\n      platform as a service to build scalable applications\n    \n    \n      Big Query\n      enterprise data warehouse\n    \n    \n      CloudSQL\n      MySQL database service\n    \n    \n      Compute Engine\n      high performance virtual machines\n    \n    \n      Container Engine\n      kubernetes, managed by google\n    \n    \n      Datastore\n      NoSQL database\n    \n    \n      Firebase\n      mobile platform for application development\n    \n    \n      Functions\n      A serverless platform for building event-based microservices\n    \n    \n      Machine Learning\n      machine learning services\n    \n    \n      Pub/Sub\n      real-time messaging service\n    \n    \n      Spanner\n      horizontally scalable, globally consistent, relational database service\n    \n    \n      Stackdriver Logging\n      real-time log management and analysis\n    \n    \n      Storage\n      unified object storage\n    \n    \n      VPN\n      managed network functionality\n    \n  \n\n\n\nInstallation\n\nFrom the Integrations page in the Datadog app, select the Google Cloud Platform tile. Switch to the Configuration tab and click the Sign in with Google button. After you allow access enter the email associated with the account and the Project you wish to monitor. Enter the Project ID for each project. The Project ID is the multi-word id and not the Project Number.\n\nWe require the user who configures the integration to have the permissions:  \n\nhttps://www.googleapis.com/auth/compute.readonly\nhttps://www.googleapis.com/auth/monitoring.read\n\n\nBilling must also be enbled for the account(s) you wish to monitor.\n\nOptionally, you can limit the GCE instances that are pulled into Datadog by entering tags in the “Limit Metric Collection” textbox. Only hosts that match one of the defined tags will be imported into Datadog. Wildcards, such as ‘?’ (for single characters) and ‘*’ (for multiple characters) can also be used. Host matching a given tag can also be excluded by adding ‘!’ before the tag.\n\ne.x. datadog:monitored,env:production,!env:staging,instance-type:c1.*\n\n\n\n\nNOTE: gcp.loadbalancing.* metrics are available as part of a Google specifc Beta. To see these metrics in Datadog, please contact your Google representative/support and ask to join the Stackdriver Loadbalancing metrics Beta.\n\n\nMetrics\n\n\n\n\ngcp.loadbalancing.http.backend_latencies.avg(gauge)\nAverage latency of request sent by the proxy to backend until proxy receives last byte of response from backend.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.backend_latencies.samplecount(count)\nSample Count of latency of request sent by the proxy to backend until proxy receives last byte of response from backend.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.backend_latencies.max(gauge)\nMaximum latency of request sent by the proxy to backend until proxy receives last byte of response from backend.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.backend_latencies.min(gauge)\nMinimum latency of request sent by the proxy to backend until proxy receives last byte of response from backend.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.backend_latencies.sumsqdev(gauge)\nSum of Squared Deviation for latency of request sent by the proxy to backend until proxy receives last byte of response from backend.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.frontend_tcp_rtt.avg(gauge)\nAverage RTT for each connection between client and proxy.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.frontend_tcp_rtt.samplecount(count)\nSample Count of RTT for each connection between client and proxy.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.frontend_tcp_rtt.max(gauge)\nMaximum RTT for each connection between client and proxy.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.frontend_tcp_rtt.min(gauge)\nMinimum RTT for each connection between client and proxy.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.frontend_tcp_rtt.sumsqdev(gauge)\nSum of Squared Deviation of RTT for each connection between client and proxy.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.request_bytes_count(count)\nBytes sent as requests from clients to L7 load balancer.shown as byte\n\n\n\n\ngcp.loadbalancing.http.request_count(count)\nNumber of requests served by L7 load balancer.shown as request\n\n\n\n\ngcp.loadbalancing.http.response_bytes_count(count)\nBytes sent as responses from L7 load balancer to clients.shown as byte\n\n\n\n\ngcp.loadbalancing.http.response_code_class_percentage(gauge)\nPer response code class percentage of total responses by proxy to clients.shown as percent\n\n\n\n\ngcp.loadbalancing.http.total_latencies.avg(gauge)\nAverage latency calculated from request received by proxy until proxy sees ACK from client on last response byte.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.total_latencies.samplecount(count)\nSample Count of latency calculated from request received by proxy until proxy sees ACK from client on last response byte.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.total_latencies.max(gauge)\nMaximum latency calculated from request received by proxy until proxy sees ACK from client on last response byte.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.total_latencies.min(gauge)\nMinimum latency calculated from request received by proxy until proxy sees ACK from client on last response byte.shown as millisecond\n\n\n\n\ngcp.loadbalancing.http.total_latencies.sumsqdev(gauge)\nSum of Squared Deviation of latency calculated from request received by proxy until proxy sees ACK from client on last response byte.shown as millisecond\n\n\n\n\n\nTags Assigned\n\nTags are automatically assigned based on a variety of configuration options with regards to Google Cloud Platform and the Google Compute Engine. The following tags will be automatically assigned:\n\n\n  Zone\n  Instance-type\n  Instance-id\n  Automatic-restart\n  On-host-maintenance\n  Project\n  Numeric_project_id\n  Name\n\n\nTo learn more about tags in the Datadog platform, refer to the Guide to Tagging\n\n","tags":"","loc":"/integrations/google_cloud_platform/"},{"title":"Datadog-Google Pub/Sub Integration","text":"\n\nOverview\nGoogle Cloud Pub/Sub brings the scalability, flexibility, and reliability of enterprise message-oriented middleware to the cloud.\n\nGet metrics from Google Pub/Sub to:\n\n\n  Visualize the performance of your Pub/Sub topics and subscriptions\n  Correlate the performance of your Pub/sub topics and subscriptions with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.pubsub.subscription.backlog_bytes(gauge)\nApproximate size of the message backlog in a subscription.shown as byte\n\n\n\n\ngcp.pubsub.subscription.byte_cost(count)\nCost of operations per subscription measured.shown as byte\n\n\n\n\ngcp.pubsub.subscription.config_updates_count(count)\nNumber of configuration changes for subscriptions.shown as occurrence\n\n\n\n\ngcp.pubsub.subscription.mod_ack_deadline_message_operation_count(count)\nNumber of ModifyAckDeadline operations.shown as operation\n\n\n\n\ngcp.pubsub.subscription.mod_ack_deadline_request_count(count)\nNumber of ModifyAckDeadline requests.shown as request\n\n\n\n\ngcp.pubsub.subscription.num_outstanding_messages(gauge)\nMessages delivered but not yet acknowledged.shown as message\n\n\n\n\ngcp.pubsub.subscription.num_undelivered_messages(gauge)\nMessages pending to be delivered.shown as message\n\n\n\n\ngcp.pubsub.subscription.oldest_unacked_message_age(gauge)\nAge of the oldest unacknowledged message in a subscription.shown as second\n\n\n\n\ngcp.pubsub.subscription.pull_ack_message_operation_count(count)\nNumber of acknowledge message operations.shown as operation\n\n\n\n\ngcp.pubsub.subscription.pull_ack_request_count(count)\nDelta count of message pull acknowledgement requests.shown as request\n\n\n\n\ngcp.pubsub.subscription.pull_message_operation_count(count)\nNumber of pull message operations.shown as operation\n\n\n\n\ngcp.pubsub.subscription.pull_request_count(count)\nNumber of message pull requests.shown as request\n\n\n\n\ngcp.pubsub.subscription.push_request_count(count)\nNumber of message push attempts.shown as request\n\n\n\n\ngcp.pubsub.topic.byte_cost(count)\nByte cost of operations per topic.shown as byte\n\n\n\n\ngcp.pubsub.topic.config_updates_count(count)\nNumber of configuration changes for topics.shown as occurrence\n\n\n\n\ngcp.pubsub.topic.send_message_operation_count(count)\nNumber of publish message operations.shown as operation\n\n\n\n\ngcp.pubsub.topic.send_request_count(count)\nNumber of message send requests.shown as request\n\n\n\n\ngcp.pubsub.subscription.push_request_latencies.avg(gauge)\nAverage of push request latencies.shown as microsecond\n\n\n\n\ngcp.pubsub.subscription.push_request_latencies.samplecount(count)\nSample Count for push request latencies.shown as microsecond\n\n\n\n\ngcp.pubsub.subscription.push_request_latencies.max(gauge)\nMaximum of push request latencies.shown as microsecond\n\n\n\n\ngcp.pubsub.subscription.push_request_latencies.min(gauge)\nMinimum of push request latencies.shown as microsecond\n\n\n\n\ngcp.pubsub.subscription.push_request_latencies.sumsqdev(gauge)\nSum of Squared Deviation for push request latencies.shown as microsecond\n\n\n\n\ngcp.pubsub.topic.message_sizes.avg(gauge)\nAverage of publish message sizes.shown as byte\n\n\n\n\ngcp.pubsub.topic.message_sizes.samplecount(count)\nSample Count for publish message sizes.shown as byte\n\n\n\n\ngcp.pubsub.topic.message_sizes.max(gauge)\nMaximum of publish message sizes.shown as byte\n\n\n\n\ngcp.pubsub.topic.message_sizes.min(gauge)\nMinimum of publish message sizes.shown as byte\n\n\n\n\ngcp.pubsub.topic.message_sizes.sumsqdev(gauge)\nSum of Squared Deviation for publish message sizes.shown as byte\n\n\n\n","tags":"","loc":"/integrations/google_cloud_pubsub/"},{"title":"Datadog-Google Spanner Integration","text":"\n\nOverview\nGoogle Cloud Spanner is the first and only relational database service that is both strongly consistent and horizontally scalable.\n\nGet metrics from Google Spanner to:\n\n\n  Visualize the performance of your Spanner databases\n  Correlate the performance of your Spanner databases with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.spanner.api.request_count(rate every 60 seconds)\nRate of Cloud Spanner API requests.shown as request/second\n\n\n\n\ngcp.spanner.instance.cpu.utilization(gauge every 60 seconds)\nUtilization of provisioned CPUshown as fraction\n\n\n\n\ngcp.spanner.instance.node_count(gauge every 60 seconds)\nNumber of nodesshown as node\n\n\n\n\ngcp.spanner.instance.storage.used_bytes(gauge every 60 seconds)\nAmount of used storage in bytesshown as byte\n\n\n\n","tags":"","loc":"/integrations/google_cloud_spanner/"},{"title":"Datadog-Google Storage Integration","text":"\n\nOverview\nGoogle Cloud Storage is unified object storage for developers and enterprises, from live data serving to data analytics/ML to data archiving.\n\nGet metrics from Google Storage to:\n\n\n  Visualize the performance of your Storage services\n  Correlate the performance of your Storage services with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.storage.api.request_count(count)\nNumber of API calls.shown as request\n\n\n\n\ngcp.storage.network.received_bytes_count(count)\nNumber of bytes received over the network.shown as byte\n\n\n\n\ngcp.storage.network.sent_bytes_count(count)\nNumber of bytes sent over the network.shown as byte\n\n\n\n","tags":"","loc":"/integrations/google_cloud_storage/"},{"title":"Datadog-Google VPN Integration","text":"\n\nOverview\nGoogle Cloud VPN securely connects your existing network to your Google Cloud Platform network.\n\nGet metrics from Google VPN to:\n\n\n  Visualize the performance of your VPNs\n  Correlate the performance of your VPNs with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.vpn.network.dropped_received_packets_count(count)\nIngress packets dropped for tunnel.shown as packet\n\n\n\n\ngcp.vpn.network.dropped_sent_packets_count(count)\nEgress packets dropped for tunnel.shown as packet\n\n\n\n\ngcp.vpn.network.received_bytes_count(count)\nIngress bytes for tunnel.shown as byte\n\n\n\n\ngcp.vpn.network.sent_bytes_count(count)\nEgress bytes for tunnel.shown as byte\n\n\n\n\ngcp.vpn.tunnel_established(gauge)\nIndicates successful tunnel establishment if greater than 0.\n\n\n\n\ngcp.router.best_received_routes_count(gauge)\nNumber of best routes received by router.shown as route\n\n\n\n\ngcp.router.bgp.received_routes_count(gauge)\nNumber of routes received on a bgp session.shown as route\n\n\n\n\ngcp.router.bgp.sent_routes_count(gauge)\nNumber of routes sent on a bgp session.shown as route\n\n\n\n\ngcp.router.bgp.session_up(gauge)\nIndicator for successful bgp session establishment.\n\n\n\n\ngcp.router.bgp_sessions_down_count(gauge)\nNumber of BGP sessions on the router that are down.shown as session\n\n\n\n\ngcp.router.bgp_sessions_up_count(gauge)\nNumber of BGP sessions on the router that are up.shown as session\n\n\n\n\ngcp.router.router_up(gauge)\nRouter status up or down\n\n\n\n\ngcp.router.sent_routes_count(gauge)\nNumber of routes sent by router.shown as route\n\n\n\n","tags":"","loc":"/integrations/google_cloud_vpn/"},{"title":"Datadog-Google CloudSQL Integration","text":"\n\nOverview\nGoogle Cloud SQL is a fully-managed database service that makes it easy to set up, maintain, manage, and administer your MySQL databases in the cloud.\n\nGet metrics from Google CloudSQL to:\n\n\n  Visualize the performance of your CloudSQL databases\n  Correlate the performance of your CloudSQL databases with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.cloudsql.database.disk.bytes_used(gauge)\nDisk space used.shown as byte\n\n\n\n\ngcp.cloudsql.database.disk.write_ops_count(count)\nDisk write IO operations.shown as operation\n\n\n\n\ngcp.cloudsql.database.mysql.innodb_data_fsyncs(count)\nInnoDB fsync calls.shown as operation/second\n\n\n\n\ngcp.cloudsql.database.mysql.innodb_os_log_fsyncs(count)\nInnoDB fsync calls to the log file.shown as operation/second\n\n\n\n\ngcp.cloudsql.database.mysql.innodb_pages_read(count)\nInnoDB pages read.shown as page/second\n\n\n\n\ngcp.cloudsql.database.mysql.innodb_pages_written(count)\nInnoDB pages written.shown as page/second\n\n\n\n\ngcp.cloudsql.database.mysql.queries(count)\nNumber of query statements executed by the server.shown as query/second\n\n\n\n\ngcp.cloudsql.database.mysql.questions(count)\nNumber of question statements executed by the server. Includes only statements sent to the server by clients and not statements executed within stored programsshown as question/second\n\n\n\n\ngcp.cloudsql.database.mysql.replication.available_for_failover(gauge)\nFailover operation is available on the master instance if greater than 0.\n\n\n\n\ngcp.cloudsql.database.mysql.replication.seconds_behind_master(gauge)\nApproximate number of seconds the read replica is behind its' master.shown as second\n\n\n\n\ngcp.cloudsql.database.network.connections(gauge)\nNumber of connections to the Cloud SQL instance.shown as connection\n\n\n\n\ngcp.cloudsql.database.network.sent_bytes_count(count)\nNumber of bytes sent through the network.shown as byte\n\n\n\n\ngcp.cloudsql.database.up(gauge)\nIndicates if the server is up or not.\n\n\n\n\ngcp.cloudsql.database.uptime(gauge)\nNumber of seconds the instance has been running.shown as second\n\n\n\n\ngcp.cloudsql.database.state(gauge)\nThe current serving state of the Cloud SQL instance\n\n\n\n\ngcp.cloudsql.database.cpu.reserved_cores(gauge)\nNumber of cores reserved for the database.shown as core\n\n\n\n\ngcp.cloudsql.database.cpu.usage_time(gauge)\nCumulative CPU usage timeshown as second\n\n\n\n\ngcp.cloudsql.database.cpu.utilization(gauge)\nFraction of the reserved CPU that is currently in use.shown as fraction\n\n\n\n\ngcp.cloudsql.database.disk.quota(gauge)\nMaximum data disk size in bytes.shown as byte\n\n\n\n\ngcp.cloudsql.database.disk.read_ops_count(count)\nDisk read IO operations.shown as operation\n\n\n\n\ngcp.cloudsql.database.disk.utilization(gauge)\nThe fraction of the disk quota that is currently in use.shown as fraction\n\n\n\n\ngcp.cloudsql.database.memory.quota(gauge)\nMaximum RAM in bytesshown as byte\n\n\n\n\ngcp.cloudsql.database.memory.usage(gauge)\nRAM usage in bytesshown as byte\n\n\n\n\ngcp.cloudsql.database.memory.utilization(gauge)\nFraction of memory quota currently in useshown as fraction\n\n\n\n\ngcp.cloudsql.database.mysql.innodb_buffer_pool_pages_dirty(gauge)\nNumber of unflushed pages in the InnoDB buffer pool.shown as page\n\n\n\n\ngcp.cloudsql.database.mysql.innodb_buffer_pool_pages_free(gauge)\nNumber of unused pages in the InnoDB buffer pool.shown as page\n\n\n\n\ngcp.cloudsql.database.mysql.innodb_buffer_pool_pages_total(gauge)\nTotal number of pages in the InnoDB buffer pool.shown as page\n\n\n\n\ngcp.cloudsql.database.mysql.replication.slave_io_running(gauge)\nIndicates whether the I/O thread for reading the master's binary log is running. Possible values are Yes, No and Connecting.\n\n\n\n\ngcp.cloudsql.database.mysql.replication.slave_sql_running(gauge)\nIndicates whether the SQL thread for executing events in the relay log is running\n\n\n\n","tags":"","loc":"/integrations/google_cloudsql/"},{"title":"Datadog-Google Compute Engine Integration","text":"\n\nOverview\nGoogle Compute Engine delivers virtual machines running in Google’s innovative data centers and worldwide fiber network.\n\nGet metrics from Google Compute Engine to:\n\n\n  Visualize the performance of your Compute Engines\n  Correlate the performance of your Compute Engines with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.gce.instance.is_running(gauge)\nStatus check that returns 1 if instance is running\n\n\n\n\ngcp.gce.project.quota.backend_services.limit(gauge)\nThe backend services quota limit\n\n\n\n\ngcp.gce.project.quota.backend_services.usage(gauge)\nThe percentage of backend services quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.firewalls.limit(gauge)\nThe firewalls quota limit\n\n\n\n\ngcp.gce.project.quota.firewalls.usage(gauge)\nThe percentage of firewalls quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.forwarding_rules.limit(gauge)\nThe forwarding rules quota limit\n\n\n\n\ngcp.gce.project.quota.forwarding_rules.usage(gauge)\nThe percentage of the forwarding rules quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.health_checks.limit(gauge)\nThe health checks quota limit\n\n\n\n\ngcp.gce.project.quota.health_checks.usage(gauge)\nThe percentage of the health checks quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.images.limit(gauge)\nThe images quota limit\n\n\n\n\ngcp.gce.project.quota.images.usage(gauge)\nThe percentage of the images quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.in_use_addresses.limit(gauge)\nThe in_use_addresses quota limit\n\n\n\n\ngcp.gce.project.quota.in_use_addresses.usage(gauge)\nThe percentage of the in_use_addresses quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.instance_templates.limit(gauge)\nThe instance templates quota limit\n\n\n\n\ngcp.gce.project.quota.instance_templates.usage(gauge)\nThe percentage of the instance templates quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.networks.limit(gauge)\nThe networks quota limit\n\n\n\n\ngcp.gce.project.quota.networks.usage(gauge)\nThe percentage of the networks quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.routes.limit(gauge)\nThe routes quota limit\n\n\n\n\ngcp.gce.project.quota.routes.usage(gauge)\nThe percentage of the routes quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.snapshots.limit(gauge)\nThe snapshots quota limit\n\n\n\n\ngcp.gce.project.quota.snapshots.usage(gauge)\nThe percentage of the snapshots quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.ssl_certificates.limit(gauge)\nThe SSL certificates quota limit\n\n\n\n\ngcp.gce.project.quota.ssl_certificates.usage(gauge)\nThe percentage of the SSL certificates quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.static_addresses.limit(gauge)\nThe static addresses quota limit\n\n\n\n\ngcp.gce.project.quota.static_addresses.usage(gauge)\nThe percentage of the static addresses quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.subnetworks.limit(gauge)\nThe subnetworks quota limit\n\n\n\n\ngcp.gce.project.quota.subnetworks.usage(gauge)\nThe percentage of the subnetworks quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.target_http_proxies.limit(gauge)\nThe target http proxies quota limit\n\n\n\n\ngcp.gce.project.quota.target_http_proxies.usage(gauge)\nThe percentage of the target http proxies quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.target_https_proxies.limit(gauge)\nThe target https proxies quota limit\n\n\n\n\ngcp.gce.project.quota.target_https_proxies.usage(gauge)\nThe percentage of the target https proxies quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.target_instances.limit(gauge)\nThe target instances quota limit\n\n\n\n\ngcp.gce.project.quota.target_instances.usage(gauge)\nThe percentage of the target instances quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.target_pools.limit(gauge)\nThe target pools quota limit\n\n\n\n\ngcp.gce.project.quota.target_pools.usage(gauge)\nThe percentage of the target pools quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.target_vpn_gateways.limit(gauge)\nThe target vpn gateways quota limit\n\n\n\n\ngcp.gce.project.quota.target_vpn_gateways.usage(gauge)\nThe percentage of the target vpn gateways quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.url_maps.limit(gauge)\nThe url maps quota limit\n\n\n\n\ngcp.gce.project.quota.url_maps.usage(gauge)\nThe percentage of the url maps quota being usedshown as percent\n\n\n\n\ngcp.gce.project.quota.vpn_tunnels.limit(gauge)\nThe vpn tunnels quota limit\n\n\n\n\ngcp.gce.project.quota.vpn_tunnels.usage(gauge)\nThe percentage of the vpn tunnels quota being usedshown as percent\n\n\n\n\ngcp.gce.firewall.dropped_bytes_count(count)\nIncoming bytes dropped by the firewall.shown as byte\n\n\n\n\ngcp.gce.firewall.dropped_packets_count(count)\nIncoming packets dropped by the firewall.shown as packet\n\n\n\n\ngcp.gce.instance.cpu.reserved_cores(gauge)\nNumber of cores reserved on the host of the instance.shown as core\n\n\n\n\ngcp.gce.instance.cpu.usage_time(gauge)\nCPU usage time for all cores.shown as second\n\n\n\n\ngcp.gce.instance.cpu.utilization(gauge)\nFraction of the allocated CPU that is currently in use on the instance. Note that some machine types allow bursting above 100% usage.shown as fraction\n\n\n\n\ngcp.gce.instance.disk.read_bytes_count(count)\nBytes read from disk.shown as byte\n\n\n\n\ngcp.gce.instance.disk.read_ops_count(count)\nDisk read IO operations.shown as operation\n\n\n\n\ngcp.gce.instance.disk.throttled_read_bytes_count(count)\nBytes in throttled read operations.shown as byte\n\n\n\n\ngcp.gce.instance.disk.throttled_read_ops_count(count)\nThrottled read operations.shown as operation\n\n\n\n\ngcp.gce.instance.disk.throttled_write_bytes_count(count)\nBytes in throttled write operations.shown as byte\n\n\n\n\ngcp.gce.instance.disk.throttled_write_ops_count(count)\nThrottled write operations.shown as operation\n\n\n\n\ngcp.gce.instance.disk.write_bytes_count(count)\nBytes written to disk.shown as byte\n\n\n\n\ngcp.gce.instance.disk.write_ops_count(count)\nDisk write IO operations.shown as operation\n\n\n\n\ngcp.gce.instance.network.received_bytes_count(count)\nBytes received from network.shown as byte\n\n\n\n\ngcp.gce.instance.network.received_packets_count(count)\nPackets received from network.shown as packet\n\n\n\n\ngcp.gce.instance.network.sent_bytes_count(count)\nBytes sent over network.shown as byte\n\n\n\n\ngcp.gce.instance.network.sent_packets_count(count)\nPackets sent over network.shown as packet\n\n\n\n\ngcp.gce.instance.uptime(gauge)\nIndicates the VM running time in seconds.shown as second\n\n\n\n","tags":"","loc":"/integrations/google_compute_engine/"},{"title":"Datadog-Google Container Engine Integration","text":"\n\nOverview\nGoogle Container Engine is a powerful cluster manager and orchestration system for running your Docker containers.\n\nGet metrics from Google Container Engine to:\n\n\n  Visualize the performance of your Container Engine containers\n  Correlate the performance of your Container Engine containers with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.container.cpu.reserved_cores(gauge)\nCPU cores reserved for the container.shown as core\n\n\n\n\ngcp.container.cpu.usage_time(gauge)\nCPU usage on all cores.shown as second\n\n\n\n\ngcp.container.cpu.utilization(gauge)\nFraction of the allocated CPU that is currently in use on the container.shown as fraction\n\n\n\n\ngcp.container.disk.bytes_total(gauge)\nTotal byte capacity on disk.shown as byte\n\n\n\n\ngcp.container.disk.bytes_used(gauge)\nBytes used on disk.shown as byte\n\n\n\n\ngcp.container.memory.bytes_total(gauge)\nMemory limit of the container.shown as byte\n\n\n\n\ngcp.container.memory.bytes_used(gauge)\nMemory usage on the container.shown as byte\n\n\n\n\ngcp.container.memory.page_fault_count(count)\nNumber of page faults.shown as fault\n\n\n\n\ngcp.container.uptime(gauge)\nNumber of seconds since the container started.shown as second\n\n\n\n","tags":"","loc":"/integrations/google_container_engine/"},{"title":"Datadog-Google Stackdriver Logging Integration","text":"\n\nOverview\nStackdriver Logging allows you to store, search, analyze, monitor, and alert on log data and events from Google Cloud Platform.\n\nGet metrics from Google Stackdriver Logging to:\n\n\n  Visualize the performance of your Stackdriver logs\n  Correlate the performance of your Stackdriver logs with your applications\n\n\n\nInstallation\n\nIf you haven’t already, set up the Google Cloud Platform integration first. There are no other installation steps that need to be performed.\n\n\nMetrics\n\n\n\n\ngcp.logging.byte_count(count)\nNumber of bytes in all log entries ingested.shown as byte\n\n\n\n\ngcp.logging.dropped_log_entry_count(count)\nNumber of log entries that did not contribute to user defined metrics.shown as entry\n\n\n\n\ngcp.logging.log_entry_count(count)\nNumber of log entries that contributed to user-defined metrics.shown as entry\n\n\n\n","tags":"","loc":"/integrations/google_stackdriver_logging/"},{"title":"Datadog-Gunicorn Integration","text":"\n\nOverview\n\nThe Datadog Agent collects one main metric about Gunicorn: the number of worker processes running. Gunicorn itself can provide further metrics via DogStatsD, including those for:\n\n\n  Total request rate\n  Request rate by status code (2xx, 3xx, 4xx, 5xx)\n  Request duration (average, median, max, 95th percentile, etc)\n  Log message rate by log level (critical, error, warning, exception)\n\n\n\nInstallation\n\nThe Datadog Agent’s Gunicorn check is included in the Agent package, so simply install the Agent on your Gunicorn servers. If you need the newest version of the Gunicorn check, install the dd-check-gunicorn package; this package’s check will override the one packaged with the Agent. See the integrations-core repository for more details.\n\nThe Gunicorn check requires your Gunicorn app’s Python environment to have the setproctitle package; without it, the Datadog Agent will always report that it cannot find a gunicorn master process (and hence, cannot find workers, either). Install the setproctitle package in your app’s Python environment if you want to collect the gunicorn.workers metric.\n\n\nConfiguration\n\n\nConfigure the Agent\n\nCreate a gunicorn.yaml in the Datadog Agent’s conf.d directory:\n\ninit_config:\n\ninstances:\n  # as set \n  # 1) in your app's config.py (proc_name = <YOUR_APP_NAME>), OR\n  # 2) via CLI (gunicorn --name <YOUR_APP_NAME> your:app)\n  - proc_name: <YOUR_APP_NAME>\n\n\nRestart the Agent to begin sending Gunicorn metrics to Datadog.\n\n\nConnect Gunicorn to DogStatsD\n\nSince version 19.1, Gunicorn provides an option to send its metrics to a StatsD daemon. As with many Gunicorn options, you can either pass it to gunicorn on the CLI (--statsd-host) or set it in your app’s configuration file (statsd_host). Configure your app to send metrics to DogStatsD at \"localhost:8125\", and restart the app.\n\n\nValidation\n\nRun the Agent’s info command and look for gunicorn under the Checks section:\n\n  Checks\n  ======\n    [...]\n\n    gunicorn (5.12.1)\n    -----------------\n      - instance #0 [OK]\n      - Collected 2 metrics, 0 events & 1 service check\n\n    [...]\n\n\nIf the status is not OK, see the Troubleshooting section.\n\nUse netstat to verify that Gunicorn is sending its metrics, too:\n\n$ sudo netstat -nup | grep \"127.0.0.1:8125.*ESTABLISHED\"\nudp        0      0 127.0.0.1:38374         127.0.0.1:8125          ESTABLISHED 15500/gunicorn: mas\n\n\n\nTroubleshooting\n\n\nAgent cannot find Gunicorn process\n  Checks\n  ======\n\n    gunicorn (5.12.1)\n    -----------------\n      - instance #0 [ERROR]: 'Found no master process with name: gunicorn: master [my_web_app]'\n      - Collected 0 metrics, 0 events & 1 service check\n      - Dependencies:\n          - psutil: 4.4.1\n\n\nEither Gunicorn really isn’t running, or your app’s Python environment doesn’t have the setproctitle package installed.\n\nIf setproctitle is not installed, Gunicorn appears in the process table like so:\n\n$ ps -ef | grep gunicorn\nubuntu   18013 16695  2 20:23 pts/0    00:00:00 /usr/bin/python /usr/bin/gunicorn --config test-app-config.py gunicorn-test:app\nubuntu   18018 18013  0 20:23 pts/0    00:00:00 /usr/bin/python /usr/bin/gunicorn --config test-app-config.py gunicorn-test:app\nubuntu   18019 18013  0 20:23 pts/0    00:00:00 /usr/bin/python /usr/bin/gunicorn --config test-app-config.py gunicorn-test:app\n\n\nIf it is installed, gunicorn processes appear in the format the Datadog Agent expects:\n\n$ ps -ef | grep gunicorn\nubuntu   18457 16695  5 20:26 pts/0    00:00:00 gunicorn: master [my_app]\nubuntu   18462 18457  0 20:26 pts/0    00:00:00 gunicorn: worker [my_app]\nubuntu   18463 18457  0 20:26 pts/0    00:00:00 gunicorn: worker [my_app]\n\n\n\nCompatibility\n\nThe gunicorn check is compatible with all major platforms.\n\n\nMetrics\n\n\n\n\ngunicorn.requests(rate every 10 seconds)\nThe rate of requests received.shown as request/second\n\n\n\n\ngunicorn.workers(gauge every 10 seconds)\nNumber of workers managed by the arbiter.shown as worker\n\n\n\n\ngunicorn.request.duration.95percentile(gauge every 10 seconds)\nThe 95th percentile of request duration time.shown as millisecond\n\n\n\n\ngunicorn.request.duration.avg(gauge every 10 seconds)\nThe average request duration time.shown as millisecond\n\n\n\n\ngunicorn.request.duration.count(rate every 10 seconds)\nThe rate of requests received.shown as request/second\n\n\n\n\ngunicorn.request.duration.max(gauge every 10 seconds)\nThe maximum request duration time.shown as millisecond\n\n\n\n\ngunicorn.request.duration.median(gauge every 10 seconds)\nThe median request duration time.shown as millisecond\n\n\n\n\ngunicorn.log.critical(rate every 10 seconds)\nThe rate of logged critical statements.shown as occurrence/second\n\n\n\n\ngunicorn.log.error(rate every 10 seconds)\nThe rate of logged errors.shown as occurrence/second\n\n\n\n\ngunicorn.log.warning(rate every 10 seconds)\nThe rate of logged warnings.shown as occurrence/second\n\n\n\n\ngunicorn.log.exception(rate every 10 seconds)\nThe rate of logged exceptions.shown as occurrence/second\n\n\n\n\ngunicorn.request.status.100(rate every 10 seconds)\nThe rate of requests that generate responses with a 100 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.101(rate every 10 seconds)\nThe rate of requests that generate responses with a 101 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.102(rate every 10 seconds)\nThe rate of requests that generate responses with a 102 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.200(rate every 10 seconds)\nThe rate of requests that generate responses with a 200 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.201(rate every 10 seconds)\nThe rate of requests that generate responses with a 201 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.202(rate every 10 seconds)\nThe rate of requests that generate responses with a 202 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.203(rate every 10 seconds)\nThe rate of requests that generate responses with a 203 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.204(rate every 10 seconds)\nThe rate of requests that generate responses with a 204 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.205(rate every 10 seconds)\nThe rate of requests that generate responses with a 205 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.206(rate every 10 seconds)\nThe rate of requests that generate responses with a 206 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.207(rate every 10 seconds)\nThe rate of requests that generate responses with a 207 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.208(rate every 10 seconds)\nThe rate of requests that generate responses with a 208 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.226(rate every 10 seconds)\nThe rate of requests that generate responses with a 226 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.300(rate every 10 seconds)\nThe rate of requests that generate responses with a 300 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.301(rate every 10 seconds)\nThe rate of requests that generate responses with a 301 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.302(rate every 10 seconds)\nThe rate of requests that generate responses with a 302 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.303(rate every 10 seconds)\nThe rate of requests that generate responses with a 303 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.304(rate every 10 seconds)\nThe rate of requests that generate responses with a 304 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.305(rate every 10 seconds)\nThe rate of requests that generate responses with a 305 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.307(rate every 10 seconds)\nThe rate of requests that generate responses with a 307 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.308(rate every 10 seconds)\nThe rate of requests that generate responses with a 308 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.400(rate every 10 seconds)\nThe rate of requests that generate responses with a 400 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.401(rate every 10 seconds)\nThe rate of requests that generate responses with a 401 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.402(rate every 10 seconds)\nThe rate of requests that generate responses with a 402 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.403(rate every 10 seconds)\nThe rate of requests that generate responses with a 403 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.404(rate every 10 seconds)\nThe rate of requests that generate responses with a 404 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.405(rate every 10 seconds)\nThe rate of requests that generate responses with a 405 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.406(rate every 10 seconds)\nThe rate of requests that generate responses with a 406 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.407(rate every 10 seconds)\nThe rate of requests that generate responses with a 407 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.408(rate every 10 seconds)\nThe rate of requests that generate responses with a 408 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.409(rate every 10 seconds)\nThe rate of requests that generate responses with a 409 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.410(rate every 10 seconds)\nThe rate of requests that generate responses with a 410 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.411(rate every 10 seconds)\nThe rate of requests that generate responses with a 411 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.412(rate every 10 seconds)\nThe rate of requests that generate responses with a 412 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.413(rate every 10 seconds)\nThe rate of requests that generate responses with a 413 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.414(rate every 10 seconds)\nThe rate of requests that generate responses with a 414 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.415(rate every 10 seconds)\nThe rate of requests that generate responses with a 415 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.416(rate every 10 seconds)\nThe rate of requests that generate responses with a 416 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.417(rate every 10 seconds)\nThe rate of requests that generate responses with a 417 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.419(rate every 10 seconds)\nThe rate of requests that generate responses with a 419 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.421(rate every 10 seconds)\nThe rate of requests that generate responses with a 421 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.422(rate every 10 seconds)\nThe rate of requests that generate responses with a 422 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.423(rate every 10 seconds)\nThe rate of requests that generate responses with a 423 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.424(rate every 10 seconds)\nThe rate of requests that generate responses with a 424 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.426(rate every 10 seconds)\nThe rate of requests that generate responses with a 426 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.428(rate every 10 seconds)\nThe rate of requests that generate responses with a 428 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.429(rate every 10 seconds)\nThe rate of requests that generate responses with a 429 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.431(rate every 10 seconds)\nThe rate of requests that generate responses with a 431 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.451(rate every 10 seconds)\nThe rate of requests that generate responses with a 451 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.500(rate every 10 seconds)\nThe rate of requests that generate responses with a 500 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.501(rate every 10 seconds)\nThe rate of requests that generate responses with a 501 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.502(rate every 10 seconds)\nThe rate of requests that generate responses with a 502 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.503(rate every 10 seconds)\nThe rate of requests that generate responses with a 503 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.504(rate every 10 seconds)\nThe rate of requests that generate responses with a 504 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.505(rate every 10 seconds)\nThe rate of requests that generate responses with a 505 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.506(rate every 10 seconds)\nThe rate of requests that generate responses with a 506 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.507(rate every 10 seconds)\nThe rate of requests that generate responses with a 507 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.508(rate every 10 seconds)\nThe rate of requests that generate responses with a 508 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.510(rate every 10 seconds)\nThe rate of requests that generate responses with a 510 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.511(rate every 10 seconds)\nThe rate of requests that generate responses with a 511 status code.shown as request/second\n\n\n\n\ngunicorn.request.status.512(rate every 10 seconds)\nThe rate of requests that generate responses with a 512 status code.shown as request/second\n\n\n\n\n\nService Checks\n\ngunicorn.is_running:\n\nReturns CRITICAL if the Agent cannot find a Gunicorn master process, or if cannot find any working or idle worker processes.\n\n\nFurther Reading\n\nTo get a better idea of how (or why) to integrate your Gunicorn apps with Datadog, check out our blog post.\n","tags":"","loc":"/integrations/gunicorn/"},{"title":"Datadog-HAProxy Integration","text":"\n\nOverview\n\n\n\nCapture HAProxy activity in Datadog to:\n\n\n  Visualize HAProxy load-balancing performance.\n  Know when a server goes down.\n  Correlate the performance of HAProxy with the rest of your applications.\n\n\n\nInstallation\n\nMake sure that stats are enabled on your HAProxy configuration. See this post for guidance on doing this.\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to HAProxy. Edit conf.d/haproxy.yaml:\n\n    init_config:\n\ninstances:\n    -   username: username\n        password: password\n        url: https://localhost/admin?stats\n\n  \n  \n    Restart the Agent\n  \n\n\n\nValidation\n\n\n  \n    Execute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\n    Checks\n======\n\n[...]\n\nhaproxy\n-------\n    - instance #0 [OK]\n    - Collected 8 metrics & 0 events\n\n  \n\n\nLearn more about how to monitor HAProxy performance metrics thanks to our series of posts. We detail the key performance metrics, how to collect them, and how to use Datadog to monitor HAProxy.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nHAProxy YAML example\nHAProxy checks.d\n\n\n\nMetrics\n\n\n\n\nhaproxy.backend_hosts(gauge)\nNumber of backend hosts.shown as host\n\n\n\n\nhaproxy.backend.bytes.in_rate(gauge)\nRate of bytes in on backend hosts.shown as byte/second\n\n\n\n\nhaproxy.backend.bytes.out_rate(gauge)\nRate of bytes out on backend hosts.shown as byte/second\n\n\n\n\nhaproxy.backend.connect.time(gauge)\nAverage connect time over the last 1024 requests.shown as millisecond\n\n\n\n\nhaproxy.backend.denied.req_rate(gauge)\nNumber of requests denied due to security concerns.shown as request/second\n\n\n\n\nhaproxy.backend.denied.resp_rate(gauge)\nNumber of responses denied due to security concerns.shown as response/second\n\n\n\n\nhaproxy.backend.errors.con_rate(gauge)\nRate of requests that encountered an error trying to connect to a backend server.shown as error/second\n\n\n\n\nhaproxy.backend.errors.resp_rate(gauge)\nRate of responses aborted due to error.shown as error/second\n\n\n\n\nhaproxy.backend.queue.current(gauge)\nNumber of requests without an assigned backend.shown as request\n\n\n\n\nhaproxy.backend.queue.time(gauge)\nAverage queue time over the last 1024 requests.shown as millisecond\n\n\n\n\nhaproxy.backend.response.1xx(gauge)\nBackend HTTP responses with 1xx code.shown as response\n\n\n\n\nhaproxy.backend.response.2xx(gauge)\nBackend HTTP responses with 2xx code.shown as response\n\n\n\n\nhaproxy.backend.response.3xx(gauge)\nBackend HTTP responses with 3xx code.shown as response\n\n\n\n\nhaproxy.backend.response.4xx(gauge)\nBackend HTTP responses with 4xx code.shown as response\n\n\n\n\nhaproxy.backend.response.5xx(gauge)\nBackend HTTP responses with 5xx code.shown as response\n\n\n\n\nhaproxy.backend.response.other(gauge)\nBackend HTTP responses with other code (protocol error).shown as response\n\n\n\n\nhaproxy.backend.response.time(gauge)\nAverage response time over the last 1024 requests (0 for TCP).shown as millisecond\n\n\n\n\nhaproxy.backend.session.current(gauge)\nNumber of active backend sessions.shown as connection\n\n\n\n\nhaproxy.backend.session.limit(gauge)\nConfigured backend session limit.shown as connection\n\n\n\n\nhaproxy.backend.session.pct(gauge)\nPercentage of sessions in use (backend.session.current/backend.session.limit * 100).shown as percent\n\n\n\n\nhaproxy.backend.session.rate(gauge)\nNumber of backend sessions created per second.shown as connection/second\n\n\n\n\nhaproxy.backend.session.time(gauge)\nAverage total session time over the last 1024 requests.shown as millisecond\n\n\n\n\nhaproxy.backend.uptime(gauge)\nNumber of seconds since the last UP<->DOWN transitionshown as second\n\n\n\n\nhaproxy.backend.warnings.redis_rate(gauge)\nNumber of times a connection to a server was retried.shown as error/second\n\n\n\n\nhaproxy.backend.warnings.retr_rate(gauge)\nNumber of times a request was redispatched to another server.shown as error/second\n\n\n\n\nhaproxy.count_per_status(gauge)\nNumber of hosts by status (UP/DOWN/NOLB/MAINT).shown as host\n\n\n\n\nhaproxy.frontend.bytes.in_rate(gauge)\nRate of bytes in on frontend hosts.shown as byte/second\n\n\n\n\nhaproxy.frontend.bytes.out_rate(gauge)\nRate of bytes out on frontend hosts.shown as byte/second\n\n\n\n\nhaproxy.frontend.denied.req_rate(gauge)\nNumber of requests denied due to security concerns.shown as request/second\n\n\n\n\nhaproxy.frontend.denied.resp_rate(gauge)\nNumber of responses denied due to security concerns.shown as response/second\n\n\n\n\nhaproxy.frontend.errors.req_rate(gauge)\nRate of request errors.shown as error/second\n\n\n\n\nhaproxy.frontend.requests.rate(gauge)\nNumber of HTTP requests per second.shown as request/second\n\n\n\n\nhaproxy.frontend.response.1xx(gauge)\nFrontend HTTP responses with 1xx code.shown as response\n\n\n\n\nhaproxy.frontend.response.2xx(gauge)\nFrontend HTTP responses with 2xx code.shown as response\n\n\n\n\nhaproxy.frontend.response.3xx(gauge)\nFrontend HTTP responses with 3xx code.shown as response\n\n\n\n\nhaproxy.frontend.response.4xx(gauge)\nFrontend HTTP responses with 4xx code.shown as response\n\n\n\n\nhaproxy.frontend.response.5xx(gauge)\nFrontend HTTP responses with 5xx code.shown as response\n\n\n\n\nhaproxy.frontend.response.other(gauge)\nFrontend HTTP responses with other code (protocol error).shown as response\n\n\n\n\nhaproxy.frontend.session.current(gauge)\nNumber of active frontend sessions.shown as connection\n\n\n\n\nhaproxy.frontend.session.limit(gauge)\nConfigured backend session limit.shown as connection\n\n\n\n\nhaproxy.frontend.session.pct(gauge)\nPercentage of sessions in use (frontend.session.current/frontend.session.limit * 100).shown as percent\n\n\n\n\nhaproxy.frontend.session.rate(gauge)\nNumber of frontend sessions created per second.shown as connection/second\n\n\n\n\n","tags":"","loc":"/integrations/haproxy/"},{"title":"Datadog-Hadoop HDFS Integration","text":"\n\nOverview\n\nCapture NameNode and DataNode HDFS metrics in Datadog to:\n\n\n  Visualize cluster health, performance and utilization.\n  Analyze and inspect individual node utilization\n\n\n\nConfiguration\n\nThese steps only apply to the Datadog Agent >= 5.7.0, please refer to the conf.d/hdfs.yaml file for older versions of the Agent.\n\n\n  \n    Configure the NameNode agent to connect to the JMX URI: Edit conf.d/hdfs_namenode.yaml\n\n    init_config:\n\ninstances:\n  #\n  # The HDFS NameNode check retrieves metrics from the HDFS NameNode's JMX\n  # interface. This check must be installed on the NameNode. The HDFS\n  # NameNode JMX URI is composed of the NameNode's hostname and port.\n  #\n  # The hostname and port can be found in the hdfs-site.xml conf file under\n  # the property dfs.http.address or dfs.namenode.http-address\n  #\n  -  hdfs_namenode_jmx_uri: http://localhost:50070\n\n  \n  \n    Configure the DataNode agent to connect to the JMX URI: Edit conf.d/hdfs_datanode.yaml\n\n    init_config:\n\ninstances:\n  #\n  # The HDFS DataNode check retrieves metrics from the HDFS DataNode's JMX\n  # interface. This check must be installed on a HDFS DataNode. The HDFS\n  # DataNode JMX URI is composed of the DataNode's hostname and port.\n  #\n  # The hostname and port can be found in the hdfs-site.xml conf file under\n  # the property dfs.datanode.http.address\n  #\n  - hdfs_datanode_jmx_uri: http://localhost:50075\n\n  \n  \n    Restart the Agent\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nHDFS NameNode YAML example\nHDFS NameNode checks.d\n\n\n\nHDFS DataNode YAML example\nHDFS DataNode checks.d\n\n\n\nValidation\n\nExecute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n  hdfs_datanode\n  -------------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n  hdfs_namenode\n  -------------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\nThe metrics available are collected using df from Spotify’s Snakebite. hdfs.in_use is calculated by dividing used by capacity.\n\n\n\n\nhdfs.namenode.capacity_total(gauge)\nTotal disk capacity in bytesshown as byte\n\n\n\n\nhdfs.namenode.capacity_used(gauge)\nDisk usage in bytesshown as byte\n\n\n\n\nhdfs.namenode.capacity_remaining(gauge)\nRemaining disk space left in bytesshown as byte\n\n\n\n\nhdfs.namenode.total_load(gauge)\nTotal load on the file system\n\n\n\n\nhdfs.namenode.fs_lock_queue_length(gauge)\nLock queue length\n\n\n\n\nhdfs.namenode.blocks_total(gauge)\nTotal number of blocksshown as block\n\n\n\n\nhdfs.namenode.max_objects(gauge)\nMaximum number of files HDFS supportsshown as object\n\n\n\n\nhdfs.namenode.files_total(gauge)\nTotal number of filesshown as file\n\n\n\n\nhdfs.namenode.pending_replication_blocks(gauge)\nNumber of blocks pending replicationshown as block\n\n\n\n\nhdfs.namenode.under_replicated_blocks(gauge)\nNumber of under replicated blocksshown as block\n\n\n\n\nhdfs.namenode.scheduled_replication_blocks(gauge)\nNumber of blocks scheduled for replicationshown as block\n\n\n\n\nhdfs.namenode.pending_deletion_blocks(gauge)\nNumber of pending deletion blocksshown as block\n\n\n\n\nhdfs.namenode.num_live_data_nodes(gauge)\nTotal number of live data nodesshown as node\n\n\n\n\nhdfs.namenode.num_dead_data_nodes(gauge)\nTotal number of dead data nodesshown as node\n\n\n\n\nhdfs.namenode.num_decom_live_data_nodes(gauge)\nNumber of decommissioning live data nodesshown as node\n\n\n\n\nhdfs.namenode.num_decom_dead_data_nodes(gauge)\nNumber of decommissioning dead data nodesshown as node\n\n\n\n\nhdfs.namenode.volume_failures_total(gauge)\nTotal volume failures\n\n\n\n\nhdfs.namenode.estimated_capacity_lost_total(gauge)\nEstimated capacity lost in bytesshown as byte\n\n\n\n\nhdfs.namenode.num_decommissioning_data_nodes(gauge)\nNumber of decommissioning data nodesshown as node\n\n\n\n\nhdfs.namenode.num_stale_data_nodes(gauge)\nNumber of stale data nodesshown as node\n\n\n\n\nhdfs.namenode.num_stale_storages(gauge)\nNumber of stale storages\n\n\n\n\nhdfs.namenode.missing_blocks(gauge)\nNumber of missing blocksshown as block\n\n\n\n\nhdfs.namenode.corrupt_blocks(gauge)\nNumber of corrupt blocksshown as block\n\n\n\n\nhdfs.datanode.dfs_remaining(gauge)\nThe remaining disk space left in bytesshown as byte\n\n\n\n\nhdfs.datanode.dfs_capacity(gauge)\nDisk capacity in bytesshown as byte\n\n\n\n\nhdfs.datanode.dfs_used(gauge)\nDisk usage in bytesshown as byte\n\n\n\n\nhdfs.datanode.cache_capacity(gauge)\nCache capacity in bytesshown as byte\n\n\n\n\nhdfs.datanode.cache_used(gauge)\nCache used in bytesshown as byte\n\n\n\n\nhdfs.datanode.num_failed_volumes(gauge)\nNumber of failed volumes\n\n\n\n\nhdfs.datanode.last_volume_failure_date(gauge)\nThe date/time of the last volume failure in milliseconds since epochshown as millisecond\n\n\n\n\nhdfs.datanode.estimated_capacity_lost_total(gauge)\nThe estimated capacity lost in bytesshown as byte\n\n\n\n\nhdfs.datanode.num_blocks_cached(gauge)\nThe number of blocks cachedshown as block\n\n\n\n\nhdfs.datanode.num_blocks_failed_to_cache(gauge)\nThe number of blocks that failed to cacheshown as block\n\n\n\n\nhdfs.datanode.num_blocks_failed_to_uncache(gauge)\nThe number of failed blocks to remove from cacheshown as block\n\n\n\n\nYou may experience reduced functionality if using hadoop before v2.2.0. For earlier versions, we need to use Snakebite v1.3.9. If using HA Mode, you may want to upgrade.\n","tags":"","loc":"/integrations/hdfs/"},{"title":"Datadog-HipChat Integration","text":"\n\nOverview\n\nConnect HipChat to Datadog in order to:\n\n\n  Receive notifications when someone posts on your stream.\n  Receive metric alerts and see graphs within Hipchat.\n\n\n\nInstallation\n\nNo installation steps are required for this integration\n\n\nConfiguration\n\n\n  \nCreate a new access token for Datadog. Only notification level acccess is required.\n  Copy your key and enter it in the HipChat integration tile.\n  Enter the room names you wish to allow access to from Datadog.\nTick the checkbox if you want to be notified for every comment, in all configured rooms. If the checkbox is left unchecked, you will need to use the @hipchat-chat_name syntax.\n  Save your configuration\n\n\nYou can now share graphs or send alerts to HipChat rooms using the syntax @hipchat-chat_name\n\n*NOTICE : If your chat name contains special characters such as commas or brackets, they’ll be escaped when sending notifications with the @ handle. You shouldn’t have to worry about that, the autocomplete box automatically takes care of escaping chat names.\n\n\nMetrics\n\nThis integration does not provide metrics.\n\n","tags":"","loc":"/integrations/hipchat/"},{"title":"Datadog-Honeybadger Integration","text":"\n\nOverview\n\nConnect Honeybadger to Datadog to:\n\n\n  See errors in the stream, in real time\n  Search for errors in your graphs\n  Discuss errors with your team\n  Be super awesome\n\n\n\n\n\nInstallation\n\nTo capture errors from Honeybadger:\n\n\n  Open your Honeybadger project list.\n  Click on “Settings” for the project you want to monitor.\n  Click on “Alerts & Integrations”.\n  Select “Datadog” as a new integration.\n  Add your API key.\n  Save the integration.\n\n\n\nConfiguration\n\nClick the Install Integration button on the Honeybadger Integration Tile. configuration steps are required for this integration.\n\n","tags":"","loc":"/integrations/honeybadger/"},{"title":"HTTP check","text":"\n\nOverview\n\nHTTP checks run in the agent and can verify whether or not a website is up or down, responds in a certain time, and/or contains specific text on the page.\n\nAlso see the related TCP Checks\n\n\nInstallation\n\nNo installation is required\n\n\nConfiguration\n\nEdit the http_check.yaml file in your agent’s conf.d directory. The following yaml file will check the Datadog home page for the text “Cloud-Scale Monitoring” within 5 seconds. The response time will be available in the metric network.http.response_time.\n\ninit_config:\n\ninstances:\n  - name: My first service\n    url: https://datadoghq.com\n    timeout: 5\n\n    content_match: 'Cloud-Scale Monitoring'\n    collect_response_time: true\n    skip_event: true\n\n    tags:\n      - url:datadoghq.com\n      - env:production\n\n\nOther settings available include:\n\n\n  \n    \n      Setting\n      Description\n    \n  \n  \n    \n      url\n      The URL to test.\n    \n    \n      timeout\n      The time in seconds to allow for a response.\n    \n    \n      method\n      The HTTP method. This setting defaults to GET, though many other HTTP methods are supported, including POST and PUT.\n    \n    \n      data\n      The data option is only available when using the POST method. Data should be included as key-value pairs and will be sent in the body of the request.\n    \n    \n      content_match\n      A string or Python regular expression. The HTTP check will search for this value in the response and will report as DOWN if the string or expression is not found.\n    \n    \n      \nusername & password\n\n      If your service uses basic authentication, you can provide the username and password here.\n    \n    \n      http_response_status_code\n      A string or Python regular expression for an HTTP status code. This check will report DOWN for any status code that does not match. This defaults to 1xx, 2xx and 3xx HTTP status codes. For example: 401 or 4\\d\\d.\n    \n    \n      include_content\n      When set to true, the check will include the first 200 characters of the HTTP response body in notifications. The default value is false.\n    \n    \n      collect_response_time\n      By default, the check will collect the response time (in seconds) as the metric network.http.response_time. To disable, set this value to false.\n    \n    \n      disable_ssl_validation\n      This setting will skip SSL certificate validation and is enabled by default. If you require SSL certificate validation, set this to false.\n    \n    \n      ignore_ssl_warning\n      When SSL certificate validation is enabled (see setting above), this setting will allow you to disable security warnings.\n    \n    \n      ca_certs\n      This setting will allow you to override the default certificate path as specified in init_config\n\n    \n    \n      check_certificate_expiration\n      When check_certificate_expiration is enabled, the service check will check the expiration date of the SSL certificate. Note that this will cause the SSL certificate to be validated, regardless of the value of the disable_ssl_validation setting.\n    \n    \n      \ndays_warning & days_critical\n\n      When check_certificate_expiration is enabled, these settings will raise a warning or critical alert when the SSL certificate is within the specified number of days from expiration.\n    \n    \n      headers\n      This parameter allows you to send additional headers with the request. Please see the example YAML file for additional information and caveats.\n    \n    \n      skip_event\n      When enabled, the check will not create an event. This is useful to avoid duplicates with a server side service check. This defaults to false.\n    \n    \n      no_proxy\n      If set, the check will bypass proxy settings and attempt to reach the check url directly. This defaults to false.\n    \n    \n      allow_redirects\n      This setting allows the service check to follow HTTP redirects and defaults to true.\n    \n    \n      tags\n      A list of arbitrary tags that will be associated with the check. For more information about tags, please see our Guide to tagging and blog post, The power of tagged metrics\n\n    \n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nHTTP Check YAML example\nHTTP Check checks.d\n\n\n\nValidation\n\nExecute the agent info command and verify that the integration check was successful. The output should contain a section similar to the following:\n\nhttp_check\n----------\n  - instance #0 [OK]\n  - Collected 0 metrics, 0 events & 1 service check\n\n","tags":"","loc":"/integrations/http_check/"},{"title":"Datadog-IIS Integration","text":"\n\nOverview\n\n\n\nConnect IIS to Datadog in order to:\n\n\n  Visualize your web server performance.\n  Correlate the performance of IIS with the rest of your applications.\n\n\n\nInstallation\n\n\n  \n    In order to be sure that IIS performance counters will be sent to WMI, resync the WMI counters.\n\n    On Windows <= 2003 (or equivalent) run the following in cmd.exe:\n\n    winmgmt /clearadap\nwinmgmt /resyncperf\n\n\n    On Windows >= 2008 (or equivalent) run the following in cmd.exe:\n\n    winmgmt /resyncperf\n\n  \n\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to IIS. Edit conf.d/iis.yaml and add this server to instances with (optional) tags:\n\n    init_config:\n\ninstances:\n  - host: . # \".\" means the current host\n    tags:\n      - mytag1\n      - mytag2\n\n  \n  \n    Restart the Agent using the Agent Manager (or restart the service)\n  \n\n\n\nConfiguration Options\n\nBy default, this check will run against a single instance - the current machine that\nthe Agent is running on. It will check the WMI performance counters for IIS on that machine.\n\nIf you want to check other remote machines as well, you can add one instance per host.\nNote: If you also want to check the counters on the current machine, you will have\nto create an instance with empty params.\n\nThe optional provider parameter allows to specify a WMI provider (default to 32\non Datadog Agent 32-bit or 64). It is used to request WMI data from the non-default\nprovider. Available options are: 32 or 64. For more information,\nreview this MSDN article.\n\nThe sites parameter allows you to specify a list of sites you want to read metrics\nfrom. With sites specified, metrics will be tagged with the site name. If you don’t\ndefine any sites, the check will pull the aggregate values across all sites.\n\nHere’s an example of configuration that would check the current machine and a remote machine\ncalled MYREMOTESERVER. For the remote host we are only pulling metrics from the default site.\n\n- host: .\n  tags:\n    - myapp1\n  sites:\n    - Default Web Site\n- host: MYREMOTESERVER\n  username: MYREMOTESERVER\\fred\n  password: mysecretpassword\n  is_2008: false\n\n\n\n  \nis_2008 (Optional) - NOTE: because of a typo in IIS6/7 (typically on W2K8) where perfmon reports TotalBytesTransferred as TotalBytesTransfered, you may have to enable this to grab the IIS metrics in that environment.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nIIS YAML example\nIIS checks.d\n\n\n\nValidation\n\nCheck the info page in the Agent Manager and verify that the integration check has passed. It should display a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  iis\n  ---\n      - instance #0 [OK]\n      - Collected 20 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\niis.uptime(gauge)\nThe amount of time the IIS server has been runningshown as second\n\n\n\n\niis.net.bytes_sent(gauge)\nThe number of bytes served per secondshown as byte/second\n\n\n\n\niis.net.bytes_rcvd(gauge)\nThe number of bytes received per secondshown as byte/second\n\n\n\n\niis.net.bytes_total(gauge)\nThe total number of bytes transferred per secondshown as byte/second\n\n\n\n\niis.net.num_connections(gauge)\nThe number of active connectionsshown as connection\n\n\n\n\niis.net.files_sent(gauge)\nThe number of files sent per secondshown as file/second\n\n\n\n\niis.net.files_rcvd(gauge)\nThe number of files received per secondshown as file/second\n\n\n\n\niis.net.connection_attempts(gauge)\nThe number of connection attempts per secondshown as connection/second\n\n\n\n\niis.httpd_request_method.get(gauge)\nThe number of GET requests per secondshown as request/second\n\n\n\n\niis.httpd_request_method.post(gauge)\nThe number of POST requests per secondshown as request/second\n\n\n\n\niis.httpd_request_method.head(gauge)\nThe number of HEAD requests per secondshown as request/second\n\n\n\n\niis.httpd_request_method.put(gauge)\nThe number of PUT requests per secondshown as request/second\n\n\n\n\niis.httpd_request_method.delete(gauge)\nThe number of DELETE requests per secondshown as request/second\n\n\n\n\niis.httpd_request_method.options(gauge)\nThe number of OPTIONS requests per secondshown as request/second\n\n\n\n\niis.httpd_request_method.trace(gauge)\nThe number of TRACE requests per secondshown as request/second\n\n\n\n\niis.errors.not_found(gauge)\nThe number of not found errors per second (typically reported as an HTTP 404 response code)shown as error/second\n\n\n\n\niis.errors.locked(gauge)\nThe number of locked errors per second (typically reported as an HTTP 423 response code)shown as error/second\n\n\n\n\niis.users.anon(gauge)\nThe number of requests from users over an anonymous connection per secondshown as request/second\n\n\n\n\niis.users.nonanon(gauge)\nThe number of requests from users over a non-anonymous connection per secondshown as request/second\n\n\n\n\niis.requests.cgi(gauge)\nThe number of Common Gateway Interface requests executed per secondshown as request/second\n\n\n\n\niis.requests.isapi(gauge)\nThe number of ISAPI requests executed per secondshown as request/second\n\n\n\n\n","tags":"","loc":"/integrations/iis/"},{"title":"Datadog-Immunio Integration","text":"\n\nOverview\n\n\n\nConnect IMMUNIO’s advanced application security monitoring with Datadog to visualize the impact Attacks have on your web application, and monitor IMMUNIO’s automatic protection.\n\nIMMUNIO monitors your applications to detect and defend against all of the following:\n\n\n  Account Takeover attacks like Brute Force, Credential Stuffing, etc.,\n  Code-level attacks like XSS, SQLi, and Remote Command Execution,\n  Custom business-level attacks like credit card fraud and other abuse,\n  General bad behaviour like scanning and scraping.\n\n\n\nInstallation\n\n\n  Login to your IMMUNIO account.\n  Navigate to the integrations setup page.\n\n\n  Click “Add an API Key”.\n\n\n  Add your API key.\n\n\n\nConfiguration\n\nNo configuration steps are required for this integration.\n\n\nValidation\n\nTo validate your installation and configuration, restart the agent and execute the info command. The output should contain a section similar to the following:\n\nChecks\n======\n  [...]\n  immunio\n  -----\n      - instance #0 [OK]\n      - Collected 4 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\nimmunio.requests(count)\nThe total number of requests inspected by IMMUNIO.shown as request/second\n\n\n\n\nimmunio.attacks(count)\nThe count and breakdown of all the detected attacks for your account. Broken down by App and Environment.shown as occurrence/second\n\n\n\n\nimmunio.failed_login(count)\nThe number of failed login attempts for your account. Broken down by App and Environment.shown as occurrence/second\n\n\n\n\nimmunio.mitigated.captcha(count)\nThe number of suspicious requests that were stopped with a CAPTCHA challenge.shown as occurrence/second\n\n\n\n\n\nEvents\n\nNo events are included with this integration.\n\n","tags":"","loc":"/integrations/immunio/"},{"title":"Get Started with Datadog","text":"\nWelcome to Datadog’s integration documentation.\n\nThe pages below walk through how to integrate, what to expect, and how to troubleshoot.\n\nEach page is organized as follows:\n\n\n  \nOverview - This section provides an overview of the integration.\n  \nInstallation - This section explains what you need to do on the host to prepare for the integration. Examples include creating users or permissions, opening ports, and more. If there is nothing you need to do, this section might be omitted.\n  \nConfiguration - This section covers everything you need to do in the Datadog platform. This may include clicking install on the tile, editing the yaml file, and entering API keys.\n  \nValidation - This section shows you how to validate that the integration is in fact working correctly.\n  \nUsage - With some integrations, there are additional steps required to take full advantage of the integration. This could include creating dashboards, monitors, or using an API. This section is sometimes omitted.\n  \nMetrics - This is a list of all the metrics provided by the integration\n  \nCompatibility - This section will include which versions the integration has been tested and validated on.\n\n\nWe are in the process of moving all the integration docs to this newer format so there will continue to be some integrations written in the older style.\n\n\n\n\n  \n    ActiveMQ\n\n    Airbrake\n\n    Amazon Web Services\n\n    Ansible\n\n    Apache\n\n    Apache Kafka\n\n    AWS API Gateway\n\n    AWS Auto Scaling\n\n    AWS Billing\n\n    AWS CloudFront\n\n    AWS CloudSearch\n\n    AWS CloudTrail\n\n    AWS DynamoDB\n\n    AWS EC2\n\n    AWS ECS\n\n    AWS Elastic Beanstalk\n\n    AWS Elastic Block Store\n\n    AWS Elastic File System\n\n    AWS Elastic Map Reduce\n\n    AWS ElastiCache\n\n    AWS ELB\n\n    AWS ES\n\n    AWS Firehose\n\n    AWS Internet of Things\n\n    AWS Key Management Service\n\n    AWS Kinesis\n\n    AWS Lambda\n\n    AWS Machine Learning\n\n    AWS OpsWorks\n\n    AWS Polly\n\n    AWS RDS\n\n    AWS Redshift\n\n    AWS Route 53\n\n    AWS S3\n\n    AWS SES\n\n    AWS Simple Workflow Service\n\n    AWS SNS\n\n    AWS SQS\n\n    AWS Storage Gateway\n\n    AWS Web Application Firewall\n\n    AWS Workspaces\n\n    Bitbucket\n\n    btrfs\n\n    Bugsnag\n\n    Cacti\n\n    Campfire\n\n    Capistrano\n\n    Cassandra\n\n    Catchpoint\n\n    Ceph\n\n    Chatwork\n\n    Chef\n\n    Consul\n\n    Couchbase\n\n    CouchDB\n\n    Desk\n\n    Directory Check\n\n    Disk Check\n\n    DNS Service Check\n\n    Docker\n\n    Dyn\n\n    Elasticsearch\n\n    etcd\n\n    Event Viewer\n\n    ExpressJS\n\n    Fabric\n\n    Fastly\n\n    Flowdock\n\n    Fluentd\n\n    Gearman\n\n    Git\n\n    Github\n\n    Go Expvar\n\n    Google App Engine\n\n    Google BigQuery\n\n    Google Cloud Functions\n\n    Google Cloud Platform\n\n    Google CloudSQL\n\n    Google Compute Engine\n\n    Google Container Engine\n\n    Google Datastore\n\n    Google Firebase\n\n    Google Machine Learning\n\n    Google Pub/Sub\n\n    Google Spanner\n\n    Google Stackdriver Logging\n\n    Google Storage\n\n    Google VPN\n\n    gunicorn\n\n    Hadoop HDFS\n\n    Hadoop MapReduce\n\n    Hadoop YARN\n\n    HAProxy\n\n    HipChat\n\n    Honeybadger\n\n    HTTP Check\n\n    IIS\n\n    Immunio\n\n    Java/JMX\n\n    Jenkins\n\n    Jira\n\n    Kong\n\n    Kubernetes\n\n    Kyoto Tycoon\n\n    Lighttpd\n\n    Marathon\n\n    Memcached\n\n    Mesos\n\n    Microsoft Azure\n\n    Microsoft Azure App Service\n\n    Microsoft Azure Batch Service\n\n    Microsoft Azure Event Hub Service\n\n    Microsoft Azure IOT Hub\n\n    Microsoft Azure Logic App\n\n    Microsoft Azure Redis Cache\n\n    Microsoft Azure SQL Database\n\n    Microsoft Azure SQL Elastic Pool\n\n    Microsoft Azure Storage\n\n    Microsoft Azure Virtual Machine Scale Set\n\n    Microsoft Azure VM\n\n    MongoDB\n\n    Moxtra\n\n    mParticle\n\n    MySQL\n\n    Nagios\n\n    Network Check\n\n    New Relic\n\n    NGINX\n\n    NodeJS\n\n    NTP Check\n\n    OpenStack\n\n    OpsGenie\n\n    Opsmatic\n\n    PagerDuty\n\n    PaperTrail\n\n    PGBouncer\n\n    PHP\n\n    PHP-FPM\n\n    Pingdom\n\n    Pivotal Tracker\n\n    Postfix\n\n    PostgreSQL\n\n    PowerDNS Recursor\n\n    Process Check\n\n    Puppet\n\n    Python\n\n    RabbitMQ\n\n    Redis\n\n    Redmine\n\n    Riak\n\n    RiakCS\n\n    Rollbar\n\n    RSS\n\n    Ruby\n\n    Sentry\n\n    ServiceNow\n\n    Slack\n\n    SNMP\n\n    Solr\n\n    Spark\n\n    Splunk\n\n    SQL Server\n\n    ssh\n\n    StatsD\n\n    StatusPageIO\n\n    Sumo Logic\n\n    Supervisor\n\n    System Check\n\n    System Core\n\n    TCP Check\n\n    TCP RTT Check\n\n    TeamCity\n\n    TokuMX\n\n    Tomcat\n\n    Varnish\n\n    VictorOps\n\n    VMware\n\n    Webhooks\n\n    Windows Services\n\n    WMI\n\n    Zendesk\n\n    Zookeeper\n\n\n\n","tags":"","loc":"/integrations/"},{"title":"Datadog-Java/JMX Integration","text":"\n\nIntroduction\n\nThe JMX integration collects metrics from applications that expose JMX metrics.\n\nA lightweight Java plugin named JMXFetch is called by the Datadog Agent to connect to the MBean Server and to collect these metrics. This plugin sends metrics to the Datadog Agent using the Dogstatsd server running within the Agent. This functionality is also leveraged in the integrations for ActiveMQ, Cassandra, Solr, and Tomcat.\n\nJMXFetch also sends service checks that report on the status of your monitored instances.\n\nJMX Checks have a limit of 350 metrics per instance which should be enough to satisfy your needs as it’s  easy to customize which metrics you want to collect.\n\n\nInstallation\n\nMake sure you can open a JMX remote connection.\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect using JMX and edit it according to your needs. Here is a sample jmx.yaml file:\n\n    init_config:\n  custom_jar_paths: # optional\n    - /path/to/custom/jarfile.jar\n  #is_jmx: true\n\ninstances:\n  - host: localhost\n    port: 7199\n    user: username\n    password: password\n\n    jmx_url: \"service:jmx:rmi:///jndi/rmi://myhost.host:9999/custompath\" # optional\n\n    name: jmx_instance  # optional\n    java_bin_path: /path/to/java\n    java_options: \"-Xmx200m -Xms50m\"\n    trust_store_path: /path/to/trustStore.jks\n    trust_store_password: password\n\n    process_name_regex: .*process_name.*\n    tools_jar_path: /usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar\n    refresh_beans: 600 # optional (in seconds)\n    tags:\n      env: stage\n      newTag: test\n\n    conf:\n      - include:\n          domain: my_domain\n          bean:\n            - my_bean\n            - my_second_bean\n          attribute:\n            attribute1:\n              metric_type: counter\n              alias: jmx.my_metric_name\n            attribute2:\n              metric_type: gauge\n              alias: jmx.my2ndattribute\n      - include:\n          domain: 2nd_domain\n        exclude:\n          bean:\n            - excluded_bean\n      - include:\n          domain_regex: regex_on_domain\n        exclude:\n          bean_regex:\n            - regex_on_excluded_bean\n\n  \n\n\n\nConfiguration Options\n\n\n  \ncustom_jar_paths (Optional) - Allows specifying custom jars that will be added to the classpath of the agent’s JVM.\n  \njmx_url - (Optional) - If the agent needs to connect to a non-default JMX URL, specify it here instead of a host and a port. If you use this you need to specify a ‘name’ for the instance.\n  \nis_jmx (Optional) - Allows creating different configuration files for each application rather than using a single long jmx file. Include the option in each configuration file.\n  \nname - (Optional) - Used in conjunction with jmx_url.\n  \njava_bin_path - (Optional) - Should be set if the agent cannot find your java executable.\n  \njava_options - (Optional) - Java JVM options\n  \ntrust_store_path and trust_store_password - (Optional) - Should be set if ssl is enabled.\n  \nprocess_name_regex - (Optional) - Instead of specifying a host and port or jmx_url, the agent can connect using the attach api. This requires the JDK to be installed and the path to tools.jar to be set.\n  \ntools_jar_path - (Optional) - To be set when process_name_regex is set.\n  \nrefresh_beans - (Optional) - Refresh period for refreshing the matching MBeans list.  Default is 600 seconds.  Decreasing this value may result in increased CPU usage.\n\n\nThe conf parameter is a list of dictionaries. Only 2 keys are allowed in this dictionary:\n\n\n  \ninclude (mandatory): Dictionary of filters, any attribute that matches these filters will be collected unless it also matches the “exclude” filters (see below)\n  \nexclude (optional): Another dictionary of filters. Attributes that match these filters won’t be collected\n\n\nFor a given bean, metrics get tagged in the following manner:\n\nmydomain:attr0=val0,attr1=val1\n\n\nYour metric will be mydomain (or some variation depending on the attribute inside the bean) and have the tags attr0:val0, attr1:val1, domain:mydomain.\n\nIf you specify an alias in an include key that is formatted as camel case, it will be converted to snake case. For example, MyMetricName will be shown in Datadog as my_metric_name.\n\n\nDescription of the filters\n\nEach include or exclude dictionary supports the following keys:\n\n\n  \ndomain: a list of domain names (e.g. java.lang)\n  \ndomain_regex: a list of regexes on the domain name (e.g. java\\.lang.*)\n  \nbean or bean_name: A list of full bean names (e.g. java.lang:type=Compilation)\n  \nbean_regex: A list of regexes on the full bean names (e.g. java\\.lang.*[,:]type=Compilation.*)\n  \nattribute: A list or a dictionary of attribute names (see below for more details)\n\n\nThe regexes defined in domain_regex and bean_regex must conform to Java’s regular expression format.\n\nThe domain_regex and bean_regex filters were added in version 5.5.0.\n\nOn top of these parameters, the filters support “custom” keys which means that you can filter by bean parameters. For example, if you want to collect metrics regarding the Cassandra cache, you could use the type: - Caches filter:\n\nconf:\n- include:\n    domain: org.apache.cassandra.db\n    type:\n      - Caches\n\n\n\nThe attribute filter\n\nThe attribute filter can accept two types of values:\n\n\n  \n    A dictionary whose keys are attributes names:\n\n    conf:\n  - include:\n      attribute:\n        maxThreads:\n          alias: tomcat.threads.max\n          metric_type: gauge\n        currentThreadCount:\n          alias: tomcat.threads.count\n          metric_type: gauge\n        bytesReceived:\n          alias: tomcat.bytes_rcvd\n          metric_type: counter\n\n  \n\n\nIn that case you can specify an alias for the metric that will become the metric name in Datadog. You can also specify the metric type either a gauge or a counter. If you choose counter, a rate per second will be computed for this metric.\n\n\n  \n    A list of attributes names:\n\n    conf:\n  - include:\n      domain: org.apache.cassandra.db\n      attribute:\n        - BloomFilterDiskSpaceUsed\n        - BloomFilterFalsePositives\n        - BloomFilterFalseRatio\n        - Capacity\n        - CompressionRatio\n        - CompletedTasks\n        - ExceptionCount\n        - Hits\n        - RecentHitRate\n\n  \n\n\nIn that case:\n\n\n  The metric type will be a gauge\n  The metric name will be jmx.[DOMAIN_NAME].[ATTRIBUTE_NAME]\n\n\nHere is another filtering example:\n\ninstances:\n  - host: 127.0.0.1\n    name: jmx_instance\n    port: 9999\n\ninit_config:\n  conf:\n    - include:\n        bean: org.apache.cassandra.metrics:type=ClientRequest,scope=Write,name=Latency\n        attribute:\n          - OneMinuteRate\n          - 75thPercentile\n          - 95thPercentile\n          - 99thPercentile\n\n\n\nNote\n\nList of filters is only supported in Datadog Agent > 5.3.0. If you are using an older version, please use singletons and multiple include statements instead.\n\n# Datadog Agent > 5.3.0\n  conf:\n    - include:\n        domain: domain_name\n        bean:\n          - first_bean_name\n          - second_bean_name\n...\n\n\n# Older Datadog Agent versions\n  conf:\n    - include:\n        domain: domain_name\n        bean: first_bean_name\n    - include:\n        domain: domain_name\n        bean: second_bean_name\n...\n\n\n\nCommands to view the metrics that are available:\n\nThe datadog-agent jmx command was added in version 4.1.0.\n\n\n  List attributes that match at least one of your instances configuration:\nsudo /etc/init.d/datadog-agent jmx list_matching_attributes\n\n  List attributes that do match one of your instances configuration but that are not being collected because it would exceed the number of metrics that can be collected:\nsudo /etc/init.d/datadog-agent jmx list_limited_attributes\n\n  List attributes that will actually be collected by your current instances configuration:\nsudo /etc/init.d/datadog-agent jmx list_collected_attributes\n\n  List attributes that don’t match any of your instances configuration:\nsudo /etc/init.d/datadog-agent jmx list_not_matching_attributes\n\n  List every attributes available that has a type supported by JMXFetch:\nsudo /etc/init.d/datadog-agent jmx list_everything\n\n  Start the collection of metrics based on your current configuration and display them in the console:\nsudo /etc/init.d/datadog-agent jmx collect\n\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\n\n  Java/JMX YAML example\n\n\n\n\n\nValidation\n\nJMX Checks have a default configuration that will collect 11 metrics from your JMX application. A few of these metrics are: jvm.heap_memory, jvm.non_heap_memory, jvm.gc.cms.count… So seeing these metrics is a sign that JMXFetch is properly running.\n\n\nMetrics\n\n\n\n\njvm.heap_memory(gauge every 10 seconds)\nThe total Java heap memory used.shown as byte\n\n\n\n\njvm.heap_memory_committed(gauge every 10 seconds)\nThe total Java heap memory committed to be used.shown as byte\n\n\n\n\njvm.heap_memory_init(gauge every 10 seconds)\nThe initial Java heap memory allocated.shown as byte\n\n\n\n\njvm.heap_memory_max(gauge every 10 seconds)\nThe maximum Java heap memory available.shown as byte\n\n\n\n\njvm.non_heap_memory(gauge every 10 seconds)\nThe total Java non-heap memory used.shown as byte\n\n\n\n\njvm.non_heap_memory_committed(gauge every 10 seconds)\nThe total Java non-heap memory committed to be used.shown as byte\n\n\n\n\njvm.non_heap_memory_init(gauge every 10 seconds)\nThe initial Java non-heap memory allocated.shown as byte\n\n\n\n\njvm.non_heap_memory_max(gauge every 10 seconds)\nThe maximum Java non-heap memory available.shown as byte\n\n\n\n\njvm.thread_count(gauge every 10 seconds)\nThe number of live threads.shown as thread\n\n\n\n\njvm.gc.cms.count(gauge every 10 seconds)\nThe total number of garbage collections that have occurred.\n\n\n\n\njvm.gc.parnew.time(gauge every 10 seconds)\nThe approximate accumulated garbage collection time elapsed.shown as millisecond\n\n\n\n\n\nTroubleshooting\n\n\nThe 350 metric limit\n\nDue to the nature of these integrations, it is possible to submit an extremely high number of metrics directly to Datadog. What we’ve found in speaking with many customers is that some of these metrics are not needed; thus, we’ve set the limit at 350 metrics.\n\nTo see what you’re collecting and get below the limit, begin by using the commands seen above to investigate what metrics are available. We then recommend creating filters to refine what metrics are collected. If you believe you need more than 350 metrics, please reach out to support@datadoghq.com.\n\n\nJava Path\n\nThe agent does not come with a bundled JVM, but will use the one installed on your system. Therefore you must make sure that the Java home directory is present in the path of the user running the agent.\n\nAlternatively, you can specify the JVM path in the integration’s configuration file:\n\njava_bin_path: /path/to/java\n\n\n\nMonitoring JBoss/WildFly applications\n\nThe following instructions will work on version 5.6.0 (and higher) of the Agent\n\nJBoss/WildFly applications expose JMX over a specific protocol (Remoting JMX) that is not bundled by default with JMXFetch. To allow JMXFetch to connect to these applications, configure it as follows:\n\n\n  Locate the jboss-cli-client.jar file on your JBoss/WildFly server (by default, its path should be $JBOSS_HOME/bin/client/jboss-cli-client.jar).\n  If JMXFetch is running on a different host than the JBoss/WildFly application, copy jboss-cli-client.jar to a location on the host JMXFetch is running on.\n  Add the path of the jar to the init_config section of your configuration:\n\n\n# Datadog Agent >= 5.6.0\n\ninit_config:\n  custom_jar_paths:\n    - /path/to/jboss-cli-client.jar\n\n\n\n  Specify a custom URL that JMXFetch will connect to, in the instances section of your configuration:\n\n\n# Datadog Agent >= 5.6.0\n\n# The jmx_url may be different depending on the version of JBoss/WildFly you're using\n# and the way you've set up JMX on your server\n# Please refer to the relevant documentation of JBoss/WildFly for more information\ninstances:\n  - jmx_url: \"service:jmx:remoting-jmx://localhost:9999\"\n    name: jboss-application  # Mandatory, but can be set to any value,\n                             # will be used to tag the metrics pulled from that instance\n\n\n\n  Restart the agent: sudo /etc/init.d/datadog-agent\n\n\n\n\nMonitoring Tomcat with JMX Remote Lifecycle Listener enabled\n\nThe following instructions will work on version 5.6.0 (and higher) of the Agent\n\nIf you’re using Tomcat with JMX Remote Lifecycle Listener enabled (see the Tomcat documentation for more information), JMXFetch will need some extra setup to be able to connect to your Tomcat application.\n\n\n  Locate the catalina-jmx-remote.jar file on your Tomcat server (by default, its path should be $CATALINA_HOME/lib).\n  If JMXFetch is running on a different host than the Tomcat application, copy catalina-jmx-remote.jar to a location on the host JMXFetch is running on.\n  Add the path of the jar to the init_config section of your configuration:\n\n\n# Datadog Agent >= 5.6.0\n\ninit_config:\n  custom_jar_paths:\n    - /path/to/catalina-jmx-remote.jar\n\n\n\n  Specify a custom URL that JMXFetch will connect to, in the instances section of your configuration:\n\n\n# Datadog Agent >= 5.6.0\n\n# The jmx_url may be different depending on the way you've set up JMX on your Tomcat server\ninstances:\n  - jmx_url: \"service:jmx:rmi://:10002/jndi/rmi://:10001/jmxrmi\"\n    name: tomcat-application  # Mandatory, but can be set to any arbitrary value,\n                              # will be used to tag the metrics pulled from that instance\n\n\n\n  Restart the agent: sudo /etc/init.d/datadog-agent\n\n\n\n","tags":"","loc":"/integrations/java/"},{"title":"Datadog-Jenkins Integration","text":"\n\nOverview\n\n\nA Jenkins plugin used to forward metrics, events, and service checks to an account at Datadog, automatically.\n\nNote: The Jenkins Agent Integration is Deprecated: The integration in the Datadog agent for Jenkins has been deprecated in favor of the open-source Jenkins plugin. This document refers to installing the Jenkins plugin. For more details about the plugin, refer to the GitHub repo.\n\n\nInstallation\n\nThis plugin requires Jenkins 1.580.1 or newer.\n\nThis plugin can be installed from the Update Center (found at Manage Jenkins -> Manage Plugins) in your Jenkins installation. \n\n\n  Select the Available tab, search for Datadog and look for Datadog Plugin. \n  Once you find it, check the checkbox next to it, and install via your preference by using one of the two install buttons at the bottom of the screen. \n  \n    Check to see that the plugin has been successfully installed by searching for Datadog Plugin on the Installed tab. If the plugin has been successfully installed, then continue on to the configuration step, described below.\n\n    Note: If you do not see the version of Datadog Plugin that you are expecting, make sure you have run Check Now from the Manage Jenkins -> Manage Plugins screen.\n  \n  To configure your newly installed Datadog Plugin, simply navigate to the Manage Jenkins -> Configure System page on your Jenkins installation. \n  Once there, scroll down to find the Datadog Plugin section. \n  \n    Find your API Key from the API Keys page on your Datadog account, and copy/paste it into the API Key textbox on the Jenkins configuration screen. \n\n    You can test that your API Key works by pressing the Test Key button, on the Jenkins configuration screen, directly below the API Key textbox. \n  \n  Once your configuration changes are finished, simply save them, and you’re good to go!\n\n\n\nConfiguration\n\nNo configuration steps are required for this integration.\n\n\nValidation\n\nYou will start to see Jenkins events in the Event Stream when the plugin is up and running.\n\n\nUsage\n\n\nMetrics\n\n\n  \n    \n      \njenkins.job.duration(gauge)\n      Build duration shown as seconds\n\n    \n    \n      \njenkins.job.completed(count)\n      Jobs completed\n    \n  \n\n\n\nEvents\n\nThe following events are generated by the plugin:\n\n\n  Started build\n  Finished build\n\n\n","tags":"","loc":"/integrations/jenkins/"},{"title":"Datadog-Jira Integration","text":"\n\nOverview\n\nJIRA is an issue and project tracking system for software teams. This integration allows you to create tickets from triggered alerts in Datadog, and update existing tickets with new information as it arises. Additionally, you can see JIRA ticket creations as events within Datadog to overlay with all of your metrics.\n\n\n\n\nInstallation\n\n\n  \n    Navigate to your Jira account\n  \n  \n    Go to settings (Gear icon) –> Applications\n\n    \n  \n  \n    Under “Integrations” in left menu, Select Application Links\n\n    \n  \n  \n    Enter app.datadoghq.com as the URL to link –> press “Create new link”\n\n    \n  \n  \n    Fill in Application Name with any name (used simply for identification)\n  \n  \n    Leave Generic Application Selected\n  \n  \n    Check “Create Incoming Link”\n  \n  \n    Press Continue\n\n    \n  \n  \n    Copy and Paste the Consumer Key, Consumer Name, and Public Key from the Jira tile\n  \n  \n    Press Continue\n\n    \n  \n\n\n\nConfiguration\n\n\n  \n    Navigate back to the Jira Tile\n  \n  \n    Copy and paste the URL of your Jira account into the tile from http… to .net i.e https://some-account.atlassian.net\n  \n  \n    Press Install\n\n    \n  \n\n\n\nSetting up Ticket Types\n\nAfter installing the JIRA integration, you can create custom tickets types that can be created within Datadog.\n\n\n  To begin, press “Add Ticket Type”\n  Each ticket type stems from a unique Project ID – Issue Type combination. \n  Select a Project ID and Issue Type for the ticket type you would like to create.\n  A list of required fields will show up for the selected combination.\n  Each of these fields must be filled out in order for tickets to be created.\n  Optionally, you can add Datadog tags in the form of key1:value1, key2:value2 for this ticket.\n  Press “Save Ticket Type”.\n\n\nRaw values as well as variables from the alert event can be used to fill in these fields.\n\nA full list of variables can be seen below.\n\n\n  \n    \n      Variable\n      Meaning\n    \n  \n  \n    \n      $ID\n      ID of the event (ex: 1234567)\n\n    \n    \n      $EVENT_TITLE\n      Title of the event (ex: [Triggered] [Memory Alert])\n\n    \n    \n      $EVENT_MSG\n      Text of the event (ex: @webhook-url Sending to the webhook)\n\n    \n    \n      $EVENT_TYPE\n      Type of the event (ex: metric_alert_monitor)\n\n    \n    \n      $LAST_UPDATED\n      Date when the event was last updated\n    \n    \n      $DATE\n      Date (epoch) where the event happened *(ex: 1406662672000)\n\n    \n    \n      $AGGREG_KEY\n      ID to aggregate events belonging together (ex: 9bd4ac313a4d1e8fae2482df7b77628)\n\n    \n    \n      $ORG_ID\n      ID of your organization (ex: 11023)\n\n    \n    \n      $ORG_NAME\n      Name of your organization (ex: Datadog)\n\n    \n    \n      $USER\n      User posting the event that triggered the webhook (ex: rudy)\n\n    \n    \n      $SNAPSHOT\n      Url of the image if the event contains a snapshot (ex: https://url.to.snpashot.com/)\n\n    \n    \n      $LINK\n      Url of the event (ex: https://app.datadoghq.com/event/jump_to?event_id=123456)\n\n    \n    \n      $PRIORITY\n      Priority of the event (ex: normal)\n\n    \n    \n      $TAGS\n      Comma-separated list of the event tags (ex: monitor, name:myService, role:computing-node)\n\n    \n    \n      $TEXT_ONLY_MSG\n      Text of the event without markdown formatting\n    \n    \n      $ALERT_ID\n      ID of alert (ex: 1234)\n\n    \n    \n      $ALERT_METRIC\n      Name of the metric if it’s an alert (ex: system.load.1)\n\n    \n    \n      $ALERT_QUERY\n      Query of the monitor that triggered the webhook\n    \n    \n      $ALERT_STATUS\n      Summary of the alert status (ex: system.load.1 over host:my-host was > 0 at least once during the last 1m)\n\n    \n    \n      $ALERT_TRANSITION\n      Type of alert notification (ex: Triggered)\n\n    \n  \n\n\n\nAutomatically Create Tickets from Datadog Alerts\n\nTo automatically have JIRA tickets created within Datadog alerts, use the @jira-projectname-issuetype command within the “Say what’s happening” section of the new monitor creation process.\n\nA new ticket will be created when this alert is triggered. \n\nThe @jira-update command can be used to update existing tickets. This command will add a comment to the JIRA ticket with the text followed by the @jira-update command. \n\nTIP – It might be useful to use the @jira command within an #is_alert or #is_warning variable!\n\n\n\n\nValidation\n\nCheck to see if you can select a Project when creating a new Ticket Type. If this dropdown is empty, it means the integration is not properly installed (or your Jira account has no Projects!)\n","tags":"","loc":"/integrations/jira/"},{"title":"Datadog-Apache Kafka Integration","text":"\n\nOverview\n\nConnect Kafka to Datadog in order to:\n\n\n  Visualize the performance of your cluster in real time\n  Correlate the performance of Kafka with the rest of your applications\n\n\nThis check has a limit of 350 metrics per instance. The number of returned metrics is indicated in the info page. You can specify the metrics you are interested in by editing the configuration below. To learn how to customize the metrics to collect visit the JMX Checks documentation for more detailed instructions. If you need to monitor more metrics, please send an email to support.\n\n\nInstallation\n\nKafka metrics are captured using a JMX connection. We recommend the use of Oracle’s JDK for this integration.\n\n\nConfiguration\n\nNote - The following instructions are for the Datadog agent >= 5.0. For agents before that, refer to the older documentation.\n\nThere are two configuration files to edit for this integration, both of which are in the standard conf.d directory under the agent installation directory:\n\n\n  kafka.yaml\n  kafka_consumer.yaml\n\n\nThe first step is to edit your kafka.yaml file. Kafka bean names depend on the exact Kafka version you’re running. You should always use the example that comes in your agent installation as a base since that will be the most up to date version. You can also find the latest versions on the GitHub repo, but note that the version on their may be for a newer version of the agent than what you have installed.\n\n##########\n# WARNING\n##########\n# This sample works only for Kafka >= 0.8.2.\n# If you are running a version older than that, you can refer to agent 5.2.x released\n# sample files, https://raw.githubusercontent.com/DataDog/dd-agent/5.2.1/conf.d/kafka.yaml.example\n\ninstances:\n  - host: localhost\n    port: 9999 # This is the JMX port on which Kafka exposes its metrics (usually 9999)\n    tags:\n      kafka: broker\n\ninit_config:\n  is_jmx: true\n\n  # Metrics collected by this check. You should not have to modify this.\n  conf:\n    # v0.8.2.x Producers\n    - include:\n        domain: 'kafka.producer'\n        bean_regex: 'kafka\\.producer:type=ProducerRequestMetrics,name=ProducerRequestRateAndTimeMs,clientId=.*'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.producer.request_rate\n    - include:\n        domain: 'kafka.producer'\n        bean_regex: 'kafka\\.producer:type=ProducerRequestMetrics,name=ProducerRequestRateAndTimeMs,clientId=.*'\n        attribute:\n          Mean:\n            metric_type: gauge\n            alias: kafka.producer.request_latency_avg\n    - include:\n        domain: 'kafka.producer'\n        bean_regex: 'kafka\\.producer:type=ProducerTopicMetrics,name=BytesPerSec,clientId=.*'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.producer.bytes_out\n    - include:\n        domain: 'kafka.producer'\n        bean_regex: 'kafka\\.producer:type=ProducerTopicMetrics,name=MessagesPerSec,clientId=.*'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.producer.message_rate\n    # v0.8.2.x Consumers\n    - include:\n        domain: 'kafka.consumer'\n        bean_regex: 'kafka\\.consumer:type=ConsumerFetcherManager,name=MaxLag,clientId=.*'\n        attribute:\n          Value:\n            metric_type: gauge\n            alias: kafka.consumer.max_lag\n    - include:\n        domain: 'kafka.consumer'\n        bean_regex: 'kafka\\.consumer:type=ConsumerFetcherManager,name=MinFetchRate,clientId=.*'\n        attribute:\n          Value:\n            metric_type: gauge\n            alias: kafka.consumer.fetch_rate\n    - include:\n        domain: 'kafka.consumer'\n        bean_regex: 'kafka\\.consumer:type=ConsumerTopicMetrics,name=BytesPerSec,clientId=.*'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.consumer.bytes_in\n    - include:\n        domain: 'kafka.consumer'\n        bean_regex: 'kafka\\.consumer:type=ConsumerTopicMetrics,name=MessagesPerSec,clientId=.*'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.consumer.messages_in\n\n    # Offsets committed to ZooKeeper\n    - include:\n        domain: 'kafka.consumer'\n        bean_regex: 'kafka\\.consumer:type=ZookeeperConsumerConnector,name=ZooKeeperCommitsPerSec,clientId=.*'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.consumer.zookeeper_commits\n    # Offsets committed to Kafka\n    - include:\n        domain: 'kafka.consumer'\n        bean_regex: 'kafka\\.consumer:type=ZookeeperConsumerConnector,name=KafkaCommitsPerSec,clientId=.*'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.consumer.kafka_commits\n    # v0.9.0.x Producers\n    - include:\n        domain: 'kafka.producer'\n        bean_regex: 'kafka\\.producer:type=producer-metrics,client-id=.*'\n        attribute:\n          response-rate:\n            metric_type: gauge\n            alias: kafka.producer.response_rate\n    - include:\n        domain: 'kafka.producer'\n        bean_regex: 'kafka\\.producer:type=producer-metrics,client-id=.*'\n        attribute:\n          request-rate:\n            metric_type: gauge\n            alias: kafka.producer.request_rate\n    - include:\n        domain: 'kafka.producer'\n        bean_regex: 'kafka\\.producer:type=producer-metrics,client-id=.*'\n        attribute:\n          request-latency-avg:\n            metric_type: gauge\n            alias: kafka.producer.request_latency_avg\n    - include:\n        domain: 'kafka.producer'\n        bean_regex: 'kafka\\.producer:type=producer-metrics,client-id=.*'\n        attribute:\n          outgoing-byte-rate:\n            metric_type: gauge\n            alias: kafka.producer.bytes_out\n    - include:\n        domain: 'kafka.producer'\n        bean_regex: 'kafka\\.producer:type=producer-metrics,client-id=.*'\n        attribute:\n          io-wait-time-ns-avg:\n            metric_type: gauge\n            alias: kafka.producer.io_wait\n\n    # v0.9.0.x Consumers\n    - include:\n        domain: 'kafka.consumer'\n        bean_regex: 'kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=.*'\n        attribute:\n          bytes-consumed-rate:\n            metric_type: gauge\n            alias: kafka.consumer.bytes_in\n    - include:\n        domain: 'kafka.consumer'\n        bean_regex: 'kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=.*'\n        attribute:\n          records-consumed-rate:\n            metric_type: gauge\n            alias: kafka.consumer.messages_in\n    #\n    # Aggregate cluster stats\n    #\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.net.bytes_out.rate\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.net.bytes_in.rate\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.messages_in.rate\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.net.bytes_rejected.rate\n\n    #\n    # Request timings\n    #\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=BrokerTopicMetrics,name=FailedFetchRequestsPerSec'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.request.fetch.failed.rate\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.request.produce.failed.rate\n    - include:\n        domain: 'kafka.network'\n        bean: 'kafka.network:type=RequestMetrics,name=RequestsPerSec,request=Produce'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.request.produce.rate\n    - include:\n        domain: 'kafka.network'\n        bean: 'kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Produce'\n        attribute:\n          Mean:\n            metric_type: gauge\n            alias: kafka.request.produce.time.avg\n          99thPercentile:\n            metric_type: gauge\n            alias: kafka.request.produce.time.99percentile\n    - include:\n        domain: 'kafka.network'\n        bean: 'kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchConsumer'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.request.fetch_consumer.rate\n    - include:\n        domain: 'kafka.network'\n        bean: 'kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchFollower'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.request.fetch_follower.rate\n    - include:\n        domain: 'kafka.network'\n        bean: 'kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchConsumer'\n        attribute:\n          Mean:\n            metric_type: gauge\n            alias: kafka.request.fetch_consumer.time.avg\n          99thPercentile:\n            metric_type: gauge\n            alias: kafka.request.fetch_consumer.time.99percentile\n    - include:\n        domain: 'kafka.network'\n        bean: 'kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchFollower'\n        attribute:\n          Mean:\n            metric_type: gauge\n            alias: kafka.request.fetch_follower.time.avg\n          99thPercentile:\n            metric_type: gauge\n            alias: kafka.request.fetch_follower.time.99percentile\n    - include:\n        domain: 'kafka.network'\n        bean: 'kafka.network:type=RequestMetrics,name=TotalTimeMs,request=UpdateMetadata'\n        attribute:\n          Mean:\n            metric_type: gauge\n            alias: kafka.request.update_metadata.time.avg\n          99thPercentile:\n            metric_type: gauge\n            alias: kafka.request.update_metadata.time.99percentile\n    - include:\n        domain: 'kafka.network'\n        bean: 'kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Metadata'\n        attribute:\n          Mean:\n            metric_type: gauge\n            alias: kafka.request.metadata.time.avg\n          99thPercentile:\n            metric_type: gauge\n            alias: kafka.request.metadata.time.99percentile\n    - include:\n        domain: 'kafka.network'\n        bean: 'kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Offsets'\n        attribute:\n          Mean:\n            metric_type: gauge\n            alias: kafka.request.offsets.time.avg\n          99thPercentile:\n            metric_type: gauge\n            alias: kafka.request.offsets.time.99percentile\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.request.handler.avg.idle.pct.rate\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=ProducerRequestPurgatory,name=PurgatorySize'\n        attribute:\n          Value:\n            metric_type: gauge\n            alias: kafka.request.producer_request_purgatory.size\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=FetchRequestPurgatory,name=PurgatorySize'\n        attribute:\n          Value:\n            metric_type: gauge\n            alias: kafka.request.fetch_request_purgatory.size\n\n    #\n    # Replication stats\n    #\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions'\n        attribute:\n          Value:\n            metric_type: gauge\n            alias: kafka.replication.under_replicated_partitions\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=ReplicaManager,name=IsrShrinksPerSec'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.replication.isr_shrinks.rate\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=ReplicaManager,name=IsrExpandsPerSec'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.replication.isr_expands.rate\n    - include:\n        domain: 'kafka.controller'\n        bean: 'kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.replication.leader_elections.rate\n    - include:\n        domain: 'kafka.controller'\n        bean: 'kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.replication.unclean_leader_elections.rate\n    - include:\n        domain: 'kafka.controller'\n        bean: 'kafka.controller:type=KafkaController,name=OfflinePartitionsCount'\n        attribute:\n          Value:\n            metric_type: gauge\n            alias: kafka.replication.offline_partitions_count\n    - include:\n        domain: 'kafka.controller'\n        bean: 'kafka.controller:type=KafkaController,name=ActiveControllerCount'\n        attribute:\n          Value:\n            metric_type: gauge\n            alias: kafka.replication.active_controller_count\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=ReplicaManager,name=PartitionCount'\n        attribute:\n          Value:\n            metric_type: gauge\n            alias: kafka.replication.partition_count\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=ReplicaManager,name=LeaderCount'\n        attribute:\n          Value:\n            metric_type: gauge\n            alias: kafka.replication.leader_count\n    - include:\n        domain: 'kafka.server'\n        bean: 'kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica'\n        attribute:\n          Value:\n            metric_type: gauge\n            alias: kafka.replication.max_lag\n\n    #\n    # Log flush stats\n    #\n    - include:\n        domain: 'kafka.log'\n        bean: 'kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs'\n        attribute:\n          Count:\n            metric_type: rate\n            alias: kafka.log.flush_rate.rate\n\n\nAnd edit conf.d/kafka_consumer.yaml\n\ninit_config:\n#  Customize the ZooKeeper connection timeout here\n#  zk_timeout: 5\n#  Customize the Kafka connection timeout here\n#  kafka_timeout: 5\n\ninstances:\n  # - kafka_connect_str: localhost:9092\n  #   zk_connect_str: localhost:2181\n  #   zk_prefix: /0.8\n  #   consumer_groups:\n  #     my_consumer:\n  #       my_topic: [0, 1, 4, 12]\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\nApache Kafka YAML example\n\n\nApache Kafka Consumer YAML example\nApache Kafka Consumer checks.d\n\n\n\nValidation\n\nTo validate that the integration is working, restart the agent and then run the info command (For help on these steps, see Getting Started with the Agent.  The output should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  kafka-localhost-9999\n  --------------------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\nkafka.broker_offset(gauge)\nCurrent message offset on broker.shown as offset\n\n\n\n\nkafka.consumer_lag(gauge)\nLag in messages between consumer and broker.shown as offset\n\n\n\n\nkafka.consumer_offset(gauge)\nCurrent message offset on consumer.shown as offset\n\n\n\n\nkafka.net.bytes_out(gauge every 10 seconds)\nOutgoing byte rate.shown as byte/second\n\n\n\n\nkafka.net.bytes_in(gauge every 10 seconds)\nIncoming byte rate.shown as byte/second\n\n\n\n\nkafka.net.bytes_rejected(gauge every 10 seconds)\nRejected byte rate.shown as byte/second\n\n\n\n\nkafka.messages_in(gauge every 10 seconds)\nIncoming message rate.shown as message\n\n\n\n\nkafka.request.fetch.failed(gauge every 10 seconds)\nNumber of client fetch request failures.shown as request\n\n\n\n\nkafka.request.fetch.failed_per_second(gauge every 10 seconds)\nRate of client fetch request failures per second.shown as request/second\n\n\n\n\nkafka.request.produce.time.avg(gauge every 10 seconds)\nAverage time for a produce request.shown as request/second\n\n\n\n\nkafka.request.produce.time.99percentile(gauge every 10 seconds)\nTime for produce requests for 99th percentile.shown as request/second\n\n\n\n\nkafka.request.produce.failed_per_second(gauge every 10 seconds)\nRate of failed produce requests per second.shown as request/second\n\n\n\n\nkafka.request.produce.failed(gauge every 10 seconds)\nNumber of failed produce requests.shown as request\n\n\n\n\nkafka.request.fetch.time.avg(gauge every 10 seconds)\nAverage time per fetch request.shown as request/second\n\n\n\n\nkafka.request.fetch.time.99percentile(gauge every 10 seconds)\nTime for fetch requests for 99th percentile.shown as request/second\n\n\n\n\nkafka.request.update_metadata.time.avg(gauge every 10 seconds)\nAverage time for a request to update metadata.shown as millisecond\n\n\n\n\nkafka.request.update_metadata.time.99percentile(gauge every 10 seconds)\nTime for update metadata requests for 99th percentile.shown as millisecond\n\n\n\n\nkafka.request.metadata.time.avg(gauge every 10 seconds)\nAverage time for metadata request.shown as millisecond\n\n\n\n\nkafka.request.metadata.time.99percentile(gauge every 10 seconds)\nTime for metadata requests for 99th percentile.shown as millisecond\n\n\n\n\nkafka.request.offsets.time.avg(gauge every 10 seconds)\nAverage time for an offset request.shown as millisecond\n\n\n\n\nkafka.request.offsets.time.99percentile(gauge every 10 seconds)\nTime for offset requests for 99th percentile.shown as millisecond\n\n\n\n\nkafka.request.handler.avg.idle.pct(gauge every 10 seconds)\nAverage fraction of time the request handler threads are idle.shown as fraction\n\n\n\n\nkafka.replication.isr_shrinks(gauge every 10 seconds)\nRate of replicas leaving the ISR pool.shown as node/second\n\n\n\n\nkafka.replication.isr_expands(gauge every 10 seconds)\nRate of replicas joining the ISR pool.shown as node/second\n\n\n\n\nkafka.replication.leader_elections(gauge every 10 seconds)\nLeader election rate.shown as event/second\n\n\n\n\nkafka.replication.unclean_leader_elections(gauge every 10 seconds)\nUnclean leader election rate.shown as event/second\n\n\n\n\nkafka.replication.under_replicated_partitions(gauge every 10 seconds)\nNumber of unreplicated partitions.\n\n\n\n\nkafka.log.flush_rate(gauge every 10 seconds)\nLog flush rate.shown as flush/second\n\n\n\n\nkafka.consumer.delayed_requests(gauge every 10 seconds)\nNumber of delayed consumer requests.shown as request\n\n\n\n\nkafka.consumer.expires_per_second(gauge every 10 seconds)\nRate of delayed consumer request expiration.shown as eviction/second\n\n\n\n\nkafka.expires_sec(gauge every 10 seconds)\nRate of delayed producer request expiration.shown as eviction/second\n\n\n\n\nkafka.follower.expires_per_second(gauge every 10 seconds)\nRate of request expiration on followers.shown as eviction/second\n\n\n\n\nkafka.producer.delayed_requests(gauge every 10 seconds)\nNumber of producer requests delayed.shown as request\n\n\n\n\nkafka.producer.expires_per_seconds(gauge every 10 seconds)\nRate of producer request expiration.shown as eviction/second\n\n\n\n\nkafka.producer.request_rate(gauge every 10 seconds)\nNumber of producer requests per second.shown as request/second\n\n\n\n\nkafka.producer.response_rate(gauge every 10 seconds)\nNumber of producer responses per second.shown as response/second\n\n\n\n\nkafka.producer.request_latency_avg(gauge every 10 seconds)\nProducer average request latency.shown as millisecond\n\n\n\n\nkafka.producer.bytes_out(gauge every 10 seconds)\nProducer bytes out rate.shown as byte/second\n\n\n\n\nkafka.producer.message_rate(gauge every 10 seconds)\nProducer message rate.shown as message/second\n\n\n\n\nkafka.producer.io_wait(gauge every 10 seconds)\nProducer I/O wait time.shown as nanosecond\n\n\n\n\nkafka.consumer.max_lag(gauge every 10 seconds)\nMaximum consumer lag.shown as offset\n\n\n\n\nkafka.consumer.fetch_rate(gauge every 10 seconds)\nThe minimum rate at which the consumer sends fetch requests to a broker.shown as request\n\n\n\n\nkafka.consumer.bytes_in(gauge every 10 seconds)\nConsumer bytes in rate.shown as byte/second\n\n\n\n\nkafka.consumer.messages_in(gauge every 10 seconds)\nRate of consumer message consumption.shown as message/second\n\n\n\n\nkafka.consumer.zookeeper_commits(gauge every 10 seconds)\nRate of offset commits to ZooKeeper.shown as write/second\n\n\n\n\nkafka.consumer.kafka_commits(gauge every 10 seconds)\nRate of offset commits to Kafka.shown as write/second\n\n\n\n","tags":"","loc":"/integrations/kafka/"},{"title":"Datadog-Kong Integration","text":"\n\nOverview\n\nConnect Kong to Datadog to:\n\n\n  Visualize Kong performance data\n  Correlate the performance of Kong with the rest of your applications\n\n\n\nConfiguration\n\nConfigure the Agent to connect to Kong. Edit conf.d/kong.yaml\n\ninit_config:\n\ninstances:\n# For every instance, you have an `kong_status_url` and (optionally)\n# a list of tags.\n\n-   kong_status_url: http://example.com:8001/status/\n    tags:\n        -   instance:foo\n\n-   kong_status_url: http://example2.com:8001/status/\n    tags:\n        -   instance:bar\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nKong YAML example\nKong checks.d\n\n\n\nValidation\n\nTo validate that the integration is working, restart the agent and then run the info command (For help on these steps, see Getting Started with the Agent.  You should see output that validates that the check passed.\n\n","tags":"","loc":"/integrations/kong/"},{"title":"Datadog-Kubernetes Integration","text":"\n\nOverview\n\n\n\nGet metrics from your Kubelets in real time to:\n\n\n  Visualize your Kubernetes cluster performance\n  Collect performances metrics for your containers, pods, container namespaces\n  Create monitors on the status of your Kubelets\n  Ingest Kubernetes labels as tags in Datadog.\n\n\n\nInstallation\n\nThe Kubernetes integration is deployed as a docker container along side your existing workloads.\n\n\nInstallation via DaemonSets (Kubernetes >=1.1.0)\n\nIf you are running Kubernetes >= 1.2.0, you can take advantage of DaemonSets to automatically deploy the Datadog Agent on all your nodes. On clusters running 1.1.x you will need to explicitly enable the DaemonSets extension.\n\n\n  Download the dd-agent.yaml manifest file.\n  \n    Launch dd-agent:\n\n    kubectl create -f dd-agent.yaml\n  \n\n\n\nManual Installation\n\nIf DaemonSets are not an option for your Kubernetes cluster, you will need to install the Datadog agent as a sidecar container on each Kubernetes node.\n\ndocker run -d --name dd-agent -h `hostname` \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v /proc/:/host/proc/:ro -v /sys/fs/cgroup/:/host/sys/fs/cgroup:ro \\\n  -e API_KEY='YOUR_API_KEY_HERE' -e KUBERNETES=yes datadog/docker-dd-agent:latest\n\n\n\nConfiguration\n\nConfigure the agent by editing the kubernetes.yaml file in conf.d:\n\ninit_config:\n\ninstances:\n  # The kubernetes check retrieves metrics from cadvisor running under kubelet.\n  # By default we will assume we're running under docker and will use the address\n  # of the default router to reach the cadvisor api.\n  #\n  # To override, e.g. in the case of a standalone cadvisor instance, use the following:\n  #\n  # host: localhost\n  # port: 4194\n  # method: http\n  - port: 4194\n\n  # use_histogram controls whether we send detailed metrics, i.e. one per container.\n  # When false, we send detailed metrics corresponding to individual containers, tagging by container id\n  # to keep them unique.\n  # When true, we aggregate data based on container image.\n  # Defaults to false\n\n  # use_histogram: True\n  #\n  # kubelet_port: 10255\n  #\n  # We can define a whitelist of patterns that permit publishing raw metrics.\n  # enabled_rates:\n  #   - cpu.*\n  #   - network.*\n  #\n  # enabled_gauges:\n  #   - filesystem.*\n  #\n  # Custom tags that should be applied to kubernetes metrics\n  # tags:\n  #  - optional_tag1\n  #  - optional_tag2\n\n\nSince the agent is deployed as a docker container, refer to the Agent container documentation.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nKubernetes YAML example\nKubernetes checks.d\n\n\n\nKubernetes State Metrics\n\nIf you are running Kubernetes >= 1.2.0, you can use the kube-state-metrics project to provide additional metrics (identified by the kubernetes_state prefix in the metrics list below) to Datadog.\n\nTo run kube-state-metrics, create a kube-state-metrics.yaml file using the following manifest to deploy the kube-state-metrics service:\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: kube-state-metrics\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: kube-state-metrics\n    spec:\n      containers:\n      - name: kube-state-metrics\n        image: gcr.io/google_containers/kube-state-metrics:v0.3.0\n        ports:\n        - name: metrics\n          containerPort: 8080\n        resources:\n          requests:\n            memory: 30Mi\n            cpu: 100m\n          limits:\n            memory: 50Mi\n            cpu: 200m\n---\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    prometheus.io/scrape: 'true'\n  labels:\n    app: kube-state-metrics\n  name: kube-state-metrics\nspec:\n  ports:\n  - name: metrics\n    port: 8080\n    targetPort: metrics\n    protocol: TCP\n  selector:\n    app: kube-state-metrics\n\n\nThen deploy it by running:\n\nkubectl create -f kube-state-metrics.yaml\n\n\nThe manifest above uses Google’s publicly available kube-state-metrics container. If you would like to build your own, you can do so by:\n\n\n  Clone the kube-state-metrics Github repository\n\n  Run make container to build the container\n  Run kubectl apply -f kubernetes\n\n\n\nIf you configure your Kubernetes State Metrics service to run on a different URL or port, you can configure the Datadog Agent by setting the kube_state_url parameter in conf.d/kubernetes_state.yaml, then restarting the agent. For more information, see the kubernetes_state.yaml.example file. If you have enabled Autodiscovery, the kube state URL will be configured and managed automatically.\n\n\nValidation\n\nTo verify the Datadog agent is running in your environment as a daemonset, execute:\n\nkubectl get daemonset\n\n\nIf the agent is deployed you will see similar output to the text below, where desired and current are equal to the number of running nodes in your cluster.\n\nNAME       DESIRED   CURRENT   NODE-SELECTOR   AGE\ndd-agent   3         3         <none>          11h\n\n\n\nLimitations\n\nPlease be aware that Kubernetes relies on Heapster to report metrics, rather than the cgroup file directly. The collection interval for Heapster is unknown which can lead to innacurate time-related data, such as CPU usage. If you require more precise metrics, we recommend using the Datadog-Docker Integration.\n\nAdditionally please note that Heapster must be running in standalone mode.\n\n\nMetrics\n\n\n\n\nkubernetes.cpu.capacity(gauge)\nThe number of cores in this machine.\n\n\n\n\nkubernetes.cpu.usage.total(gauge)\nThe percentage of CPU time usedshown as percent_nano\n\n\n\n\nkubernetes.cpu.limits(gauge)\nThe limit of cpu cores setshown as cpu\n\n\n\n\nkubernetes.cpu.requests(gauge)\nThe requested cpu coresshown as cpu\n\n\n\n\nkubernetes.filesystem.usage(gauge)\nThe amount of disk usedshown as byte\n\n\n\n\nkubernetes.filesystem.usage_pct(gauge)\nThe percentage of disk usedshown as fraction\n\n\n\n\nkubernetes.memory.capacity(gauge)\nThe amount of memory (in bytes) in this machineshown as byte\n\n\n\n\nkubernetes.memory.limits(gauge)\nThe limit of memory setshown as byte\n\n\n\n\nkubernetes.memory.requests(gauge)\nThe requested memoryshown as byte\n\n\n\n\nkubernetes.memory.usage(gauge)\nThe amount of memory usedshown as byte\n\n\n\n\nkubernetes.network.rx_bytes(gauge)\nThe amount of bytes per second receivedshown as byte/second\n\n\n\n\nkubernetes.network.tx_bytes(gauge)\nThe amount of bytes per second transmittedshown as byte/second\n\n\n\n\nkubernetes.network_errors(gauge)\nThe amount of network errors per secondshown as error/second\n\n\n\n\nkubernetes_state.deployment.replicas_available(gauge)\nThe number of available replicas per deployment\n\n\n\n\nkubernetes_state.deployment.replicas_unavailable(gauge)\nThe number of unavailable replicas per deployment\n\n\n\n\nkubernetes_state.deployment.replicas_updated(gauge)\nThe number of updated replicas per deployment\n\n\n\n\nkubernetes_state.deployment.replicas_desired(gauge)\nThe number of desired replicas per deployment\n\n\n\n\nkubernetes_state.node.cpu_capacity(gauge)\nThe total CPU resources of the nodeshown as cpu\n\n\n\n\nkubernetes_state.node.memory_capacity(gauge)\nThe total memory resources of the nodeshown as byte\n\n\n\n\nkubernetes_state.node.pods_capacity(gauge)\nThe total pod resources of the node\n\n\n\n\nkubernetes_state.node.cpu_allocatable(gauge)\nThe CPU resources of a node that are available for schedulingshown as cpu\n\n\n\n\nkubernetes_state.node.memory_allocatable(gauge)\nThe memory resources of a node that are available for schedulingshown as byte\n\n\n\n\nkubernetes_state.node.pods_allocatable(gauge)\nThe pod resources of a node that are available for scheduling\n\n\n\n\nkubernetes_state.node.unschedulable(gauge)\nWhether a node can schedule new pods\n\n\n\n","tags":"","loc":"/integrations/kubernetes/"},{"title":"Datadog-Kyoto Tycoon Integration","text":"\nCapture Kyoto Tycoon metrics in Datadog to:\n\n\n  Visualize your database server performance\n  Correlate the performance of Kyoto Tycoon with the rest of your applications\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nKyoto Tycoon YAML example\nKyoto Tycoon checks.d\n\n\n","tags":"","loc":"/integrations/kyototycoon/"},{"title":"Datadog-Lighttpd Integration","text":"\n\nOverview\n\n\n\nBring Lighttpd metrics to Datadog to:\n\n\n  Visualize your web server performance.\n  Correlate the performance of Ligttpd with the rest of your applications.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nLighttpd YAML example\nLighttpd checks.d\n\n\n\nInstallation\n\n\n  Make sure that mod_status is installed on your Lighttpd server\n\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to Lighttpd. Edit conf.d/lighttpd.yaml\n\n    init_config:\n\ninstances:\n    # For every instance, you have an `lighttpd_status_url` and (optionally)\n    # a list of tags.\n\n    -   lighttpd_status_url: http://example.com/server-status?auto\n        tags:\n            -   instance:foo\n\n  \n  \n    Restart the Agent\n  \n\n\n\nValidation\n\n\n  \n    Execute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\n    Checks\n======\n\n  [...]\n\n  lighttpd\n  --------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n  \n\n\n\nMetrics\n\nThe following metrics are collected for either Lighttpd1 and Lighttpd2:\n\n\n\n\nlighttpd.performance.idle_server(gauge)\nThe number of idle connections.shown as connection\n\n\n\n\nlighttpd.performance.busy_servers(gauge)\nThe number of active connections.shown as connection\n\n\n\n\nlighttpd.performance.uptime(gauge)\nThe amount of time the server has been up and running.shown as second\n\n\n\n\nlighttpd.net.bytes(gauge)\nThe number of bytes sent and received since start.shown as byte\n\n\n\n\nlighttpd.net.hits(gauge)\nThe number of hits since start.shown as hit\n\n\n\n\nlighttpd.performance.memory_usage(gauge)\nThe amount of memory used by the server.shown as byte\n\n\n\n\nlighttpd.net.requests_avg(gauge)\nThe average number of requests per second since start.shown as request/second\n\n\n\n\nlighttpd.net.bytes_out_avg(gauge)\nThe average number of bytes sent per second since start.shown as byte/second\n\n\n\n\nlighttpd.net.bytes_in_avg(gauge)\nThe average number of bytes received per second since start.shown as byte/second\n\n\n\n\nlighttpd.net.connections_avg(gauge)\nThe average number of connections per second since start.shown as connection/second\n\n\n\n\nlighttpd.connections.state_start(gauge)\nThe number of active connections in the state of initializing the read-idle timer.shown as connection\n\n\n\n\nlighttpd.connections.state_read_header(gauge)\nThe number of active connections in the state of reading the http request header.shown as connection\n\n\n\n\nlighttpd.connections.state_handle_request(gauge)\nThe number of active connections in the state of handling the request internally.shown as connection\n\n\n\n\nlighttpd.connections.state_write_response(gauge)\nThe number of active connections in the state of writing the response to the network.shown as connection\n\n\n\n\nlighttpd.connections.state_keep_alive(gauge)\nThe number of idle connections.shown as connection\n\n\n\n\nlighttpd.net.requests_avg_5sec(gauge)\nThe average number of requests per second in the past 5 seconds.shown as request/second\n\n\n\n\nlighttpd.net.bytes_out_avg_5sec(gauge)\nThe average number of bytes sent per second in the past 5 seconds.shown as byte/second\n\n\n\n\nlighttpd.net.bytes_in_avg_5sec(gauge)\nThe average number of bytes received per second in the past 5 seconds.shown as byte/second\n\n\n\n\nlighttpd.net.connections_avg_5sec(gauge)\nThe average number of connections per second in the past 5 seconds.shown as connection/second\n\n\n\n\nlighttpd.net.requests_total(rate)\nThe number of requests per second.shown as request/second\n\n\n\n\nlighttpd.net.bytes_out(rate)\nThe number of bytes sent per second.shown as byte/second\n\n\n\n\nlighttpd.net.bytes_in(rate)\nThe number of bytes received per second.shown as byte/second\n\n\n\n\nlighttpd.net.connections_total(rate)\nThe total number of connections per second.shown as connection/second\n\n\n\n\nlighttpd.response.status_1xx(rate)\nThe number of 1xx status codes generated per second.shown as response/second\n\n\n\n\nlighttpd.response.status_2xx(rate)\nThe number of 2xx status codes generated per second.shown as response/second\n\n\n\n\nlighttpd.response.status_3xx(rate)\nThe number of 3xx status codes generated per second.shown as response/second\n\n\n\n\nlighttpd.response.status_4xx(rate)\nThe number of 4xx status codes generated per second.shown as response/second\n\n\n\n\nlighttpd.response.status_5xx(rate)\nThe number of 5xx status codes generated per second.shown as response/second\n\n\n\n\nlighttpd.net.bytes_per_s(gauge)\nThe number of bytes sent and received per second.shown as byte/second\n\n\n\n\nlighttpd.net.request_per_s(gauge)\nThe number of requests per second.shown as request/second\n\n\n\n\n\n  \n    \n      Metrics collected for Lighttpd1\n    \n  \n  \n    \n      lighttpd.net.bytes\n    \n    \n      lighttpd.net.bytes_per_s\n    \n    \n      lighttpd.net.hits\n    \n    \n      lighttpd.net.request_per_s\n    \n    \n      lighttpd.performance.busy_servers\n    \n    \n      lighttpd.performance.idle_server\n    \n    \n      lighttpd.performance.uptime\n    \n  \n\n\n\n  \n    \n      Metrics collected for Lighttpd2\n    \n  \n  \n    \n      lighttpd.connections.state_handle_request\n    \n    \n      lighttpd.connections.state_keep_alive\n    \n    \n      lighttpd.connections.state_read_header\n    \n    \n      lighttpd.connections.state_start\n    \n    \n      lighttpd.connections.state_write_response\n    \n    \n      lighttpd.net.bytes_in\n    \n    \n      lighttpd.net.bytes_in_avg\n    \n    \n      lighttpd.net.bytes_in_avg_5sec\n    \n    \n      lighttpd.net.bytes_out\n    \n    \n      lighttpd.net.bytes_out_avg\n    \n    \n      lighttpd.net.bytes_out_avg_5sec\n    \n    \n      lighttpd.net.connections_avg\n    \n    \n      lighttpd.net.connections_avg_5sec\n    \n    \n      lighttpd.net.connections_total\n    \n    \n      lighttpd.net.requests_avg\n    \n    \n      lighttpd.net.requests_avg_5sec\n    \n    \n      lighttpd.net.requests_total\n    \n    \n      lighttpd.performance.memory_usage\n    \n    \n      lighttpd.performance.uptime\n    \n    \n      lighttpd.response.status_1xx\n    \n    \n      lighttpd.response.status_2xx\n    \n    \n      lighttpd.response.status_3xx\n    \n    \n      lighttpd.response.status_4xx\n    \n    \n      lighttpd.response.status_5xx\n    \n  \n\n\n","tags":"","loc":"/integrations/lighttpd/"},{"title":"Datadog-Hadoop MapReduce Integration","text":"\n\nOverview\n\nCapture MapReduce metrics to:\n\n\n  Analyze and inspect individual MapReduce jobs and tasks.\n  Visualize performance of individual tasks.\n\n\n\nInstallation\n\nInstall Datadog Agent on the Master Node where the ResourceManager is running.\n\n\nConfiguration\n\n\n  \n    Configure the agent to connect to the ResourceManager: Edit conf.d/mapreduce.yaml\n\n    instances:\n  # The MapReduce check retrieves metrics from YARN's ResourceManager. This\n  # check must be run from the Master Node and the ResourceManager URI must\n  # be specified below. The ResourceManager URI is composed of the\n  # ResourceManager's hostname and port.\n  # The ResourceManager port can be found in the yarn-site.xml conf file under\n  # the property yarn.resourcemanager.webapp.address\n  - resourcemanager_uri: http://localhost:8088\n\ninit_config:\n general_counters:\n    - counter_group_name: 'org.apache.hadoop.mapreduce.TaskCounter'\n      counters:\n        - counter_name: 'MAP_INPUT_RECORDS'\n        - counter_name: 'MAP_OUTPUT_RECORDS'\n        - counter_name: 'REDUCE_INPUT_RECORDS'\n        - counter_name: 'REDUCE_OUTPUT_RECORDS'\n\n    # Additional counter's can be specified as following\n    # - counter_group_name: 'org.apache.hadoop.mapreduce.FileSystemCounter'\n    #   counters:\n    #     - counter_name: 'HDFS_BYTES_READ'\n\n  \n  \n    Restart the Agent\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nHadoop MapReduce YAML example\nHadoop MapReduce checks.d\n\n\n\nValidation\n\nExecute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  mapreduce\n  ---------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\nThe metrics available are collected using df from Spotify’s Snakebite. hdfs.in_use is calculated by dividing used by capacity.\n\n\n\n\nmapreduce.job.elapsed_time.max(gauge)\nMax elapsed time since the application startedshown as millisecond\n\n\n\n\nmapreduce.job.elapsed_time.avg(gauge)\nAverage elapsed time since the application startedshown as millisecond\n\n\n\n\nmapreduce.job.elapsed_time.median(gauge)\nMedian elapsed time since the application startedshown as millisecond\n\n\n\n\nmapreduce.job.elapsed_time.95percentile(gauge)\n95th percentile elapsed time since the application startedshown as millisecond\n\n\n\n\nmapreduce.job.elapsed_time.count(rate)\nNumber of times the elapsed time was sampled\n\n\n\n\nmapreduce.job.maps_total(rate)\nTotal number of mapsshown as task/second\n\n\n\n\nmapreduce.job.maps_completed(rate)\nNumber of completed mapsshown as task/second\n\n\n\n\nmapreduce.job.reduces_total(rate)\nNumber of reducesshown as task/second\n\n\n\n\nmapreduce.job.reduces_completed(rate)\nNumber of completed reducesshown as task/second\n\n\n\n\nmapreduce.job.maps_pending(rate)\nNumber of pending mapsshown as task/second\n\n\n\n\nmapreduce.job.maps_running(rate)\nNumber of running mapsshown as task/second\n\n\n\n\nmapreduce.job.reduces_pending(rate)\nNumber of pending reducesshown as task/second\n\n\n\n\nmapreduce.job.reduces_running(rate)\nNumber of running reducesshown as task/second\n\n\n\n\nmapreduce.job.new_reduce_attempts(rate)\nNumber of new reduce attemptsshown as task/second\n\n\n\n\nmapreduce.job.running_reduce_attempts(rate)\nNumber of running reduce attemptsshown as task/second\n\n\n\n\nmapreduce.job.failed_reduce_attempts(rate)\nNumber of failed reduce attemptsshown as task/second\n\n\n\n\nmapreduce.job.killed_reduce_attempts(rate)\nNumber of killed reduce attemptsshown as task/second\n\n\n\n\nmapreduce.job.successful_reduce_attempts(rate)\nNumber of successful reduce attemptsshown as task/second\n\n\n\n\nmapreduce.job.new_map_attempts(rate)\nNumber of new map attemptsshown as task/second\n\n\n\n\nmapreduce.job.running_map_attempts(rate)\nNumber of running map attemptsshown as task/second\n\n\n\n\nmapreduce.job.failed_map_attempts(rate)\nNumber of failed map attemptsshown as task/second\n\n\n\n\nmapreduce.job.killed_map_attempts(rate)\nNumber of killed map attemptsshown as task/second\n\n\n\n\nmapreduce.job.successful_map_attempts(rate)\nNumber of successful map attemptsshown as task/second\n\n\n\n\nmapreduce.job.counter.reduce_counter_value(rate)\nCounter value of reduce tasksshown as task/second\n\n\n\n\nmapreduce.job.counter.map_counter_value(rate)\nCounter value of map tasksshown as task/second\n\n\n\n\nmapreduce.job.counter.total_counter_value(rate)\nCounter value of all tasksshown as task/second\n\n\n\n\nmapreduce.job.map.task.elapsed_time.max(gauge)\nMax of all map tasks elapsed timeshown as millisecond\n\n\n\n\nmapreduce.job.map.task.elapsed_time.avg(gauge)\nAverage of all map tasks elapsed timeshown as millisecond\n\n\n\n\nmapreduce.job.map.task.elapsed_time.median(gauge)\nMedian of all map tasks elapsed timeshown as millisecond\n\n\n\n\nmapreduce.job.map.task.elapsed_time.95percentile(gauge)\n95th percentile of all map tasks elapsed timeshown as millisecond\n\n\n\n\nmapreduce.job.map.task.elapsed_time.count(rate)\nNumber of times the map tasks elapsed time were sampled\n\n\n\n\nmapreduce.job.reduce.task.elapsed_time.max(gauge)\nMax of all reduce tasks elapsed timeshown as millisecond\n\n\n\n\nmapreduce.job.reduce.task.elapsed_time.avg(gauge)\nAverage of all reduce tasks elapsed timeshown as millisecond\n\n\n\n\nmapreduce.job.reduce.task.elapsed_time.median(gauge)\nMedian of all reduce tasks elapsed timeshown as millisecond\n\n\n\n\nmapreduce.job.reduce.task.elapsed_time.95percentile(gauge)\n95th percentile of all reduce tasks elapsed timeshown as millisecond\n\n\n\n\nmapreduce.job.reduce.task.elapsed_time.count(rate)\nNumber of times the reduce tasks elapsed time were sampled\n\n\n\n","tags":"","loc":"/integrations/mapreduce/"},{"title":"Datadog-Marathon Integration","text":"\n\nOverview\n\nConnects Marathon to Datadog in order to:\n\n\n  Visualize your Marathon framework’s performance\n  Correlate the performance of Marathon with the rest of your Mesos applications\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nMarathon YAML example\nMarathon checks.d\n\n\n\nConfiguration\n\n*NOTICE : If you include the acs_url parameter in the marathon.yaml config, the user and password will be used to generate an ACS token, not as basic auth for the marathon api.\n\n\n  \n    Configure the Agent to connect to Marathon. Edit conf.d/marathon.yaml:\n\n    init_config:\ndefault_timeout: 5\ninstances:\n# url: the API endpoint of your Marathon master\n- url: https://server:port\n# user: the user for marathon API or ACS token authentication\n- user: username\n# password: the password for marathon API or ACS token authentication\n- password: password\n# acs_url: the base ACS endpoint url if an ACS token is required to access the marathon API\n- acs_url: https://server:port\n\n  \n  \n    Restart the Agent\n  \n\n\n\nValidation\n\n\n  \n    Execute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\n    Checks\n======\n\n[...]\n\nmarathon\n--------\n    - instance #0 [OK]\n    - Collected 8 metrics & 0 events\n\n  \n\n\n\nMetrics\n\n\n\n\nmarathon.apps(gauge)\nNumber of defined apps\n\n\n\n\nmarathon.backoffFactor(gauge)\nBackoff time multiplication factor for each consecutive failed task launch\n\n\n\n\nmarathon.backoffSeconds(gauge)\nTask backoff periodshown as second\n\n\n\n\nmarathon.cpus(gauge)\nNumber of CPU's this application needs per instance\n\n\n\n\nmarathon.disk(gauge)\nDisk that is needed for the applicationshown as mebibyte\n\n\n\n\nmarathon.instances(gauge)\nNumber of instances of this application to start\n\n\n\n\nmarathon.mem(gauge)\nMemory that is needed for the application per instanceshown as mebibyte\n\n\n\n\nmarathon.tasksRunning(gauge)\nNumber of tasks runningshown as task\n\n\n\n\nmarathon.tasksStaged(gauge)\nNumber of tasks staged to runshown as task\n\n\n\n","tags":"","loc":"/integrations/marathon/"},{"title":"Datadog-Memcached Integration","text":"\n\nOverview\n\nConnect Memcached to Datadog in order to:\n\n\n  Visualize its performance\n  Correlate the performance of Memcached with the rest of your applications\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nMemcached YAML example\nMemcached checks.d\n\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to the Memcached server. Edit conf.d/mcache.yaml:\n\n    init_config:\n\ninstances:\n  - url: localhost  # url used to connect to the memcached instance\n  #   socket: /socket/path # if url missing; 'dd-agent' user must have read/write permission\n  #   port: 11211 # If this line is not present, port will default to 11211\n    tags:\n      - optional_tag\n\n    options:\n      items: false  # set to true if you wish to collect items memcached stats.\n      slabs: false  # set to true if you wish to collect slabs memcached stats.\n\n  \n  \n    Restart the Agent\n  \n\n\n\nValidation\n\nExecute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  mcache\n  ------\n    - instance #0 [OK]\n    - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\nmemcache.avg_item_size(gauge)\nThe average size of an item.shown as byte\n\n\n\n\nmemcache.bytes(gauge)\nCurrent number of bytes used by this server to store items.shown as byte\n\n\n\n\nmemcache.bytes_read_rate(gauge)\nRate of bytes read from the network by this server.shown as byte/second\n\n\n\n\nmemcache.bytes_written_rate(gauge)\nRate of bytes written to the network by this server.shown as byte/second\n\n\n\n\nmemcache.cas_badval_rate(gauge)\nRate at which keys are compared and swapped where the comparison (original) value did not match the supplied value.shown as key/second\n\n\n\n\nmemcache.cas_hits_rate(gauge)\nRate at which keys are compared and swapped and found present.shown as hit/second\n\n\n\n\nmemcache.cas_misses_rate(gauge)\nRate at which keys are compared and swapped and not found present.shown as miss/second\n\n\n\n\nmemcache.cmd_flush_rate(gauge)\nRate of \"flush_all\" commands.shown as command/second\n\n\n\n\nmemcache.cmd_get_rate(gauge)\nRate of \"get\" commands.shown as command/second\n\n\n\n\nmemcache.cmd_set_rate(gauge)\nRate of \"set\" commands.shown as command/second\n\n\n\n\nmemcache.connection_structures(gauge)\nNumber of connection structures allocated by the server.\n\n\n\n\nmemcache.curr_connections(gauge)\nNumber of open connections to this server.shown as connection\n\n\n\n\nmemcache.curr_items(gauge)\nCurrent number of items stored by the server.shown as item\n\n\n\n\nmemcache.delete_hits_rate(gauge)\nRate at which delete commands result in items being removed.shown as hit/second\n\n\n\n\nmemcache.delete_misses_rate(gauge)\nRate at which delete commands result in no items being removed.shown as miss/second\n\n\n\n\nmemcache.evictions_rate(gauge)\nRate at which valid items are removed from cache to free memory for new items.shown as eviction/second\n\n\n\n\nmemcache.fill_percent(gauge)\nAmount of memory being used by the server for storing items as a percentage of the max allowed.shown as percent\n\n\n\n\nmemcache.get_hit_percent(gauge)\nPercentage of requested keys that are found present.shown as percent\n\n\n\n\nmemcache.get_hits_rate(gauge)\nRate at which keys are requested and found present.shown as hit/second\n\n\n\n\nmemcache.get_misses_rate(gauge)\nRate at which keys are requested and not found.shown as miss/second\n\n\n\n\nmemcache.limit_maxbytes(gauge)\nNumber of bytes this server is allowed to use for storage.shown as byte\n\n\n\n\nmemcache.listen_disabled_num_rate(gauge)\nRate at which the server has reached the max connection limit.shown as event/second\n\n\n\n\nmemcache.pointer_size(gauge)\nDefault size of pointers on the host OS (generally 32 or 64)shown as bit\n\n\n\n\nmemcache.rusage_system_rate(gauge)\nFraction of user time the CPU spent executing this server process.shown as fraction\n\n\n\n\nmemcache.rusage_user_rate(gauge)\nFraction of time the CPU spent executing kernel code on behalf of this server process.shown as fraction\n\n\n\n\nmemcache.threads(gauge)\nNumber of threads used by the current Memcached server process.shown as thread\n\n\n\n\nmemcache.total_connections_rate(gauge)\nRate at which connections to this server are opened.shown as connection/second\n\n\n\n\nmemcache.total_items(gauge)\nTotal number of items stored by this server since it started.shown as item\n\n\n\n\nmemcache.uptime(gauge)\nNumber of seconds this server has been running.shown as second\n\n\n\n\nmemcache.items.evicted_rate(gauge)\nRate st which items had to be evicted from the LRU before expiringshown as eviction/second\n\n\n\n\nmemcache.items.evicted_nonzero_rate(gauge)\nRate at which nonzero items which had an explicit expire time set had to be evicted from the LRU before expiringshown as eviction/second\n\n\n\n\nmemcache.items.expired_unfetched_rate(gauge)\nRate at which expired items reclaimed from the LRU which were never touched after being setshown as eviction/second\n\n\n\n\nmemcache.items.evicted_unfetched_rate(gauge)\nRate at which valid items evicted from the LRU which were never touched after being setshown as eviction/second\n\n\n\n\nmemcache.items.outofmemory_rate(gauge)\nRate at which the underlying slab class was unable to store a new itemshown as error/second\n\n\n\n\nmemcache.items.tailrepairs_rate(gauge)\nRate at which memcache self-healed a slab with a refcount leakshown as operation/second\n\n\n\n\nmemcache.items.moves_to_cold_rate(gauge)\nRate at which items were moved from HOT or WARM into COLDshown as item/second\n\n\n\n\nmemcache.items.moves_to_warm_rate(gauge)\nRate at which items were moved from COLD to WARMshown as item/second\n\n\n\n\nmemcache.items.moves_within_lru_rate(gauge)\nRate at which active items were bumped within HOT or WARMshown as item/second\n\n\n\n\nmemcache.items.reclaimed_rate(gauge)\nRate at which entries were stored using memory from an expired entryshown as operation/second\n\n\n\n\nmemcache.items.crawler_reclaimed_rate(gauge)\nRate at which items freed by the LRU Crawlershown as operation/second\n\n\n\n\nmemcache.items.lrutail_reflocked_rate(gauge)\nRate at which items found to be refcount locked in the LRU tailshown as item/second\n\n\n\n\nmemcache.items.direct_reclaims_rate(gauge)\nRate at which worker threads had to directly pull LRU tails to find memory for a new itemshown as operation/second\n\n\n\n\nmemcache.items.number(gauge)\nNumber of items presently stored in this slab classshown as item\n\n\n\n\nmemcache.items.number_hot(gauge)\nNumber of items presently stored in the HOT LRUshown as item\n\n\n\n\nmemcache.items.number_warm(gauge)\nNumber of items presently stored in the WARM LRUshown as item\n\n\n\n\nmemcache.items.number_cold(gauge)\nNumber of items presently stored in the COLD LRUshown as item\n\n\n\n\nmemcache.items.number_noexp(gauge)\nNumber of items presently stored in the NOEXP classshown as item\n\n\n\n\nmemcache.items.age(gauge)\nAge of the oldest item in the LRUshown as second\n\n\n\n\nmemcache.items.evicted_time(gauge)\nSeconds since the last access for the most recent item evicted from this classshown as second\n\n\n\n\nmemcache.slabs.get_hits_rate(gauge)\nRate at which get requests were serviced by this slab classshown as hit/second\n\n\n\n\nmemcache.slabs.cmd_set_rate(gauge)\nRate at which set requests stored data in this slab classshown as command/second\n\n\n\n\nmemcache.slabs.delete_hits_rate(gauge)\nRate at which delete commands succeeded in this slab classshown as operation/second\n\n\n\n\nmemcache.slabs.incr_hits_rate(gauge)\nRate at which incrs commands modified this slab classshown as operation/second\n\n\n\n\nmemcache.slabs.decr_hits_rate(gauge)\nRate at which decrs commands modified this slab classshown as operation/second\n\n\n\n\nmemcache.slabs.cas_hits_rate(gauge)\nRate at which CAS commands modified this slab classshown as operation/second\n\n\n\n\nmemcache.slabs.cas_badval_rate(gauge)\nRate at which CAS commands failed to modify a value due to a bad CAS idshown as key/second\n\n\n\n\nmemcache.slabs.touch_hits_rate(gauge)\nRate of touches serviced by this slab classshown as operation/second\n\n\n\n\nmemcache.slabs.used_chunks_rate(gauge)\nRate at which chunks have been allocated to itemsshown as buffer/second\n\n\n\n\nmemcache.slabs.chunk_size(gauge)\nThe amount of space each chunk usesshown as byte\n\n\n\n\nmemcache.slabs.chunks_per_page(gauge)\nHow many chunks exist within one pageshown as buffer\n\n\n\n\nmemcache.slabs.total_pages(gauge)\nTotal number of pages allocated to the slab classshown as page\n\n\n\n\nmemcache.slabs.total_chunks(gauge)\nTotal number of chunks allocated to the slab classshown as buffer\n\n\n\n\nmemcache.slabs.used_chunks(gauge)\nHow many chunks have been allocated to itemsshown as buffer\n\n\n\n\nmemcache.slabs.free_chunks(gauge)\nChunks not yet allocated to items or freed via deleteshown as buffer\n\n\n\n\nmemcache.slabs.free_chunks_end(gauge)\nNumber of free chunks at the end of the last allocated pageshown as buffer\n\n\n\n\nmemcache.slabs.mem_requested(gauge)\nNumber of bytes requested to be stored in this slabshown as byte\n\n\n\n\nmemcache.slabs.active_slabs(gauge)\nTotal number of slab classes allocatedshown as occurrence\n\n\n\n\nmemcache.slabs.total_malloced(gauge)\nTotal amount of memory allocated to slab pagesshown as byte\n\n\n\n\nTo learn more details about the different metrics, go to this blog entry.\n\n","tags":"","loc":"/integrations/memcached/"},{"title":"Datadog-Mesos Integration","text":"\nConnects Mesos to Datadog in order to:\n\n\n  Visualize your Mesos cluster performance\n  Correlate the performance of Mesos with the rest of your applications\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nMesos YAML example\nMesos checks.d\n\n\n\nMesos Master YAML example\nMesos Master checks.d\n\n\n\nMesos Slave YAML example\nMesos Slave checks.d\n\n\n\nMetrics\n\n\n\n\nmesos.framework.cpu(gauge)\nFramework cpu\n\n\n\n\nmesos.framework.mem(gauge)\nFramework memshown as mebibyte\n\n\n\n\nmesos.framework.disk(gauge)\nFramework diskshown as mebibyte\n\n\n\n\nmesos.role.cpu(gauge)\nRole cpu\n\n\n\n\nmesos.role.mem(gauge)\nRole memshown as mebibyte\n\n\n\n\nmesos.role.disk(gauge)\nRole diskshown as mebibyte\n\n\n\n\nmesos.cluster.tasks_error(gauge)\nNumber of tasks that were invalidshown as task\n\n\n\n\nmesos.cluster.tasks_failed(count)\nNumber of failed tasksshown as task\n\n\n\n\nmesos.cluster.tasks_finished(count)\nNumber of finished tasksshown as task\n\n\n\n\nmesos.cluster.tasks_killed(count)\nNumber of killed tasksshown as task\n\n\n\n\nmesos.cluster.tasks_lost(count)\nNumber of lost tasksshown as task\n\n\n\n\nmesos.cluster.tasks_running(gauge)\nNumber of running tasksshown as task\n\n\n\n\nmesos.cluster.tasks_staging(gauge)\nNumber of staging tasksshown as task\n\n\n\n\nmesos.cluster.tasks_starting(gauge)\nNumber of starting tasksshown as task\n\n\n\n\nmesos.cluster.slave_registrations(gauge)\nNumber of slaves that were able to cleanly re-join the cluster and connect back to the master after the master is disconnected.\n\n\n\n\nmesos.cluster.slave_removals(gauge)\nNumber of slaves removed for various reasons, including maintenance\n\n\n\n\nmesos.cluster.slave_reregistrations(gauge)\nNumber of slave re-registrations\n\n\n\n\nmesos.cluster.slave_shutdowns_canceled(gauge)\nNumber of cancelled slave shutdowns\n\n\n\n\nmesos.cluster.slave_shutdowns_scheduled(gauge)\nNumber of slaves which have failed their health check and are scheduled to be removed\n\n\n\n\nmesos.cluster.slaves_active(gauge)\nNumber of active slaves\n\n\n\n\nmesos.cluster.slaves_connected(gauge)\nNumber of connected slaves\n\n\n\n\nmesos.cluster.slaves_disconnected(gauge)\nNumber of disconnected slaves\n\n\n\n\nmesos.cluster.slaves_inactive(gauge)\nNumber of inactive slaves\n\n\n\n\nmesos.cluster.cpus_percent(gauge)\nPercentage of allocated CPUsshown as percent\n\n\n\n\nmesos.cluster.cpus_used(gauge)\nNumber of allocated CPUs\n\n\n\n\nmesos.cluster.cpus_total(gauge)\nNumber of CPUs\n\n\n\n\nmesos.cluster.disk_percent(gauge)\nPercentage of allocated disk spaceshown as percent\n\n\n\n\nmesos.cluster.disk_used(gauge)\nAllocated disk spaceshown as mebibyte\n\n\n\n\nmesos.cluster.disk_total(gauge)\nDisk spaceshown as mebibyte\n\n\n\n\nmesos.cluster.mem_percent(gauge)\nPercentage of allocated memoryshown as percent\n\n\n\n\nmesos.cluster.mem_used(gauge)\nAllocated memoryshown as mebibyte\n\n\n\n\nmesos.cluster.mem_total(gauge)\nTotal memoryshown as mebibyte\n\n\n\n\nmesos.registrar.queued_operations(gauge)\nNumber of queued operations\n\n\n\n\nmesos.registrar.registry_size_bytes(gauge)\nRegistry sizeshown as byte\n\n\n\n\nmesos.registrar.state_fetch_ms(gauge)\nRegistry read latencyshown as millisecond\n\n\n\n\nmesos.registrar.state_store_ms(gauge)\nRegistry write latencyshown as millisecond\n\n\n\n\nmesos.registrar.state_store_ms.count(gauge)\nRegistry write count\n\n\n\n\nmesos.registrar.state_store_ms.max(gauge)\nMaximum registry write latencyshown as millisecond\n\n\n\n\nmesos.registrar.state_store_ms.min(gauge)\nMinimum registry write latencyshown as millisecond\n\n\n\n\nmesos.registrar.state_store_ms.p50(gauge)\nMedian registry write latencyshown as millisecond\n\n\n\n\nmesos.registrar.state_store_ms.p90(gauge)\n90th percentile registry write latencyshown as millisecond\n\n\n\n\nmesos.registrar.state_store_ms.p95(gauge)\n95th percentile registry write latencyshown as millisecond\n\n\n\n\nmesos.registrar.state_store_ms.p99(gauge)\n99th percentile registry write latencyshown as millisecond\n\n\n\n\nmesos.registrar.state_store_ms.p999(gauge)\n99.9th percentile registry write latencyshown as millisecond\n\n\n\n\nmesos.registrar.state_store_ms.p9999(gauge)\n99.99th percentile registry write latencyshown as millisecond\n\n\n\n\nmesos.cluster.frameworks_active(gauge)\nNumber of active frameworks\n\n\n\n\nmesos.cluster.frameworks_connected(gauge)\nNumber of connected frameworks\n\n\n\n\nmesos.cluster.frameworks_disconnected(gauge)\nNumber of disconnected frameworks\n\n\n\n\nmesos.cluster.frameworks_inactive(gauge)\nNumber of inactive frameworks\n\n\n\n\nmesos.stats.system.cpus_total(gauge)\nNumber of CPUs available\n\n\n\n\nmesos.stats.system.load_15min(gauge)\nLoad average for the past 15 minutes\n\n\n\n\nmesos.stats.system.load_1min(gauge)\nLoad average for the past minutes\n\n\n\n\nmesos.stats.system.load_5min(gauge)\nLoad average for the past 5 minutes\n\n\n\n\nmesos.stats.system.mem_free_bytes(gauge)\nFree memoryshown as byte\n\n\n\n\nmesos.stats.system.mem_total_bytes(gauge)\nTotal memoryshown as byte\n\n\n\n\nmesos.stats.elected(gauge)\nWhether this is the elected master\n\n\n\n\nmesos.stats.uptime_secs(gauge)\nUptimeshown as second\n\n\n\n\nmesos.cluster.dropped_messages(gauge)\nNumber of dropped messagesshown as message\n\n\n\n\nmesos.cluster.outstanding_offers(gauge)\nNumber of outstanding resource offers\n\n\n\n\nmesos.cluster.event_queue_dispatches(gauge)\nNumber of dispatches in the event queue\n\n\n\n\nmesos.cluster.event_queue_http_requests(gauge)\nNumber of HTTP requests in the event queueshown as request\n\n\n\n\nmesos.cluster.event_queue_messages(gauge)\nNumber of messages in the event queueshown as message\n\n\n\n\nmesos.cluster.invalid_framework_to_executor_messages(gauge)\nNumber of invalid framework messagesshown as message\n\n\n\n\nmesos.cluster.invalid_status_update_acknowledgements(gauge)\nNumber of invalid status update acknowledgements\n\n\n\n\nmesos.cluster.invalid_status_updates(gauge)\nNumber of invalid status updates\n\n\n\n\nmesos.cluster.valid_framework_to_executor_messages(gauge)\nNumber of valid framework messagesshown as message\n\n\n\n\nmesos.cluster.valid_status_update_acknowledgements(gauge)\nNumber of valid status update acknowledgements\n\n\n\n\nmesos.cluster.valid_status_updates(gauge)\nNumber of valid status updates\n\n\n\n\nmesos.state.task.cpu(gauge)\nTask cpu\n\n\n\n\nmesos.state.task.mem(gauge)\nTask memoryshown as mebibyte\n\n\n\n\nmesos.state.task.disk(gauge)\nTask diskshown as mebibyte\n\n\n\n\nmesos.slave.tasks_failed(count)\nNumber of failed tasksshown as task\n\n\n\n\nmesos.slave.tasks_finished(count)\nNumber of finished tasksshown as task\n\n\n\n\nmesos.slave.tasks_killed(count)\nNumber of killed tasksshown as task\n\n\n\n\nmesos.slave.tasks_lost(count)\nNumber of lost tasksshown as task\n\n\n\n\nmesos.slave.tasks_running(gauge)\nNumber of running tasksshown as task\n\n\n\n\nmesos.slave.tasks_staging(gauge)\nNumber of staging tasksshown as task\n\n\n\n\nmesos.slave.tasks_starting(gauge)\nNumber of starting tasksshown as task\n\n\n\n\nmesos.stats.system.cpus_total(gauge)\nNumber of CPUs available\n\n\n\n\nmesos.stats.system.load_15min(gauge)\nLoad average for the past 15 minutes\n\n\n\n\nmesos.stats.system.load_1min(gauge)\nLoad average for the past minutes\n\n\n\n\nmesos.stats.system.load_5min(gauge)\nLoad average for the past 5 minutes\n\n\n\n\nmesos.stats.system.mem_free_bytes(gauge)\nFree memoryshown as byte\n\n\n\n\nmesos.stats.system.mem_total_bytes(gauge)\nTotal memoryshown as byte\n\n\n\n\nmesos.stats.registered(gauge)\nWhether this slave is registered with a master\n\n\n\n\nmesos.stats.uptime_secs(gauge)\nSlave uptime\n\n\n\n\nmesos.slave.cpus_percent(gauge)\nPercentage of allocated CPUsshown as percent\n\n\n\n\nmesos.slave.cpus_used(gauge)\nNumber of allocated CPUs\n\n\n\n\nmesos.slave.cpus_total(gauge)\nNumber of CPUs\n\n\n\n\nmesos.slave.disk_percent(gauge)\nPercentage of allocated disk spaceshown as percent\n\n\n\n\nmesos.slave.disk_used(gauge)\nAllocated disk spaceshown as mebibyte\n\n\n\n\nmesos.slave.disk_total(gauge)\nDisk spaceshown as mebibyte\n\n\n\n\nmesos.slave.mem_percent(gauge)\nPercentage of allocated memoryshown as percent\n\n\n\n\nmesos.slave.mem_used(gauge)\nAllocated memoryshown as mebibyte\n\n\n\n\nmesos.slave.mem_total(gauge)\nTotal memoryshown as mebibyte\n\n\n\n\nmesos.slave.executors_registering(gauge)\nNumber of executors registering\n\n\n\n\nmesos.slave.executors_running(gauge)\nNumber of executors running\n\n\n\n\nmesos.slave.executors_terminated(gauge)\nNumber of terminated executors\n\n\n\n\nmesos.slave.executors_terminating(gauge)\nNumber of terminating executors\n\n\n\n\nmesos.slave.frameworks_active(gauge)\nNumber of active frameworks\n\n\n\n\nmesos.slave.invalid_framework_messages(gauge)\nNumber of invalid framework messagesshown as message\n\n\n\n\nmesos.slave.invalid_status_updates(gauge)\nNumber of invalid status updates\n\n\n\n\nmesos.slave.recovery_errors(gauge)\nNumber of errors encountered during slave recoveryshown as error\n\n\n\n\nmesos.slave.valid_framework_messages(gauge)\nNumber of valid framework messagesshown as message\n\n\n\n\nmesos.slave.valid_status_updates(gauge)\nNumber of valid status updates\n\n\n\n","tags":"","loc":"/integrations/mesos/"},{"title":"Datadog-MongoDB Integration","text":"\n\nOverview\n\nConnect MongoDB to Datadog in order to:\n\n\n  Visualize key MongoDB metrics.\n  Correlate MongoDB performance with the rest of your applications.\n\n\n\nInstallation\n\n\n  To capture MongoDB metrics you need to install the Datadog Agent.\n  \n    Create a read-only admin user for Datadog (Admin rights are needed to collect complete server statistics). In the mongo shell, run:\n\n    # Authenticate as the admin user.\nuse admin\ndb.auth(\"admin\", \"admin-password\")\n\n# On MongoDB 2.x, use the addUser command.\ndb.addUser(\"datadog\", \"<UNIQUEPASSWORD>\", true)\n\n# On MongoDB 3.x or higher, use the createUser command.\ndb.createUser({\n  \"user\":\"datadog\",\n  \"pwd\": \"<UNIQUEPASSWORD>\",\n  \"roles\" : [\n    {role: 'read', db: 'admin' },\n    {role: 'clusterMonitor', db: 'admin'},\n    {role: 'read', db: 'local' }\n  ]\n})\n\n  \n\n\n\nConfiguration\n\n\n  \n    Edit your conf.d/mongo.yaml file as follows:\n\n    init_config:\n\ninstances:\n  # The format for the server entry below is:\n  # server: mongodb://username:password@host:port/database where database will default to admin\n  - server: mongodb://admin:datadog@localhost:27017/admin\n    tags:\n      - mytag1\n      - mytag2\n    additional_metrics:\n      - durability\n      - locks\n      - top\n\n  \n  \n    Restart the agent\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nMongoDB YAML example\nMongoDB checks.d\n\n\n\nValidation\n\nTo validate that the integration is working, run datadog-agent info. You should see results similar to the following:\n\n    Checks\n    ======\n\n      mongo\n      -----\n        - instance #0 [OK]\n        - Collected 89 metrics, 0 events & 2 service checks\n        - Dependencies:\n            - pymongo: 2.8\n\n\n\nMetrics\n\n\n\n\nmongodb.asserts.msgps(gauge)\nNumber of message assertions raised per second.shown as assertion/second\n\n\n\n\nmongodb.asserts.regularps(gauge)\nNumber of regular assertions raised per second.shown as assertion/second\n\n\n\n\nmongodb.asserts.rolloversps(gauge)\nNumber of times that the rollover counters roll over per second. The counters rollover to zero every 2 to the 30 assertions.shown as assertion/second\n\n\n\n\nmongodb.asserts.userps(gauge)\nNumber of user assertions raised per second.shown as assertion/second\n\n\n\n\nmongodb.asserts.warningps(gauge)\nNumber of warnings raised per second.shown as assertion/second\n\n\n\n\nmongodb.backgroundflushing.average_ms(gauge)\nAverage time for each flush to disk.shown as millisecond\n\n\n\n\nmongodb.backgroundflushing.flushesps(gauge)\nNumber of times the database has flushed all writes to disk.shown as flush/second\n\n\n\n\nmongodb.backgroundflushing.last_ms(gauge)\nAmount of time that the last flush operation took to complete.shown as millisecond\n\n\n\n\nmongodb.backgroundflushing.total_ms(gauge)\nTotal number of time that the `mongod` processes have spent writing (i.e. flushing) data to disk.shown as millisecond\n\n\n\n\nmongodb.connections.available(gauge)\nNumber of unused available incoming connections the database can provide.shown as connection\n\n\n\n\nmongodb.connections.current(gauge)\nNumber of connections to the database server from clients.shown as connection\n\n\n\n\nmongodb.cursors.timedout(gauge)\nTotal number of cursors that have timed out since the server process started.shown as cursor\n\n\n\n\nmongodb.cursors.totalopen(gauge)\nNumber of cursors that MongoDB is maintaining for clientsshown as cursor\n\n\n\n\nmongodb.dur.commits(gauge)\nNumber of transactions written to the journal during the last journal group commit interval.shown as transaction\n\n\n\n\nmongodb.dur.commitsinwritelock(gauge)\nCount of the commits that occurred while a write lock was held.shown as commit\n\n\n\n\nmongodb.dur.compression(gauge)\nCompression ratio of the data written to the journal.shown as fraction\n\n\n\n\nmongodb.dur.earlycommits(gauge)\nNumber of times MongoDB requested a commit before the scheduled journal group commit interval.shown as commit\n\n\n\n\nmongodb.dur.journaledmb(gauge)\nAmount of data written to journal during the last journal group commit interval.shown as mebibyte\n\n\n\n\nmongodb.dur.timems.commits(gauge)\nAmount of time spent for commits.shown as millisecond\n\n\n\n\nmongodb.dur.timems.commitsinwritelock(gauge)\nAmount of time spent for commits that occurred while a write lock was held.shown as millisecond\n\n\n\n\nmongodb.dur.timems.dt(gauge)\nAmount of time over which MongoDB collected the `dur.timeMS` data.shown as millisecond\n\n\n\n\nmongodb.dur.timems.preplogbuffer(gauge)\nAmount of time spent preparing to write to the journal.shown as millisecond\n\n\n\n\nmongodb.dur.timems.remapprivateview(gauge)\nAmount of time spent remapping copy-on-write memory mapped views.shown as millisecond\n\n\n\n\nmongodb.dur.timems.writetodatafiles(gauge)\nAmount of time spent writing to data files after journaling.shown as millisecond\n\n\n\n\nmongodb.dur.timems.writetojournal(gauge)\nAmount of time spent writing to the journalshown as millisecond\n\n\n\n\nmongodb.dur.writetodatafilesmb(gauge)\nAmount of data written from journal to the data files during the last journal group commit interval.shown as mebibyte\n\n\n\n\nmongodb.extra_info.page_faultsps(gauge)\nNumber of page faults per second that require disk operations.shown as fault/second\n\n\n\n\nmongodb.globallock.activeclients.readers(gauge)\nCount of the active client connections performing read operations.shown as connection\n\n\n\n\nmongodb.globallock.activeclients.total(gauge)\nTotal number of active client connections to the database.shown as connection\n\n\n\n\nmongodb.globallock.activeclients.writers(gauge)\nCount of active client connections performing write operations.shown as connection\n\n\n\n\nmongodb.globallock.currentqueue.readers(gauge)\nNumber of operations that are currently queued and waiting for the read lock.shown as operation\n\n\n\n\nmongodb.globallock.currentqueue.total(gauge)\nTotal number of operations queued waiting for the lock.shown as operation\n\n\n\n\nmongodb.globallock.currentqueue.writers(gauge)\nNumber of operations that are currently queued and waiting for the write lock.shown as operation\n\n\n\n\nmongodb.globallock.locktime(gauge)\nTime since the database last started that the globalLock has been held.shown as millisecond\n\n\n\n\nmongodb.globallock.ratio(gauge)\nRatio of the time that the globalLock has been held to the total time since it was created.shown as fraction\n\n\n\n\nmongodb.globallock.totaltime(gauge)\nTime since the database last started and created the global lock.shown as microsecond\n\n\n\n\nmongodb.indexcounters.accessesps(gauge)\nNumber of times that operations have accessed indexes per second.shown as event/second\n\n\n\n\nmongodb.indexcounters.hitsps(gauge)\nNumber of times per second that an index has been accessed and mongod is able to return the index from memory.shown as hit/second\n\n\n\n\nmongodb.indexcounters.missesps(gauge)\nNumber of times per second that an operation attempted to access an index that was not in memory.shown as miss/second\n\n\n\n\nmongodb.indexcounters.missratio(gauge)\nRatio of index hits to misses.shown as fraction\n\n\n\n\nmongodb.indexcounters.resetsps(gauge)\nNumber of times per second the index counters have been reset.shown as event/second\n\n\n\n\nmongodb.locks.collection.acquirecount.exclusiveps(gauge)\nNumber of times the collection lock type was aquired in the Exclusive (X) mode.shown as lock/second\n\n\n\n\nmongodb.locks.collection.acquirecount.intent_exclusiveps(gauge)\nNumber of times the collection lock type was aquired in the Intent Exclusive (IX) mode.shown as lock/second\n\n\n\n\nmongodb.locks.collection.acquirecount.intent_sharedps(gauge)\nNumber of times the collection lock type was aquired in the Intent Shared (IS) mode.shown as lock/second\n\n\n\n\nmongodb.locks.collection.acquirecount.sharedps(gauge)\nNumber of times the collection lock type was aquired in the Shared (S) mode.shown as lock/second\n\n\n\n\nmongodb.locks.collection.acquirewaitcount.exclusiveps(gauge)\nNumber of times the collection lock type acquisition in the Exclusive (X) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.collection.acquirewaitcount.sharedps(gauge)\nNumber of times the collection lock type acquisition in the Shared (S) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.collection.timeacquiringmicros.exclusiveps(gauge)\nWait time for the collection lock type acquisitions in the Exclusive (X) mode.shown as fraction\n\n\n\n\nmongodb.locks.collection.timeacquiringmicros.sharedps(gauge)\nWait time for the collection lock type acquisitions in the Shared (S) mode.shown as fraction\n\n\n\n\nmongodb.locks.database.acquirecount.exclusiveps(gauge)\nNumber of times the database lock type was aquired in the Exclusive (X) mode.shown as lock/second\n\n\n\n\nmongodb.locks.database.acquirecount.intent_exclusiveps(gauge)\nNumber of times the database lock type was aquired in the Intent Exclusive (IX) mode.shown as lock/second\n\n\n\n\nmongodb.locks.database.acquirecount.intent_sharedps(gauge)\nNumber of times the database lock type was aquired in the Intent Shared (IS) mode.shown as lock/second\n\n\n\n\nmongodb.locks.database.acquirecount.sharedps(gauge)\nNumber of times the database lock type was aquired in the Shared (S) mode.shown as lock/second\n\n\n\n\nmongodb.locks.database.acquirewaitcount.exclusiveps(gauge)\nNumber of times the database lock type acquisition in the Exclusive (X) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.database.acquirewaitcount.intent_exclusiveps(gauge)\nNumber of times the database lock type acquisition in the Intent Exclusive (IX) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.database.acquirewaitcount.intent_sharedps(gauge)\nNumber of times the database lock type acquisition in the Intent Shared (IS) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.database.acquirewaitcount.sharedps(gauge)\nNumber of times the database lock type acquisition in the Shared (S) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.database.timeacquiringmicros.exclusiveps(gauge)\nWait time for the database lock type acquisitions in the Exclusive (X) mode.shown as fraction\n\n\n\n\nmongodb.locks.database.timeacquiringmicros.intent_exclusiveps(gauge)\nWait time for the database lock type acquisitions in the Intent Exclusive (IX) mode.shown as fraction\n\n\n\n\nmongodb.locks.database.timeacquiringmicros.intent_sharedps(gauge)\nWait time for the database lock type acquisitions in the Intent Shared (IS) mode.shown as fraction\n\n\n\n\nmongodb.locks.database.timeacquiringmicros.sharedps(gauge)\nWait time for the database lock type acquisitions in the Shared (S) mode.shown as fraction\n\n\n\n\nmongodb.locks.global.acquirecount.exclusiveps(gauge)\nNumber of times the global lock type was aquired in the Exclusive (X) mode.shown as lock/second\n\n\n\n\nmongodb.locks.global.acquirecount.intent_exclusiveps(gauge)\nNumber of times the global lock type was aquired in the Intent Exclusive (IX) mode.shown as lock/second\n\n\n\n\nmongodb.locks.global.acquirecount.intent_sharedps(gauge)\nNumber of times the global lock type was aquired in the Intent Shared (IS) mode.shown as lock/second\n\n\n\n\nmongodb.locks.global.acquirecount.sharedps(gauge)\nNumber of times the global lock type was aquired in the Shared (S) mode.shown as lock/second\n\n\n\n\nmongodb.locks.global.acquirewaitcount.exclusiveps(gauge)\nNumber of times the global lock type acquisition in the Exclusive (X) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.global.acquirewaitcount.intent_exclusiveps(gauge)\nNumber of times the global lock type acquisition in the Intent Exclusive (IX) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.global.acquirewaitcount.intent_sharedps(gauge)\nNumber of times the global lock type acquisition in the Intent Shared (IS) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.global.acquirewaitcount.sharedps(gauge)\nNumber of times the global lock type acquisition in the Shared (S) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.global.timeacquiringmicros.exclusiveps(gauge)\nWait time for the global lock type acquisitions in the Exclusive (X) mode.shown as fraction\n\n\n\n\nmongodb.locks.global.timeacquiringmicros.intent_exclusiveps(gauge)\nWait time for the global lock type acquisitions in the Intent Exclusive (IX) mode.shown as fraction\n\n\n\n\nmongodb.locks.global.timeacquiringmicros.intent_sharedps(gauge)\nWait time for the global lock type acquisitions in the Intent Shared (IS) mode.shown as fraction\n\n\n\n\nmongodb.locks.global.timeacquiringmicros.sharedps(gauge)\nWait time for the global lock type acquisitions in the Shared (S) mode.shown as fraction\n\n\n\n\nmongodb.locks.metadata.acquirecount.exclusiveps(gauge)\nNumber of times the metadata lock type was aquired in the Exclusive (X) mode.shown as lock/second\n\n\n\n\nmongodb.locks.metadata.acquirecount.sharedps(gauge)\nNumber of times the metadata lock type was aquired in the Shared (S) mode.shown as lock/second\n\n\n\n\nmongodb.locks.mmapv1journal.acquirecount.intent_exclusiveps(gauge)\nNumber of times the MMAPv1 storage engine lock type was aquired in the Intent Exclusive (IX) mode.shown as lock/second\n\n\n\n\nmongodb.locks.mmapv1journal.acquirecount.intent_sharedps(gauge)\nNumber of times the MMAPv1 storage engine lock type was aquired in the Intent Shared (IS) mode.shown as lock/second\n\n\n\n\nmongodb.locks.mmapv1journal.acquirewaitcount.intent_exclusiveps(gauge)\nNumber of times the MMAPv1 storage engine lock type acquisition in the Intent Exclusive (IX) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.mmapv1journal.acquirewaitcount.intent_sharedps(gauge)\nNumber of times the MMAPv1 storage engine lock type acquisition in the Intent Shared (IS) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.mmapv1journal.timeacquiringmicros.intent_exclusiveps(gauge)\nWait time for the MMAPv1 storage engine lock type acquisitions in the Intent Exclusive (IX) mode.shown as fraction\n\n\n\n\nmongodb.locks.mmapv1journal.timeacquiringmicros.intent_sharedps(gauge)\nWait time for the MMAPv1 storage engine lock type acquisitions in the Intent Shared (IS) mode.shown as fraction\n\n\n\n\nmongodb.locks.oplog.acquirecount.intent_exclusiveps(gauge)\nNumber of times the oplog lock type was aquired in the Intent Exclusive (IX) mode.shown as lock/second\n\n\n\n\nmongodb.locks.oplog.acquirecount.sharedps(gauge)\nNumber of times the oplog lock type was aquired in the Shared (S) mode.shown as lock/second\n\n\n\n\nmongodb.locks.oplog.acquirewaitcount.intent_exclusiveps(gauge)\nNumber of times the oplog lock type acquisition in the Intent Exclusive (IX) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.oplog.acquirewaitcount.sharedps(gauge)\nNumber of times the oplog lock type acquisition in the Shared (S) mode encountered waits because the locks were held in a conflicting mode.shown as wait/second\n\n\n\n\nmongodb.locks.oplog.timeacquiringmicros.intent_exclusiveps(gauge)\nWait time for the oplog lock type acquisitions in the Intent Exclusive (IX) mode.shown as fraction\n\n\n\n\nmongodb.locks.oplog.timeacquiringmicros.sharedps(gauge)\nWait time for the oplog lock type acquisitions in the Shared (S) mode.shown as fraction\n\n\n\n\nmongodb.mem.mapped(gauge)\nAmount of mapped memory by the database.shown as mebibyte\n\n\n\n\nmongodb.mem.mappedwithjournal(gauge)\nThe amount of mapped memory, including the memory used for journaling.shown as mebibyte\n\n\n\n\nmongodb.mem.resident(gauge)\nAmount of memory currently used by the database process.shown as mebibyte\n\n\n\n\nmongodb.mem.virtual(gauge)\nAmount of virtual memory used by the mongod process.shown as mebibyte\n\n\n\n\nmongodb.metrics.cursor.open.notimeout(gauge)\nNumber of open cursors with the option `DBQuery.Option.noTimeout` set to prevent timeout after a period of inactivity.shown as cursor\n\n\n\n\nmongodb.metrics.cursor.open.pinned(gauge)\nNumber of “pinned” open cursors.shown as cursor\n\n\n\n\nmongodb.metrics.cursor.open.total(gauge)\nNumber of cursors that MongoDB is maintaining for clients.shown as cursor\n\n\n\n\nmongodb.metrics.cursor.timedoutps(gauge)\nNumber of cursors that time out, per second.shown as cursor/second\n\n\n\n\nmongodb.metrics.document.deletedps(gauge)\nNumber of documents deleted per second.shown as document/second\n\n\n\n\nmongodb.metrics.document.insertedps(gauge)\nNumber of documents inserted per second.shown as document/second\n\n\n\n\nmongodb.metrics.document.returnedps(gauge)\nNumber of documents returned by queries per second.shown as document/second\n\n\n\n\nmongodb.metrics.document.updatedps(gauge)\nNumber of documents updated per second.shown as document/second\n\n\n\n\nmongodb.metrics.getlasterror.wtime.numps(gauge)\nNumber of getLastError operations per second with a specified write concern (i.e. w) that wait for one or more members of a replica set to acknowledge the write operation.shown as operation/second\n\n\n\n\nmongodb.metrics.getlasterror.wtime.totalmillisps(gauge)\nFraction of time (ms/s) that the mongod has spent performing getLastError operations with write concern (i.e. w) that wait for one or more members of a replica set to acknowledge the write operation.shown as fraction\n\n\n\n\nmongodb.metrics.getlasterror.wtimeoutsps(gauge)\nNumber of times per second that write concern operations have timed out as a result of the wtimeout threshold to getLastErrorshown as event/second\n\n\n\n\nmongodb.metrics.operation.fastmodps(gauge)\nNumber of update operations per second that neither cause documents to grow nor require updates to the index.shown as operation/second\n\n\n\n\nmongodb.metrics.operation.idhackps(gauge)\nNumber of queries per second that contain the _id field.shown as query/second\n\n\n\n\nmongodb.metrics.operation.scanandorderps(gauge)\nNumber of queries per second that return sorted numbers that cannot perform the sort operation using an index.shown as query/second\n\n\n\n\nmongodb.metrics.queryexecutor.scannedps(gauge)\nNumber of index items scanned per second during queries and query-plan evaluation.shown as operation/second\n\n\n\n\nmongodb.metrics.record.movesps(gauge)\nNumber of times per second documents move within the on-disk representation of the MongoDB data set.shown as operation/second\n\n\n\n\nmongodb.metrics.repl.apply.batches.numps(gauge)\nNumber of batches applied across all databases per second.shown as operation/second\n\n\n\n\nmongodb.metrics.repl.apply.batches.totalmillisps(gauge)\nFraction of time (ms/s) the mongod has spent applying operations from the oplog.shown as fraction\n\n\n\n\nmongodb.metrics.repl.apply.opsps(gauge)\nNumber of oplog operations applied per second.shown as operation/second\n\n\n\n\nmongodb.metrics.repl.buffer.count(gauge)\nNumber of operations in the oplog buffer.shown as operation\n\n\n\n\nmongodb.metrics.repl.buffer.maxsizebytes(gauge)\nMaximum size of the buffer.shown as byte\n\n\n\n\nmongodb.metrics.repl.buffer.sizebytes(gauge)\nCurrent size of the contents of the oplog buffer.shown as byte\n\n\n\n\nmongodb.metrics.repl.network.bytesps(gauge)\nAmount of data read from the replication sync source per second.shown as byte/second\n\n\n\n\nmongodb.metrics.repl.network.getmores.numps(gauge)\nNumber of getmore operations per second.shown as operation/second\n\n\n\n\nmongodb.metrics.repl.network.getmores.totalmillisps(gauge)\nFraction of time (ms/s) required to collect data from getmore operations.shown as fraction\n\n\n\n\nmongodb.metrics.repl.network.opsps(gauge)\nNumber of operations read from the replication source per second.shown as operation/second\n\n\n\n\nmongodb.metrics.repl.network.readerscreatedps(gauge)\nNumber of oplog query processes created per second.shown as process/second\n\n\n\n\nmongodb.metrics.ttl.deleteddocumentsps(gauge)\nNumber of documents deleted from collections with a ttl index per second.shown as document/second\n\n\n\n\nmongodb.metrics.ttl.passesps(gauge)\nNumber of times per second the background process removes documents from collections with a ttl index.shown as operation/second\n\n\n\n\nmongodb.opcounters.commandps(gauge)\nTotal number of commands per second issued to the database.shown as command/second\n\n\n\n\nmongodb.opcounters.deleteps(gauge)\nNumber of delete operations per second.shown as operation/second\n\n\n\n\nmongodb.opcounters.getmoreps(gauge)\nNumber of getmore operations per second.shown as operation/second\n\n\n\n\nmongodb.opcounters.insertps(gauge)\nNumber of insert operations per second.shown as operation/second\n\n\n\n\nmongodb.opcounters.queryps(gauge)\nTotal number of queries per second.shown as query/second\n\n\n\n\nmongodb.opcounters.updateps(gauge)\nNumber of update operations per second.shown as operation/second\n\n\n\n\nmongodb.opcountersrepl.commandps(gauge)\nTotal number of replicated commands issued to the database per second.shown as command/second\n\n\n\n\nmongodb.opcountersrepl.deleteps(gauge)\nNumber of replicated delete operations per second.shown as operation/second\n\n\n\n\nmongodb.opcountersrepl.getmoreps(gauge)\nNumber of replicated getmore operations per second.shown as operation/second\n\n\n\n\nmongodb.opcountersrepl.insertps(gauge)\nNumber of replicated insert operations per second.shown as operation/second\n\n\n\n\nmongodb.opcountersrepl.queryps(gauge)\nTotal number of replicated queries per second.shown as query/second\n\n\n\n\nmongodb.opcountersrepl.updateps(gauge)\nNumber of replicated update operations per second.shown as operation/second\n\n\n\n\nmongodb.oplog.logsizemb(gauge)\nTotal size of the oplog.shown as mebibyte\n\n\n\n\nmongodb.oplog.timediff(gauge)\nOplog window: difference between the first and last operation in the oplog.shown as second\n\n\n\n\nmongodb.oplog.usedsizemb(gauge)\nTotal amount of space used by the oplog.shown as mebibyte\n\n\n\n\nmongodb.replset.health(gauge)\nMember health value of the replica set: conveys if the member is up (i.e. 1) or down (i.e. 0).\n\n\n\n\nmongodb.replset.replicationlag(gauge)\nDelay between a write operation on the primary and its copy to a secondary.shown as second\n\n\n\n\nmongodb.stats.datasize(gauge)\nTotal size of the data held in this database including the padding factor.shown as byte\n\n\n\n\nmongodb.stats.indexes(gauge)\nTotal number of indexes across all collections in the database.shown as index\n\n\n\n\nmongodb.stats.indexsize(gauge)\nTotal size of all indexes created on this database.shown as byte\n\n\n\n\nmongodb.stats.objects(gauge)\nNumber of objects (documents) in the database across all collections.shown as object\n\n\n\n\nmongodb.stats.storagesize(gauge)\nTotal amount of space allocated to collections in this database for document storage.shown as byte\n\n\n\n\nmongodb.uptime(gauge)\nNumber of seconds that the mongos or mongod process has been active.shown as second\n\n\n\n\nmongodb.wiredtiger.cache.bytes_currently_in_cache(gauge)\nSize of the data currently in cache.shown as byte\n\n\n\n\nmongodb.wiredtiger.cache.failed_eviction_of_pages_exceeding_the_in_memory_maximumps(gauge)\nNumber of failed eviction of pages that exceeded the in-memory maximum, per second.shown as page/second\n\n\n\n\nmongodb.wiredtiger.cache.in_memory_page_splits(gauge)\nIn-memory page splits.shown as split\n\n\n\n\nmongodb.wiredtiger.cache.maximum_bytes_configured(gauge)\nMaximum cache size.shown as byte\n\n\n\n\nmongodb.wiredtiger.cache.maximum_page_size_at_eviction(gauge)\nMaximum page size at eviction.shown as byte\n\n\n\n\nmongodb.wiredtiger.cache.modified_pages_evicted(gauge)\nNumber of pages, that have been modified, evicted from the cache.shown as page\n\n\n\n\nmongodb.wiredtiger.cache.pages_currently_held_in_cache(gauge)\nNumber of pages currently held in the cache.shown as page\n\n\n\n\nmongodb.wiredtiger.cache.pages_evicted_by_application_threadsps(gauge)\nNumber of page evicted by application threads per second.shown as page/second\n\n\n\n\nmongodb.wiredtiger.cache.pages_evicted_exceeding_the_in_memory_maximumps(gauge)\nNumber of pages evicted because they exceeded the cache in-memory maximum, per second.shown as page/second\n\n\n\n\nmongodb.wiredtiger.cache.tracked_dirty_bytes_in_cache(gauge)\nSize of the dirty data in the cache.shown as byte\n\n\n\n\nmongodb.wiredtiger.cache.unmodified_pages_evicted(gauge)\nNumber of pages, that were not modified, evicted from the cache.shown as page\n\n\n\n\nmongodb.wiredtiger.concurrenttransactions.read.available(gauge)\nNumber of available read tickets (concurrent transactions) remaining.shown as ticket\n\n\n\n\nmongodb.wiredtiger.concurrenttransactions.read.out(gauge)\nNumber of read tickets (concurrent transactions) in use.shown as ticket\n\n\n\n\nmongodb.wiredtiger.concurrenttransactions.read.totaltickets(gauge)\nTotal number of read tickets (concurrent transactions) available.shown as ticket\n\n\n\n\nmongodb.wiredtiger.concurrenttransactions.write.available(gauge)\nNumber of available write tickets (concurrent transactions) remaining.shown as ticket\n\n\n\n\nmongodb.wiredtiger.concurrenttransactions.write.out(gauge)\nNumber of write tickets (concurrent transactions) in use.shown as ticket\n\n\n\n\nmongodb.wiredtiger.concurrenttransactions.write.totaltickets(gauge)\nTotal number of write tickets (concurrent transactions) available.shown as ticket\n\n\n\n\nmongodb.collection.size(gauge)\nThe total size in bytes of the data in the collection plus the size of every indexes on the mongodb.collection.shown as byte\n\n\n\n\nmongodb.collection.avgObjSize(gauge)\nThe size of the average object in the collection in bytes.shown as byte\n\n\n\n\nmongodb.collection.count(gauge)\nTotal number of objects in the collection.shown as item\n\n\n\n\nmongodb.collection.capped(gauge)\nWhether or not the collection is capped.shown as record\n\n\n\n\nmongodb.collection.max(gauge)\nMaximum number of documents in a capped collection.shown as document\n\n\n\n\nmongodb.collection.maxSize(gauge)\nMaximum size of a capped collection in bytes.shown as byte\n\n\n\n\nmongodb.collection.storageSize(gauge)\nTotal storage space allocated to this collection for document storage.shown as byte\n\n\n\n\nmongodb.collection.nindexes(gauge)\nTotal number of indices on the collection.shown as index\n\n\n\n\nmongodb.collection.indexSizes(gauge)\nSize of index in bytes.shown as byte\n\n\n\n\nNote: many of these metrics are described in the MongoDB Manual 3.0\n\n","tags":"","loc":"/integrations/mongodb/"},{"title":"Datadog-Moxtra Integration","text":"\n\nOverview\n\nMoxtra delivers an embeddable, multilayered cloud collaboration service that lets people work on the go or at their desks.\n\nIntegrate Moxtra to\n\n\n  Be notified when a metric alert is triggered\n  Share your graphs with your team\n\n\n\nInstallation\n\nTo enable this integration…\n\n\n  In your Moxtra account, navigate to the Integrations tab.\n  Search for Datadog and Add the integration.\n\n\n\nConfiguration\n\n\n  Click the Install Integration button on the Moxtra Integration Tile.\n  Add your Webhook URL to Datadog’s webhooks-enabled services here.\n\n\n","tags":"","loc":"/integrations/moxtra/"},{"title":"Datadog-mParticle Integration","text":"\nConnect mParticle to Datadog and see the following information in real-time in your Datadog dashboard:\n\n\n  Crash Reports\n  3rd Party Network Performance Data\n  Active Session Details\n  Device CPU, Memory, and Battery Utilization\n\n","tags":"","loc":"/integrations/mparticle/"},{"title":"Datadog-MySQL Integration","text":"\n\nOverview\n\nConnect MySQL to Datadog in order to:\n\n\n  Visualize your database performance\n  Correlate the performance of MySQL with the rest of your applications\n\n\n\nInstallation\n\n\n  \n    Create a datadog user with replication rights on your MySQL server with the following command, replacing <UNIQUEPASSWORD> with a unique password:\n\n    sudo mysql -e \"CREATE USER 'datadog'@'localhost' IDENTIFIED BY '<UNIQUEPASSWORD>';\"\nsudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'datadog'@'localhost' WITH MAX_USER_CONNECTIONS 5;\"\n\n\n    If you’d like to get the full metrics catalog please also grant the following privileges:\n\n    sudo mysql -e \"GRANT PROCESS ON *.* TO 'datadog'@'localhost';\"\nsudo mysql -e \"GRANT SELECT ON performance_schema.* TO 'datadog'@'localhost';\"\n\n  \n  \n    Verify that the user was created successfully using the following command, replacing <UNIQUEPASSWORD> with the password above:\n\n    mysql -u datadog --password=<UNIQUEPASSWORD> -e \"show status\" | \\\ngrep Uptime && echo -e \"\\033[0;32mMySQL user - OK\\033[0m\" || \\\necho -e \"\\033[0;31mCannot connect to MySQL\\033[0m\"\nmysql -u datadog --password=<UNIQUEPASSWORD> -e \"show slave status\" && \\\necho -e \"\\033[0;32mMySQL grant - OK\\033[0m\" || \\\necho -e \"\\033[0;31mMissing REPLICATION CLIENT grant\\033[0m\"\n\n  \n\n\n\nConfiguration\n\n\n  \n    Edit the mysql.yaml file in your agent’s conf.d directory, replacing <UNIQUEPASSWORD> with the password used above.\n\n    init_config:\n\ninstances:\n  - server: localhost\n    user: datadog\n    pass: <UNIQUEPASSWORD>\n\n    tags:\n        - optional_tag1\n        - optional_tag2\n    options:\n        replication: 0\n        galera_cluster: 1\n        extra_status_metrics: true\n        extra_innodb_metrics: true\n        extra_performance_metrics: true\n        schema_size_metrics: false\n        disable_innodb_metrics: false\n\n\n    Agent 5.7 added a new option: disable_innodb_metrics. This should only be used with older versions of MySQL without innodb engine support.\n\n    See the metrics section below to see a list of the new metrics provided by each of the metric options.\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nMySQL YAML example\nMySQL checks.d\n\n\n\nValidation\n\nTo validate your installation and configuration, restart the agent and execute the info command. The output should contain a section similar to the following:\n\nChecks\n======\n  [...]\n  mysql\n  -----\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\nmysql.galera.wsrep_cluster_size(gauge)\nThe current number of nodes in the Galera cluster.shown as node\n\n\n\n\nmysql.innodb.buffer_pool_free(gauge)\nThe number of free pages in the InnoDB Buffer Pool.shown as page\n\n\n\n\nmysql.innodb.buffer_pool_total(gauge)\nThe total number of pages in the InnoDB Buffer Pool.shown as page\n\n\n\n\nmysql.innodb.buffer_pool_used(gauge)\nThe number of used pages in the InnoDB Buffer Pool.shown as page\n\n\n\n\nmysql.innodb.buffer_pool_utilization(gauge)\nThe utilization of the InnoDB Buffer Pool.shown as fraction\n\n\n\n\nmysql.innodb.current_row_locks(gauge)\nThe number of current row locks.shown as lock\n\n\n\n\nmysql.innodb.data_reads(gauge)\nThe rate of data reads.shown as read/second\n\n\n\n\nmysql.innodb.data_writes(gauge)\nThe rate of data writes.shown as write/second\n\n\n\n\nmysql.innodb.mutex_os_waits(gauge)\nThe rate of mutex OS waits.shown as event/second\n\n\n\n\nmysql.innodb.mutex_spin_rounds(gauge)\nThe rate of mutex spin rounds.shown as event/second\n\n\n\n\nmysql.innodb.mutex_spin_waits(gauge)\nThe rate of mutex spin waits.shown as event/second\n\n\n\n\nmysql.innodb.os_log_fsyncs(gauge)\nThe rate of fsync writes to the log file.shown as write/second\n\n\n\n\nmysql.innodb.row_lock_time(gauge)\nFraction of time spent (ms/s) acquring row locks.shown as fraction\n\n\n\n\nmysql.innodb.row_lock_waits(gauge)\nThe number of times per second a row lock had to be waited for.shown as event/second\n\n\n\n\nmysql.net.connections(gauge)\nThe rate of connections to the server.shown as connection/second\n\n\n\n\nmysql.net.max_connections(gauge)\nThe maximum number of connections that have been in use simultaneously since the server started.shown as connection\n\n\n\n\nmysql.performance.com_delete(gauge)\nThe rate of delete statements.shown as query/second\n\n\n\n\nmysql.performance.com_delete_multi(gauge)\nThe rate of delete-multi statements.shown as query/second\n\n\n\n\nmysql.performance.com_insert(gauge)\nThe rate of insert statements.shown as query/second\n\n\n\n\nmysql.performance.com_insert_select(gauge)\nThe rate of insert-select statements.shown as query/second\n\n\n\n\nmysql.performance.com_replace_select(gauge)\nThe rate of replace-select statements.shown as query/second\n\n\n\n\nmysql.performance.com_select(gauge)\nThe rate of select statements.shown as query/second\n\n\n\n\nmysql.performance.com_update(gauge)\nThe rate of update statements.shown as query/second\n\n\n\n\nmysql.performance.com_update_multi(gauge)\nThe rate of update-multi.shown as query/second\n\n\n\n\nmysql.performance.created_tmp_disk_tables(gauge)\nThe rate of internal on-disk temporary tables created by second by the server while executing statements.shown as table/second\n\n\n\n\nmysql.performance.created_tmp_files(gauge)\nThe rate of temporary files created by second.shown as file/second\n\n\n\n\nmysql.performance.created_tmp_tables(gauge)\nThe rate of internal temporary tables created by second by the server while executing statements.shown as table/second\n\n\n\n\nmysql.performance.kernel_time(gauge)\nPercentage of CPU time spent in kernel space by MySQL.shown as percent\n\n\n\n\nmysql.performance.key_cache_utilization(gauge)\nThe key cache utilization ratio.shown as fraction\n\n\n\n\nmysql.performance.open_files(gauge)\nThe number of open files.shown as file\n\n\n\n\nmysql.performance.open_tables(gauge)\nThe number of of tables that are open.shown as table\n\n\n\n\nmysql.performance.qcache_hits(gauge)\nThe rate of query cache hits.shown as hit/second\n\n\n\n\nmysql.performance.questions(gauge)\nThe rate of statements executed by the server.shown as query/second\n\n\n\n\nmysql.performance.slow_queries(gauge)\nThe rate of slow queries.shown as query/second\n\n\n\n\nmysql.performance.table_locks_waited(gauge)\nThe total number of times that a request for a table lock could not be granted immediately and a wait was needed.\n\n\n\n\nmysql.performance.threads_connected(gauge)\nThe number of currently open connections.shown as connection\n\n\n\n\nmysql.performance.threads_running(gauge)\nThe number of threads that are not sleeping.shown as thread\n\n\n\n\nmysql.performance.user_time(gauge)\nPercentage of CPU time spent in user space by MySQL.shown as percent\n\n\n\n\nmysql.replication.seconds_behind_master(gauge)\nThe lag in seconds between the master and the slave.shown as second\n\n\n\n\nmysql.replication.slave_running(gauge)\nA boolean showing if this server is a replication slave that is connected to a replication master.\n\n\n\n\nmysql.performance.queries(gauge)\nThe rate of queries.shown as query/second\n\n\n\n\n\n  \n    \n      \nextra_status_metrics adds the following metrics:\n       \n    \n  \n  \n    \n      mysql.binlog.cache_disk_use\n      GAUGE\n    \n    \n      mysql.binlog.cache_use\n      GAUGE\n    \n    \n      mysql.performance.handler_commit\n      RATE\n    \n    \n      mysql.performance.handler_delete\n      RATE\n    \n    \n      mysql.performance.handler_prepare\n      RATE\n    \n    \n      mysql.performance.handler_read_first\n      RATE\n    \n    \n      mysql.performance.handler_read_key\n      RATE\n    \n    \n      mysql.performance.handler_read_next\n      RATE\n    \n    \n      mysql.performance.handler_read_prev\n      RATE\n    \n    \n      mysql.performance.handler_read_rnd\n      RATE\n    \n    \n      mysql.performance.handler_read_rnd_next\n      RATE\n    \n    \n      mysql.performance.handler_rollback\n      RATE\n    \n    \n      mysql.performance.handler_update\n      RATE\n    \n    \n      mysql.performance.handler_write\n      RATE\n    \n    \n      mysql.performance.opened_tables\n      RATE\n    \n    \n      mysql.performance.qcache_total_blocks\n      GAUGE\n    \n    \n      mysql.performance.qcache_free_blocks\n      GAUGE\n    \n    \n      mysql.performance.qcache_free_memory\n      GAUGE\n    \n    \n      mysql.performance.qcache_not_cached\n      RATE\n    \n    \n      mysql.performance.qcache_queries_in_cache\n      GAUGE\n    \n    \n      mysql.performance.select_full_join\n      RATE\n    \n    \n      mysql.performance.select_full_range_join\n      RATE\n    \n    \n      mysql.performance.select_range\n      RATE\n    \n    \n      mysql.performance.select_range_check\n      RATE\n    \n    \n      mysql.performance.select_scan\n      RATE\n    \n    \n      mysql.performance.sort_merge_passes\n      RATE\n    \n    \n      mysql.performance.sort_range\n      RATE\n    \n    \n      mysql.performance.sort_rows\n      RATE\n    \n    \n      mysql.performance.sort_scan\n      RATE\n    \n    \n      mysql.performance.table_locks_immediate\n      GAUGE\n    \n    \n      mysql.performance.table_locks_immediate.rate\n      RATE\n    \n    \n      mysql.performance.threads_cached\n      GAUGE\n    \n    \n      mysql.performance.threads_created\n      MONOTONIC\n    \n  \n\n\n\n  \n    \n      \nextra_innodb_metrics adds the following metrics:\n       \n    \n  \n  \n    \n      mysql.innodb.active_transactions\n      GAUGE\n    \n    \n      mysql.innodb.buffer_pool_data\n      GAUGE\n    \n    \n      mysql.innodb.buffer_pool_pages_data\n      GAUGE\n    \n    \n      mysql.innodb.buffer_pool_pages_dirty\n      GAUGE\n    \n    \n      mysql.innodb.buffer_pool_pages_flushed\n      RATE\n    \n    \n      mysql.innodb.buffer_pool_pages_free\n      GAUGE\n    \n    \n      mysql.innodb.buffer_pool_pages_total\n      GAUGE\n    \n    \n      mysql.innodb.buffer_pool_read_ahead\n      RATE\n    \n    \n      mysql.innodb.buffer_pool_read_ahead_evicted\n      RATE\n    \n    \n      mysql.innodb.buffer_pool_read_ahead_rnd\n      GAUGE\n    \n    \n      mysql.innodb.buffer_pool_wait_free\n      MONOTONIC\n    \n    \n      mysql.innodb.buffer_pool_write_requests\n      RATE\n    \n    \n      mysql.innodb.checkpoint_age\n      GAUGE\n    \n    \n      mysql.innodb.current_transactions\n      GAUGE\n    \n    \n      mysql.innodb.data_fsyncs\n      RATE\n    \n    \n      mysql.innodb.data_pending_fsyncs\n      GAUGE\n    \n    \n      mysql.innodb.data_pending_reads\n      GAUGE\n    \n    \n      mysql.innodb.data_pending_writes\n      GAUGE\n    \n    \n      mysql.innodb.data_read\n      RATE\n    \n    \n      mysql.innodb.data_written\n      RATE\n    \n    \n      mysql.innodb.dblwr_pages_written\n      RATE\n    \n    \n      mysql.innodb.dblwr_writes\n      RATE\n    \n    \n      mysql.innodb.hash_index_cells_total\n      GAUGE\n    \n    \n      mysql.innodb.hash_index_cells_used\n      GAUGE\n    \n    \n      mysql.innodb.history_list_length\n      GAUGE\n    \n    \n      mysql.innodb.ibuf_free_list\n      GAUGE\n    \n    \n      mysql.innodb.ibuf_merged\n      RATE\n    \n    \n      mysql.innodb.ibuf_merged_delete_marks\n      RATE\n    \n    \n      mysql.innodb.ibuf_merged_deletes\n      RATE\n    \n    \n      mysql.innodb.ibuf_merged_inserts\n      RATE\n    \n    \n      mysql.innodb.ibuf_merges\n      RATE\n    \n    \n      mysql.innodb.ibuf_segment_size\n      GAUGE\n    \n    \n      mysql.innodb.ibuf_size\n      GAUGE\n    \n    \n      mysql.innodb.lock_structs\n      RATE\n    \n    \n      mysql.innodb.locked_tables\n      GAUGE\n    \n    \n      mysql.innodb.locked_transactions\n      GAUGE\n    \n    \n      mysql.innodb.log_waits\n      RATE\n    \n    \n      mysql.innodb.log_write_requests\n      RATE\n    \n    \n      mysql.innodb.log_writes\n      RATE\n    \n    \n      mysql.innodb.lsn_current\n      RATE\n    \n    \n      mysql.innodb.lsn_flushed\n      RATE\n    \n    \n      mysql.innodb.lsn_last_checkpoint\n      RATE\n    \n    \n      mysql.innodb.mem_adaptive_hash\n      GAUGE\n    \n    \n      mysql.innodb.mem_additional_pool\n      GAUGE\n    \n    \n      mysql.innodb.mem_dictionary\n      GAUGE\n    \n    \n      mysql.innodb.mem_file_system\n      GAUGE\n    \n    \n      mysql.innodb.mem_lock_system\n      GAUGE\n    \n    \n      mysql.innodb.mem_page_hash\n      GAUGE\n    \n    \n      mysql.innodb.mem_recovery_system\n      GAUGE\n    \n    \n      mysql.innodb.mem_thread_hash\n      GAUGE\n    \n    \n      mysql.innodb.mem_total\n      GAUGE\n    \n    \n      mysql.innodb.os_file_fsyncs\n      RATE\n    \n    \n      mysql.innodb.os_file_reads\n      RATE\n    \n    \n      mysql.innodb.os_file_writes\n      RATE\n    \n    \n      mysql.innodb.os_log_pending_fsyncs\n      GAUGE\n    \n    \n      mysql.innodb.os_log_pending_writes\n      GAUGE\n    \n    \n      mysql.innodb.os_log_written\n      RATE\n    \n    \n      mysql.innodb.pages_created\n      RATE\n    \n    \n      mysql.innodb.pages_read\n      RATE\n    \n    \n      mysql.innodb.pages_written\n      RATE\n    \n    \n      mysql.innodb.pending_aio_log_ios\n      GAUGE\n    \n    \n      mysql.innodb.pending_aio_sync_ios\n      GAUGE\n    \n    \n      mysql.innodb.pending_buffer_pool_flushes\n      GAUGE\n    \n    \n      mysql.innodb.pending_checkpoint_writes\n      GAUGE\n    \n    \n      mysql.innodb.pending_ibuf_aio_reads\n      GAUGE\n    \n    \n      mysql.innodb.pending_log_flushes\n      GAUGE\n    \n    \n      mysql.innodb.pending_log_writes\n      GAUGE\n    \n    \n      mysql.innodb.pending_normal_aio_reads\n      GAUGE\n    \n    \n      mysql.innodb.pending_normal_aio_writes\n      GAUGE\n    \n    \n      mysql.innodb.queries_inside\n      GAUGE\n    \n    \n      mysql.innodb.queries_queued\n      GAUGE\n    \n    \n      mysql.innodb.read_views\n      GAUGE\n    \n    \n      mysql.innodb.rows_deleted\n      RATE\n    \n    \n      mysql.innodb.rows_inserted\n      RATE\n    \n    \n      mysql.innodb.rows_read\n      RATE\n    \n    \n      mysql.innodb.rows_updated\n      RATE\n    \n    \n      mysql.innodb.s_lock_os_waits\n      RATE\n    \n    \n      mysql.innodb.s_lock_spin_rounds\n      RATE\n    \n    \n      mysql.innodb.s_lock_spin_waits\n      RATE\n    \n    \n      mysql.innodb.semaphore_wait_time\n      GAUGE\n    \n    \n      mysql.innodb.semaphore_waits\n      GAUGE\n    \n    \n      mysql.innodb.tables_in_use\n      GAUGE\n    \n    \n      mysql.innodb.x_lock_os_waits\n      RATE\n    \n    \n      mysql.innodb.x_lock_spin_rounds\n      RATE\n    \n    \n      mysql.innodb.x_lock_spin_waits\n      RATE\n    \n  \n\n\n\n  \n    \n      \nextra_performance_metrics adds the following metrics:\n       \n    \n  \n  \n    \n      mysql.performance.query_run_time.avg\n      GAUGE\n    \n    \n      mysql.performance.digest_95th_percentile.avg_us\n      GAUGE\n    \n  \n\n\n\n  \n    \n      \nschema_size_metrics adds the following metric:\n       \n    \n  \n  \n    \n      mysql.info.schema.size\n      GAUGE\n    \n  \n\n\n","tags":"","loc":"/integrations/mysql/"},{"title":"Datadog-Nagios Integration","text":"\n\nOverview\n\nCapture Nagios activity in Datadog to:\n\n\n  Identify trends in service failures at a glance.\n  Recall issue resolutions with a single click.\n  Discuss service failures with your team.\n\n\nSet up information collection for Nagios by editing the given YAML configuration file nagios.yaml.example and renaming it as nagios.yaml After having Nagios reporting to Datadog for a week, an interactive report on alerting checks can be found here. To integrate with the Icinga fork of Nagios, you should be able to use the Nagios integration to pull in Icinga events. Just link to the Icinga configuration instead of the Nagios one.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nNagios YAML example\nNagios checks.d\n\n\n","tags":"","loc":"/integrations/nagios/"},{"title":"Network check","text":"\n\nOverview\n\n\n\nThe network check collects TCP and IP network metrics from the agent’s host.\n\n\nConfiguration\n\nThe network check is enabled by default. If you would like to make any changes to the check, rename network.yaml.default to network.yaml and edit:\n\ninit_config:\n\ninstances:\n  # Network check only supports one configured instance\n  - collect_connection_state: false\n    excluded_interfaces:\n      - lo\n      - lo0\n    # Optionally completely ignore any network interface\n    # matching the given regex:\n    # excluded_interface_re: my-network-interface.*\n\n\n\nMetrics\n\n\n\n\nsystem.net.bytes_rcvd(gauge)\nThe number of bytes received on a device per second.shown as byte/second\n\n\n\n\nsystem.net.bytes_sent(gauge)\nThe number of bytes sent from a device per second.shown as byte/second\n\n\n\n\nsystem.net.packets_in.count(gauge)\nThe number of packets of data received by the interface.shown as packet/second\n\n\n\n\nsystem.net.packets_in.error(gauge)\nThe number of packet receive errors detected by the device driver.shown as error/second\n\n\n\n\nsystem.net.packets_out.count(gauge)\nThe number of packets of data transmitted by the interface.shown as packet/second\n\n\n\n\nsystem.net.packets_out.error(gauge)\nThe number of packet transmit errors detected by the device driver.shown as error/second\n\n\n\n\nsystem.net.tcp.in_segs **Solaris only(gauge)\nThe number of TCP segments received.shown as segment/second\n\n\n\n\nsystem.net.tcp.out_segs **Solaris only(gauge)\nThe number of TCP segments transmitted.shown as segment/second\n\n\n\n\nsystem.net.tcp.rcv_packs **BSD only(gauge)\nThe number of TCP packets received.shown as packet/second\n\n\n\n\nsystem.net.tcp.retrans_packs **BSD only(gauge)\nThe number of TCP packets retransmitted.shown as packet/second\n\n\n\n\nsystem.net.tcp.retrans_segs **Solaris only(gauge)\nThe number of TCP segments retransmitted.shown as segment/second\n\n\n\n\nsystem.net.tcp.sent_packs **BSD only(gauge)\nThe number of TCP packets transmitted.shown as packet/second\n\n\n\n\nsystem.net.tcp.rtt(gauge every 10 seconds)\nThe TCP round trip time.shown as millisecond\n\n\n\n\nsystem.net.tcp.rtt.avg(gauge every 10 seconds)\nThe average TCP round trip time as typically computed by the TCP stack.shown as millisecond\n\n\n\n\nsystem.net.tcp.rtt.jitter(gauge every 10 seconds)\nThe TCP round trip time jitter.shown as millisecond\n\n\n\n\nsystem.net.udp.in_datagrams(gauge)\nThe rate of UDP datagrams delivered to UDP users.shown as datagram/second\n\n\n\n\nsystem.net.udp.in_errors(gauge)\nThe rate of received UDP datagrams that could not be delivered for reasons other than the lack of an application at the destination port.shown as datagram/second\n\n\n\n\nsystem.net.udp.no_ports(gauge)\nThe rate of received UDP datagrams for which there was no application at the destination port.shown as datagram/second\n\n\n\n\nsystem.net.udp.out_datagrams(gauge)\nThe rate of UDP datagrams sent from this entity.shown as datagram/second\n\n\n\n\nsystem.net.udp.rcv_buf_errors(gauge)\nThe rate of UDP datagrams lost because there was no room in the receive buffer.shown as error/second\n\n\n\n\nsystem.net.udp.snd_buf_errors(gauge)\nThe rate of UDP datagrams lost because there was no room in the send buffer.shown as error/second\n\n\n\n","tags":"","loc":"/integrations/network/"},{"title":"Datadog-New Relic Integration","text":"\n\nOverview\n\n\n\nConnect to New Relic to:\n\n\n  See key New Relic metrics (like response time and Apdex score) in context with the rest of your Datadog metrics\n  See New Relic alerts in your event stream\n\n\n\nInstallation\n\n\nNew Relic Alerts in Event Stream\n\n\n  \n    On the Webhook tab of New Relic’s alerting notification settings page, enter the following webhook URL:\n\n    https://app.datadoghq.com/intake/webhook/newrelic?api_key={YOUR_DATADOG_API_KEY}\n\n  \n  \n    For ‘Custom Payload’(s), select JSON ‘Payload Type’.\n  \n\n\n\nNew Relic APM Metric Collection\n\n\n  \n    Locate your API key on New Relic’s API Keys page (Account Settings -> Integrations -> API Keys) and enter it in the form on the Datadog New Relic Integration page.\n\n    Note: Metrics can only be imported for New Relic customers at the Pro level or above.\n  \n  If you wish to tag metrics at an account level, please add an account tag.\n  \n    Choose whether you want to collect your metrics per hosts or app-wide.\n\n    Note: Enabling this options will import New Relic hosts to Datadog.\n  \n\n\n\nMetrics\n\n\n\n\nnew_relic.apdex.score(gauge)\nRatio of satisfactory response times to unsatisfactory response timesshown as apdex\n\n\n\n\nnew_relic.application_summary.apdex_score(gauge)\nRatio of satisfactory response times to unsatisfactory response timesshown as apdex\n\n\n\n\nnew_relic.application_summary.apdex_target(gauge)\nThreshold ratio of satisfactory response times to unsatisfactory response timesshown as apdex\n\n\n\n\nnew_relic.application_summary.concurrent_instance_count(gauge)\nNumber of concurrent instances serving the applicationshown as instance\n\n\n\n\nnew_relic.application_summary.error_rate(gauge)\nRatio of the number of errors reported by the application to the total number of served requestsshown as percent\n\n\n\n\nnew_relic.application_summary.host_count(gauge)\nNumber of hosts serving the applicationshown as host\n\n\n\n\nnew_relic.application_summary.instance_count(gauge)\nNumber of instances serving the applicationshown as instance\n\n\n\n\nnew_relic.application_summary.response_time(gauge)\nApplication response timeshown as millisecond\n\n\n\n\nnew_relic.application_summary.throughput(gauge)\nNumber of requests served by the applicationshown as request/minute\n\n\n\n\nnew_relic.database.all.average_exclusive_time(gauge)\nAverage time spent in database queries, exclusive of any time instrumented by other metricsshown as millisecond\n\n\n\n\nnew_relic.errors.all.errors_per_minute(gauge)\nNumber of errors reported by the applicationshown as error/minute\n\n\n\n\nnew_relic.web_transaction.average_response_time(gauge)\nAverage response time of web transactions served by the applicationshown as millisecond\n\n\n\n\nnew_relic.web_transaction.requests_per_minute(gauge)\nNumber of web transaction requests served by the applicationshown as request/minute\n\n\n\n\nnew_relic.synthetics_summary.monitors.count(gauge)\nCount of monitorsshown as monitor\n\n\n\n\nnew_relic.synthetics_summary.monitors.frequency(gauge)\nFrequency of the monitorshown as minute\n\n\n\n\nnew_relic.synthetics_summary.locations.count(gauge)\nCount of locations associated with the monitorshown as location\n\n\n\n\nnew_relic.synthetic_check.duration(gauge)\nTotal time for the monitor runshown as millisecond\n\n\n\n\nnew_relic.synthetic_check.total_request_body_size(gauge)\nSize of the body request to the servershown as byte\n\n\n\n\nnew_relic.synthetic_check.total_request_header_size(gauge)\nSize of the header request to the servershown as byte\n\n\n\n\nnew_relic.synthetic_check.total_response_header_size(gauge)\nSize of the response header returned by the servershown as byte\n\n\n\n\nnew_relic.synthetic_check.total_response_body_size(gauge)\nSize of the response body returned by the servershown as byte\n\n\n\n\nnew_relic.synthetic_check.count(count)\nCount of monitor runsshown as check\n\n\n\n\nnew_relic.synthetic_check.errors(count)\nCount of monitor failuresshown as error\n\n\n\n\nnew_relic.synthetic_request.count(count)\nCount of requestsshown as request\n\n\n\n\nnew_relic.synthetic_request.duration_blocked.average(gauge)\nAverage time the requests were blockedshown as millisecond\n\n\n\n\nnew_relic.synthetic_request.duration_connect.average(gauge)\nAverage time the requests were establishing a connectionshown as millisecond\n\n\n\n\nnew_relic.synthetic_request.duration_dns.average(gauge)\nAverage time the requests were resolving DNSshown as millisecond\n\n\n\n\nnew_relic.synthetic_request.duration_receive.average(gauge)\nAverage time the requests were receiving datashown as millisecond\n\n\n\n\nnew_relic.synthetic_request.duration_send.average(gauge)\nAverage time the requests were sending datashown as millisecond\n\n\n\n\nnew_relic.synthetic_request.duration_ssl.average(gauge)\nAverage time establishing an SSL connectionshown as millisecond\n\n\n\n\nnew_relic.synthetic_request.duration_wait.average(gauge)\nAverage time the requests were waitingshown as millisecond\n\n\n\n\nnew_relic.synthetic_request.resources_load_time(gauge)\nAverage resources load timeshown as millisecond\n\n\n\n\nnew_relic.synthetic_request.time_spent_third_parties(gauge)\nAverage time spent by third partiesshown as millisecond\n\n\n\n\n\nTroubleshooting\n\nWhat does the ‘Collect metrics by host’ option do?\n\nWhen set, Datadog collects application metrics for every associated hosts,\ninstead of the overall host throughput based average.\n\nThis makes sense when using those metrics separately, i.e.\n“host X has aberrant error rate Y which is problematic, though application Z overall\nacross many hosts has an acceptable error rate in aggregate”.\n\nThis also import New Relic hosts to Datadog Infrastructure section.\n\nI have the ‘Collect metrics by host’ option enable. Why do my application-level metrics have different values in New Relic and Datadog?\n\nWhen New Relic computes the aggregate application-level value for\nmetrics that are measured at the host level (e.g. response time), they\ncompute a weighted average based on each host’s measured throughput.\n\nThe closest thing you’ll see in Datadog is the avg aggregator, which\ncomputes the arithmetic mean of the values. This is also the default\naggregator, and what you’ll get for the simplest query, something like\nnew_relic.web_transaction.average_response_time{*}. If your hosts all\nhave approximately the same throughput, our average aggregation and NR’s\nthroughput-weighted aggregation will yield similar numbers, but if\nthoughput is not balanced, you will see different aggregate\napplication-level values in NR and Datadog.\n\nFor example, say you have an application with three hosts. At a\nspecific point in time, the hosts have the following values:\n\n           throughput    response time\nhostA         305 rpm           240 ms\nhostB         310 rpm           250 ms\nhostC          30 rpm            50 ms\n\n\nNew Relic would compute the application-level response time as follows:\n\nhostA: 240 ms * 305 rpm = 73200 total time\nhostB: 250 ms * 310 rpm = 77500 total time\nhostC:  50 ms *  30 rpm =  1500 total time\n\ntotal throughput = 305 + 310 + 30 = 645 rpm\naverage response time = (73200 + 77500 + 1500) / 645 = 236.0 ms\n\n\nWhereas we would simply compute the arithmetic mean:\n\naverage response time = (240 + 250 + 50) / 3 = 180.0 ms\n\n\nBeta Alerts: How can I include custom tags?\n\nYou can include custom tags by utilizing the “Use Custom Payload” option through New Relic’s Beta Alerts feature. To configure this, you’ll navigate to your New Relic account, and click the ‘Alerts Beta’ button in the upper right-hand corner of the screen. From here, select the ‘Notification channels’ section and find the Webhook you’ve setup for Datadog. From here there should be a section called ‘Use Custom Payload’, and once selected, it will expand to reveal a JSON payload. You need to modify this payload by adding a “tags” attribute. For example, a modified payload might look like this:\n\n{\n  \"account_id\": \"$ACCOUNT_ID\",\n  \"account_name\": \"$ACCOUNT_NAME\",\n  \"condition_id\": \"$CONDITION_ID\",\n  \"condition_name\": \"$CONDITION_NAME\",\n  \"current_state\": \"$EVENT_STATE\",\n  \"details\": \"$EVENT_DETAILS\",\n  \"event_type\": \"$EVENT_TYPE\",\n  \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\",\n  \"incident_id\": \"$INCIDENT_ID\",\n  \"incident_url\": \"$INCIDENT_URL\",\n  \"owner\": \"$EVENT_OWNER\",\n  \"policy_name\": \"$POLICY_NAME\",\n  \"policy_url\": \"$POLICY_URL\",\n  \"runbook_url\": \"$RUNBOOK_URL\",\n  \"severity\": \"$SEVERITY\",\n  \"targets\": \"$TARGETS\",\n  \"timestamp\": \"$TIMESTAMP\",\n  \"tags\": [\"application:yourapplication\", \"host:yourhostname\", \"sometag\"]\n}\n\n\nAfter your modifications are complete, make sure you select ‘Update Chanel’, for your changes to be saved.\n","tags":"","loc":"/integrations/new_relic/"},{"title":"Datadog-NGINX Integration","text":"\n\nOverview\n\nConnect NGINX to Datadog in order to:\n\n\n  Visualize your web server performance\n  Correlate the performance of NGINX with the rest of your applications\n\n\n\n\nLearn more about how to monitor NGINX performance metrics thanks to our series of posts. We detail the key performance metrics, how to collect them, and how to use Datadog to monitor NGINX.\n\nThe default agent checks require the NGINX stub status module, which is not compiled by default.  In debian/ubuntu, this module is enabled in the nginx-extras package.  To check if your version of nginx has the stub status module support compiled in, you can run:\n\n\n$ nginx -V |& grep http_stub_status_module\n\n\nIf you see some output with configure arguments: and lots of options, then you have it enabled.  Once you have a status-enabled version of nginx, you can set up a URL for the status module:\n\nserver {\n  listen 80;\n  server_name localhost;\n\n  access_log off;\n  allow 127.0.0.1;\n  deny all;\n\n  location /nginx_status {\n    stub_status on;\n  }\n}\n\n\nFor more information on configuration, read the stub status docs.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nNGINX YAML example\nNGINX checks.d\n\n\nAll metrics collected for NGINX and NGINX Plus\n\n\n\n\nnginx.net.writing(gauge)\nThe number of connections waiting on upstream responses and/or writing responses back to the client.shown as connection\n\n\n\n\nnginx.net.waiting(gauge)\nThe number of keep-alive connections waiting for work.shown as connection\n\n\n\n\nnginx.net.reading(gauge)\nThe number of connections reading client requets.shown as connection\n\n\n\n\nnginx.net.connections(gauge)\nThe total number of active connections.shown as connection\n\n\n\n\nnginx.net.request_per_s(gauge)\nRate of requests processed.shown as request/second\n\n\n\n\nnginx.net.conn_opened_per_s(gauge)\nRate of connections opened.shown as connection/second\n\n\n\n\nnginx.net.conn_dropped_per_s(gauge)\nRate of connections dropped.shown as connection/second\n\n\n\n\nnginx.connections.accepted(gauge)\nThe total number of accepted client connections.shown as connection\n\n\n\n\nnginx.connections.active(gauge)\nThe current number of active client connections.shown as connection\n\n\n\n\nnginx.connections.dropped(gauge)\nThe total number of dropped client connections.shown as connection\n\n\n\n\nnginx.connections.idle(gauge)\nThe current number of idle client connections.shown as connection\n\n\n\n\nnginx.generation(gauge)\nThe total number of configuration reloads.\n\n\n\n\nnginx.load_timestamp(gauge)\nTime of the last reload of configuration (time since Epoch).shown as millisecond\n\n\n\n\nnginx.pid(gauge)\nThe ID of the worker process that handled status request.\n\n\n\n\nnginx.processes.respawned(gauge)\nThe total number of abnormally terminated and respawned child processes.shown as process\n\n\n\n\nnginx.requests.current(gauge)\nThe current number of client requests.shown as request\n\n\n\n\nnginx.requests.total(gauge)\nThe total number of client requests.shown as request\n\n\n\n\nnginx.server_zone.discarded(gauge)\nThe total number of requests completed without sending a response.shown as request\n\n\n\n\nnginx.server_zone.processing(gauge)\nThe number of client requests that are currently being processed.shown as request\n\n\n\n\nnginx.server_zone.received(gauge)\nThe total amount of data received from clients.shown as byte\n\n\n\n\nnginx.server_zone.requests(gauge)\nThe total number of client requests received from clients.shown as request\n\n\n\n\nnginx.server_zone.responses.1xx(gauge)\nThe number of responses with 1xx status code.shown as response\n\n\n\n\nnginx.server_zone.responses.2xx(gauge)\nThe number of responses with 2xx status code.shown as response\n\n\n\n\nnginx.server_zone.responses.3xx(gauge)\nThe number of responses with 3xx status code.shown as response\n\n\n\n\nnginx.server_zone.responses.4xx(gauge)\nThe number of responses with 4xx status code.shown as response\n\n\n\n\nnginx.server_zone.responses.5xx(gauge)\nThe number of responses with 5xx status code.shown as response\n\n\n\n\nnginx.server_zone.responses.total(gauge)\nThe total number of responses sent to clients.shown as response\n\n\n\n\nnginx.server_zone.sent(gauge)\nThe total amount of data sent to clients.shown as byte\n\n\n\n\nnginx.ssl.handshakes(gauge)\nThe total number of successful SSL handshakes.\n\n\n\n\nnginx.ssl.handshakes_failed(gauge)\nThe total number of failed SSL handshakes.\n\n\n\n\nnginx.ssl.session_reuses(gauge)\nThe total number of session reuses during SSL handshake.\n\n\n\n\nnginx.timestamp(gauge)\nCurrent time since Epoch.shown as millisecond\n\n\n\n\nnginx.upstream.keepalive(gauge)\nThe current number of idle keepalive connections.shown as connection\n\n\n\n\nnginx.upstream.peers.active(gauge)\nThe current number of active connections.shown as connection\n\n\n\n\nnginx.upstream.peers.backup(gauge)\nA boolean value indicating whether the server is a backup server.\n\n\n\n\nnginx.upstream.peers.downstart(gauge)\nThe time (since Epoch) when the server became “unavail” or “unhealthy”.shown as millisecond\n\n\n\n\nnginx.upstream.peers.downtime(gauge)\nTotal time the server was in the “unavail” and “unhealthy” states.shown as millisecond\n\n\n\n\nnginx.upstream.peers.fails(gauge)\nThe total number of unsuccessful attempts to communicate with the server.\n\n\n\n\nnginx.upstream.peers.health_checks.checks(gauge)\nThe total number of health check requests made.\n\n\n\n\nnginx.upstream.peers.health_checks.fails(gauge)\nThe number of failed health checks.\n\n\n\n\nnginx.upstream.peers.health_checks.last_passed(gauge)\nBoolean indicating if the last health check request was successful and passed tests.\n\n\n\n\nnginx.upstream.peers.health_checks.unhealthy(gauge)\nHow many times the server became unhealthy (state “unhealthy”).\n\n\n\n\nnginx.upstream.peers.id(gauge)\nThe ID of the server.\n\n\n\n\nnginx.upstream.peers.received(gauge)\nThe total amount of data received from this server.shown as byte\n\n\n\n\nnginx.upstream.peers.requests(gauge)\nThe total number of client requests forwarded to this server.shown as request\n\n\n\n\nnginx.upstream.peers.responses.1xx(gauge)\nThe number of responses with 1xx status code.shown as response\n\n\n\n\nnginx.upstream.peers.responses.2xx(gauge)\nThe number of responses with 2xx status code.shown as response\n\n\n\n\nnginx.upstream.peers.responses.3xx(gauge)\nThe number of responses with 3xx status code.shown as response\n\n\n\n\nnginx.upstream.peers.responses.4xx(gauge)\nThe number of responses with 4xx status code.shown as response\n\n\n\n\nnginx.upstream.peers.responses.5xx(gauge)\nThe number of responses with 5xx status code.shown as response\n\n\n\n\nnginx.upstream.peers.responses.total(gauge)\nThe total number of responses obtained from this server.shown as response\n\n\n\n\nnginx.upstream.peers.selected(gauge)\nThe time (since Epoch) when the server was last selected to process a request (1.7.5).shown as millisecond\n\n\n\n\nnginx.upstream.peers.sent(gauge)\nThe total amount of data sent to this server.shown as byte\n\n\n\n\nnginx.upstream.peers.unavail(gauge)\nHow many times the server became unavailable for client requests (state “unavail”) due to the number of unsuccessful attempts reaching the max_fails threshold.\n\n\n\n\nnginx.upstream.peers.weight(gauge)\nWeight of the server.\n\n\n\n\nnginx.version(gauge)\nVersion of nginx.\n\n\n\n\n\nNGINX (Open Source)\n\n\n\n\nnginx.net.writing(gauge)\nThe number of connections waiting on upstream responses and/or writing responses back to the client.shown as connection\n\n\n\n\nnginx.net.waiting(gauge)\nThe number of keep-alive connections waiting for work.shown as connection\n\n\n\n\nnginx.net.reading(gauge)\nThe number of connections reading client requets.shown as connection\n\n\n\n\nnginx.net.connections(gauge)\nThe total number of active connections.shown as connection\n\n\n\n\nnginx.net.request_per_s(gauge)\nRate of requests processed.shown as request/second\n\n\n\n\nnginx.net.conn_opened_per_s(gauge)\nRate of connections opened.shown as connection/second\n\n\n\n\nnginx.net.conn_dropped_per_s(gauge)\nRate of connections dropped.shown as connection/second\n\n\n\n\nThe data pulled from the nginx stub status page are described in the NGINX docs.\n\n\nNGINX Plus\n\nIf you are using NGINX Plus, you have access to the extended http_status_module.  The agent supports this module too, and will collect a much longer list of metrics when the instance target is an http status module URL.\n\nThe metrics shown for the basic NGINX integration show up differently in the NGINX Plus integration.\nHere are the  metrics name changes from NGINX to NGINX Plus:\n\n\n  \n    \n      NGINX Metrics\n      NGINX Plus Metrics\n    \n  \n  \n    \n      nginx.net.connections\n      nginx.connections.active\n    \n    \n      nginx.net.conn_opened_per_s\n      nginx.connections.accepted\n    \n    \n      nginx.net.conn_dropped_per_s\n      nginx.connections.dropped\n    \n    \n      nginx.net.request_per_s\n      nginx.requests.total\n    \n  \n\n\n\nThese metrics do not have a directly related metric, but here are close translations:\n\n\n  \n    \n      NGINX Metrics\n      NGINX Plus Metrics\n    \n  \n  \n    \n      nginx.net.waiting\n      nginx.connections.idle\n    \n  \n\n\n\nFinally, these metrics have no good translation:\n\n\n  \n    \n      nginx.net.reading\n      The current number of connections where nginx is reading the request header.\n    \n    \n      nginx.net.writing\n      The current number of connections where nginx is writing the response back to the client.\n    \n  \n\n\nThe data pulled from the NGINX Plus status page are described in the NGINX docs.\n","tags":"","loc":"/integrations/nginx/"},{"title":"Datadog-NodeJS Integration","text":"\nConnect your Node.js applications to Datadog to:\n\n\n  Visualize their performance\n  Correlate their performance with the rest of your applications\n  Monitor any relevant metric\n\n","tags":"","loc":"/integrations/nodejs/"},{"title":"Datadog-NTP Check Integration","text":"\n\nOverview\n\n\n\nThe Network Time Protocol (NTP) integration is enabled by default and reports the time offset from an ntp server every 15 minutes. When the local agent’s time is more than 15 seconds off from the Datadog service and the other hosts that you are monitoring, you may experience:\n\n\n  Incorrect alert triggers\n  Metric delays\n  Gaps in graphs of metrics\n\n\nFor more information on syncing your system clock with NTP, see this article in the Datadog Knowledge Base\n\n\nInstallation\n\nNo installation steps are required for this integration.\n\n\nConfiguration\n\n\n  \n    The ntp check is enabled by default. If you would like to make any changes to the configuration, move ntp.yaml.default to ntp.yaml and edit:\n\n    init_config:\n\ninstances:\n  - offset_threshold: 60\n\n  \n  \n    Restart the agent\n  \n\n\n\nConfiguration Options\n\n\n  \nhost (Optional) - Host name of alternate ntp server, for example pool.ntp.org\n\n  \nport (Optional) - What port to use\n  \nversion (Optional) - ntp version\n  \ntimeout (Optional) - Response timeout\n\n\n\nValidation\n\nTo validate your installation and configuration, restart the agent and execute the info command. The output should contain a section similar to the following:\n\nChecks\n======\n  [...]\n  ntp\n  -----\n      - instance #0 [OK]\n      - Collected 1 metric & 0 events\n\n\n\nUsage\n\n\nMetrics\n\n\n\nntp.offset(gauge)\nThe time difference between the local clock and the NTP reference clock.shown as second\n\n\n\n\nEvents\n\nNo events are included with this integration.\n\n","tags":"","loc":"/integrations/ntp/"},{"title":"Datadog-OpenStack Integration","text":"\n\nOverview\n\nConnects your OpenStack cluster to Datadog in order to:\n\n\n  Track vital statistics about your Nova hypervisors\n  Track resource usage and I/O on your Nova-managed servers\n  Verify connectivity of your Neutron networks\n\n\n\n\nLearn more about how to monitor OpenStack Nova performance metrics thanks to our series of posts. We detail the key performance metrics, how to collect them, and how to use Datadog to monitor OpenStack Nova.\n\n\nInstallation\n\nNote: Installing the OpenStack Integration could increase the number of VMs that Datadog monitors. For more information on how this may affect your billing, please visit our Billing FAQ.\n\nTo capture OpenStack metrics you need to install the Datadog Agent on your hosts running hypervisors.\n\n\n  \n    First configure a Datadog role and user with your identity server\n\n     openstack role create datadog_monitoring\n openstack user create datadog \\\n     --password my_password \\\n     --project my_project_name\n openstack role add datadog_monitoring \\\n     --project my_project_name \\\n     --user datadog\n\n  \n  \n    Update your policy.json files to grant the needed permissions.\nrole:datadog_monitoring requires access to the following operations:\n\n    Nova\n\n     - \"compute_extension:aggregates\",\n - \"compute_extension:hypervisors\",\n - \"compute_extension:server_diagnostics\",\n - \"compute_extension:v3:os-hypervisors\",\n - \"compute_extension:v3:os-server-diagnostics\",\n - \"compute_extension:availability_zone:detail\",\n - \"compute_extension:v3:availability_zone:detail\",\n - \"compute_extension:used_limits_for_admin\",\n - \"os_compute_api:os-aggregates:index\",\n - \"os_compute_api:os-aggregates:show\",\n - \"os_compute_api:os-hypervisors\",\n - \"os_compute_api:os-hypervisors:discoverable\",\n - \"os_compute_api:os-server-diagnostics\",\n - \"os_compute_api:os-used-limits\"\n\n\n    Neutron\n\n     - \"get_network\"\n\n\n    Keystone\n\n     - \"identity:get_project\"\n - \"identity:list_projects\"\n\n\n    You may need to restart your Keystone, Neutron and Nova API services to ensure that the policy changes take.\n  \n  \n    Configure the Datadog Agent to connect to your Keystone server, and specify individual projects to monitor. Edit openstack.yaml. You can find a sample configuration in the conf.d directory in your agent install.\n  \n  Restart the Agent\n  \n    Execute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\n     Checks\n ======\n\n   [...]\n\n   openstack\n   ---------\n       - instance #0 [OK]\n       - Collected 8 metrics & 0 events\n\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nOpenStack YAML example\nOpenStack checks.d\n\n\n\nMetrics\n\n\n\n\nopenstack.nova.current_workload(gauge)\nCurrent workload on the Nova hypervisor\n\n\n\n\nopenstack.nova.disk_available_least(gauge)\nDisk available for the Nova hypervisorshown as gibibyte\n\n\n\n\nopenstack.nova.free_disk_gb(gauge)\nFree disk on the Nova hypervisorshown as gibibyte\n\n\n\n\nopenstack.nova.free_ram_mb(gauge)\nFree RAM on the Nova hypervisorshown as mebibyte\n\n\n\n\nopenstack.nova.hypervisor_load.1(gauge)\nThe average hypervisor load over one minute.\n\n\n\n\nopenstack.nova.hypervisor_load.5(gauge)\nThe average hypervisor load over five minutes.\n\n\n\n\nopenstack.nova.hypervisor_load.15(gauge)\nThe average hypervisor load over fifteen minutes.\n\n\n\n\nopenstack.nova.limits.max_image_meta(gauge)\nThe maximum allowed image metadata definitions for this tenant\n\n\n\n\nopenstack.nova.limits.max_personality(gauge)\nThe maximum allowed personalities for this tenant\n\n\n\n\nopenstack.nova.limits.max_personality_size(gauge)\nThe maximum size of a single personality allowed for this tenant\n\n\n\n\nopenstack.nova.limits.max_security_group_rules(gauge)\nThe maximum number of security group rules allowed for this tenant\n\n\n\n\nopenstack.nova.limits.max_security_groups(gauge)\nThe maximum number of security groups allowed for this tenant\n\n\n\n\nopenstack.nova.limits.max_server_meta(gauge)\nThe maximum allowed service metadata definitions for this tenant\n\n\n\n\nopenstack.nova.limits.max_total_cores(gauge)\nThe maximum allowed cores for this tenant\n\n\n\n\nopenstack.nova.limits.max_total_floating_ips(gauge)\nThe maximum allowed floating IPs for this tenant\n\n\n\n\nopenstack.nova.limits.max_total_instances(gauge)\nThe maximum number of instances allowed for this tenant\n\n\n\n\nopenstack.nova.limits.max_total_keypairs(gauge)\nThe maximum allowed keypairs allowed for this tenant\n\n\n\n\nopenstack.nova.limits.total_cores_used(gauge)\nThe total cores used by this tenant\n\n\n\n\nopenstack.nova.limits.total_floating_ips_used(gauge)\nThe total floating IPs used by this tenant\n\n\n\n\nopenstack.nova.limits.total_instances_used(gauge)\nThe total instances used by this tenant\n\n\n\n\nopenstack.nova.limits.total_security_groups_used(gauge)\nThe total number of security groups used by this tenant\n\n\n\n\nopenstack.nova.running_vms(gauge)\nNumber of running VMs on this hypervisor host\n\n\n\n\nopenstack.nova.vcpus(gauge)\nNumber of vCPUs available on this hypervisor host\n\n\n\n\nopenstack.nova.vcpus_used(gauge)\nNumber of vCPUS used on this hypervisor host\n\n\n\n\nopenstack.nova.server.hdd_errors(gauge)\nThe number of errors seen by the server when accessing an HDD device\n\n\n\n\nopenstack.nova.server.hdd_read_req(gauge)\nThe number of read requests made to an HDD device by this server\n\n\n\n\nopenstack.nova.server.hdd_write_req(gauge)\nThe number of write requests made to an HDD device by this server\n\n\n\n\nopenstack.nova.server.vda_errors(gauge)\nThe number of errors seen by the server when accessing a VDA device\n\n\n\n\nopenstack.nova.server.vda_read_req(gauge)\nThe number of read requests made to a VDA device by this server\n\n\n\n\nopenstack.nova.server.vda_write_req(gauge)\nThe number of write requests made to a VDA device by this server\n\n\n\n\nopenstack.nova.limits.max_total_ram_size(gauge)\nThe max allowed RAM size for this tenantshown as gibibyte\n\n\n\n\nopenstack.nova.limits.total_ram_used(gauge)\nThe current RAM used by this tenantshown as gibibyte\n\n\n\n\nopenstack.nova.local_gb(gauge)\nThe size in GB of the ephemeral disk present on this hypervisor hostshown as gibibyte\n\n\n\n\nopenstack.nova.local_gb_used(gauge)\nThe size in GB of disk used on this hypervisor hostshown as gibibyte\n\n\n\n\nopenstack.nova.memory_mb(gauge)\nThe size in MB of RAM present on this hypervisor hostshown as mebibyte\n\n\n\n\nopenstack.nova.memory_mb_used(gauge)\nThe size in MB of RAM used on this hypervisor hostshown as mebibyte\n\n\n\n\nopenstack.nova.server.hdd_read(gauge)\nNumber of bytes read from an HDD device by this servershown as byte\n\n\n\n\nopenstack.nova.server.hdd_write(gauge)\nNumber of bytes written to an HDD device by this servershown as byte\n\n\n\n\nopenstack.nova.server.vda_read(gauge)\nNumber of bytes read from a VDA device by this servershown as byte\n\n\n\n\nopenstack.nova.server.vda_write(gauge)\nNumber of bytes written to a VDA device by this servershown as byte\n\n\n\n\nopenstack.nova.server.memory(gauge)\nThe amount of memory in MB provisioned for this servershown as mebibyte\n\n\n\n\nopenstack.nova.server.memory_actual(gauge)\nThe amount of memory in MB provisioned for this servershown as mebibyte\n\n\n\n\nopenstack.nova.server.memory_rss(gauge)\nThe amount of memory used by the processes of this server that is not associated with disk pages - such as stack and heap memoryshown as mebibyte\n\n\n\n\nopenstack.nova.server.cpu0_time(gauge)\nCPU time in nanoseconds of this virtual CPUshown as nanosecond\n\n\n\n","tags":"","loc":"/integrations/openstack/"},{"title":"Datadog-OpsGenie Integration","text":"\n\nOverview\n\nCreate alerts using @opsgenie:\n\n\n  From your event stream\n  By taking a snapshot\n  When a metric alert is triggered\n\n\n\nConfiguration\n\n\nCreate a Datadog integration in OpsGenie\n\n\n  Log in to your OpsGenie account and go to the OpsGenie Integrations page.\n  As seen below, filter for Datadog and click on the tile.\n\n\n  Enter your Datadog API key from the Integrations > APIs page in the dedicated field. The key looks like this:\n\n\n  Choose the recipients in OpsGenie and set up your filters.\n  Change the name of the integration if necessary.\n  Save the configuration.\n  Copy the red key and the name. You will use this in Datadog.\n\n\n  Add more DataDog integrations on OpsGenie by going to the OpsGenie Integrations page and repeating the steps above.\n\n\n\nList the integration(s) you made in OpsGenie in Datadog\n\n\n  In Datadog, select the OpsGenie tile on Account Integrations.\n  In the dialog box that pops up, click on the Configuration tab.\n  Paste the key(s) provided for each Datadog integration (created in OpsGenie) in the “Datadog Integration Key” field, and enter the “Datadog Integration Name”.\n\n\n\n\n\nHow to Use Datadog and OpsGenie Together\n\n\nCreate, acknowledge and close OpsGenie alerts from Datadog\n\nCreate an OpsGenie alert by putting @opsgenie-service_name or @opsgenie in the Say What’s Happening field, section 5, in the Edit Metric Alert. When this alert is triggered in Datadog, an alert will be sent to the recipients in your OpsGenie service.\n\n\n\nAcknowledge or close OpsGenie alerts from Datadog using @opsgenie-acknowledge or @opsgenie-close mentions in the Comments field of an OpsGenie event in Datadog.\n\n\n\nReceive, acknowledge and close Datadog alerts created by OpsGenie\n\nSet-up alerts in OpsGenie. When that alert is triggered, an event will be created in Datadog. The tags and description field from the OpsGenie alert will be carried over to Datadog.\n\n\n\nAcknowledge and close OpsGenie alerts from OpsGenie. When you do this, the associated event in Datadog will be updated with the username of the person who closed this alert.\n\n\n\n","tags":"","loc":"/integrations/opsgenie/"},{"title":"Datadog-Opsmatic Integration","text":"\n\nOverview\n\nConnect Opsmatic to Datadog to get:\n\n\n  Instant awareness of any critical change\n  Full visibility of the live state and history of all your hosts\n\n\n\nInstallation\n\nTo see Opsmatic events in your DataDog stream:\n\n\n  Add your DataDog API key to your Opsmatic Integrations page.\n  Configure your Opsmatic notifications to go to DataDog.\n\n\nCheck out the docs on the Opsmatic website for more information.\n\n\nConfiguration\n\nClick the Install Integration button on the Opsmatic Integration Tile. configuration steps are required for this integration.\n\n","tags":"","loc":"/integrations/opsmatic/"},{"title":"Datadog-PagerDuty Integration","text":"\n\nOverview\n\nConnect PagerDuty to Datadog in order to:\n\n\n  Trigger and resolve incidents from your stream by mentioning @pagerduty in your post\n  See incidents and escalations in your stream as they occur\n  Get a daily reminder of who’s on-call\n\n\nYou can also check out this documentation from Pagerduty.\n\nOnce you have Pagerduty integrated, you can check out our custom Pagerduty Incident Trends. \n\n","tags":"","loc":"/integrations/pagerduty/"},{"title":"Datadog-PaperTrail Integration","text":"\n\nOverview\n\n\n\nUse Papertrail and Datadog to:\n\n\n  Turn freeform log data into actionable metrics\n  Avoid silo-ed operational knowledge. See and correlate log-derived metrics alongside app- and system-level metrics.\n\n\n\nInstallation\n\nTo capture metrics from Papertrail:\n\n\n  In Papertrail’s event viewer, save a search for the log event(s) which should be graphed.\n  Enter the name for the search and click the Save & Setup an Alert button.\n  \n    Choose Datadog under Graphing & Metrics.\n\n    \n  \n  Choose your alert frequency and other details.\n  \n    Provide your Datadog API key, enter what you want to name your metric, and optionally enter some tags to associate with the metric.\n\n    \n  \n  Click the Create Alert button.\n\n\nPapertrail will update Datadog at your chosen interval.\n\n\nConfiguration\n\nNo configuration steps are required for this integration.\n\n","tags":"","loc":"/integrations/papertrail/"},{"title":"Datadog-PGBouncer Integration","text":"\n\nOverview\n\nConnect your PGBouncer to Datadog in order to:\n\n\n  Visualize your pools of connections.\n  Monitor the traffic between PostgreSQL and your applications.\n  Be notified about pgbouncer failovers and events.\n\n\n\nConfiguration\n\nTo configure the PGBouncer integration, copy pgbouncer.yaml.example to pgbouncer.yaml and make the appropriate changes.\n\ninit_config:\n\ninstances:\n  - host: localhost\n    port: 15433\n    username: my_username\n    password: my_password\n    tags:\n      - env:prod\n  - database_url: postgresql://user:pass@host:5432/dbname?sslmode=require\n    tags:\n      - role:main\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nPGBouncer YAML example\nPGBouncer checks.d\n\n\n\nValidation\n\nWhen you run datadog-agent info you should see something like the following:\n\nChecks\n======\n\n    pgbouncer\n    -----------\n      - instance #0 [OK]\n      - Collected 39 metrics, 0 events & 1 service check ### Metrics\n\n\n\n\n\npgbouncer.stats.requests_per_second(gauge)\nThe request rateshown as request/second\n\n\n\n\npgbouncer.stats.bytes_received_per_second(gauge)\nThe total network traffic receivedshown as byte/second\n\n\n\n\npgbouncer.stats.bytes_sent_per_second(gauge)\nThe total network traffic sentshown as byte/second\n\n\n\n\npgbouncer.stats.total_query_time(gauge)\nTime spent by pgbouncer actively querying PostgreSQLshown as microsecond\n\n\n\n\npgbouncer.stats.avg_req(gauge)\nThe average number of requests per second in last stat periodshown as request/second\n\n\n\n\npgbouncer.stats.avg_recv(gauge)\nThe client network traffic receivedshown as byte/second\n\n\n\n\npgbouncer.stats.avg_sent(gauge)\nThe client network traffic sentshown as byte/second\n\n\n\n\npgbouncer.stats.avg_query(gauge)\nThe average query durationshown as microsecond\n\n\n\n\npgbouncer.pools.cl_active(gauge)\nClient connections linked to server connection and able to process queriesshown as connection\n\n\n\n\npgbouncer.pools.cl_waiting(gauge)\nClient connections waiting on a server connectionshown as connection\n\n\n\n\npgbouncer.pools.sv_active(gauge)\nServer connections linked to a client connectionshown as connection\n\n\n\n\npgbouncer.pools.sv_idle(gauge)\nServer connections idle and ready for a client queryshown as connection\n\n\n\n\npgbouncer.pools.sv_used(gauge)\nServer connections idle more than server_check_delay, needing server_check_queryshown as connection\n\n\n\n\npgbouncer.pools.sv_tested(gauge)\nServer connections currently running either server_reset_query or server_check_queryshown as connection\n\n\n\n\npgbouncer.pools.sv_login(gauge)\nServer connections currently in the process of logging inshown as connection\n\n\n\n\npgbouncer.pools.maxwait(gauge)\nAge of oldest unserved client connectionshown as second\n\n\n\n\n\nService Checks\n\n\n  pgbouncer.can_connect\n  Agent is able to connect to the pgbouncer instance\n\n","tags":"","loc":"/integrations/pgbouncer/"},{"title":"Datadog-PHP Integration","text":"\n\nOverview\n\n\n\nConnect your PHP applications to Datadog to:\n\n\n  Visualize their performance\n  Correlate their performance with the rest of your applications\n  Monitor any relevant metric\n\n\n\nInstallation\n\nThe PHP integration enables you to monitor any custom metric by instrumenting a few lines of code. \nFor instance, you can have a metric that returns the number of page views or the time of any function call. \nFor additional information about the PHP integration, please refer to this guide on submitting metrics. \nFor advanced usage, please refer to the documentation in the repository.\n\n\n  \n    Install the library by cloning the Git repository:\n\n    git clone git@github.com:DataDog/php-datadogstatsd.git\n\n  \n  \n    Start instrumenting your code:\n\n    # Require the datadogstatsd.php library file\nrequire './libraries/datadogstatsd.php';\n\n\n# Increment a counter.\nDataDogStatsD::increment('your.data.point');\n\n  \n  \n    Go to the Metrics explorer page and see that it works! \n  \n\n","tags":"","loc":"/integrations/php/"},{"title":"Datadog-PHP-FPM Integration","text":"\n\nOverview\n\n\n\nEnable the PHP-FPM check to monitor the state of your FPM pool and track requests performance.\n\n\nInstallation\n\nNo installation steps are required for this integration.\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to your FPM status endpoint (look at your pools definition). Edit conf.d/php_fpm.yaml:\n\n    init_config:\n\ninstances:\n  - status_url: http://localhost/status\n    ping_url: http://localhost/ping\n    ping_reply: pong\n    tags:\n      - instance:foo\n\n  \n  \n    Restart the Agent\n  \n\n\n\nConfiguration Options\n\n\n  \nstatus_url (Required) - URL for the PHP FPM status page defined in the fpm pool config file (pm.status_path)\n  \nping_url (Required) - URL for the PHP FPM ping page defined in the fpm pool config file (ping.path)\n  \nping_reply (Required) - Reply from the ping_url. Unless you define a reply, it is pong\n\n  \nuser (Optional) - Used if you have set basic authentication on the status and ping pages\n  \npassword (Optional) - Used if you have set basic authentication on the status and ping pages\n  \nhttp_host (Optional) - If your FPM pool is only accessible via a specific HTTP vhost, specify it here\n\n\n\nValidation\n\nTo validate your installation and configuration, restart the agent and execute the info command. The output should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  php_fpm\n  -------\n      - instance #0 [OK]\n      - Collected 7 metrics & 0 events & 2 service checks\n\n\n\nMetrics\n\n\n  \n    \n      \nphp_fpm.listen_queue.size(gauge)\n      Size of the socket queue of pending connections\n    \n    \n      \nphp_fpm.processes.active(gauge)\n      Total number of active processes\n    \n    \n      \nphp_fpm.processes.idle(gauge)\n      Total number of idle processes\n    \n    \n      \nphp_fpm.processes.total(gauge)\n      Total number of processes\n    \n  \n\n\n","tags":"","loc":"/integrations/phpfpm/"},{"title":"Datadog-Pingdom Integration","text":"\n\nOverview\n\nTrack Pingdom user-centric performance metrics in Datadog, for correlation with other relevant events and metrics.\n\nAt this time we track the response_time metric for any sites you configure on the Pingdom website.\n\nPingdom events can be added by configuring the relevant Integration Status Monitor\n\nNote: Metrics can only be imported for Pingdom customers at the Starter level or above.\n\n\nConfiguration\n\n\n  Open the Pingdom integration tile.\n  Enter the username and password to your Pingdom account.\n(If you have a Team account, you can use your own credentials and specify the account you wish to pull checks from.)\n  You can ignore some checks by unchecking them or add some tags to the events that are going to be generated.\n\n\n\nMetrics\n\n\n\n\npingdom.response_time(gauge)\nThe HTTP response time for this Pingdom checkshown as millisecond\n\n\n\n\npingdom.uptime(gauge)\nThe elapsed time since the last HTTP error for this Pingdom checkshown as second\n\n\n\n\n","tags":"","loc":"/integrations/pingdom/"},{"title":"Datadog-Pivotal Tracker Integration","text":"\n\nOverview\n\nConnect Pivotal Tracker to Datadog to:\n\n\n  See and discuss the progress of your stories in your event stream.\n  Correlate story completion with other events and metrics in your system.\n\n\n","tags":"","loc":"/integrations/pivotal/"},{"title":"Datadog-Postfix Integration","text":"\n\nOverview\n\n\n\nGet metrics from Postfix in real time to monitor the messages pending in your Postfix mail queues.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nPostfix YAML example\nPostfix checks.d\n\n\n\nConfiguration\n\n\n  Make sure that the user that dd-agent runs has sudo access for the ‘find’ command.\n  \n    Configure the Agent to connect to Postfix. Edit conf.d/postfix.yaml:\n\n    # The user running dd-agent must have passwordless sudo access for the find\n# command to run the postfix check.  Here's an example:\n#\n# example /etc/sudoers entry:\n#          dd-agent ALL=(ALL) NOPASSWD:/usr/bin/find\n\n# The user running dd-agent must have passwordless sudo access for the find\n# command to run the postfix check.  Here's an example:\n#\n# example /etc/sudoers entry:\n#          dd-agent ALL=(ALL) NOPASSWD:/usr/bin/find\n#\n# Redhat/CentOS/Amazon Linux flavours will need to add:\n#          Defaults:dd-agent !requiretty\n\ninit_config:\n\ninstances:\n  - directory: /var/spool/postfix\n    queues:\n      - incoming\n      - active\n      - deferred\n    tags:\n      - optional_tag1\n      - optional_tag2\n  - directory: /var/spool/postfix-2\n    queues:\n      - incoming\n      - active\n      - deferred\n    tags:\n      - optional_tag3\n      - optional_tag4\n\n  \n  Restart the Agent\n\n\n\nValidation\n\n\n  \n    Execute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\n    Checks\n======\n\n  [...]\n\n  postfix\n  -------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n  \n\n\n\nMetrics\n\n\n\npostfix.queue.size(gauge)\nThe number of mails in this queue.shown as email\n\n\n","tags":"","loc":"/integrations/postfix/"},{"title":"Datadog-PostgreSQL Integration","text":"\n\nOverview\n\n\nConnect PostgreSQL to Datadog in order to:\n\n\n  Visualize your database performance.\n  Correlate the performance of PostgreSQL with the rest of your applications.\n\n\n\nInstallation\n\nTo get started with the PostgreSQL integration, create at least a read-only datadog user with proper access to your PostgreSQL Server. Start psql on your PostgreSQL database and run:\n\ncreate user datadog with password '<PASSWORD>';\ngrant SELECT ON pg_stat_database to datadog;\n\n\nTo verify the correct permissions you can run the following command:\n\npsql -h localhost -U datadog postgres -c \\\n\"select * from pg_stat_database LIMIT(1);\"\n&& echo -e \"\\e[0;32mPostgres connection - OK\\e[0m\" || \\ \n|| echo -e \"\\e[0;31mCannot connect to Postgres\\e[0m\"\n\n\nWhen it prompts for a password, enter the one used in the first command.\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to PostgreSQL. Edit conf.d/postgres.yaml:\n\n    init_config:\n\ninstances:\n  - host: localhost\n    port: 5432\n\n  \n  \n    Restart the agent.\n  \n\n\n\nConfiguration Options\n\n\n  \nusername (Optional)\n  \npassword (Optional)\n  \ndbname (Optional) - Name of the database you want to monitor\n  \nssl (Optional) - Defaults to False. Whether to use SSL to connect.\n  \ntags (Optional) - Dictionary of tags\n  \n    relations (Optional) - Dictionary of per-relation (table) metrics that you want to track. Each relation generates 10 metrics + 10 metrics per index.\n\n    By default all schemas are included. To track relations from specific schemas only, use the following syntax:\n\n    relations:\n  - relation_name: another_table\n    schemas:\n      - public\n      - prod\n\n  \n  \ncollect_function_metrics (Optional) - Collect metrics regarding PL/pgSQL functions from pg_stat_user_functions\n  \ncollect_count_metrics (Optional) - Collect count metrics, default value is True for backward compatibility but they migth be slow, suggested value is False.\n\n\n\nCustom metrics\n\nBelow are some examples of commonly used metrics, which are implemented as custom metrics. Uncomment them if you want to use them as is, or use as an example for creating your own custom metrics. \n\nThe format for describing custome metrics is identical with the one used for common metrics in postgres.py. Be extra careful with ensuring proper custom metrics description format. If your custom metric does not work after an agent restart, look for errors in the output of /etc/init.d/datadog-agent info command, as well as /var/log/datadog/collector.log file.\n\ncustom_metrics:\n- # Londiste 3 replication lag\n  descriptors:\n    - [consumer_name, consumer_name]\n  metrics:\n    >\n      GREATEST(0, EXTRACT(EPOCH FROM lag)) as lag: \n      [postgresql.londiste_lag, GAUGE]\n    >\n      GREATEST(0, EXTRACT(EPOCH FROM lag)) as last_seen: \n      [postgresql.londiste_last_seen, GAUGE]\n    pending_events: [postgresql.londiste_pending_events, GAUGE]\n  query: \n    >\n      SELECT consumer_name, %s from pgq.get_consumer_info() \n      where consumer_name !~ 'watermark$';\n  relation: false\ncollect_function_metrics: False\ncollect_count_metrics: False\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nPostgreSQL YAML example\nPostgreSQL checks.d\n\n\n\nValidation\n\nAfter you restart the agent, you should be able to run the info command which will now include a section like this if the PostgreSQL integration is working:\n\nChecks\n======\n\n  [...]\n\n  postgres\n  --------\n      - instance #0 [OK]\n      - Collected 47 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\npostgresql.connections(gauge)\nThe number of active connections to this database.shown as connection\n\n\n\n\npostgresql.commits(gauge)\nThe number of transactions that have been committed in this database.shown as transaction/second\n\n\n\n\npostgresql.rollbacks(gauge)\nThe number of transactions that have been rolled back in this database.shown as transaction/second\n\n\n\n\npostgresql.disk_read(gauge)\nThe number of disk blocks read in this database.shown as block/second\n\n\n\n\npostgresql.buffer_hit(gauge)\nThe number of times disk blocks were found in the buffer cache, preventing the need to read from the database. shown as hit/second\n\n\n\n\npostgresql.rows_returned(gauge)\nThe number of rows returned by queries in this databaseshown as row/second\n\n\n\n\npostgresql.rows_fetched(gauge)\nThe number of rows fetched by queries in this databaseshown as row/second\n\n\n\n\npostgresql.rows_inserted(gauge)\nThe number of rows inserted by queries in this databaseshown as row/second\n\n\n\n\npostgresql.rows_updated(gauge)\nThe number of rows updated by queries in this databaseshown as row/second\n\n\n\n\npostgresql.rows_deleted(gauge)\nThe number of rows deleted by queries in this databaseshown as row/second\n\n\n\n\npostgresql.database_size(gauge)\nThe disk space used by this database.shown as byte\n\n\n\n\npostgresql.deadlocks(gauge)\nThe number of deadlocks detected in this database\n\n\n\n\npostgresql.temp_bytes(gauge)\nThe amount of data written to temporary files by queries in this database.shown as byte/second\n\n\n\n\npostgresql.temp_files(gauge)\nThe number of temporary files created by queries in this database.shown as file/second\n\n\n\n\npostgresql.bgwriter.checkpoints_timed(count)\nThe number of scheduled checkpoints that were performed.\n\n\n\n\npostgresql.bgwriter.checkpoints_requested(count)\nThe number of requested checkpoints that were performed.\n\n\n\n\npostgresql.bgwriter.buffers_checkpoint(count)\nThe number of buffers written during checkpoints.\n\n\n\n\npostgresql.bgwriter.buffers_clean(count)\nThe number of buffers written by the background writer.\n\n\n\n\npostgresql.bgwriter.maxwritten_clean(count)\nThe number of times the background writer stopped a cleaning scan due to writing too many buffers.\n\n\n\n\npostgresql.bgwriter.buffers_backend(count)\nThe number of buffers written directly by a backend.shown as buffer\n\n\n\n\npostgresql.bgwriter.buffers_alloc(count)\nThe number of buffers allocated\n\n\n\n\npostgresql.bgwriter.buffers_backend_fsync(count)\nThe of times a backend had to execute its own fsync call instead of the background writer.\n\n\n\n\npostgresql.bgwriter.write_time(count)\nThe total amount of checkpoint processing time spent writing files to disk.shown as millisecond\n\n\n\n\npostgresql.bgwriter.sync_time(count)\nThe total amount of checkpoint processing time spent synchronizing files to disk.shown as millisecond\n\n\n\n\npostgresql.locks(gauge)\nThe number of locks active for this database.shown as lock\n\n\n\n\npostgresql.seq_scans(gauge)\nThe number of sequential scans initiated on this table.\n\n\n\n\npostgresql.seq_rows_read(gauge)\nThe number of live rows fetched by sequential scans.shown as row/second\n\n\n\n\npostgresql.index_scans(gauge)\nThe number of index scans initiated on this table.\n\n\n\n\npostgresql.index_rows_fetched(gauge)\nThe number of live rows fetched by index scans.shown as row/second\n\n\n\n\npostgresql.rows_hot_updated(gauge)\nThe number of rows HOT updated, meaning no separate index update was needed.shown as row/second\n\n\n\n\npostgresql.live_rows(gauge)\nThe estimated number of live rows.shown as row\n\n\n\n\npostgresql.dead_rows(gauge)\nThe estimated number of dead rows.shown as row\n\n\n\n\npostgresql.index_rows_read(gauge)\nThe number of index entries returned by scans on this index.shown as row/second\n\n\n\n\npostgresql.table_size(gauge)\nThe total disk space used by the specified table. Includes TOAST, free space map, and visibility map. Excludes indexes.shown as byte\n\n\n\n\npostgresql.index_size(gauge)\nThe total disk space used by indexes attached to the specified table.shown as byte\n\n\n\n\npostgresql.total_size(gauge)\nThe total disk space used by the table, including indexes and TOAST data.shown as byte\n\n\n\n\npostgresql.table.count(gauge)\nThe number of user tables in this database.shown as table\n\n\n\n\npostgresql.max_connections(gauge)\n The maximum number of client connections allowed to this database.shown as connection\n\n\n\n\npostgresql.percent_usage_connections(gauge)\nThe number of connections to this database as a fraction of the maximum number of allowed connections.shown as fraction\n\n\n\n\npostgresql.replication_delay(gauge)\nThe current replication delay in seconds. Only available with postgresql 9.1 and newershown as second\n\n\n\n\npostgres.replication_delay_bytes(gauge)\nThe current replication delay in bytes. Only available with postgresql 9.2 and newershown as byte\n\n\n\n\npostgresql.heap_blocks_read(gauge)\nThe number of disk blocks read from this table.shown as block/second\n\n\n\n\npostgresql.heap_blocks_hit(gauge)\nThe number of buffer hits in this table.shown as hit/second\n\n\n\n\npostgresql.index_blocks_read(gauge)\nThe number of disk blocks read from all indexes on this table.shown as block/second\n\n\n\n\npostgresql.index_blocks_hit(gauge)\nThe number of buffer hits in all indexes on this table.shown as hit/second\n\n\n\n\npostgresql.toast_blocks_read(gauge)\nThe number of disk blocks read from this table's TOAST table.shown as block/second\n\n\n\n\npostgresql.toast_blocks_hit(gauge)\nThe number of buffer hits in this table's TOAST table.shown as hit/second\n\n\n\n\npostgresql.toast_index_blocks_read(gauge)\nThe number of disk blocks read from this table's TOAST table index.shown as block/second\n\n\n\n\npostgresql.toast_index_blocks_hit(gauge)\nThe number of buffer hits in this table's TOAST table index.shown as block/second\n\n\n\n\n","tags":"","loc":"/integrations/postgresql/"},{"title":"Datadog-PowerDNS Integration","text":"\n\nOverview\n\nConnect your PowerDNS Recursor to Datadog to:\n\n\n  Visualize its performance\n  Understand query latency\n  Get alerted when something fails or when you’re under attack\n\n\n\nConfiguration\n\nConfigure the Agent to connect to the PowerDNS Recursor. Edit conf.d/powerdns_recursor.yaml\n\ninit_config:\n\ninstances:\n  - host: 127.0.0.1\n    port: 8082\n    api_key: pdns_api_key\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nPowerDNS Recursor YAML example\nPowerDNS Recursor checks.d\n\n\n\nValidation\n\n\n  Restart the Agent\n  \n    Execute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\n    Checks\n======\n\n  [...]\n\n  powerdns_recursor\n  -----------------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n  \n\n\n\nMetrics\n\n\n\n\npowerdns.recursor.cache_entries(gauge)\nThe number of entries in the cacheshown as unit\n\n\n\n\npowerdns.recursor.concurrent_queries(gauge)\nThe number of MThreads currently runningshown as unit\n\n\n\n\npowerdns.recursor.all_outqueries(gauge)\nThe number of outgoing udp queries per secondshown as operation/second\n\n\n\n\npowerdns.recursor.answers_slow(gauge)\nNumber of queries answered after 1 secondshown as unit/second\n\n\n\n\npowerdns.recursor.answers0_1(gauge)\nNumber of queries answered after 1 secondshown as unit/second\n\n\n\n\npowerdns.recursor.answers1_10(gauge)\nNumber of queries answered within 10 millisecondsshown as unit/second\n\n\n\n\npowerdns.recursor.answers10_100(gauge)\nNumber of queries answered within 100 millisecondsshown as unit/second\n\n\n\n\npowerdns.recursor.answers100_1000(gauge)\nNumber of queries answered within 1 secondshown as unit/second\n\n\n\n\npowerdns.recursor.cache_hits(gauge)\nThe number of cache hits per secondshown as operation/second\n\n\n\n\npowerdns.recursor.cache_misses(gauge)\nThe number of cache misses per secondshown as operation/second\n\n\n\n\npowerdns.recursor.noerror_answers(gauge)\nThe number of times it answered NOERROR per secondshown as operation/second\n\n\n\n\npowerdns.recursor.outgoing_timeouts(gauge)\nThe number of timeouts per secondshown as operation/second\n\n\n\n\npowerdns.recursor.questions(gauge)\nThe number of user initiated udp queries per secondshown as operation/second\n\n\n\n\npowerdns.recursor.servfail_answers(gauge)\nThe number of times it answered SERVFAIL per secondshown as operation/second\n\n\n\n\npowerdns.recursor.tcp_outqueries(gauge)\nThe number of outgoing tcp queries per secondshown as operation/second\n\n\n\n\npowerdns.recursor.tcp_questions(gauge)\nThe number of incoming tcp queries per secondshown as operation/second\n\n\n\n","tags":"","loc":"/integrations/powerdns/"},{"title":"Process check","text":"\n\nOverview\n\n\n  Capture metrics from specific running processes on a system such as CPU %, memory, and I/O.\n  Monitor the status of running processes with Process Monitors (Requires Datadog Agent >= 5.1.0).\n\n\n\nInstallation\n\nNo installation required.\n\n\nConfiguration\n\nConfigure the Agent to connect to your processes. Our example configuration will monitor the ssh, sshd, and postgres processes.\n\n\n  \n    Edit /etc/dd-agent/conf.d/process.yaml\n\n    init_config:\n  # used to override the default procfs path, e.g. for docker\n  # containers to see the processes of the host at /host/proc\n  # procfs_path: /proc\ninstances:\n  - name: ssh\n    search_string: ['ssh', 'sshd']\n\n  - name: postgres\n    search_string: ['postgres']\n\n  - name: pid_process\n    pid: 1278\n    # Do not use search_string when searching by pid or multiple processes will be grabbed\n\n  \n  \n    Restart the Agent\n\n    sudo /etc/init.d/datadog-agent restart\n\n  \n\n\nRefer to the comments in the process.yaml.example file for more options.\n\nAfter the Agent has sent data to Datadog you can visit the New Monitor section of the application to set up a Monitor. If you only see information on how to configure the process check in the Agent, Datadog has not yet received any process information from the Agent. Use the instructions below to validate whether the Agent has been configured correctly.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nProcess Check YAML example\nProcess Check checks.d\n\n\n\nValidation\n\n\n  \n    Execute the info command\n\n    datadog-agent info\n\n  \n  \n    Verify that the check has passed. The output of the command should contain a section similar to the following:\n\n    Checks\n======\n\n[...]\n\nprocess\n---------\n    - instance #0 [OK]\n    - Collected 18 metrics & 0 events & 2 service checks\n\n  \n\n\nEach instance, regardless of the number of search strings used, counts for a single instance in the info command output.\n\n\nMetrics\n\nVisit the Metrics Explorer to see the new metrics available. You will find all the metrics under system.processes.\n\n\n\n\nsystem.processes.cpu.pct(gauge)\nThe process CPU utilization.shown as percent\n\n\n\n\nsystem.processes.involuntary_ctx_switches(gauge)\nThe number of involuntary context switches performed by this process.shown as event\n\n\n\n\nsystem.processes.ioread_bytes(gauge)\nThe number of bytes read from disk by this process.shown as byte\n\n\n\n\nsystem.processes.ioread_count(gauge)\nThe number of disk reads by this process.shown as read\n\n\n\n\nsystem.processes.iowrite_bytes(gauge)\nThe number of bytes written to disk by this process.shown as byte\n\n\n\n\nsystem.processes.iowrite_count(gauge)\nThe number of disk writes by this process.shown as write\n\n\n\n\nsystem.processes.mem.page_faults.minor_faults(gauge)\nThe number of minor page faults per second for this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.page_faults.children_minor_faults(gauge)\nThe number of minor page faults per second for children of this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.page_faults.major_faults(gauge)\nThe number of major page faults per second for this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.page_faults.children_major_faults(gauge)\nThe number of major page faults per second for children of this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.pct(gauge)\nThe process memory consumption.shown as percent\n\n\n\n\nsystem.processes.mem.real(gauge)\nThe non-swapped physical memory a process has used and cannot be shared with another process.shown as byte\n\n\n\n\nsystem.processes.mem.rss(gauge)\nThe non-swapped physical memory a process has used. aka \"Resident Set Size\".shown as byte\n\n\n\n\nsystem.processes.mem.vms(gauge)\nThe total amount of virtual memory used by the process. aka \"Virtual Memory Size\".shown as byte\n\n\n\n\nsystem.processes.number(gauge)\nThe number of processes.shown as process\n\n\n\n\nsystem.processes.open_file_descriptors(gauge)\nThe number of file descriptors used by this process.\n\n\n\n\nsystem.processes.open_handles(gauge)\nThe number of handles used by this process.\n\n\n\n\nsystem.processes.threads(gauge)\nThe number of threads used by this process.shown as thread\n\n\n\n\nsystem.processes.voluntary_ctx_switches(gauge)\nThe number of voluntary context switches performed by this process.shown as event\n\n\n\n\n","tags":"","loc":"/integrations/process/"},{"title":"Datadog-Puppet Integration","text":"\n\nOverview\n\nConnect Puppet to Datadog in order to:\n\n\n  Get real-time reports on Puppet Agent runs.\n  Track key Puppet performance metrics across all your servers.\n  Quickly identify and discuss failed Puppet runs with your team\n\n\nTo install the Datadog Agent via Puppet, please see here.\n\n","tags":"","loc":"/integrations/puppet/"},{"title":"Datadog-Python Integration","text":"\n\nOverview\nThe Python integration enables you to monitor any custom metric by instrumenting a few lines of code. For instance, you can have a metric that returns the number of page views or the time of any function call. For additional information about the Python integration, please refer to the guide on submitting metrics. For advanced usage, please refer to the documentation in the repository. You can also review the API docs for details on how to use the API with Python.\n\n\nInstallation\n\n\n  \n    To install from pip:\n\n    pip install datadog\n\n  \n  \n    Start instrumenting your code:\n\n    # Configure the module according to your needs\nfrom datadog import initialize\n\noptions = {\n    'api_key':'api_key',\n    'app_key':'app_key'\n}\n\ninitialize(**options)\n\n# Use Datadog REST API client\nfrom datadog import api\n\ntitle = \"Something big happened!\"\ntext = 'And let me tell you all about it here!'\ntags = ['version:1', 'application:web']\n\napi.Event.create(title=title, text=text, tags=tags)\n\n\n# Use Statsd, a Python client for DogStatsd\nfrom datadog import statsd\n\nstatsd.increment('whatever')\nstatsd.gauge('foo', 42)\n\n# Or ThreadStats, an alternative tool to collect and flush metrics,using Datadog REST API\nfrom datadog import ThreadStats\nstats = ThreadStats()\nstats.start()\nstats.increment('home.page.hits')\n\n  \n\n\n\nConfiguration\n\nThere is nothing that you need to do in the Datadog application to configure Python.\n\n\nValidation\n\nGo to the Metrics explorer page and see that it just works!\n","tags":"","loc":"/integrations/python/"},{"title":"Datadog-RabbitMQ Integration","text":"\n\nOverview\n\n\n\nConnect RabbitMQ to Datadog in order to:\n\n\n  Visualize RabbitMQ performance and utilization.\n  Correlate the performance of RabbitMQ with the rest of your applications.\n\n\n\nInstallation\n\nThe RabbitMQ check requires the Management Plugin. Refer to the RabbitMQ documentation for information on how to install the plugin.\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to RabbitMQ. Edit conf.d/rabbitmq.yaml\n\n    init_config:\n\ninstances:\n  - rabbitmq_api_url: http://localhost:15672/api/\n    rabbitmq_user: guest\n    rabbitmq_pass: guest\n    tag_families: true\n    nodes:\n      - rabbit@localhost\n    queues:\n      - queue1\n    vhosts:\n      - vhost1\n\n  \n  \n    Restart the Agent\n  \n\n\n\nConfiguration Options\n\n\n  \nrabbitmq_api_url - required - Points to the api url of the RabbitMQ Managment Plugin\n\n  \nrabbitmq_user - optional - Defaults to ‘guest’\n  \nrabbitmq_pass - optional - Defaults to ‘guest’\n  \ntag_families - optional - Defaults to false - Tag queue “families” based off of regex matching\n  \nnodes or nodes_regexes - optional - Use the nodes or nodes_regexes parameters to specify the nodes you’d like to collect metrics on (up to 100 nodes). If you have less than 100 nodes, you don’t have to set this parameter, the metrics will be collected on all the nodes by default. See the link to the example YAML below for more.\n  \nqueues or queues_regexes - optional - Use the queues or queues_regexes parameters to specify the queues you’d like to collect metrics on (up to 200 queues). If you have less than 200 queues, you don’t have to set this parameter, the metrics will be collected on all the queues by. default. If you have set up vhosts, set the queue names as vhost_name/queue_name. If you have tag_families enabled, the first captured group in the regex will be used as the queue_family tag.  See the link to the example YAML below for more.\n  \nvhosts - optional - By default a list of all vhosts is fetched and each one will be checked using the aliveness API. If you prefer only certain vhosts to be monitored with service checks then you can list the vhosts you care about.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nRabbitMQ YAML example\nRabbitMQ checks.d\n\n\n\nValidation\n\n\n  \n    Execute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\n    Checks\n======\n\n[...]\n\nrabbitmq\n--------\n  - instance #0 [OK]\n  - Collected 8 metrics & 0 events\n\n  \n\n\n\nMetrics\n\n\n\n\nrabbitmq.node.fd_used(gauge)\nUsed file descriptors\n\n\n\n\nrabbitmq.node.mem_used(gauge)\nMemory used in bytesshown as byte\n\n\n\n\nrabbitmq.node.run_queue(gauge)\nAverage number of Erlang processes waiting to runshown as process\n\n\n\n\nrabbitmq.node.sockets_used(gauge)\nNumber of file descriptors used as sockets\n\n\n\n\nrabbitmq.node.partitions(gauge)\nNumber of network partitions this node is seeing\n\n\n\n\nrabbitmq.queue.active_consumers(gauge)\nNumber of active consumers, consumers that can immediately receive any messages sent to the queue\n\n\n\n\nrabbitmq.queue.consumers(gauge)\nNumber of consumers\n\n\n\n\nrabbitmq.queue.consumer_utilisation(gauge)\nThe ratio of time that a queue's consumers can take new messagesshown as fraction\n\n\n\n\nrabbitmq.queue.memory(gauge)\nBytes of memory consumed by the Erlang process associated with the queue, including stack, heap and internal structuresshown as byte\n\n\n\n\nrabbitmq.queue.messages(gauge)\nCount of the total messages in the queueshown as message\n\n\n\n\nrabbitmq.queue.messages.rate(gauge)\nCount per second of the total messages in the queueshown as message/second\n\n\n\n\nrabbitmq.queue.messages_ready(gauge)\nNumber of messages ready to be delivered to clientsshown as message\n\n\n\n\nrabbitmq.queue.messages_ready.rate(gauge)\nNumber per second of messages ready to be delivered to clientsshown as message/second\n\n\n\n\nrabbitmq.queue.messages_unacknowledged(gauge)\nNumber of messages delivered to clients but not yet acknowledgedshown as message\n\n\n\n\nrabbitmq.queue.messages_unacknowledged.rate(gauge)\nNumber per second of messages delivered to clients but not yet acknowledgedshown as message/second\n\n\n\n\nrabbitmq.queue.messages.ack.count(gauge)\nNumber of messages delivered to clients and acknowledgedshown as message\n\n\n\n\nrabbitmq.queue.messages.ack.rate(gauge)\nNumber per second of messages delivered to clients and acknowledgedshown as message/second\n\n\n\n\nrabbitmq.queue.messages.deliver.count(gauge)\nCount of messages delivered in acknowledgement mode to consumersshown as message\n\n\n\n\nrabbitmq.queue.messages.deliver.rate(gauge)\nCount of messages delivered in acknowledgement mode to consumersshown as message/second\n\n\n\n\nrabbitmq.queue.messages.deliver_get.count(gauge)\nSum of messages delivered in acknowledgement mode to consumers, in no-acknowledgement mode to consumers, in acknowledgement mode in response to basic.get, and in no-acknowledgement mode in response to basic.get.shown as message\n\n\n\n\nrabbitmq.queue.messages.deliver_get.rate(gauge)\nRate per second of the sum of messages delivered in acknowledgement mode to consumers, in no-acknowledgement mode to consumers, in acknowledgement mode in response to basic.get, and in no-acknowledgement mode in response to basic.get.shown as message/second\n\n\n\n\nrabbitmq.queue.messages.publish.count(gauge)\nCount of messages publishedshown as message\n\n\n\n\nrabbitmq.queue.messages.publish.rate(gauge)\nRate per second of messages publishedshown as message/second\n\n\n\n\nrabbitmq.queue.messages.redeliver.count(gauge)\nCount of subset of messages in deliver_get which had the redelivered flag setshown as message\n\n\n\n\nrabbitmq.queue.messages.redeliver.rate(gauge)\nRate per second of subset of messages in deliver_get which had the redelivered flag setshown as message/second\n\n\n\n\nBy default, queue metrics are tagged by queue and node metrics are tagged by node. If you have a Datadog account you can see the integration installation instructions here.\n\n","tags":"","loc":"/integrations/rabbitmq/"},{"title":"Datadog-Redis Integration","text":"\n\nOverview\n\n\n\nTrack and graph your Redis activity and performance metrics with slice-and-dice at all levels\nfrom individual column families to entire clusters.\n\nLearn more about how to monitor Redis performance metrics thanks to\nour series of posts.\nWe detail the key performance metrics, how to collect them, and how to use Datadog to monitor Redis.\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to the Redis server. Edit conf.d/redisdb.yaml:\n\n    init_config:\n\ninstances:\n  - host: localhost\n    port: 6379\n    tags:\n      - optional_tag1\n      - optional_tag2\n    keys:\n      - key1\n\n  \n  \n    Restart the Agent\n  \n\n\n\nConfiguration Options\n\n\n  \nunix_socket_path - (Optional) - Can be used instead of host and port.\n  \ndb, password, and socket_timeout - (Optional) - Additional connection options.\n  \nwarn_on_missing_keys - (Optional) - Display a warning in the info page if the keys we’re tracking are missing.\n  \nslowlog-max-len - (Optional) - Maximum number of entries to fetch from the slow query log. By default, the check will\n      read this value from the redis config. If it’s above 128, it will default to 128 due to potential increased latency\n      to retrieve more than 128 slowlog entries every 15 seconds. If you need to get more entries from the slow query logs\n      set the value here. Warning: It may impact the performance of your redis instance\n  \ncommand_stats - (Optional) - Collect INFO COMMANDSTATS output as metrics.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nRedis YAML example\nRedis checks.d\n\n\n\nValidation\n\n\n  \n    Execute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\n    Checks\n======\n\n  [...]\n\n  redisdb\n  -------\n    - instance #0 [OK]\n    - Collected 8 metrics & 0 events\n\n  \n\n\n\nTroubleshooting and Questions\n\nQ: How do I filter to look at the stats for a particular DB in a particular environment?\n\nA: Prebuilt dashboards only allow you to filter on a single tag\n(these are the dashboards you see when\nclicking Overview). If you go to the Metrics Explorer, you can select which\nmetrics you want to see and what you want to see it over.  In the ‘Over:’ section\nyou can select multiple environments and then select “Save these tiles to: a new dashboard.”\n\n\n\n\nMetrics\n\n\n\n\nredis.aof.buffer_length(gauge)\nSize of the AOF buffer.shown as byte\n\n\n\n\nredis.aof.last_rewrite_time(gauge)\nDuration of the last AOF rewrite.shown as second\n\n\n\n\nredis.aof.rewrite(gauge)\nFlag indicating a AOF rewrite operation is on-going.\n\n\n\n\nredis.aof.size(gauge)\nAOF current file size (aof_current_size).shown as byte\n\n\n\n\nredis.clients.biggest_input_buf(gauge)\nThe biggest input buffer among current client connections.\n\n\n\n\nredis.clients.blocked(gauge)\nThe number of connections waiting on a blocking call.shown as connection\n\n\n\n\nredis.clients.longest_output_list(gauge)\nThe longest output list among current client connections.\n\n\n\n\nredis.cpu.sys(gauge)\nSystem CPU consumed by the Redis server.shown as second\n\n\n\n\nredis.cpu.sys_children(gauge)\nSystem CPU consumed by the background processes.shown as second\n\n\n\n\nredis.cpu.user(gauge)\nUser CPU consumed by the Redis server.shown as second\n\n\n\n\nredis.cpu.user_children(gauge)\nUser CPU consumed by the background processes.shown as second\n\n\n\n\nredis.expires(gauge)\nThe number of keys that have expired.shown as key\n\n\n\n\nredis.expires.percent(gauge)\nPercentage of total keys that have been expired.shown as percent\n\n\n\n\nredis.info.latency_ms(gauge)\nThe latency of the redis INFO command.shown as millisecond\n\n\n\n\nredis.key.length(gauge)\nThe number of elements in a given key, tagged by key, e.g. 'key:mykeyname'. Enable in Agent's redisdb.yaml with the keys option.\n\n\n\n\nredis.keys(gauge)\nThe total number of keys.shown as key\n\n\n\n\nredis.keys.evicted(gauge)\nThe total number of keys evicted due to the maxmemory limit.shown as key\n\n\n\n\nredis.keys.expired(gauge)\nThe total number of keys expired from the db.shown as key\n\n\n\n\nredis.mem.fragmentation_ratio(gauge)\nRatio between used_memory_rss and used_memory.shown as fraction\n\n\n\n\nredis.mem.lua(gauge)\nAmount of memory used by the Lua engine.shown as byte\n\n\n\n\nredis.mem.peak(gauge)\nThe peak amount of memory used by Redis.shown as byte\n\n\n\n\nredis.mem.rss(gauge)\nAmount of memory that Redis allocated as seen by the os.shown as byte\n\n\n\n\nredis.mem.used(gauge)\nAmount of memory allocated by Redis.shown as byte\n\n\n\n\nredis.net.clients(gauge)\nThe number of connected clients (excluding slaves).shown as connection\n\n\n\n\nredis.net.commands(gauge)\nThe number of commands processed by the server.shown as command\n\n\n\n\nredis.net.rejected(gauge)\nThe number of rejected connections.shown as connection\n\n\n\n\nredis.net.slaves(gauge)\nThe number of connected slaves.shown as connection\n\n\n\n\nredis.perf.latest_fork_usec(gauge)\nThe duration of the latest fork.shown as microsecond\n\n\n\n\nredis.persist(gauge)\nThe number of keys persisted (redis.keys - redis.expires).shown as key\n\n\n\n\nredis.persist.percent(gauge)\nPercentage of total keys that are persisted.shown as percent\n\n\n\n\nredis.pubsub.channels(gauge)\nThe number of active pubsub channels.\n\n\n\n\nredis.pubsub.patterns(gauge)\nThe number of active pubsub patterns.\n\n\n\n\nredis.rdb.bgsave(gauge)\nOne if a bgsave is in progress and zero otherwise.\n\n\n\n\nredis.rdb.changes_since_last(gauge)\nThe number of changes since the last background save.\n\n\n\n\nredis.rdb.last_bgsave_time(gauge)\nDuration of the last bg_save operation.shown as second\n\n\n\n\nredis.replication.backlog_histlen(gauge)\nThe amount of data in the backlog sync buffer.shown as byte\n\n\n\n\nredis.replication.delay(gauge)\nThe replication delay in offsets.shown as offset\n\n\n\n\nredis.replication.last_io_seconds_ago(gauge)\nAmount of time since the last interaction with master.shown as second\n\n\n\n\nredis.replication.master_link_down_since_seconds(gauge)\nAmount of time that the master link has been down.shown as second\n\n\n\n\nredis.replication.master_repl_offset(gauge)\nThe replication offset reported by the master.shown as offset\n\n\n\n\nredis.replication.slave_repl_offset(gauge)\nThe replication offset reported by the slave.shown as offset\n\n\n\n\nredis.replication.sync(gauge)\nOne if a sync is in progress and zero otherwise.\n\n\n\n\nredis.replication.sync_left_bytes(gauge)\nAmount of data left before syncing is complete.shown as byte\n\n\n\n\nredis.slowlog.micros.95percentile(gauge)\nThe 95th percentile of the duration of queries reported in the slow log.shown as microsecond\n\n\n\n\nredis.slowlog.micros.avg(gauge)\nThe average duration of queries reported in the slow log.shown as microsecond\n\n\n\n\nredis.slowlog.micros.count(rate)\nThe rate of queries reported in the slow log.shown as query/second\n\n\n\n\nredis.slowlog.micros.max(gauge)\nThe maximum duration of queries reported in the slow log.shown as microsecond\n\n\n\n\nredis.slowlog.micros.median(gauge)\nThe median duration of queries reported in the slow log.shown as microsecond\n\n\n\n\nredis.stats.keyspace_hits(gauge)\nThe total number of successful lookups in the db.shown as key\n\n\n\n\nredis.stats.keyspace_misses(gauge)\nThe total number of missed lookups in the db.shown as key\n\n\n\n\nredis.command.calls(gauge)\nThe number of times a redis command has been called, tagged by 'command', e.g. 'command:append'. Enable in Agent's redisdb.yaml with the command_stats option.\n\n\n\n\nredis.command.usec_per_call(gauge)\nThe CPU time consumed per redis command call, tagged by 'command', e.g. 'command:append'. Enable in Agent's redisdb.yaml with the command_stats option.\n\n\n\n\n","tags":"","loc":"/integrations/redis/"},{"title":"Datadog-Redmine Integration","text":"\n\nOverview\n\nCapture Redmine activity in Datadog to:\n\n\n  Track your development cycle.\n  View open issues in the Datadog event stream.\n  Discuss projects with your team.\n\n\nThe Redmine configuration just requires a full URL to the desired activity feed (you can add multiple URLs).\n\n","tags":"","loc":"/integrations/redmine/"},{"title":"Datadog-Riak Integration","text":"\n\nOverview\n\nConnect Riak to Datadog in order to:\n\n\n  Visualize Riak performance and utilization.\n  Correlate the performance of Riak with the rest of your applications.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nRiak YAML example\nRiak checks.d\n\n\n\nMetrics\n\n\n\n\nriak.memory_atom(gauge)\nTotal amount of memory currently allocated for atom storageshown as byte\n\n\n\n\nriak.memory_atom_used(gauge)\nTotal amount of memory currently used for atom storageshown as byte\n\n\n\n\nriak.memory_binary(gauge)\nTotal amount of memory used for binariesshown as byte\n\n\n\n\nriak.memory_code(gauge)\nTotal amount of memory allocated for Erlang codeshown as byte\n\n\n\n\nriak.memory_ets(gauge)\nTotal memory allocated for Erlang Term Storageshown as byte\n\n\n\n\nriak.memory_processes(gauge)\nTotal amount of memory allocated for Erlang processesshown as byte\n\n\n\n\nriak.memory_processes_used(gauge)\nTotal amount of memory used by Erlang processesshown as byte\n\n\n\n\nriak.memory_total(gauge)\nTotal allocated memory (sum of processes and system)shown as byte\n\n\n\n\nriak.node_get_fsm_active_60s(gauge)\nNumber of active GET FSMs\n\n\n\n\nriak.node_get_fsm_in_rate(gauge)\nAverage number of GET FSMs enqueued by Sidejob\n\n\n\n\nriak.node_get_fsm_out_rate(gauge)\nAverage number of GET FSMs dequeued by Sidejob\n\n\n\n\nriak.node_get_fsm_rejected_60s(gauge)\nNumber of GET FSMs actively being rejected by Sidejob's overload protection\n\n\n\n\nriak.node_gets(count)\nNumber of GETs coordinated by this nodeshown as operation\n\n\n\n\nriak.node_put_fsm_active_60s(gauge)\nNumber of active PUT FSMs\n\n\n\n\nriak.node_put_fsm_in_rate(gauge)\nAverage number of PUT FSMs enqueued by Sidejob\n\n\n\n\nriak.node_put_fsm_out_rate(gauge)\nAverage number of PUT FSMs dequeued by Sidejob\n\n\n\n\nriak.node_put_fsm_rejected_60s(gauge)\nNumber of PUT FSMs actively being rejected by Sidejob's overload protection\n\n\n\n\nriak.node_puts(gauge)\nNumber of PUTs coordinated by this nodeshown as operation\n\n\n\n\nriak.pbc_active(gauge)\nNumber of active protocol buffers connectionsshown as connection\n\n\n\n\nriak.pbc_connects(gauge)\nNumber of protocol buffers connectionsshown as connection\n\n\n\n\nriak.read_repairs(gauge)\nNumber of read repair operations this this node has coordinated in the last minuteshown as operation\n\n\n\n\nriak.vnode_gets(gauge)\nNumber of GET operations coordinated by vnodes on this nodeshown as operation\n\n\n\n\nriak.vnode_index_deletes(gauge)\nNumber of vnode index delete operationsshown as operation\n\n\n\n\nriak.vnode_index_reads(gauge)\nNumber of vnode index read operationsshown as read\n\n\n\n\nriak.vnode_index_writes(gauge)\nNumber of vnode index write operationsshown as write\n\n\n\n\nriak.vnode_puts(count)\nNumber of PUT operations coordinated by vnodes on this nodeshown as operation\n\n\n\n\nriak.node_get_fsm_objsize_mean(gauge)\nObject size encountered by this nodeshown as byte\n\n\n\n\nriak.node_get_fsm_siblings_mean(gauge)\nNumber of siblings encountered during all GET operations by this nodeshown as node\n\n\n\n\nriak.node_get_fsm_time_mean(gauge)\nTime between reception of client GET request and subsequent response to clientshown as microsecond\n\n\n\n\nriak.node_put_fsm_time_mean(gauge)\nTime between reception of client PUT request and subsequent response to clientshown as microsecond\n\n\n\n\nriak.node_get_fsm_objsize_median(gauge)\nObject size encountered by this nodeshown as byte\n\n\n\n\nriak.node_get_fsm_siblings_median(gauge)\nNumber of siblings encountered during all GET operations by this nodeshown as node\n\n\n\n\nriak.node_get_fsm_time_median(gauge)\nTime between reception of client GET request and subsequent response to clientshown as microsecond\n\n\n\n\nriak.node_put_fsm_time_median(gauge)\nTime between reception of client PUT request and subsequent response to clientshown as microsecond\n\n\n\n\nriak.node_get_fsm_objsize_95(gauge)\nObject size encountered by this nodeshown as byte\n\n\n\n\nriak.node_get_fsm_siblings_95(gauge)\nNumber of siblings encountered during all GET operations by this nodeshown as node\n\n\n\n\nriak.node_get_fsm_time_95(gauge)\nTime between reception of client GET request and subsequent response to clientshown as microsecond\n\n\n\n\nriak.node_put_fsm_time_95(gauge)\nTime between reception of client PUT request and subsequent response to clientshown as microsecond\n\n\n\n\nriak.node_get_fsm_objsize_99(gauge)\nObject size encountered by this nodeshown as byte\n\n\n\n\nriak.node_get_fsm_siblings_99(gauge)\nNumber of siblings encountered during all GET operations by this nodeshown as node\n\n\n\n\nriak.node_get_fsm_time_99(gauge)\nTime between reception of client GET request and subsequent response to clientshown as microsecond\n\n\n\n\nriak.node_put_fsm_time_99(gauge)\nTime between reception of client PUT request and subsequent response to clientshown as microsecond\n\n\n\n\nriak.node_get_fsm_objsize_100(gauge)\nObject size encountered by this nodeshown as byte\n\n\n\n\nriak.node_get_fsm_siblings_100(gauge)\nNumber of siblings encountered during all GET operations by this nodeshown as node\n\n\n\n\nriak.node_get_fsm_time_100(gauge)\nTime between reception of client GET request and subsequent response to clientshown as microsecond\n\n\n\n\nriak.node_put_fsm_time_100(gauge)\nTime between reception of client PUT request and subsequent response to clientshown as microsecond\n\n\n\n\nriak.search_index_fail_count(gauge)\nTotal number of documents that have failed to indexshown as object\n\n\n\n\nriak.search_index_fail_one(gauge)\nNumber of documents that have failed to index in the past one minuteshown as object\n\n\n\n\nriak.search_query_fail_count(gauge)\nTotal number of queries that have failedshown as event\n\n\n\n\nriak.search_query_fail_one(gauge)\nNumber of queries that have failed in the last one minuteshown as event\n\n\n\n\nriak.search_index_throughput_count(gauge)\nTotal number of documents that have been indexedshown as operation\n\n\n\n\nriak.search_index_throughput_one(gauge)\nNumber of documents that have been indexed in the last one minuteshown as operation\n\n\n\n\nriak.search_query_throughput_count(gauge)\nTotal number of queries that have been performedshown as operation\n\n\n\n\nriak.search_query_throughput_one(gauge)\nNumber of searches that have been performed in the last one minuteshown as operation\n\n\n\n\nriak.search_query_latency_95(gauge)\nTime between reception of query and response: 95th percentileshown as microsecond\n\n\n\n\nriak.search_query_latency_99(gauge)\nTime between reception of query and response: 99th percentileshown as microsecond\n\n\n\n\nriak.search_query_latency_999(gauge)\nTime between reception of query and response: 99.9th percentileshown as microsecond\n\n\n\n\nriak.search_query_latency_max(gauge)\nTime between reception of query and response: maxshown as microsecond\n\n\n\n\nriak.search_query_latency_min(gauge)\nTime between reception of query and response: minshown as microsecond\n\n\n\n\nriak.search_query_latency_mean(gauge)\nTime between reception of query and response: meanshown as microsecond\n\n\n\n\nriak.search_query_latency_median(gauge)\nTime between reception of query and response: medianshown as microsecond\n\n\n\n\nriak.search_index_latency_95(gauge)\nTime between insertion of document and it being indexed: 95th percentileshown as microsecond\n\n\n\n\nriak.search_index_latency_99(gauge)\nTime between insertion of document and it being indexed: 99th percentileshown as microsecond\n\n\n\n\nriak.search_index_latency_999(gauge)\nTime between insertion of document and it being indexed: 99.9th percentileshown as microsecond\n\n\n\n\nriak.search_index_latency_max(gauge)\nTime between insertion of document and it being indexed: maxshown as microsecond\n\n\n\n\nriak.search_index_latency_min(gauge)\nTime between insertion of document and it being indexed: minshown as microsecond\n\n\n\n\nriak.search_index_latency_mean(gauge)\nTime between insertion of document and it being indexed: meanshown as microsecond\n\n\n\n\nriak.search_index_latency_median(gauge)\nTime between insertion of document and it being indexed: medianshown as microsecond\n\n\n\n\n","tags":"","loc":"/integrations/riak/"},{"title":"Datadog-RiakCS Integration","text":"\n\nOverview\n\nCapture Riak CS (Cloud Storage) metrics in Datadog to:\n\n\n  Visualize key RiakCS metrics.\n  Correlate RiakCS performance with the rest of your applications.\n\n\n\nConfiguration\n\nTo configure the RiakCS integration, copy riakcs.yaml.example if the conf.d directory to riakcs.yaml and make the appropriate changes.\n\ninit_config:\n\ninstances:\n  - access_id: access-key\n    access_secret: access-secret\n    #is_secure: True # Uncomment and change to false if you are not using ssl\n    #host: localhost # Hostname/IP of your riakcs node\n    #port: 8080 # port used by your riakcs node\n    #s3_root: s3.amazonaws.com #\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nRiakCS YAML example\nRiakCS checks.d\n\n\n\nMetrics\n\n\n\n\nriakcs.block_get.latency_mean(gauge)\nMean latency of BLOCK GET operations performedshown as microsecond\n\n\n\n\nriakcs.block_put.latency_mean(gauge)\nMean latency of BLOCK PUT operations performedshown as microsecond\n\n\n\n\nriakcs.block_delete.latency_mean(gauge)\nMean latency of BLOCK DELETE operations performedshown as microsecond\n\n\n\n\nriakcs.object_get.latency_mean(gauge)\nMean latency of GET operations performedshown as microsecond\n\n\n\n\nriakcs.object_put.latency_mean(gauge)\nMean latency of PUT operations performedshown as microsecond\n\n\n\n\nriakcs.object_delete.latency_mean(gauge)\nMean latency of DELETE operations performedshown as microsecond\n\n\n\n\nriakcs.service_get_buckets.latency_mean(gauge)\nMean latency of GET BUCKETS operations performedshown as microsecond\n\n\n\n\nriakcs.bucket_delete.latency_mean(gauge)\nMean latency of BUCKET DELETE operations performedshown as microsecond\n\n\n\n\nriakcs.bucket_create.latency_mean(gauge)\nMean latency of BUCKET CREATE operations performedshown as microsecond\n\n\n\n\nriakcs.block_get.meter_rate(gauge)\nRate of BLOCK GET operations performedshown as operation/second\n\n\n\n\nriakcs.block_put.meter_rate(gauge)\nRate of BLOCK PUT operations performedshown as operation/second\n\n\n\n\nriakcs.block_delete.meter_rate(gauge)\nRate of BLOCK DELETE operations performedshown as operation/second\n\n\n\n\nriakcs.object_get.meter_rate(gauge)\nRate of GET operations performedshown as operation/second\n\n\n\n\nriakcs.object_put.meter_rate(gauge)\nRate of PUT operations performedshown as operation/second\n\n\n\n\nriakcs.object_delete.meter_rate(gauge)\nRate of DELETE operations performedshown as operation/second\n\n\n\n\nriakcs.service_get_buckets.meter_rate(gauge)\nRate of GET BUCKETS operations performedshown as operation/second\n\n\n\n\nriakcs.bucket_delete.meter_rate(gauge)\nRate of BUCKET DELETE operations performedshown as operation/second\n\n\n\n\nriakcs.bucket_create.meter_rate(gauge)\nRate of BUCKET CREATE operations performedshown as operation/second\n\n\n\n\n","tags":"","loc":"/integrations/riakcs/"},{"title":"Datadog-Rollbar Integration","text":"\n\nOverview\n\nRollbar helps developers like us build better software, faster. With Rollbar developers can view exceptions from all of of their frameworks, platforms and environments in one place.\n\nWith this integration Rollbar users can:\n\n\n  Syndicate exceptions, errors and code deployments as ‘Events’ in Datadog.\n\n\n\nInstallation\n\nNo installation is required.\n\n\nConfiguration\n\nTo integrate Rollbar with Datadog:\n\n\n  Retrieve an API key from Datadog’s API settings page\n\n  Login to Rollbar, and go to the Notification settings page for a project: Dashboard → Settings → Notifications\n  Enter your Datadog API key.\n  Click Enable Datadog Integration\n  (optional) Customize your notification settings to taste!\n\n\n\nMetrics\n\nThis integration does not include metrics at this time.\n\n\nEvents\n\nThis integration will push exceptions, errors and code deployments into Datadog as events.\n","tags":"","loc":"/integrations/rollbar/"},{"title":"Datadog-RSS Integration","text":"\n\nOverview\n\nCapture RSS feed activity in Datadog to:\n\n\n  Add events from custom sources to your stream.\n  Discuss feed events with your team.\n\n","tags":"","loc":"/integrations/rss/"},{"title":"Datadog-Ruby Integration","text":"\n\nOverview\n\nThe Ruby integration allows you to monitor custom metrics by simply adding a few lines of code to your Ruby application. For example, you can have a metric that returns the number of page views or the time of any function call. For additional information about the Ruby integration, please refer to the guide on submitting metrics. For advanced usage, please refer to the documentation in the repositories listed below. You can also review the API docs for details on how to use the API with Ruby.\n\nDatadog offers two libraries to assist you with the implementation of Ruby application metrics:\n\n\n  \ndogstatsd-ruby A client for DogStatsD, an extension of the StatsD metric server for Datadog.\n  \ndogapi-rb The Ruby client is a library suitable for inclusion in existing Ruby projects or for development of standalone scripts. It provides an abstraction on top of Datadog’s raw HTTP interface for reporting events and metrics.\n\n\n\nInstallation\n\n\n  \n    To install the Ruby client for the Datadog API:\n\n    gem install dogapi\n\n\n    To install the dogstatsd-ruby client for DogStatsD:\n\n    gem install dogstatsd-ruby\n\n  \n  \n    Start instrumenting your code using the Datadog API:\n\n    # Load the Datadog API module.\nrequire 'rubygems'\nrequire 'dogapi'\n\napi_key = \"abcdef123456\"\napplication_key = \"fedcba654321\"\n\n# Note that submitting events does not require the application key.\ndog = Dogapi::Client.new(api_key, application_key)\n\n# Send a new event.\ndog.emit_event(Dogapi::Event.new('Testing done, FTW'), :host => \"my_host\")\n\n\n    Start instrumenting your code using the DogStatsD client:\n\n    # Load the dogstats module.\nrequire 'datadog/statsd'\n\n# Create a stats instance.\nstatsd = Datadog::Statsd.new('localhost', 8125)\n\n# Increment a counter.\nstatsd.increment('page.views')\n\n# Record a gauge 50% of the time.\nstatsd.gauge('users.online', 123, :sample_rate=>0.5)\n\n  \n\n\n\nConfiguration\n\nThere is nothing that you need to do in the Datadog application to configure Ruby.\n\n\nValidation\n\nGo to the Metrics explorer page and see that it just works!\n","tags":"","loc":"/integrations/ruby/"},{"title":"Datadog-Sentry Integration","text":"\nConnect Sentry to Datadog to:\n\n\n  See exceptions in the stream, in real time\n  Search for exceptions in your graphs\n  Discuss exceptions with your team\n\n","tags":"","loc":"/integrations/sentry/"},{"title":"Datadog-ServiceNow Integration","text":"\nServiceNow is an IT service management platform for recording, tracking, and managing a company’s enterprise-level IT processes in a single location. This integration allows you to create tickets from triggered alarms in Datadog. Additionally, you can add Datadog-generated graphs and comments to ServiceNow tickets, as well as manage the resolution workflow from within Datadog\n\n\nAuto-generate support tickets from Datadog alerts\n\nNow, you can set these alerts to automatically create support tickets and send them to the ServiceNow ticketing queue. From there, your support team will be notified of issues using the communication workflows that you have already established inside ServiceNow. All you have to do is mention @servicenow in the alert message or add @servicenow to the notification list for that monitor.\n\n\n\n\nUse variables in ticket payload and field mappings\n\nVariables can be used in the body of your alerts or in field mappings to ensure rich details from the event are included in ServiceNow.  For example, you can include the title and severity in the appropriate ServiceNow field or you can include a link back to the specific incident in Datadog right from the ServiceNow ticket.\n\n \n\n\nAutomate support resolution workflow\n\nOnce the monitor state returns to normal, the associated support ticket is automatically marked as “resolved”.\n\n\n\n\nSend Datadog graphs to ServiceNow\n\nIn addition to automating ticket creation and resolution, you can also use Datadog to create ServiceNow tickets on an ad hoc basis whenever you see something in Datadog that needs your team’s attention. Just click the camera icon to share a snapshot of any Timeboard graph, add some context in the comment box to help your colleagues interpret the graph, and @mention ServiceNow to send the graph and your comments to ServiceNow.\n\n\n\n\nConfigure ServiceNow\n\nTo configure the ServiceNow integration, enter your ServiceNow instance name, and the username and password. We recommend creating a new user for the Datadog integration.\n\n\n","tags":"","loc":"/integrations/servicenow/"},{"title":"Datadog-Slack Integration","text":"\n\n  In your Slack account Administration page, go to the Integration tab and choose Datadog.\n  Copy paste the service hook into the field below.\n  Add the channels you want to be able to post to.\n  Tick the checkbox if you want to be notified for every comment, otherwise you will need to use the @slack-channel_name syntax.\n\n","tags":"","loc":"/integrations/slack/"},{"title":"Datadog-SNMP Integration","text":"\n\nOverview\n\nUse the SNMP Agent Check to:\n\n\n  Monitor all your network devices\n  Correlate their performance with the rest of your applications\n\n\n\nConfiguration\n\nTo use the SNMP checks, edit the snmp.yaml file in your conf.d directory as follows:\n\ninit_config:\n  #You can specify an additional folder for your custom mib files (python format)\n  mibs_folder: /path/to/your/mibs/folder\n\ninstances:\n\n  # SNMP v1-v2 configuration\n  - ip_address: localhost\n    port: 161\n    community_string: public\n    snmp_version: 2 # Only required for snmp v1, will default to 2\n    timeout: 1 # second, by default\n    retries: 5\n    enforce_mib_constraints: true  # if set to false we will not check the values\n                                   # returned meet the MIB constraints. Defaults to True.\n    tags:\n      - location:front\n    metrics:\n      - MIB: UDP-MIB\n        symbol: udpInDatagrams\n      - MIB: TCP-MIB\n        symbol: tcpActiveOpens\n      - OID: 1.3.6.1.2.1.6.5\n        name: tcpPassiveOpens\n\n\nFor each device that you want to monitor, you need to specify at least an ip_address and an authentication method. If not specified, a default port of 161 will be assumed.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nSNMP YAML example\nSNMP checks.d\n\n\n\nUsage\n\nOur agent allows you to monitor the SNMP Counters and Gauge of your choice. Specify for each device the metrics that you want to monitor in the metrics subsection using one of the following methods:\n\n\nSpecify a MIB and the symbol that you want to export\n\nmetrics:\n  - MIB: UDP-MIB\n    symbol: udpInDatagrams\n\n\n\nSpecify an OID and the name you want the metric to appear under in Datadog\n\nmetrics:\n  - OID: 1.3.6.1.2.1.6.5\n    name: tcpActiveOpens\n\n\nThe name here is the one specified in the MIB but you could use any name.\n\n\nSpecify a MIB and a table you want to extract information from\n\nmetrics:\n  - MIB: IF-MIB\n    table: ifTable\n    symbols:\n      - ifInOctets\n    metric_tags:\n      - tag: interface\n    column: ifDescr\n\n\nThis allows you to gather information on all the table’s row, as well as to specify tags to gather.\n\nUse the symbols list to specify the metric to gather and the metric_tags list to specify the name of the tags and the source to use.\n\nIn this example the agent would gather the rate of octets received on each interface and tag it with the interface name (found in the ifDescr column), resulting in a tag such as interface:eth0\n\nmetrics:\n  - MIB: IP-MIB\n    table: ipSystemStatsTable\n    symbols:\n      - ipSystemStatsInReceives\n    metric_tags:\n      - tag: ipversion\n    index: 1\n\n\nYou can also gather tags based on the indices of your row, in case they are meaningful. In this example, the first row index contains the ip version that the row describes (ipv4 vs. ipv6)\n\n\nUse your own Mib\n\nTo use your own MIB with the datadog-agent, you need to convert them to the pysnmp format. This can be done using the build-pysnmp-mibs script that ships with pysnmp.\n\nIt has a dependency on smidump, from the libsmi2ldbl package so make sure it is installed. Make also sure that you have all the dependencies of your MIB in your mib folder or it won’t be able to convert your MIB correctly.\n\n\nRun\n\n$ build-pysnmp-mibs -o YOUR-MIB.py YOUR-MIB.mib\n\n\nwhere YOUR-MIB.mib is the MIB you want to convert.\n\nPut all your pysnmp mibs into a folder and specify this folder’s path in snmp.yaml file, in the init_config section.\n","tags":"","loc":"/integrations/snmp/"},{"title":"Datadog-Solr Integration","text":"\n\nOverview\n\n\n\nGet metrics from Solr in real time to\n\n\n  Visualize your search platform performance\n  Correlate the performance of Solr with the rest of your applications\n\n\n\nInstallation\n\nMetrics will be captured using a JMX connection. This check has a limit of 350 metrics per instance. The number of returned metrics is indicated in the info page. You can specify the metrics you are interested in by editing the configuration below. To learn how to customize the metrics to collect visit the JMX Checks documentation for more detailed instructions. If you need to monitor more metrics, please send us an email at support@datadoghq.com\n\nMake sure that JMX Remote is enabled on your Tomcat server. For information on JMX , please see the JMX integration documentation.\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to Tomcat. Edit conf.d/solr.yaml:\n\n    instances:\n  - host: localhost\n    port: 9999\n# List of metrics to be collected by the integration\n# Read http://docs.datadoghq.com/integrations/java/ to learn how to customize it\ninit_config:\n  conf:\n    - include:\n      type: searcher\n      attribute:\n        maxDoc:\n          alias: solr.searcher.maxdoc\n          metric_type: gauge\n        numDocs:\n          alias: solr.searcher.numdocs\n          metric_type: gauge\n        warmupTime:\n          alias: solr.searcher.warmup\n          metric_type: gauge\n    - include:\n      id: org.apache.solr.search.FastLRUCache\n      attribute:\n        cumulative_lookups:\n          alias: solr.cache.lookups\n          metric_type: counter\n        cumulative_hits:\n          alias: solr.cache.hits\n          metric_type: counter\n        cumulative_inserts:\n          alias: solr.cache.inserts\n          metric_type: counter\n        cumulative_evictions:\n          alias: solr.cache.evictions\n          metric_type: counter\n    - include:\n      id: org.apache.solr.search.LRUCache\n      attribute:\n        cumulative_lookups:\n          alias: solr.cache.lookups\n          metric_type: counter\n        cumulative_hits:\n          alias: solr.cache.hits\n          metric_type: counter\n        cumulative_inserts:\n          alias: solr.cache.inserts\n          metric_type: counter\n        cumulative_evictions:\n          alias: solr.cache.evictions\n          metric_type: counter\n    - include:\n      id: org.apache.solr.handler.component.SearchHandler\n      attribute:\n        errors:\n          alias: solr.search_handler.errors\n          metric_type: counter\n        requests:\n          alias: solr.search_handler.requests\n          metric_type: counter\n        timeouts:\n          alias: solr.search_handler.timeouts\n          metric_type: counter\n        totalTime:\n          alias: solr.search_handler.time\n          metric_type: counter\n        avgTimePerRequest:\n          alias: solr.search_handler.avg_time_per_req\n          metric_type: gauge\n        avgRequestsPerSecond:\n          alias: solr.search_handler.avg_requests_per_sec\n          metric_type: gauge\n\n  \n  \n    Restart the Agent\n  \n\n\n\nConfiguration Options\n\n\n  \nuser and password (Optional) - Username and password.\n  \nprocess_name_regex - (Optional) - Instead of specifying a host and port or jmx_url, the agent can connect using the attach api. This requires the JDK to be installed and the path to tools.jar to be set.\n  \ntools_jar_path - (Optional) - To be set when process_name_regex is set.\n  \njava_bin_path - (Optional) - Should be set if the agent cannot find your java executable.\n  \njava_options - (Optional) - Java JVM options\n  \ntrust_store_path and trust_store_password - (Optional) - Should be set if ssl is enabled.\n\n\nThe conf parameter is a list of dictionaries. Only 2 keys are allowed in this dictionary:\n\n\n  \ninclude (mandatory): Dictionary of filters, any attribute that matches these filters will be collected unless it also matches the “exclude” filters (see below)\n  \nexclude (optional): Another dictionary of filters. Attributes that match these filters won’t be collected\n\n\nFor a given bean, metrics get tagged in the following manner:\n\nmydomain:attr0=val0,attr1=val1\n\n\nYour metric will be mydomain (or some variation depending on the attribute inside the bean) and have the tags attr0:val0, attr1:val1, domain:mydomain.\n\nIf you specify an alias in an include key that is formatted as camel case, it will be converted to snake case. For example, MyMetricName will be shown in Datadog as my_metric_name.\n\n\nThe attribute filter\n\nThe attribute filter can accept two types of values:\n\n\n  \n    A dictionary whose keys are attributes names:\n\n    conf:\n  - include:\n    attribute:\n      maxThreads:\n        alias: tomcat.threads.max\n        metric_type: gauge\n      currentThreadCount:\n        alias: tomcat.threads.count\n        metric_type: gauge\n      bytesReceived:\n        alias: tomcat.bytes_rcvd\n        metric_type: counter\n\n  \n\n\nIn that case you can specify an alias for the metric that will become the metric name in Datadog. You can also specify the metric type either a gauge or a counter. If you choose counter, a rate per second will be computed for this metric.\n\n\n  \n    A list of attributes names:\n\n    conf:\n  - include:\n    domain: org.apache.cassandra.db\n    attribute:\n      - BloomFilterDiskSpaceUsed\n      - BloomFilterFalsePositives\n      - BloomFilterFalseRatio\n      - Capacity\n      - CompressionRatio\n      - CompletedTasks\n      - ExceptionCount\n      - Hits\n      - RecentHitRate\n\n  \n\n\nIn that case:\n\n\n  The metric type will be a gauge\n  The metric name will be jmx.[DOMAIN_NAME].[ATTRIBUTE_NAME]\n\n\nHere is another filtering example:\n\ninstances:\n  - host: 127.0.0.1\n    name: jmx_instance\n    port: 9999\n\ninit_config:\n  conf:\n    - include:\n      bean: org.apache.cassandra.metrics:type=ClientRequest,scope=Write,name=Latency\n      attribute:\n        - OneMinuteRate\n        - 75thPercentile\n        - 95thPercentile\n        - 99thPercentile\n\n\n\nNote\n\nList of filters is only supported in Datadog Agent > 5.3.0. If you are using an older version, please use singletons and multiple include statements instead.\n\n# Datadog Agent > 5.3.0\n  conf:\n    - include:\n      domain: domain_name\n      bean:\n        - first_bean_name\n        - second_bean_name\n\n# Older Datadog Agent versions\n  conf:\n    - include:\n      domain: domain_name\n      bean: first_bean_name\n    - include:\n      domain: domain_name\n      bean: second_bean_name\n\n\n\nCommands to view the metrics that are available:\n\nThe datadog-agent jmx command was added in version 4.1.0.\n\n\n  List attributes that match at least one of your instances configuration:\nsudo /etc/init.d/datadog-agent jmx list_matching_attributes\n\n  List attributes that do match one of your instances configuration but that are not being collected because it would exceed the number of metrics that can be collected:\nsudo /etc/init.d/datadog-agent jmx list_limited_attributes\n\n  List attributes that will actually be collected by your current instances configuration:\nsudo /etc/init.d/datadog-agent jmx list_collected_attributes\n\n  List attributes that don’t match any of your instances configuration:\nsudo /etc/init.d/datadog-agent jmx list_not_matching_attributes\n\n  List every attributes available that has a type supported by JMXFetch:\nsudo /etc/init.d/datadog-agent jmx list_everything\n\n  Start the collection of metrics based on your current configuration and display them in the console:\nsudo /etc/init.d/datadog-agent jmx collect\n\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\nSolr YAML example\n\n\nValidation\n\nExecute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  solr\n  ----\n      - instance #0 [OK]\n      - Collected 13 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\nsolr.searcher.maxdoc(gauge every 10 seconds)\nOne greater than the largest possible document number.shown as document\n\n\n\n\nsolr.searcher.numdocs(gauge every 10 seconds)\nThe total number of indexed documents.shown as document\n\n\n\n\nsolr.searcher.warmup(gauge every 10 seconds)\nThe time spent warming up.shown as millisecond\n\n\n\n\nsolr.cache.hits(gauge every 10 seconds)\nThe number of cache hits per second.shown as hit/second\n\n\n\n\nsolr.cache.lookups(gauge every 10 seconds)\nThe total number of cache lookups per second.shown as get/second\n\n\n\n\nsolr.cache.inserts(gauge every 10 seconds)\nThe total number of cache inserts per second.shown as set/second\n\n\n\n\nsolr.cache.evictions(gauge every 10 seconds)\nThe total number of cache evictions per second.shown as eviction/second\n\n\n\n\nsolr.search_handler.errors(gauge every 10 seconds)\nNumber of errors per second encountered by the handler.shown as error/second\n\n\n\n\nsolr.search_handler.requests(gauge every 10 seconds)\nNumber of requests per second processed by the handler.shown as request/second\n\n\n\n\nsolr.search_handler.timeouts(gauge every 10 seconds)\nNumber of responses per second received with partial results.shown as timeout/second\n\n\n\n\nsolr.search_handler.time(gauge every 10 seconds)\nThe sum of all request processing times (in milliseconds) per second.\n\n\n\n\nsolr.search_handler.avg_time_per_req(gauge every 10 seconds)\nThe average time per request.shown as millisecond/request\n\n\n\n\nsolr.search_handler.avg_requests_per_sec(gauge every 10 seconds)\nThe average number of requests per second.shown as request/second\n\n\n\n\n","tags":"","loc":"/integrations/solr/"},{"title":"Datadog-Spark Integration","text":"\n\nOverview\n\nGet metrics from your app in real time to\n\n\n  Visualize performance metrics\n\n\n\n\n\nConfiguration\n\nInstall Datadog Agent on the Master Node where the ResourceManager is running\n\n\n  \n    Configure the agent to connect to the ResourceManager. Edit conf.d/spark.yaml\n\n    init_config:\n\ninstances:\n  #\n  # The Spark check retrieves metrics from YARN's ResourceManager. This\n  # check must be run from the Master Node and the ResourceManager URI must\n  # be specified below. The ResourceManager URI is composed of the\n  # ResourceManager's hostname and port.\n  #\n  # The ResourceManager hostname can be found in the yarn-site.xml conf file\n  # under the property yarn.resourcemanager.address\n  #\n  # The ResourceManager port can be found in the yarn-site.xml conf file under\n  # the property yarn.resourcemanager.webapp.address\n  #\n  - resourcemanager_uri: http://localhost:8088\n\n  # An optional friendly name can be specified for the cluster.\n  #   cluster_name: MySparkCluster\n\n    # Additional tags can be specified for the metrics.\n    # tags:\n    #   - optional_tag1\n    #   - optional_tag2\n\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nSpark YAML example\nSpark checks.d\n\n\n\nValidation\n\n\n  Restart the Agent\n  \n    Execute the info command and verify that the integration check passed. The output of the command should contain a section similar to the following:\n\n    Checks\n======\n\n  [...]\n\n  spark\n  -----\n    - instance #0 [OK]\n    - Collected 0 metrics, 0 events & 2 service checks\n\n  \n\n\n\nMetrics\n\n\n\n\nspark.job.num_tasks(rate)\nNumber of tasks in the applicationshown as task/second\n\n\n\n\nspark.job.num_active_tasks(rate)\nNumber of active tasks in the applicationshown as task/second\n\n\n\n\nspark.job.num_skipped_tasks(rate)\nNumber of skipped tasks in the applicationshown as task/second\n\n\n\n\nspark.job.num_failed_tasks(rate)\nNumber of failed tasks in the applicationshown as task/second\n\n\n\n\nspark.job.num_active_stages(rate)\nNumber of active stages in the applicationshown as stage/second\n\n\n\n\nspark.job.num_completed_stages(rate)\nNumber of completed stages in the applicationshown as stage/second\n\n\n\n\nspark.job.num_skipped_stages(rate)\nNumber of skipped stages in the applicationshown as stage/second\n\n\n\n\nspark.job.num_failed_stages(rate)\nNumber of failed stages in the applicationshown as stage/second\n\n\n\n\nspark.stage.num_active_tasks(rate)\nNumber of active tasks in the application's stagesshown as task/second\n\n\n\n\nspark.stage.num_complete_tasks(rate)\nNumber of complete tasks in the application's stagesshown as task/second\n\n\n\n\nspark.stage.num_failed_tasks(rate)\nNumber of failed tasks in the application's stagesshown as task/second\n\n\n\n\nspark.stage.executor_run_time(gauge)\nFraction of time (ms/s) spent by the executor in the application's stagesshown as fraction\n\n\n\n\nspark.stage.input_bytes(rate)\nInput bytes in the application's stagesshown as byte/second\n\n\n\n\nspark.stage.input_records(rate)\nInput records in the application's stagesshown as record/second\n\n\n\n\nspark.stage.output_bytes(rate)\nOutput bytes in the application's stagesshown as byte/second\n\n\n\n\nspark.stage.output_records(rate)\nOutput records in the application's stagesshown as record/second\n\n\n\n\nspark.stage.shuffle_read_bytes(rate)\nNumber of bytes read during a shuffle in the application's stagesshown as byte/second\n\n\n\n\nspark.stage.shuffle_read_records(rate)\nNumber of records read during a shuffle in the application's stagesshown as record/second\n\n\n\n\nspark.stage.shuffle_write_bytes(rate)\nNumber of shuffled bytes in the application's stagesshown as byte/second\n\n\n\n\nspark.stage.shuffle_write_records(rate)\nNumber of shuffled records in the application's stagesshown as record/second\n\n\n\n\nspark.stage.memory_bytes_spilled(rate)\nNumber of bytes spilled to disk in the application's stagesshown as byte/second\n\n\n\n\nspark.stage.disk_bytes_spilled(rate)\nMax size on disk of the spilled bytes in the application's stagesshown as byte/second\n\n\n\n\nspark.driver.rdd_blocks(rate)\nNumber of RDD blocks in the drivershown as block/second\n\n\n\n\nspark.driver.memory_used(rate)\nAmount of memory used in the drivershown as byte/second\n\n\n\n\nspark.driver.disk_used(rate)\nAmount of disk used in the drivershown as byte/second\n\n\n\n\nspark.driver.active_tasks(rate)\nNumber of active tasks in the drivershown as task/second\n\n\n\n\nspark.driver.failed_tasks(rate)\nNumber of failed tasks in the drivershown as task/second\n\n\n\n\nspark.driver.completed_tasks(rate)\nNumber of completed tasks in the drivershown as task/second\n\n\n\n\nspark.driver.total_tasks(rate)\nNumber of total tasks in the drivershown as task/second\n\n\n\n\nspark.driver.total_duration(gauge)\nFraction of time (ms/s) spent by the drivershown as fraction\n\n\n\n\nspark.driver.total_input_bytes(rate)\nNumber of input bytes in the drivershown as byte/second\n\n\n\n\nspark.driver.total_shuffle_read(rate)\nNumber of bytes read during a shuffle in the drivershown as byte/second\n\n\n\n\nspark.driver.total_shuffle_write(rate)\nNumber of shuffled bytes in the drivershown as byte/second\n\n\n\n\nspark.driver.max_memory(rate)\nMaximum memory used in the drivershown as byte/second\n\n\n\n\nspark.executor.rdd_blocks(rate)\nNumber of persisted RDD blocks in the application's executorsshown as block/second\n\n\n\n\nspark.executor.memory_used(rate)\nAmount of memory used for cached RDDs in the application's executorsshown as byte/second\n\n\n\n\nspark.executor.disk_used(rate)\nAmount of disk space used by persisted RDDs in the application's executorsshown as byte/second\n\n\n\n\nspark.executor.active_tasks(rate)\nNumber of active tasks in the application's executorsshown as task/second\n\n\n\n\nspark.executor.failed_tasks(rate)\nNumber of failed tasks in the application's executorsshown as task/second\n\n\n\n\nspark.executor.completed_tasks(rate)\nNumber of completed tasks in the application's executorsshown as task/second\n\n\n\n\nspark.executor.total_tasks(rate)\nTotal number of tasks in the application's executorsshown as task/second\n\n\n\n\nspark.executor.total_duration(gauge)\nFraction of time (ms/s) spent by the application's executors executing tasksshown as fraction\n\n\n\n\nspark.executor.total_input_bytes(rate)\nTotal number of input bytes in the application's executorsshown as byte/second\n\n\n\n\nspark.executor.total_shuffle_read(rate)\nTotal number of bytes read during a shuffle in the application's executorsshown as byte/second\n\n\n\n\nspark.executor.total_shuffle_write(rate)\nTotal number of shuffled bytes in the application's executorsshown as byte/second\n\n\n\n\nspark.executor_memory(rate)\nMaximum memory available for caching RDD blocks in the application's executorsshown as byte/second\n\n\n\n\nspark.rdd.num_partitions(rate)\nNumber of persisted RDD partitions in the application/second\n\n\n\n\nspark.rdd.num_cached_partitions(rate)\nNumber of in-memory cached RDD partitions in the application/second\n\n\n\n\nspark.rdd.memory_used(rate)\nAmount of memory used in the application's persisted RDDsshown as byte/second\n\n\n\n\nspark.rdd.disk_used(rate)\nAmount of disk space used by persisted RDDs in the applicationshown as byte/second\n\n\n\n","tags":"","loc":"/integrations/spark/"},{"title":"Datadog-Splunk Integration","text":"\n\nOverview\n\nConnect your Splunk log monitoring to be able to:\n\n\n  Get notified of your reports. \n  Correlate these reports with your other metrics\n  Collaborate with your team on thse events \n\n\n\nInstallation\n\nTo receive your reports from Splunk into Datadog, you need to have datadog installed:\n\n#!shell\npip install datadog\n\n\nOnce it is done, get your api key and an application key and drop the following dog-splunk.sh script into $SPLUNK_HOME/bin/scripts\n\n#!shell\n#!/bin/bash\nexport API_KEY=YOURAPIKEYHERE\nexport APP_KEY=YOURAPPKEYHERE\n/opt/datadog-agent/bin/dog --api-key $API_KEY --application-key $APP_KEY event post \\\n\"Found $SPLUNK_ARG_1 events in splunk\" \\\n\"Matching $SPLUNK_ARG_2 based on $SPLUNK_ARG_5,\" \\\n\" from report $SPLUNK_ARG_4. More details at $SPLUNK_ARG_6.\" \\\n --aggregation_key $SPLUNK_ARG_3 --type splunk\n\n\nMake sure the script is executable and owned by the splunk user and group. \n\nOnce the script is in place, create a new report or navigate to an existing report. Click the Edit Schedule and check the checkbox to Schedule the Report. When you get to the option to Run a Script, enter dog-splunk.sh in the Filename textbox. Click Save and you should see the results start appearing in your Event Stream. \n\n\nTroubleshooting\n\nIf you see an error code on each run of runshellscript in splunkd.log, try adding > dog_splunk_trace.txt 2>&1 to the end of the last command. This will create a $SPLUNK_HOME/etc/apps/search/bin/dog_splunk_trace.txt file. You will get more detail about the problem in this file.\n\nIf the trace file has something like the usage help for the dog command followed by dog: error: unrecognized arguments: OR failed OR severe, you probably will need to add single quotes around $SPLUNK_ARG_3 on the last line. \n\nIf the trace file include a Traceback that ends with pkg_resources.DistributionNotFound or something similar, add 3 unsets to the top of your dog-splunk.sh script to make it look like this:\n\n#!shell\n#!/bin/bash\nunset PYTHONHOME\nunset PYTHONPATH\nunset LD_LIBRARY_PATH\nexport API_KEY=YOURAPIKEYHERE\nexport APP_KEY=YOURAPPKEYHERE\n/opt/datadog-agent/bin/dog --api-key $API_KEY --application-key $APP_KEY event post \\\n\"Found $SPLUNK_ARG_1 events in splunk\" \\\n\"Matching $SPLUNK_ARG_2 based on $SPLUNK_ARG_5,\" \\\n\" from report $SPLUNK_ARG_4. More details at $SPLUNK_ARG_6.\" \\\n --aggregation_key $SPLUNK_ARG_3 --type splunk\n\n\n\nCustomizing\n\nThe script file uses variables made available by Splunk. If you would like to customize the message, refer to the following table of variables:\n\n\n  \n    \n      $SPLUNK_ARG_0\n      Script Name\n    \n    \n      $SPLUNK_ARG_1\n      Number of events returned\n    \n    \n      $SPLUNK_ARG_2\n      Search terms\n    \n    \n      $SPLUNK_ARG_3\n      Fully qualified query string\n    \n    \n      $SPLUNK_ARG_4\n      Name of saved search\n    \n    \n      $SPLUNK_ARG_5\n      Trigger reason (for example, “The number of events was greater than 1”)\n    \n    \n      $SPLUNK_ARG_6\n      Browser URL to view the saved search\n    \n    \n      $SPLUNK_ARG_7\n      option removed in version 3.6\n    \n    \n      $SPLUNK_ARG_8\n      File in which the results for this search are stored (contains raw results)\n    \n  \n\n\nYou can modify the text of the events by for example using datadog’s @mention to notify people of these reports.\n\n\n\nThis documentation verified on October 28, 2015 using the Splunk Enterprise AMI on AWS\n","tags":"","loc":"/integrations/splunk/"},{"title":"Datadog-SQL Server Integration","text":"\n\nOverview\n\nConnect SQL Server to Datadog in order to:\n\n\n  Visualize your database performance.\n  Correlate the performance of SQL Server with the rest of your applications.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nSQL Server YAML example\nSQL Server checks.d\n\n\n\nMetrics\n\n\n\n\nsqlserver.buffer.cache_hit_ratio(gauge)\nThe ratio of data pages found and read from the buffer cache over all data page requests.shown as fraction\n\n\n\n\nsqlserver.buffer.page_life_expectancy(gauge)\nDuration that a page resides in the buffer pool.shown as second\n\n\n\n\nsqlserver.stats.batch_requests(gauge)\nThe number of batch requests per second.shown as request/second\n\n\n\n\nsqlserver.stats.sql_compilations(gauge)\nThe number of SQL compilations per second.shown as operation/second\n\n\n\n\nsqlserver.stats.sql_recompilations(gauge)\nThe number of SQL re-compilations per second.shown as operation/second\n\n\n\n\nsqlserver.stats.connections(gauge)\nThe number of user connections.shown as connection\n\n\n\n\nsqlserver.stats.lock_waits(gauge)\nThe number of times per second that SQL Server is unable to retain a lock right away for a resource.shown as lock/second\n\n\n\n\nsqlserver.access.page_splits(gauge)\nThe number of page splits per second.shown as operation/second\n\n\n\n\nsqlserver.stats.procs_blocked(gauge)\nThe number of processes blocked.shown as process\n\n\n\n\nsqlserver.buffer.checkpoint_pages(gauge)\nThe number of pages flushed to disk per second by a checkpoint or other operation that require all dirty pages to be flushed.shown as page/second\n\n\n\n\n","tags":"","loc":"/integrations/sqlserver/"},{"title":"Datadog-ssh Integration","text":"\nCapture SSH activity into Datadog to:\n\n\n  Visualize your SSH performance in real-time\n  Detect any protocol failure or network outage\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nssh YAML example\nssh checks.d\n\n\n\nMetrics\n\n\n\nsftp.response_time(gauge)\nThe response time of SFTPshown as second\n\n\n","tags":"","loc":"/integrations/ssh/"},{"title":"Datadog-StatsD","text":"\n\nOverview\n\nThis Agent check monitors the availability and uptime of non-Datadog StatsD servers. It also tracks the rate StatsD servers are receiving metrics.\n\nThis check does NOT forward application metrics from StatsD servers to Datadog.\n\n\nConfiguration\n\nTo configure the Agent to connect to StatsD, edit /etc/dd-agent/conf.d/statsd.yaml.\nAn example configuration can be found at statsd.yaml.example.\n\ninit_config:\n\ninstances:\n  - host: localhost\n    port: 8126\n\n\nHOST: Set the host name or ip address of the StatsD server being monitored.\n\nPORT: The admin port of the StatsD server being monitored.\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nStatsD YAML example\nStatsD checks.d\n\n\n\nValidation\n\nExecute the info command (/etc/init.d/datadog-agent info on *NIX) and verify that the integration check was successful.\n","tags":"","loc":"/integrations/statsd/"},{"title":"Datadog-StatusPage.io Integration","text":"\n\nOverview\n\nCapture incidents from the StatusPage of your third-party services to correlate incidents with your own metrics and events. This integration does not require having your own StatusPage.io account.\n\n\nConfiguration\n\nAfter you activate the integration tile, enter the StatusPage.io page for whichever service you want to monitor. For instance, the PagerDuty status page can be found at https://status.pagerduty.com. Enter any custom tags you wish to associate with the page and click on Update Configuration.\n\n","tags":"","loc":"/integrations/statuspage/"},{"title":"Datadog-Sumo Logic Integration","text":"\n\nOverview\n\nDatadog integrates with Sumo Logic in two ways: you can forward Sumo Logic log data to your Datadog event stream, and you can use Sumo Logic as a notification channel from Datadog alerts and events. In other words, each service can inform the other.\n\n\nInstallation\n\n\nDatadog to Sumo Logic\n\n\n  Login to Sumo Logic as a user with Administrator rights.\n  From the main menu, choose Manage -> Collection.\n  Click the Add Collector link at the top left. \n\n  Choose Hosted Collector.\n  Enter a Name and optionally a description, category, and time zone. Click Save.\n  Click HTTP under Cloud APIs. Fill in the form as appropriate for the collector. Click Save.\n  Copy the URL given on the next dialog. You will need this again soon.\n  Go to the Sumo Logic Integration settings screen in Datadog.\n  Enter the name you want to assign to the collector and the URL from above.\n  Next time you want to send a message from Datadog to Sumo Logic, use @sumologic-{YOUR COLLECTOR NAME}.\n\n\n\nSumo Logic to Datadog\n\n\n  Login to Sumo Logic as a user with Administrator rights.\n  From the main menu, choose Manage -> Connections.\n  Click the Add button.\n  Click the Datadog button. \n\n  \n    Give the connection a Name and optionally a Description. For the URL, enter:\n\n     https://app.datadoghq.com/api/v1/events?api_key=YOUR_API_KEY\n\n  \n  Customize the payload as needed. Click the Help link to learn about the available variables.\n  Click Test Connection. You should see a new item in your Event Stream similar to this: \n\n  If everything looks good, click Save.\n  In Sumo Logic, save any search and choose to schedule the search.\n  Choose Webhook for the Alert Type. Choose your new Datadog Connection from the list of webhooks. Optionally customize the Payload. You will probably want to change the Alert Condition to send a notification only if the number of results is greater than 0. \n\n\n\n","tags":"","loc":"/integrations/sumologic/"},{"title":"Datadog-Supervisor Integration","text":"\n\nOverview\n\n\n\nEnable the supervisord check to monitor the states of your processes running under supervisord.\n\nFor more about using the Supervisor integration, read the post on our blog.\n\n\nInstallation\n\nThere are two ways to get started with the supervisord check.\n\nYou can configure inet_http_server in /etc/supervisord.conf. Below is an example inet_http_server configuration:\n\n[inet_http_server]\nport:localhost:9001\nusername:user  # optional\npassword:pass  # optional\n\n\nOR, you can use supervisorctl socket to communicate with supervisor. If supervisor is running as root, make sure chmod property is set to a permission accessible to non-root users. See the example below:\n\n[supervisorctl]\nserverurl=unix:///var/run//supervisor.sock\n\n[unix_http_server]\nfile=/var/run/supervisor.sock\nchmod=777\n\n\nReload supervisor and specify the inet or unix socket server information\nin the supervisord.yaml file along with an optional list of the processes you want\nto monitor per instance.\n\nSee the supervisor configuration docsfor more information on configuring supervisord sockets and inet http servers.\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to the supervisor daemon. Edit conf.d/supervisord.yaml:\n\n    init_config:\n\ninstances:\n  - name: server0   \n    host: localhost  \n    port: 9001\n  - name: server1\n    host: localhost\n    port: 9002\n  - name: server2\n    socket: unix:///var/run//supervisor.sock\n    host: http://127.0.0.1 \n\n  \n  \n    Restart the Agent\n  \n\n\n\nConfiguration Options\n\n\n  \nname (Required) - An arbitrary name to identify the supervisord server.\n  \nhost (Optional) - Defaults to localhost. The host where supervisord server is running.\n  \nport (Optional) - Defaults to 9001. The port number.\n  \nuser (Optional) - Username\n  \npass (Optional) - Password\n  \nproc_names (Optional) - Dictionary of process names to monitor\n  \nserver_check (Optional) - Defaults to true. Service check for connection to supervisord server.\n  \nsocket (Optional) - If using supervisorctl to communicate with supervisor, a socket is needed.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nSupervisor YAML example\nSupervisor checks.d\n\n\n\nValidation\n\nExecute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  supervisord\n  -----------\n      - instance #0 [OK]\n      - Collected 2 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\nsupervisord.process.count(gauge)\nThe number of supervisord monitored processesshown as process\n\n\n\n\nsupervisord.process.uptime(gauge)\nThe process uptimeshown as second\n\n\n\n","tags":"","loc":"/integrations/supervisor/"},{"title":"System Check","text":"\n\nOverview\n\nGet metrics from your base system about the CPU, IO, load, memory, processes, swap, and uptime. Other system-related checks can be found here:\n\n\n  \nDirectory Check - Capture metrics from the files in given directories.\n  \nDisk Check - Capture metrics about the disk\n  \nProcess check - Capture metrics from specific running processes on a system.\n\n\n\nConfiguration\n\nNo configuration is necessary for the system.\n\n\nMetrics\n\n\n\n\nsystem.cpu.guest(gauge)\nThe percent of time the CPU spent running the virtual processor. Only applies to hypervisors.shown as percent\n\n\n\n\nsystem.cpu.idle(gauge)\nPercent of time the CPU spent in an idle state.shown as percent\n\n\n\n\nsystem.cpu.interrupt(gauge)\nThe percentage of time that the processor is spending on handling Interrupts.shown as percent\n\n\n\n\nsystem.cpu.iowait(gauge)\nThe percent of time the CPU spent waiting for IO operations to complete.shown as percent\n\n\n\n\nsystem.cpu.stolen(gauge)\nThe percent of time the virtual CPU spent waiting for the hypervisor to service another virtual CPU. Only applies to virtual machines.shown as percent\n\n\n\n\nsystem.cpu.system(gauge)\nThe percent of time the CPU spent running the kernel.shown as percent\n\n\n\n\nsystem.cpu.user(gauge)\nThe percent of time the CPU spent running user space processes.shown as percent\n\n\n\n\nsystem.io.avg_q_sz(gauge)\nThe average queue size of requests issued to the device.shown as request\n\n\n\n\nsystem.io.avg_rq_sz(gauge)\nThe average size of requests issued to the device.shown as sector\n\n\n\n\nsystem.io.await(gauge)\nThe average time for I/O requests issued to the device to be served. This includes the time spent by the requests in queue and the time spent servicing them.shown as millisecond\n\n\n\n\nsystem.io.bytes_per_s(gauge)\nByte transfer rate for this device.shown as byte/second\n\n\n\n\nsystem.io.r_await(gauge)\nThe average time for read requests issued to the device to be served. This includes the time spent by the requests in queue and the time spent servicing them.shown as millisecond\n\n\n\n\nsystem.io.r_s(gauge)\nThe number of read requests issued to the device per second.shown as request/second\n\n\n\n\nsystem.io.rkb_s(gauge)\nThe number of kibibytes read from the device per second.shown as kibibyte/second\n\n\n\n\nsystem.io.rrqm_s(gauge)\nThe number of read requests merged per second that were queued to the device.shown as request/second\n\n\n\n\nsystem.io.svctm(gauge)\nThe average service time for requests issued to the device.shown as millisecond\n\n\n\n\nsystem.io.util(gauge)\nThe percent of CPU time during which I/O requests were issued to the deviceshown as percent\n\n\n\n\nsystem.io.w_await(gauge)\nThe average time for write requests issued to the device to be served. This includes the time spent by the requests in queue and the time spent servicing them.shown as millisecond\n\n\n\n\nsystem.io.w_s(gauge)\nThe number of write requests issued to the device per second.shown as request/second\n\n\n\n\nsystem.io.wkb_s(gauge)\nThe number of kibibytes written to the device per second.shown as kibibyte/second\n\n\n\n\nsystem.io.wrqm_s(gauge)\nThe number of write requests merged per second that were queued to the device.shown as request/second\n\n\n\n\nsystem.load.1(gauge)\nThe average system load over one minute.\n\n\n\n\nsystem.load.15(gauge)\nThe average system load over fifteen minutes.\n\n\n\n\nsystem.load.5(gauge)\nThe average system load over five minutes.\n\n\n\n\nsystem.load.norm.1(gauge)\nThe average system load over one minute normalized by the number of CPUs.\n\n\n\n\nsystem.load.norm.15(gauge)\nThe average system load over fifteen minutes normalized by the number of CPUs.\n\n\n\n\nsystem.load.norm.5(gauge)\nThe average system load over five minutes normalized by the number of CPUs.\n\n\n\n\nsystem.mem.buffered(gauge)\nThe amount of physical RAM used for file buffers.shown as byte\n\n\n\n\nsystem.mem.cached(gauge)\nThe amount of physical RAM used as cache memory.shown as byte\n\n\n\n\nsystem.mem.committed(gauge)\nThe amount of physical memory for which space has been reserved on the disk paging file in case it must be written back to disk.shown as byte\n\n\n\n\nsystem.mem.free(gauge)\nThe amount of free RAM.shown as byte\n\n\n\n\nsystem.mem.nonpaged(gauge)\nThe amount of physical memory used by the OS for objects that cannot be written to disk, but must remain in physical memory as long as they are allocated.shown as byte\n\n\n\n\nsystem.mem.page_free(gauge)\nThe amount of the page file that's free.shown as byte\n\n\n\n\nsystem.mem.page_pct_free(gauge)\nThe amount of the page file in use as a fraction of the total.shown as fraction\n\n\n\n\nsystem.mem.page_tables(gauge)\nThe amount of memory dedicated to the lowest page table level.shown as byte\n\n\n\n\nsystem.mem.page_total(gauge)\nThe total size of the page fileshown as byte\n\n\n\n\nsystem.mem.page_used(gauge)\nThe amount of the page file in use.shown as byte\n\n\n\n\nsystem.mem.paged(gauge)\nThe amount of physical memory used by the OS for objects that can be written to disk when they are not in use.shown as byte\n\n\n\n\nsystem.mem.pct_usable(gauge)\nThe amount of usable physical RAM as a fraction of the total.shown as fraction\n\n\n\n\nsystem.mem.shared(gauge)\nThe amount of physical RAM used as shared memory.shown as byte\n\n\n\n\nsystem.mem.slab(gauge)\nThe amount of memory used by the kernel to cache data structures for its own use.shown as byte\n\n\n\n\nsystem.mem.total(gauge)\nThe total amount of physical RAM.shown as byte\n\n\n\n\nsystem.mem.usable(gauge)\nThe sum of free, buffered, and cached physical RAM.shown as byte\n\n\n\n\nsystem.mem.used(gauge)\nThe amount of RAM in use.shown as byte\n\n\n\n\nsystem.proc.count(gauge)\nThe number of processes.shown as process\n\n\n\n\nsystem.proc.queue_length(gauge)\nThe number of threads that are observed as delayed in the processor ready queue and are waiting to be executed.shown as thread\n\n\n\n\nsystem.processes.cpu.pct(gauge)\nThe process CPU utilization.shown as percent\n\n\n\n\nsystem.processes.involuntary_ctx_switches(gauge)\nThe number of involuntary context switches performed by this process.shown as event\n\n\n\n\nsystem.processes.ioread_bytes(gauge)\nThe number of bytes read from disk by this process.shown as byte\n\n\n\n\nsystem.processes.ioread_count(gauge)\nThe number of disk reads by this process.shown as read\n\n\n\n\nsystem.processes.iowrite_bytes(gauge)\nThe number of bytes written to disk by this process.shown as byte\n\n\n\n\nsystem.processes.iowrite_count(gauge)\nThe number of disk writes by this process.shown as write\n\n\n\n\nsystem.processes.mem.page_faults.minor_faults(gauge)\nThe number of minor page faults per second for this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.page_faults.children_minor_faults(gauge)\nThe number of minor page faults per second for children of this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.page_faults.major_faults(gauge)\nThe number of major page faults per second for this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.page_faults.children_major_faults(gauge)\nThe number of major page faults per second for children of this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.pct(gauge)\nThe process memory consumption.shown as percent\n\n\n\n\nsystem.processes.mem.real(gauge)\nThe non-swapped physical memory a process has used and cannot be shared with another process.shown as byte\n\n\n\n\nsystem.processes.mem.rss(gauge)\nThe non-swapped physical memory a process has used. aka \"Resident Set Size\".shown as byte\n\n\n\n\nsystem.processes.mem.vms(gauge)\nThe total amount of virtual memory used by the process. aka \"Virtual Memory Size\".shown as byte\n\n\n\n\nsystem.processes.number(gauge)\nThe number of processes.shown as process\n\n\n\n\nsystem.processes.open_file_descriptors(gauge)\nThe number of file descriptors used by this process.\n\n\n\n\nsystem.processes.open_handles(gauge)\nThe number of handles used by this process.\n\n\n\n\nsystem.processes.threads(gauge)\nThe number of threads used by this process.shown as thread\n\n\n\n\nsystem.processes.voluntary_ctx_switches(gauge)\nThe number of voluntary context switches performed by this process.shown as event\n\n\n\n\nsystem.processes.cpu.pct(gauge)\nThe process CPU utilization.shown as percent\n\n\n\n\nsystem.processes.involuntary_ctx_switches(gauge)\nThe number of involuntary context switches performed by this process.shown as event\n\n\n\n\nsystem.processes.ioread_bytes(gauge)\nThe number of bytes read from disk by this process.shown as byte\n\n\n\n\nsystem.processes.ioread_count(gauge)\nThe number of disk reads by this process.shown as read\n\n\n\n\nsystem.processes.iowrite_bytes(gauge)\nThe number of bytes written to disk by this process.shown as byte\n\n\n\n\nsystem.processes.iowrite_count(gauge)\nThe number of disk writes by this process.shown as write\n\n\n\n\nsystem.processes.mem.page_faults.minor_faults(gauge)\nThe number of minor page faults per second for this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.page_faults.children_minor_faults(gauge)\nThe number of minor page faults per second for children of this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.page_faults.major_faults(gauge)\nThe number of major page faults per second for this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.page_faults.children_major_faults(gauge)\nThe number of major page faults per second for children of this process.shown as occurrence/second\n\n\n\n\nsystem.processes.mem.pct(gauge)\nThe process memory consumption.shown as percent\n\n\n\n\nsystem.processes.mem.real(gauge)\nThe non-swapped physical memory a process has used and cannot be shared with another process.shown as byte\n\n\n\n\nsystem.processes.mem.rss(gauge)\nThe non-swapped physical memory a process has used. aka \"Resident Set Size\".shown as byte\n\n\n\n\nsystem.processes.mem.vms(gauge)\nThe total amount of virtual memory used by the process. aka \"Virtual Memory Size\".shown as byte\n\n\n\n\nsystem.processes.number(gauge)\nThe number of processes.shown as process\n\n\n\n\nsystem.processes.open_file_descriptors(gauge)\nThe number of file descriptors used by this process.\n\n\n\n\nsystem.processes.open_handles(gauge)\nThe number of handles used by this process.\n\n\n\n\nsystem.processes.threads(gauge)\nThe number of threads used by this process.shown as thread\n\n\n\n\nsystem.processes.voluntary_ctx_switches(gauge)\nThe number of voluntary context switches performed by this process.shown as event\n\n\n\n\nsystem.swap.cached(gauge)\nThe amount of swap used as cache memory.shown as byte\n\n\n\n\nsystem.swap.free(gauge)\nThe amount of free swap space.shown as byte\n\n\n\n\nsystem.swap.pct_free(gauge)\nThe amount of swap space in use as a fraction of the total.shown as fraction\n\n\n\n\nsystem.swap.total(gauge)\nThe total amount of swap space.shown as byte\n\n\n\n\nsystem.swap.used(gauge)\nThe amount of swap space in use.shown as byte\n\n\n\n\nsystem.uptime(gauge)\nThe amount of time the system has been working and available.shown as second\n\n\n\n","tags":"","loc":"/integrations/system/"},{"title":"Datadog-System Core Integration","text":"\n\nOverview\n\n\n\nThe System Core integration collects information about the host’s CPU Cores. \n\n\nInstallation\n\nNo installation steps are required for this integration.\n\n\nConfiguration\n\nThe only configuration step for this integration is to copy system_core.yaml.example to system_core.yaml.\n\n\nValidation\n\nTo validate your installation and configuration, restart the agent and execute the info command. The output should contain a section similar to the following:\n\nChecks\n======\n  [...]\n  system_core                                                              \n  -----------                                                              \n    - instance #0 [OK]                                                     \n    - Collected 33 metrics, 0 events & 1 service check                     \n\n\n\nMetrics\n\nFor each core the following metrics are collected:\n\n\n  system.core.count\n  system.core.system\n  system.core.user\n  system.core.idle\n  system.core.nice\n\n\n\nEvents\n\nNo events are included with this integration.\n\n","tags":"","loc":"/integrations/systemcore/"},{"title":"TCP check","text":"\n\nOverview\n\n\n\nTCP checks run in the agent and can verify whether or not a TCP service is up or down and responds in a certain time.\n\nAlso see the related HTTP Checks.\n\n\nInstallation\n\nNo installation is required\n\n\nConfiguration\n\nEdit the tcp_check.yaml file in your agent’s conf.d directory. The following yaml file will check both ports 22 and 443 on 192.168.22.1 with timeouts of 10 seconds. The response time will be available in the metric network.tcp.response_time.\n\ninit_config:\n\ninstances:\n  - name: SSH on Server\n    host: 192.168.22.1\n    port: 22\n    timeout: 10\n    collect_response_time: true\n    skip_event: true\n    tags:\n      - demo:matt\n\n  - name: 443 on Server\n    host: 192.168.22.1\n    port: 443\n    timeout: 10\n    skip_event: true\n    collect_response_time: true\n    tags:\n      - demo:matt\n\n\n\nConfiguration Options\n\n\n  \nname (Required) - Name of the service. This will be included as a tag: instance:<name>.\n  \nhost (Required) - Host to be checked. This will be included as a tag: url:<host>:<port>.\n  \nport (Required) - Port to be checked. This will be included as a tag: url:<host>:<port>.\n  \ntimeout (Optional) - Timeout for the check. Defaults to 10 seconds.\n  \nthreshold (Optional) - Used in conjunction with window. An alert will trigger if the check fails <threshold> times in <window> attempts.\n  \nwindow (Optional) - Refer to ‘threshold’.\n  \ncollect_response_time (Optional) - Defaults to false. If this is not set to true, no response time metric will be collected. If it is set to true, the metric returned is network.tcp.response_time.\n  \nskip_event (Optional) - Defaults to false. Set to true to skip creating an event. This option will be removed in a future version and will default to true.\n  \ntags (Optional) - Tags to be assigned to the metric.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nTCP Check YAML example\nTCP Check checks.d\n\n\n\nValidation\n\nExecute the agent info command and verify that the integration check was successful. The output should contain a section similar to the following:\n\nChecks\n======\n\n  tcp_check\n  ---------\n    - instance #0 [OK]\n    - instance #1 [OK]\n    - Collected 2 metrics, 0 events & 3 service checks\n\n","tags":"","loc":"/integrations/tcpcheck/"},{"title":"TCP RTT check","text":"\n\nOverview\n\nThe TCP RTT check reports on roundtrip times between the host the agent is running on and any host it is communicating with. This check is passive and will only report RTT times for packets being sent and received from outside the check. The check itself will not send any packets.\n\nThis check is only shipped in the 64-bit DEB and RPM Datadog Agent packages.\n\n\nInstallation\n\nThe check uses timestamps provided by the PCAP library to compute the time between any outgoing packet and the corresponding TCP acknowledgement. As such, PCAP must be installed and configured.\n\nDebian-based systems should use one of the following:\n\n$ sudo apt-get install libcap\n$ sudo apt-get install libcap2-bin\n\n\nRedhat-based systems should use one of these:\n\n$ sudo yum install libcap\n$ sudo yum install compat-libcap1\n\n\nFinally, configure PCAP:\n\n$ sudo setcap cap_net_raw+ep /opt/datadog-agent/bin/go-metro\n\n\n\nConfiguration\n\nEdit the go-metro.yaml file in your agent’s conf.d directory. The following is an example file that will show the TCP RTT times for app.datadoghq.com and 192.168.0.22:\n\ninit_config:\n  snaplen: 512\n  idle_ttl: 300\n  exp_ttl: 60\n  statsd_ip: 127.0.0.1\n  statsd_port: 8125\n  log_to_file: true\n  log_level: info\n\ninstances:\n  - interface: eth0\n    tags:\n      - env:prod\n    ips:\n      - 45.33.125.153\n    hosts:\n      - app.datadoghq.com\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\nTCP RTT Check YAML example\n\n\nValidation\n\nTo validate that the check is running correctly, you should see system.net.tcp.rtt metrics showing in the Datadog interface. Also, if you run sudo /etc/init.d/datadog-agent status, you should see something similar to the following:\n\n● datadog-agent.service - \"Datadog Agent\"\n   Loaded: loaded (/lib/...datadog-agent.service; enabled; vendor preset: enabled)\n   Active: active (running) since Thu 2016-03-31 20:35:27 UTC; 42min ago\n  Process: 10016 ExecStop=/opt/.../supervisorctl -c /etc/dd-....conf shutdown (code=exited, status=0/SUCCESS)\n  Process: 10021 ExecStart=/opt/.../start_agent.sh (code=exited, status=0/SUCCESS)\n Main PID: 10025 (supervisord)\n   CGroup: /system.slice/datadog-agent.service\n           ├─10025 /opt/datadog-...python /opt/datadog-agent/bin/supervisord -c /etc/dd-agent/supervisor.conf\n           ├─10043 /opt/datadog-...python /opt/datadog-agent/agent/dogstatsd.py --use-local-forwarder\n           ├─10044 /opt/datadog-agent/bin/go-metro -cfg=/etc/dd-agent/conf.d/go-metro.yaml\n           ├─10046 /opt/datadog-.../python /opt/datadog-agent/agent/ddagent.py\n           └─10047 /opt/datadog-.../python /opt/datadog-agent/agent/agent.py foreground --use-local-forwarder\n\n\nIf the TCP RTT check has started you should see something similar to the go-metro line above.\n\nThis is a passive check, so unless there are packets actively being sent to the hosts mentioned in the yaml file, the metrics will not be reported.\n\n\nMetrics\n\n\n\n\nsystem.net.tcp.rtt(gauge every 10 seconds)\nThe TCP round trip time.shown as millisecond\n\n\n\n\nsystem.net.tcp.rtt.avg(gauge every 10 seconds)\nThe average TCP round trip time as typically computed by the TCP stack.shown as millisecond\n\n\n\n\nsystem.net.tcp.rtt.jitter(gauge every 10 seconds)\nThe TCP round trip time jitter.shown as millisecond\n\n\n\n","tags":"","loc":"/integrations/tcprtt/"},{"title":"Datadog-TeamCity Integration","text":"\n\nOverview\n\nConnect TeamCity to Datadog to create events for each build in order to:\n\n\n  Monitor the status of your builds and deployments\n  Collect stats and bind tags to every step of your builds.\n\n\n\nInstallation\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to TeamCity\n\n     init_config:\n\n # Add your different projects in here to monitor their build\n # success with Datadog events\n instances:\n     # A custom unique name per build configuration that will show\n     # in the events\n   - name: My Website\n\n     # Specify the server name of your teamcity instance here\n     # Guest authentication must be on if you want the check to be able to get data\n     # When using the optional basic_http_authentication use\n     # server: user:password@teamcity.mycompany.com\n     server: teamcity.mycompany.com\n\n     # This is the internal build ID of the build configuration you wish to track.\n     # You can find it labelled as \"Build configuration ID\" when editing the configuration in question.\n     build_configuration: MyWebsite_Deploy\n\n     # Optional, this turns on basic http authentication. Defaults to False.\n     # basic_http_authentication: true\n\n     # Optional, if you wish to override the host that is affected by this build configuration.\n     # Defaults to the host that the agent is running on.\n     # host_affected: msicalweb6\n\n     # Optional, this changes the event message slightly to specify that TeamCity was used to deploy something\n     # rather than just that a successful build happened\n     # is_deployment: true\n\n     # Optional, this turns off ssl certificate validation. Defaults to True.\n     # ssl_validation: false\n\n     # Optional, any additional tags you'd like to add to the event\n     # tags:\n     #   - test\n\n  \n  \n    Restart the Agent\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nTeamCity YAML example\nTeamCity checks.d\n\n\n\nValidation\n\nExecute the datadog info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  teamcity\n  --------\n      - instance #0 [OK]\n      - Collected 0 metrics & 1 events\n\n\n\nMetrics\n\nThis integration only create events. It will not return any metrics.\n","tags":"","loc":"/integrations/teamcity/"},{"title":"Datadog-TokuMX Integration","text":"\n\nOverview\n\nCapture TokuMX metrics in Datadog to:\n\n\n  Visualize key TokuMX metrics.\n  Correlate TokuMX performance with the rest of your applications.\n\n\n\nInstallation\n\n\n  \n    Install the Python MongoDB module on your MongoDB server using the following command:\n\n    sudo pip install --upgrade \"pymongo<3.0\"\n\n  \n  \n    You can verify that the module is installed using this command:\n\n    python -c \"import pymongo\" 2>&1 | grep ImportError && \\\necho -e \"\\033[0;31mpymongo python module - Missing\\033[0m\" || \\\necho -e \"\\033[0;32mpymongo python module - OK\\033[0m\"\n\n  \n  Start the mongo shell.\n  \n    Create a read-only admin user for datadog using the following command. Make sure you replace <UNIQUEPASSWORD> with a unique password for the user. Datadog needs admin rights to collect complete server statistics.\n\n    use admin\ndb.auth(\"admin\", \"admin-password\")\ndb.addUser(\"datadog\", \"<UNIQUEPASSWORD>\", true)\n\n  \n  \n    Verify that you created the user with the following command (not in the mongo shell).\n\n    python -c 'from pymongo import Connection; print Connection().admin.authenticate(\"datadog\", \"<UNIQUEPASSWORD>\")' | \\\ngrep True && \\\necho -e \"\\033[0;32mdatadog user - OK\\033[0m\" || \\\necho -e \"\\033[0;31mdatadog user - Missing\\033[0m\"\n\n  \n\n\nFor more details about creating and managing users in MongoDB, refer to the MongoDB documentation.\n\n\nConfiguration\n\nConfigure the Agent to connect to your TokuMX instance using your new Datadog user.\n\n\n  \n    Edit the tokumx.yaml file in your Agent’s conf.d directory:\n\n    init_config:\n\n# Specify the MongoDB URI, with database to use for reporting (defaults to \"admin\")\n# E.g. mongodb://datadog:LnCbkX4uhpuLHSUrcayEoAZA@localhost:27017/my-db\ninstances:\n      -   server: mongodb://datadog:<UNIQUEPASSWORD>@localhost:27017\n          tags:\n              - mytag1\n              - mytag2\n      -   server: mongodb://datadog:<UNIQUEPASSWORD>@localhost:27017\n          tags:\n              - mytag1\n              - mytag2\n\n  \n  \n    Restart the Agent.\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nTokuMX YAML example\nTokuMX checks.d\n\n\n\nValidation\n\n\n  \n    To validate that your integration is working run the Agent’s info command. You should see output similar to the following:\n\n    Checks\n======\n\n  [...]\n\n  tokumx\n  ------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n  \n\n\n\nMetrics\n\n\n\n\ntokumx.asserts.msgps(gauge)\nThe number of message assertions raised per second.shown as assertion/second\n\n\n\n\ntokumx.asserts.regularps(gauge)\nThe number of regular assertions raised per second.shown as assertion/second\n\n\n\n\ntokumx.asserts.rolloversps(gauge)\nThe number of times that the rollover counters roll over per second. The counters rollover to zero every 2 to the 30 assertions.shown as assertion/second\n\n\n\n\ntokumx.asserts.userps(gauge)\nThe number of user assertions raised per second.shown as assertion/second\n\n\n\n\ntokumx.asserts.warningps(gauge)\nThe number of warnings raised per second.shown as assertion/second\n\n\n\n\ntokumx.connections.available(gauge)\nThe number of unused available incoming connections the database can provide.shown as connection\n\n\n\n\ntokumx.connections.current(gauge)\nThe number of connections to the database server from clients.shown as connection\n\n\n\n\ntokumx.cursors.timedOut(gauge)\nThe total number of cursors that have timed out since the server process started.shown as cursor\n\n\n\n\ntokumx.cursors.totalOpen(gauge)\nThe number of cursors that tokumx is maintaining for clients.shown as cursor\n\n\n\n\ntokumx.ft.alerts.checkpointFailures(gauge)\nThe number of checkpoints that have failed for any reason.shown as event\n\n\n\n\ntokumx.ft.alerts.locktreeRequestsPending(gauge)\nThe number of requests for Document-level Locks in the locktree that are waiting for other requests to release their locks.shown as request\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.cachePressure.countps(gauge)\nRate at which a thread had to wait more than 1 second for evictions to create space in the cachetable for it to page in data it needed.shown as event/second\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.cachePressure.timeps(gauge)\nFraction of time (microseconds/second) that a thread had to wait more than 1 second for evictions to create space in the cachetable for it to page in data it needed.shown as fraction\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.checkpointBegin.countps(gauge)\nRate at which the begin checkpoint phase of checkpoint has run (these should be fairly quick).shown as event/second\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.checkpointBegin.timeps(gauge)\nFraction of time (microseconds/second) that a begin checkpoint phase has spent blocking other threads.shown as fraction\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.fsync.countps(gauge)\nRate at which fsync operations took more than 1 second.shown as event/second\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.fsync.timeps(gauge)\nFraction of time (microseconds/second) spent performing fsync operations that took longer than 1 second.shown as fraction\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.locktreeWait.countps(gauge)\nRate at which a thread had to wait more than 1 second to acquire a document-level lock in the locktree.shown as event/second\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.locktreeWait.timeps(gauge)\nFraction of time (microseconds/second) spent by threads waiting more than 1 second to acquire a document-level lock in the locktree.shown as fraction\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.locktreeWaitEscalation.countps(gauge)\nRate at which a thread had to wait more than 1 second to acquire a document-level lock because the locktree was at the memory limit and needed to run escalation.shown as event/second\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.locktreeWaitEscalation.timeps(gauge)\nFraction of time (microseconds/second) spent by threads waiting more than 1 second to acquire a document-level lock because the locktree was at the memory limit and needed to run escalation.shown as fraction\n\n\n\n\ntokumx.ft.alerts.longWaitEvents.logBufferWaitps(gauge)\nRate at which a writing client had to wait more than 100ms for access to the log buffer.shown as event/second\n\n\n\n\ntokumx.ft.cachetable.evictions.full.leaf.clean.bytesps(gauge)\nRate of full evictions of leaf nodes.shown as byte/second\n\n\n\n\ntokumx.ft.cachetable.evictions.full.leaf.clean.countps(gauge)\nRate of full evictions of leaf nodes.shown as event/second\n\n\n\n\ntokumx.ft.cachetable.evictions.full.leaf.dirty.bytesps(gauge)\nRate of full evictions of leaf nodes that need to be written back to disk.shown as byte/second\n\n\n\n\ntokumx.ft.cachetable.evictions.full.leaf.dirty.countps(gauge)\nRate of full evictions of leaf nodes that need to be written back to disk.shown as event/second\n\n\n\n\ntokumx.ft.cachetable.evictions.full.leaf.dirty.timeps(gauge)\nFraction of time (microseconds/second) spent performing full evictions leaf nodes, including the time spent serializing, compressing, and writing those nodes to disk.shown as fraction\n\n\n\n\ntokumx.ft.cachetable.evictions.full.nonleaf.clean.bytesps(gauge)\nRate of full evictions of nonleaf nodes.shown as byte/second\n\n\n\n\ntokumx.ft.cachetable.evictions.full.nonleaf.clean.countps(gauge)\nRate of full evictions of nonleaf nodes.shown as event/second\n\n\n\n\ntokumx.ft.cachetable.evictions.full.nonleaf.dirty.bytesps(gauge)\nRate of full evictions of nonleaf nodes that need to be written back to disk.shown as byte/second\n\n\n\n\ntokumx.ft.cachetable.evictions.full.nonleaf.dirty.countps(gauge)\nRate of full evictions of nonleaf nodes that need to be written back to disk.shown as event/second\n\n\n\n\ntokumx.ft.cachetable.evictions.full.nonleaf.dirty.timeps(gauge)\nFraction of time (microseconds/second) spent performing full evictions nonleaf nodes, including the time spent serializing, compressing, and writing those nodes to disk.shown as fraction\n\n\n\n\ntokumx.ft.cachetable.evictions.partial.leaf.clean.bytesps(gauge)\nRate of partial evictions of leaf nodes.shown as byte/second\n\n\n\n\ntokumx.ft.cachetable.evictions.partial.leaf.clean.countps(gauge)\nRate of partial evictions of leaf nodes.shown as event/second\n\n\n\n\ntokumx.ft.cachetable.evictions.partial.nonleaf.clean.bytesps(gauge)\nRate of partial evictions of nonleaf nodes.shown as byte/second\n\n\n\n\ntokumx.ft.cachetable.evictions.partial.nonleaf.clean.countps(gauge)\nRate of partial evictions of nonleaf nodes.shown as event/second\n\n\n\n\ntokumx.ft.cachetable.miss.countps(gauge)\nRate of internal cache misses. This metric is similar to MongoDB’s btree misses and page faults.shown as miss/second\n\n\n\n\ntokumx.ft.cachetable.miss.full.countps(gauge)\nRate of full internal cache misses.shown as miss/second\n\n\n\n\ntokumx.ft.cachetable.miss.full.timeps(gauge)\nFraction of time (microseconds/second) the database has had to wait for a disk read to complete for a full cache miss.shown as fraction\n\n\n\n\ntokumx.ft.cachetable.miss.partial.countps(gauge)\nRate of partial internal cache misses.shown as miss/second\n\n\n\n\ntokumx.ft.cachetable.miss.partial.timeps(gauge)\nFraction of time (microseconds/second) the database has had to wait for a disk read to complete for a partial cache miss.shown as fraction\n\n\n\n\ntokumx.ft.cachetable.miss.timeps(gauge)\nFraction of time (microseconds/second) the database has had to wait for a disk read to complete for cache misses.shown as fraction\n\n\n\n\ntokumx.ft.cachetable.size.current(gauge)\nTotal amount of uncompressed data currently in the database's internal cache.shown as byte\n\n\n\n\ntokumx.ft.cachetable.size.limit(gauge)\nTotal amount of uncompressed data that will fit in TokuMX’s internal cache.shown as byte\n\n\n\n\ntokumx.ft.cachetable.size.writing(gauge)\nTotal size of nodes that are currently queued up to be written to disk for eviction.shown as byte\n\n\n\n\ntokumx.ft.checkpoint.begin.timeps(gauge)\nFraction of time (microseconds/second) that a begin checkpoint phase has spent blocking other threads.shown as fraction\n\n\n\n\ntokumx.ft.checkpoint.countps(gauge)\nRate at which checkpoints are completed.shown as event/second\n\n\n\n\ntokumx.ft.checkpoint.lastComplete.time(gauge)\nThe time spent, in seconds, by the most recently completed checkpoint.shown as second\n\n\n\n\ntokumx.ft.checkpoint.timeps(gauge)\nFraction of time (seconds/second) spent doing checkpoints.shown as fraction\n\n\n\n\ntokumx.ft.checkpoint.write.leaf.bytes.compressedps(gauge)\nThe rate at which leaf nodes are written to disk during checkpoints, after compression.shown as byte/second\n\n\n\n\ntokumx.ft.checkpoint.write.leaf.bytes.uncompressedps(gauge)\nThe rate at which leaf nodes are written to disk during checkpoints, before compression.shown as byte/second\n\n\n\n\ntokumx.ft.checkpoint.write.leaf.countps(gauge)\nThe rate at which leaf nodes are written to disk during checkpoints.shown as write/second\n\n\n\n\ntokumx.ft.checkpoint.write.leaf.timeps(gauge)\nThe fraction of time spent writing leaf nodes to disk during checkpoints.shown as fraction\n\n\n\n\ntokumx.ft.checkpoint.write.nonleaf.bytes.compressedps(gauge)\nThe rate at which nonleaf nodes are written to disk during checkpoints, after compression.shown as byte/second\n\n\n\n\ntokumx.ft.checkpoint.write.nonleaf.bytes.uncompressedps(gauge)\nThe rate at which nonleaf nodes are written to disk during checkpoints, before compression.shown as byte/second\n\n\n\n\ntokumx.ft.checkpoint.write.nonleaf.countps(gauge)\nThe rate at which nonleaf nodes are written to disk during checkpoints.shown as write/second\n\n\n\n\ntokumx.ft.checkpoint.write.nonleaf.timeps(gauge)\nThe fraction of time spent writing nonleaf nodes to disk during checkpoints.shown as fraction\n\n\n\n\ntokumx.ft.compressionRatio.leaf(gauge)\nThe size ratio of leaf nodes before and after compression.shown as fraction\n\n\n\n\ntokumx.ft.compressionRatio.nonleaf(gauge)\nThe size ratio of nonleaf nodes before and after compression.shown as fraction\n\n\n\n\ntokumx.ft.compressionRatio.overall(gauge)\nThe size ratio of nodes before and after compression.shown as fraction\n\n\n\n\ntokumx.ft.fsync.countps(gauge)\nThe rate at which the database flushed the operating system’s file buffers to disk.shown as operation/second\n\n\n\n\ntokumx.ft.fsync.timeps(gauge)\nThe fraction of time (microseconds/second) used to fsync to disk.shown as fraction\n\n\n\n\ntokumx.ft.locktree.size.current(gauge)\nTotal memory the locktree is currently using.shown as byte\n\n\n\n\ntokumx.ft.locktree.size.limit(gauge)\nMaximum number of bytes that the locktree is allowed to use.shown as byte\n\n\n\n\ntokumx.ft.log.bytesps(gauge)\nThe rate at which the logger writes to disk.shown as byte/second\n\n\n\n\ntokumx.ft.log.countps(gauge)\nThe rate of of individual log writes.shown as write/second\n\n\n\n\ntokumx.ft.log.timeps(gauge)\nThe fraction of time spent performing log writes.shown as fraction\n\n\n\n\ntokumx.ft.serializeTime.leaf.compressps(gauge)\nFraction of time spent compressing leaf nodes before writing them to disk (for checkpoint or when evicted while dirty).shown as fraction\n\n\n\n\ntokumx.ft.serializeTime.leaf.decompressps(gauge)\nFraction of time spent decompressing leaf nodes before writing them to disk (for checkpoint or when evicted while dirty).shown as fraction\n\n\n\n\ntokumx.ft.serializeTime.leaf.deserializeps(gauge)\nFraction of time spent deserializing leaf nodes and their partitions after reading them off disk.shown as fraction\n\n\n\n\ntokumx.ft.serializeTime.leaf.serializeps(gauge)\nFraction of time spent serializing leaf nodes and their partitions after reading them off disk.shown as fraction\n\n\n\n\ntokumx.ft.serializeTime.nonleaf.compressps(gauge)\nFraction of time spent compressing nonleaf nodes before writing them to disk (for checkpoint or when evicted while dirty).shown as fraction\n\n\n\n\ntokumx.ft.serializeTime.nonleaf.decompressps(gauge)\nFraction of time spent decompressing nonleaf nodes before writing them to disk (for checkpoint or when evicted while dirty).shown as fraction\n\n\n\n\ntokumx.ft.serializeTime.nonleaf.deserializeps(gauge)\nFraction of time spent deserializing nonleaf nodes and their partitions after reading them off disk.shown as fraction\n\n\n\n\ntokumx.ft.serializeTime.nonleaf.serializeps(gauge)\nFraction of time spent serializing nonleaf nodes and their partitions after reading them off disk.shown as fraction\n\n\n\n\ntokumx.mem.resident(gauge)\nThe amount of memory currently used by the database process.shown as mebibyte\n\n\n\n\ntokumx.mem.virtual(gauge)\nThe amount of virtual memory used by the database process.shown as mebibyte\n\n\n\n\ntokumx.metrics.document.deletedps(gauge)\nThe number of documents deleted per second.shown as document/second\n\n\n\n\ntokumx.metrics.document.insertedps(gauge)\nThe number of documents inserted per second.shown as document/second\n\n\n\n\ntokumx.metrics.document.returnedps(gauge)\nThe number of documents returned by queries per second.shown as document/second\n\n\n\n\ntokumx.metrics.document.updatedps(gauge)\nThe number of documents updated per second.shown as document/second\n\n\n\n\ntokumx.metrics.getLastError.wtime.numps(gauge)\nThe number of getLastError operations per second with a specified write concern (i.e. w) that wait for one or more members of a replica set to acknowledge the write operation.shown as operation/second\n\n\n\n\ntokumx.metrics.getLastError.wtime.totalMillisps(gauge)\nThe number of times per second that write concern operations have timed out as a result of the wtimeout threshold to getLastError.shown as event/second\n\n\n\n\ntokumx.metrics.getLastError.wtimeoutsps(gauge)\nThe fraction of time (ms/s) spent performing getLastError operations with write concern (i.e. w) that wait for one or more members of a replica set to acknowledge the write operation.shown as fraction\n\n\n\n\ntokumx.metrics.operation.idhackps(gauge)\nThe rate of queries that contain the _id field.shown as query/second\n\n\n\n\ntokumx.metrics.operation.scanAndOrderps(gauge)\nThe rate of queries that return sorted numbers that cannot perform the sort operation using an index.shown as query/second\n\n\n\n\ntokumx.metrics.queryExecutor.scannedps(gauge)\nThe rate of index items scanned during queries and query-plan evaluation.shown as operation/second\n\n\n\n\ntokumx.metrics.repl.apply.batches.numps(gauge)\nThe number of batches applied across all databases per second.shown as operation/second\n\n\n\n\ntokumx.metrics.repl.apply.batches.totalMillisps(gauge)\nThe fraction of time (ms/s) spent applying operations from the oplog.shown as fraction\n\n\n\n\ntokumx.metrics.repl.apply.opsps(gauge)\nThe rate of oplog operations.shown as operation/second\n\n\n\n\ntokumx.metrics.repl.buffer.count(gauge)\nThe number of operations in the oplog buffer.shown as operation\n\n\n\n\ntokumx.metrics.repl.buffer.sizeBytes(gauge)\nThe current size of the contents of the oplog buffer.shown as byte\n\n\n\n\ntokumx.metrics.repl.network.bytesps(gauge)\nThe rate at which data is read from the replication sync source.shown as byte/second\n\n\n\n\ntokumx.metrics.repl.network.getmores.numps(gauge)\nThe rate of getmore operations.shown as operation/second\n\n\n\n\ntokumx.metrics.repl.network.getmores.totalMillisps(gauge)\nThe fraction of time (ms/s) spent collecting data from getmore operations.shown as fraction\n\n\n\n\ntokumx.metrics.repl.network.opsps(gauge)\nThe rate of operations read from the replication source.shown as operation/second\n\n\n\n\ntokumx.metrics.repl.network.readersCreatedps(gauge)\nThe rate at which oplog query processes are created.shown as process/second\n\n\n\n\ntokumx.metrics.repl.oplog.insert.numps(gauge)\nThe rate at which operations are inserted into the oplog.shown as operation/second\n\n\n\n\ntokumx.metrics.repl.oplog.insert.totalMillisps(gauge)\nThe fraction of time (ms/s) spent inserting operations into the oplog.shown as fraction\n\n\n\n\ntokumx.metrics.repl.oplog.insertBytesps(gauge)\nThe rate (in bytes) at which data is inserted into the oplog.shown as byte/second\n\n\n\n\ntokumx.metrics.ttl.deletedDocumentsps(gauge)\nThe rate at which documents are deleted from collections with a ttl index.shown as document/second\n\n\n\n\ntokumx.metrics.ttl.passesps(gauge)\nThe number of times per second the background process removes documents from collections with a ttl index.shown as event/second\n\n\n\n\ntokumx.opcounters.commandps(gauge)\nThe total number of commands per second issued to the database.shown as command/second\n\n\n\n\ntokumx.opcounters.deleteps(gauge)\nThe number of delete operations per second.shown as operation/second\n\n\n\n\ntokumx.opcounters.getmoreps(gauge)\nThe number of getmore operations per second.shown as operation/second\n\n\n\n\ntokumx.opcounters.insertps(gauge)\nThe number of insert operations per second.shown as operation/second\n\n\n\n\ntokumx.opcounters.queryps(gauge)\nThe total number of queries per second.shown as query/second\n\n\n\n\ntokumx.opcounters.updateps(gauge)\nThe number of update operations per second.shown as operation/second\n\n\n\n\ntokumx.opcountersRepl.commandps(gauge)\nThe total number of replicated commands issued to the database per second.shown as command/second\n\n\n\n\ntokumx.opcountersRepl.deleteps(gauge)\nThe number of replicated delete operations per second.shown as operation/second\n\n\n\n\ntokumx.opcountersRepl.getmoreps(gauge)\nThe number of replicated getmore operations per second.shown as operation/second\n\n\n\n\ntokumx.opcountersRepl.insertps(gauge)\nThe number of replicated insert operations per second.shown as operation/second\n\n\n\n\ntokumx.opcountersRepl.queryps(gauge)\nThe total number of replicated queries per second.shown as query/second\n\n\n\n\ntokumx.opcountersRepl.updateps(gauge)\nThe number of replicated update operations per second.shown as operation/second\n\n\n\n\ntokumx.stats.coll.count(gauge)\nThe number of objects or documents in this collection.shown as document\n\n\n\n\ntokumx.stats.coll.nindexes(gauge)\nThe number of indexes on this collection.shown as index\n\n\n\n\ntokumx.stats.coll.nindexesbeingbuilt(gauge)\nThe number of indexes currently being built.shown as index\n\n\n\n\ntokumx.stats.coll.size(gauge)\nThe total size in memory of all records in a collection. Does not include the record header, but does include the record’s padding. Does not include the size of any indexes associated with the collection.shown as byte\n\n\n\n\ntokumx.stats.coll.storageSize(gauge)\nThe total amount of storage allocated to this collection for document storage.shown as byte\n\n\n\n\ntokumx.stats.coll.totalIndexSize(gauge)\nThe total size of all indexes on this collection.shown as byte\n\n\n\n\ntokumx.stats.coll.totalIndexStorageSize(gauge)\nThe total size on disk of all indexes on this collection (after compression).shown as byte\n\n\n\n\ntokumx.stats.dataSize(gauge)\nThe total size of the data held in this database including the padding factor.shown as byte\n\n\n\n\ntokumx.stats.db.avgObjSize(gauge)\nThe average size of each document.shown as byte\n\n\n\n\ntokumx.stats.db.collections(gauge)\nThe number of collections in the database.\n\n\n\n\ntokumx.stats.db.dataSize(gauge)\nThe total size of the data held in this database including the padding factor.shown as byte\n\n\n\n\ntokumx.stats.db.indexes(gauge)\nThe total number of indexes across all collections in the database.shown as index\n\n\n\n\ntokumx.stats.db.indexSize(gauge)\nThe total size of all indexes created on this database.shown as byte\n\n\n\n\ntokumx.stats.db.indexStorageSize(gauge)\nThe total size on disk of all indexes created on this database (after compression).shown as byte\n\n\n\n\ntokumx.stats.db.objects(gauge)\nThe number of documents in the database across all collections.shown as document\n\n\n\n\ntokumx.stats.db.storageSize(gauge)\nThe total amount of space allocated to collections in this database for document storage.shown as byte\n\n\n\n\ntokumx.stats.idx.avgObjSize(gauge)\nThe average size of each index entry.shown as byte\n\n\n\n\ntokumx.stats.idx.count(gauge)\nThe number of documents in this index.shown as index\n\n\n\n\ntokumx.stats.idx.deletes(gauge)\nThe number of delete operations performed on this index.shown as operation\n\n\n\n\ntokumx.stats.idx.inserts(gauge)\nThe number of insert operations performed on this index.shown as operation\n\n\n\n\ntokumx.stats.idx.nscanned(gauge)\nThe number of index entries scanned for queries using this index.shown as index\n\n\n\n\ntokumx.stats.idx.nscannedObjects(gauge)\nThe number of collection objects examined after scanning an index entry for a query using this index.shown as object\n\n\n\n\ntokumx.stats.idx.queries(gauge)\nThe number of query operations performed using this index.shown as query\n\n\n\n\ntokumx.stats.idx.size(gauge)\nThe total size of this index.shown as byte\n\n\n\n\ntokumx.stats.idx.storageSize(gauge)\nThe total size on disk of this index (after compression).shown as byte\n\n\n\n\ntokumx.stats.indexes(gauge)\nThe total number of indexes across all collections in the database.shown as index\n\n\n\n\ntokumx.stats.indexSize(gauge)\nThe total size of all indexes created on this database.shown as byte\n\n\n\n\ntokumx.stats.objects(gauge)\nThe number of documents in the database across all collections.shown as document\n\n\n\n\ntokumx.stats.storageSize(gauge)\nThe total amount of space allocated to collections in this database for document storage.shown as byte\n\n\n\n\ntokumx.uptime(gauge)\nThe time that the tokumx process has been active.shown as second\n\n\n\n","tags":"","loc":"/integrations/tokumx/"},{"title":"Datadog-Tomcat Integration","text":"\n\nOverview\n\nGet metrics from Tomcat in real time to:\n\n\n  Visualize your web server performance\n  Correlate the performance of Tomcat with the rest of your applications\n\n\n\nInstallation\n\nMetrics will be captured using a JMX connection. Due to an issue with the OpenJDK and Tomcat, we recommend the use of Oracle’s JDK for this integration.\n\nThis check has a limit of 350 metrics per instance. The number of returned metrics is indicated in the info page. You can specify the metrics you are interested in by editing the configuration below. To learn how to customize the metrics to collect visit the JMX Checks documentation for more detailed instructions. If you need to monitor more metrics, please send us an email at support@datadoghq.com\n\nMake sure that JMX Remote is enabled on your Tomcat server. For information on JMX , please see the JMX integration documentation.\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to Tomcat. Edit conf.d/tomcat.yaml:\n\n    instances:\n  - host: localhost\n    port: 9012\n  #   name: tomcat_instance\n  #   # java_bin_path: /path/to/java\n  #   # java_options: \"-Xmx200m -Xms50m\"\n  #   # trust_store_path: /path/to/trustStore.jks\n  #   # trust_store_password: password\n  #   tags:\n  #     env: stage\n  #     newTag: test\n\ninit_config:\n  conf:\n    - include:\n      type: ThreadPool\n      attribute:\n        maxThreads:\n          alias: tomcat.threads.max\n          metric_type: gauge\n        currentThreadCount:\n          alias: tomcat.threads.count\n          metric_type: gauge\n        currentThreadsBusy:\n          alias: tomcat.threads.busy\n          metric_type: gauge\n    - include:\n      type: GlobalRequestProcessor\n      attribute:\n        bytesSent:\n          alias: tomcat.bytes_sent\n          metric_type: counter\n        bytesReceived:\n          alias: tomcat.bytes_rcvd\n          metric_type: counter\n        errorCount:\n          alias: tomcat.error_count\n          metric_type: counter\n        requestCount:\n          alias: tomcat.request_count\n          metric_type: counter\n        maxTime:\n          alias: tomcat.max_time\n          metric_type: gauge\n        processingTime:\n          alias: tomcat.processing_time\n          metric_type: counter\n    - include:\n      j2eeType: Servlet\n      attribute:\n        processingTime:\n          alias: tomcat.servlet.processing_time\n          metric_type: counter\n        errorCount:\n          alias: tomcat.servlet.error_count\n          metric_type: counter\n        requestCount:\n          alias: tomcat.servlet.request_count\n          metric_type: counter\n    - include:\n      type: Cache\n      attribute:\n        accessCount:\n          alias: tomcat.cache.access_count\n          metric_type: counter\n        hitsCounts:\n          alias: tomcat.cache.hits_count\n          metric_type: counter\n    - include:\n      type: JspMonitor\n      attribute:\n        jspCount:\n          alias: tomcat.jsp.count\n          metric_type: counter\n        jspReloadCount:\n          alias: tomcat.jsp.reload_count\n          metric_type: counter\n\n  \n  \n    Restart the Agent\n  \n\n\n\nConfiguration Options\n\n\n  \nuser and password (Optional) - Username and password.\n  \nprocess_name_regex - (Optional) - Instead of specifying a host and port or jmx_url, the agent can connect using the attach api. This requires the JDK to be installed and the path to tools.jar to be set.\n  \ntools_jar_path - (Optional) - To be set when process_name_regex is set.\n  \njava_bin_path - (Optional) - Should be set if the agent cannot find your java executable.\n  \njava_options - (Optional) - Java JVM options\n  \ntrust_store_path and trust_store_password - (Optional) - Should be set if ssl is enabled.\n\n\nThe conf parameter is a list of dictionaries. Only 2 keys are allowed in this dictionary:\n\n\n  \ninclude (mandatory): Dictionary of filters, any attribute that matches these filters will be collected unless it also matches the “exclude” filters (see below)\n  \nexclude (optional): Another dictionary of filters. Attributes that match these filters won’t be collected\n\n\nFor a given bean, metrics get tagged in the following manner:\n\nmydomain:attr0=val0,attr1=val1\n\n\nYour metric will be mydomain (or some variation depending on the attribute inside the bean) and have the tags attr0:val0, attr1:val1, domain:mydomain.\n\nIf you specify an alias in an include key that is formatted as camel case, it will be converted to snake case. For example, MyMetricName will be shown in Datadog as my_metric_name.\n\n\nThe attribute filter\n\nThe attribute filter can accept two types of values:\n\n\n  \n    A dictionary whose keys are attributes names:\n\n    conf:\n  - include:\n    attribute:\n      maxThreads:\n        alias: tomcat.threads.max\n        metric_type: gauge\n      currentThreadCount:\n        alias: tomcat.threads.count\n        metric_type: gauge\n      bytesReceived:\n        alias: tomcat.bytes_rcvd\n        metric_type: counter\n\n  \n\n\nIn that case you can specify an alias for the metric that will become the metric name in Datadog. You can also specify the metric type either a gauge or a counter. If you choose counter, a rate per second will be computed for this metric.\n\n\n  \n    A list of attributes names:\n\n    conf:\n  - include:\n    domain: org.apache.cassandra.db\n    attribute:\n      - BloomFilterDiskSpaceUsed\n      - BloomFilterFalsePositives\n      - BloomFilterFalseRatio\n      - Capacity\n      - CompressionRatio\n      - CompletedTasks\n      - ExceptionCount\n      - Hits\n      - RecentHitRate\n\n  \n\n\nIn that case:\n\n\n  The metric type will be a gauge\n  The metric name will be jmx.[DOMAIN_NAME].[ATTRIBUTE_NAME]\n\n\nHere is another filtering example:\n\ninstances:\n  - host: 127.0.0.1\n    name: jmx_instance\n    port: 9999\n\ninit_config:\n  conf:\n    - include:\n      bean: org.apache.cassandra.metrics:type=ClientRequest,scope=Write,name=Latency\n      attribute:\n        - OneMinuteRate\n        - 75thPercentile\n        - 95thPercentile\n        - 99thPercentile\n\n\n\nNote\n\nList of filters is only supported in Datadog Agent > 5.3.0. If you are using an older version, please use singletons and multiple include statements instead.\n\n# Datadog Agent > 5.3.0\n  conf:\n    - include:\n      domain: domain_name\n      bean:\n        - first_bean_name\n        - second_bean_name\n\n# Older Datadog Agent versions\n  conf:\n    - include:\n      domain: domain_name\n      bean: first_bean_name\n    - include:\n      domain: domain_name\n      bean: second_bean_name\n\n\n\nCommands to view the metrics that are available:\n\nThe datadog-agent jmx command was added in version 4.1.0.\n\n\n  List attributes that match at least one of your instances configuration:\nsudo /etc/init.d/datadog-agent jmx list_matching_attributes\n\n  List attributes that do match one of your instances configuration but that are not being collected because it would exceed the number of metrics that can be collected:\nsudo /etc/init.d/datadog-agent jmx list_limited_attributes\n\n  List attributes that will actually be collected by your current instances configuration:\nsudo /etc/init.d/datadog-agent jmx list_collected_attributes\n\n  List attributes that don’t match any of your instances configuration:\nsudo /etc/init.d/datadog-agent jmx list_not_matching_attributes\n\n  List every attributes available that has a type supported by JMXFetch:\nsudo /etc/init.d/datadog-agent jmx list_everything\n\n  Start the collection of metrics based on your current configuration and display them in the console:\nsudo /etc/init.d/datadog-agent jmx collect\n\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\nTomcat YAML example\n\n\nValidation\n\nExecute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  tomcat\n  ------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\ntomcat.threads.max(gauge every 10 seconds)\nThe maximum number of allowed worker threads.shown as thread\n\n\n\n\ntomcat.threads.count(gauge every 10 seconds)\nThe number of threads managed by the thread pool.shown as thread\n\n\n\n\ntomcat.threads.busy(gauge every 10 seconds)\nThe number of threads that are in use.shown as thread\n\n\n\n\ntomcat.bytes_sent(gauge every 10 seconds)\nBytes per second sent by all the request processors.shown as byte/second\n\n\n\n\ntomcat.bytes_rcvd(gauge every 10 seconds)\nBytes per second received by all request processors.shown as byte/second\n\n\n\n\ntomcat.error_count(gauge every 10 seconds)\nThe number of errors per second on all request processors.shown as error/second\n\n\n\n\ntomcat.request_count(gauge every 10 seconds)\nThe number of requests per second across all request processors.shown as request/second\n\n\n\n\ntomcat.max_time(gauge every 10 seconds)\nThe longest request processing time (in milliseconds).shown as millisecond\n\n\n\n\ntomcat.processing_time(gauge every 10 seconds)\nThe sum of request processing times across all requests handled by the request processors (in milliseconds) per second.\n\n\n\n\ntomcat.servlet.processing_time(gauge every 10 seconds)\nThe sum of request processing times across all requests to the servlet (in milliseconds) per second.\n\n\n\n\ntomcat.servlet.error_count(gauge every 10 seconds)\nThe number of erroneous requests received by the servlet per second.shown as error/second\n\n\n\n\ntomcat.servlet.request_count(gauge every 10 seconds)\nThe number of requests received by the servlet per second.shown as request/second\n\n\n\n\ntomcat.cache.access_count(gauge every 10 seconds)\nThe number of accesses to the cache per second.shown as get/second\n\n\n\n\ntomcat.cache.hits_count(gauge every 10 seconds)\nThe number of cache hits per second.shown as hit/second\n\n\n\n\ntomcat.jsp.count(gauge every 10 seconds)\nThe number of JSPs per second that have been loaded in the web module.shown as page/second\n\n\n\n\ntomcat.jsp.reload_count(gauge every 10 seconds)\nThe number of JSPs per second that have been reloaded in the web module.shown as page/second\n\n\n\n","tags":"","loc":"/integrations/tomcat/"},{"title":"Datadog-Varnish Integration","text":"\n\nOverview\n\nConnect Varnish to Datadog in order to:\n\n\n  Visualize your cache performance in real-time.\n  Correlate the performance of Varnish with the rest of your applications.\n\n\n\n\nLearn more about how to monitor Varnish performance metrics thanks to our series of posts. We detail the key performance metrics, how to collect them, and how to use Datadog to monitor Varnish.\n\n\nInstallation\n\nIf you’re running Varnish 4.1+, you must add the dd-agent user to the varnish group:\n$ sudo usermod -G varnish -a dd-agent\n\n\nConfiguration\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nVarnish YAML example\nVarnish checks.d\n\n\n\nValidation\n\nTo ensure the integration is installed correctly, run the agent info command.\n\nsudo /etc/init.d/datadog-agent info\n\n\nYou should see something similar to the following if everything is working correctly:\n\nChecks\n======\n\n  [...]\n\n  varnish\n  ------\n      - instance #0 [OK]\n      - Collected 20 metrics & 0 events\n\n\n\nMetrics\n\nThe following metrics are collected by default with the Varnish integration.\n\n\n\n\nvarnish.accept_fail(gauge)\nAccept failures.shown as connection/second\n\n\n\n\nvarnish.backend_busy(gauge)\nMaximum number of connections to a backend was reached.shown as connection/second\n\n\n\n\nvarnish.backend_conn(gauge)\nSuccessful connections to a backen.shown as connection/second\n\n\n\n\nvarnish.backend_fail(gauge)\nBackend connection failures.shown as connection/second\n\n\n\n\nvarnish.backend_recycle(gauge)\nBackend connections with keep-alive that are returned to the pool of connections.shown as connection/second\n\n\n\n\nvarnish.backend_req(gauge)\nBackend requests.shown as request/second\n\n\n\n\nvarnish.backend_retry(gauge)\nBackend connection retries.shown as connection/second\n\n\n\n\nvarnish.backend_reuse(gauge)\nRecycled connections that has were reused.shown as connection/second\n\n\n\n\nvarnish.backend_toolate(gauge)\nBackend connections closed because they were idle too long.shown as connection/second\n\n\n\n\nvarnish.backend_unhealthy(gauge)\nBackend connections not tried because the backend was unhealthy.shown as connection/second\n\n\n\n\nvarnish.bans(gauge)\nBans in system, including bans superseded by newer bans and bans already checked by the ban-lurker.shown as object\n\n\n\n\nvarnish.bans_added(gauge)\nBans added to ban list.shown as object/second\n\n\n\n\nvarnish.bans_completed(gauge)\nBans which are no longer active, either because they got checked by the ban-lurker or superseded by newer identical bans.shown as object\n\n\n\n\nvarnish.bans_deleted(gauge)\nBans deleted from ban list.shown as object/second\n\n\n\n\nvarnish.bans_dups(gauge)\nBans replaced by later identical bans.shown as object/second\n\n\n\n\nvarnish.bans_lurker_contention(gauge)\nTimes the ban-lurker waited for lookups.shown as event/second\n\n\n\n\nvarnish.bans_lurker_obj_killed(gauge)\nObjects killed by ban-lurker.shown as object/second\n\n\n\n\nvarnish.bans_lurker_tested(gauge)\nBans and objects tested against each other by the ban-lurker.shown as object/second\n\n\n\n\nvarnish.bans_lurker_tests_tested(gauge)\nTests and objects tested against each other by the ban-lurker. 'ban req.url == foo && req.http.host == bar' counts as one in 'bans_tested' and as two in 'bans_tests_tested'.shown as object/second\n\n\n\n\nvarnish.bans_obj(gauge)\nBans which use obj.* variables. These bans can possibly be washed by the ban-lurker.shown as object\n\n\n\n\nvarnish.bans_obj_killed(gauge)\nObjects killed by bans during object lookup.shown as object/second\n\n\n\n\nvarnish.bans_persisted_bytes(gauge)\nBytes used by the persisted ban lists.shown as byte\n\n\n\n\nvarnish.bans_persisted_fragmentation(gauge)\nExtra bytes accumulated through dropped and completed bans in the persistent ban lists.shown as byte\n\n\n\n\nvarnish.bans_req(gauge)\nBans which use req.* variables. These bans can not be washed by the ban-lurker.shown as object\n\n\n\n\nvarnish.bans_tested(gauge)\nBans and objects tested against each other during hash lookup.shown as object/second\n\n\n\n\nvarnish.bans_tests_tested(gauge)\nTests and objects tested against each other during lookup. 'ban req.url == foo && req.http.host == bar' counts as one in 'bans_tested' and as two in 'bans_tests_tested'.shown as object/second\n\n\n\n\nvarnish.busy_sleep(gauge)\nRequests sent to sleep without a worker thread because they found a busy object.shown as request/second\n\n\n\n\nvarnish.busy_wakeup(gauge)\nRequests taken off the busy object sleep list and and rescheduled.shown as request/second\n\n\n\n\nvarnish.cache_hit(gauge)\nRequests served from the cache.shown as request/second\n\n\n\n\nvarnish.cache_hitpass(gauge)\nRequests passed to a backend where the decision to pass them found in the cache.shown as request/second\n\n\n\n\nvarnish.cache_miss(gauge)\nRequests fetched from a backend server.shown as request/second\n\n\n\n\nvarnish.client_conn(gauge)\nClient connections accepted.shown as connection/second\n\n\n\n\nvarnish.client_drop(gauge)\nClient connection dropped, no session.shown as connection/second\n\n\n\n\nvarnish.client_drop_late(gauge)\nClient connection dropped late.shown as connection/second\n\n\n\n\nvarnish.client_req(gauge)\nParseable client requests seen.shown as request/second\n\n\n\n\nvarnish.client_req_400(gauge)\nRequests that were malformed in some drastic way.shown as request/second\n\n\n\n\nvarnish.client_req_411(gauge)\nRequests that were missing a Content-Length: header.shown as request/second\n\n\n\n\nvarnish.client_req_413(gauge)\nRequests that were too big.shown as request/second\n\n\n\n\nvarnish.client_req_417(gauge)\nRequests with a bad Expect: header.shown as request/second\n\n\n\n\nvarnish.dir_dns_cache_full(gauge)\nDNS director full DNS cache.shown as event/second\n\n\n\n\nvarnish.dir_dns_failed(gauge)\nDNS director failed lookup.shown as event/second\n\n\n\n\nvarnish.dir_dns_hit(gauge)\nDNS director cached lookup hit.shown as event/second\n\n\n\n\nvarnish.dir_dns_lookups(gauge)\nDNS director lookups.shown as event/second\n\n\n\n\nvarnish.esi_errors(gauge)\nEdge Side Includes (ESI) parse errors.shown as event/second\n\n\n\n\nvarnish.esi_warnings(gauge)\nEdge Side Includes (ESI) parse warnings.shown as event/second\n\n\n\n\nvarnish.exp_mailed(gauge)\nObjects mailed to expiry thread for handling.shown as object/second\n\n\n\n\nvarnish.exp_received(gauge)\nObjects received by expiry thread for handling.shown as object/second\n\n\n\n\nvarnish.fetch_1xx(gauge)\nBack end response with no body because of 1XX response (Informational).shown as response/second\n\n\n\n\nvarnish.fetch_204(gauge)\nBack end response with no body because of 204 response (No Content).shown as response/second\n\n\n\n\nvarnish.fetch_304(gauge)\nBack end response with no body because of 304 response (Not Modified).shown as response/second\n\n\n\n\nvarnish.fetch_bad(gauge)\nBack end response's body length could not be determined and/or had bad headers.shown as response/second\n\n\n\n\nvarnish.fetch_chunked(gauge)\nBack end response bodies that were chunked.shown as response/second\n\n\n\n\nvarnish.fetch_close(gauge)\nFetch wanted close.shown as response/second\n\n\n\n\nvarnish.fetch_eof(gauge)\nBack end response bodies with EOF.shown as response/second\n\n\n\n\nvarnish.fetch_failed(gauge)\nBack end response fetches that failed.shown as response/second\n\n\n\n\nvarnish.fetch_head(gauge)\nBack end HEAD requests.shown as response/second\n\n\n\n\nvarnish.fetch_length(gauge)\nBack end response bodies with Content-Length.shown as response/second\n\n\n\n\nvarnish.fetch_no_thread(gauge)\nBack end fetches that failed because no thread was available.shown as response/second\n\n\n\n\nvarnish.fetch_oldhttp(gauge)\nNumber of responses served by backends with http < 1.1shown as response/second\n\n\n\n\nvarnish.fetch_zero(gauge)\nNumber of responses that have zero length.shown as response/second\n\n\n\n\nvarnish.hcb_insert(gauge)\nHCB inserts.shown as event/second\n\n\n\n\nvarnish.hcb_lock(gauge)\nHCB lookups with lock.shown as event/second\n\n\n\n\nvarnish.hcb_nolock(gauge)\nHCB lookups without lock.shown as event/second\n\n\n\n\nvarnish.LCK.backend.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.backend.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.backend.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.backend.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.ban.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.ban.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.ban.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.ban.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.busyobj.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.busyobj.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.busyobj.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.cli.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.cli.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.cli.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.cli.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.exp.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.exp.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.exp.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.exp.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.hcb.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.hcb.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.hcb.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.hcb.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.hcl.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.hcl.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.hcl.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.hcl.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.herder.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.herder.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.herder.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.herder.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.hsl.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.hsl.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.hsl.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.hsl.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.lru.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.lru.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.lru.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.lru.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.mempool.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.mempool.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.mempool.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.nbusyobj.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.nbusyobj.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.nbusyobj.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.objhdr.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.objhdr.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.objhdr.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.objhdr.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.pipestat.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.pipestat.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.pipestat.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.sess.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.sess.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.sess.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.sessmem.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.sessmem.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.sessmem.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.sessmem.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.sma.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.sma.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.sma.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.sma.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.smf.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.smf.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.smf.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.smf.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.smp.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.smp.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.smp.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.smp.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.sms.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.sms.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.sms.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.sms.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.stat.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.stat.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.stat.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.stat.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.vbe.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.vbe.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.vbe.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.vbe.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.vbp.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.vbp.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.vbp.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.vbp.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.vcapace.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.vcapace.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.vcapace.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.vcl.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.vcl.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.vcl.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.vcl.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.vxid.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.vxid.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.vxid.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.wq.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.wq.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.wq.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.wq.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.LCK.wstat.colls(gauge)\nCollisions.shown as lock/second\n\n\n\n\nvarnish.LCK.wstat.creat(gauge)\nCreated locks.shown as lock/second\n\n\n\n\nvarnish.LCK.wstat.destroy(gauge)\nDestroyed locks.shown as lock/second\n\n\n\n\nvarnish.LCK.wstat.locks(gauge)\nLock operations.shown as lock/second\n\n\n\n\nvarnish.losthdr(gauge)\nHTTP header overflows.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.busyobj.allocs(gauge)\nAllocations.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.busyobj.frees(gauge)\nFrees.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.busyobj.live(gauge)\nIn use.\n\n\n\n\nvarnish.MEMPOOL.busyobj.pool(gauge)\nIn pool.\n\n\n\n\nvarnish.MEMPOOL.busyobj.randry(gauge)\nPool ran dry.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.busyobj.recycle(gauge)\nRecycled from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.busyobj.surplus(gauge)\nToo many for pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.busyobj.sz_needed(gauge)\nSize allocated.shown as byte\n\n\n\n\nvarnish.MEMPOOL.busyobj.sz_wanted(gauge)\nSize requested.shown as byte\n\n\n\n\nvarnish.MEMPOOL.busyobj.timeout(gauge)\nTimed out from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.busyobj.toosmall(gauge)\nToo small to recycle.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req0.allocs(gauge)\nAllocations.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req0.frees(gauge)\nFrees.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req0.live(gauge)\nIn use.\n\n\n\n\nvarnish.MEMPOOL.req0.pool(gauge)\nIn pool.\n\n\n\n\nvarnish.MEMPOOL.req0.randry(gauge)\nPool ran dry.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req0.recycle(gauge)\nRecycled from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req0.surplus(gauge)\nToo many for pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req0.sz_needed(gauge)\nSize allocated.shown as byte\n\n\n\n\nvarnish.MEMPOOL.req0.sz_wanted(gauge)\nSize requested.shown as byte\n\n\n\n\nvarnish.MEMPOOL.req0.timeout(gauge)\nTimed out from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req0.toosmall(gauge)\nToo small to recycle.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req1.allocs(gauge)\nAllocations.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req1.frees(gauge)\nFrees.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req1.live(gauge)\nIn use.\n\n\n\n\nvarnish.MEMPOOL.req1.pool(gauge)\nIn pool.\n\n\n\n\nvarnish.MEMPOOL.req1.randry(gauge)\nPool ran dry.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req1.recycle(gauge)\nRecycled from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req1.surplus(gauge)\nToo many for pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req1.sz_needed(gauge)\nSize allocated.shown as byte\n\n\n\n\nvarnish.MEMPOOL.req1.sz_wanted(gauge)\nSize requested.shown as byte\n\n\n\n\nvarnish.MEMPOOL.req1.timeout(gauge)\nTimed out from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.req1.toosmall(gauge)\nToo small to recycle.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess0.allocs(gauge)\nAllocations.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess0.frees(gauge)\nFrees.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess0.live(gauge)\nIn use.\n\n\n\n\nvarnish.MEMPOOL.sess0.pool(gauge)\nIn pool.\n\n\n\n\nvarnish.MEMPOOL.sess0.randry(gauge)\nPool ran dry.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess0.recycle(gauge)\nRecycled from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess0.surplus(gauge)\nToo many for pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess0.sz_needed(gauge)\nSize allocated.shown as byte\n\n\n\n\nvarnish.MEMPOOL.sess0.sz_wanted(gauge)\nSize requested.shown as byte\n\n\n\n\nvarnish.MEMPOOL.sess0.timeout(gauge)\nTimed out from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess0.toosmall(gauge)\nToo small to recycle.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess1.allocs(gauge)\nAllocations.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess1.frees(gauge)\nFrees.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess1.live(gauge)\nIn use.\n\n\n\n\nvarnish.MEMPOOL.sess1.pool(gauge)\nIn pool.\n\n\n\n\nvarnish.MEMPOOL.sess1.randry(gauge)\nPool ran dry.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess1.recycle(gauge)\nRecycled from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess1.surplus(gauge)\nToo many for pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess1.sz_needed(gauge)\nSize allocated.shown as byte\n\n\n\n\nvarnish.MEMPOOL.sess1.sz_wanted(gauge)\nSize requested.shown as byte\n\n\n\n\nvarnish.MEMPOOL.sess1.timeout(gauge)\nTimed out from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.sess1.toosmall(gauge)\nToo small to recycle.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.vbc.allocs(gauge)\nAllocations.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.vbc.frees(gauge)\nFrees.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.vbc.live(gauge)\nIn use.\n\n\n\n\nvarnish.MEMPOOL.vbc.pool(gauge)\nIn pool.\n\n\n\n\nvarnish.MEMPOOL.vbc.randry(gauge)\nPool ran dry.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.vbc.recycle(gauge)\nRecycled from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.vbc.surplus(gauge)\nToo many for pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.vbc.sz_needed(gauge)\nSize allocated.shown as byte\n\n\n\n\nvarnish.MEMPOOL.vbc.sz_wanted(gauge)\nSize requested.shown as byte\n\n\n\n\nvarnish.MEMPOOL.vbc.timeout(gauge)\nTimed out from pool.shown as event/second\n\n\n\n\nvarnish.MEMPOOL.vbc.toosmall(gauge)\nToo small to recycle.shown as event/second\n\n\n\n\nvarnish.MGT.child_died(gauge)\nChild processes that died due to signals.shown as process/second\n\n\n\n\nvarnish.MGT.child_dump(gauge)\nChild processes that produced core dumps.shown as process/second\n\n\n\n\nvarnish.MGT.child_exit(gauge)\nChild processes the were cleanly stopped.shown as process/second\n\n\n\n\nvarnish.MGT.child_panic(gauge)\nChild processes that panicked.shown as process/second\n\n\n\n\nvarnish.MGT.child_start(gauge)\nChild processes that started.shown as process/second\n\n\n\n\nvarnish.MGT.child_stop(gauge)\nChild processes that exited with an unexpected return code.shown as process/second\n\n\n\n\nvarnish.MGT.uptime(gauge)\n\n\n\n\nvarnish.n_backend(gauge)\nNumber of backends.\n\n\n\n\nvarnish.n_ban(gauge)\nActive bans.shown as object\n\n\n\n\nvarnish.n_ban_add(gauge)\nNew bans added.shown as object/second\n\n\n\n\nvarnish.n_ban_dups(gauge)\nDuplicate bans removed.shown as object/second\n\n\n\n\nvarnish.n_ban_obj_test(gauge)\nObjects tested.shown as object/second\n\n\n\n\nvarnish.n_ban_re_test(gauge)\nRegexps tested against.shown as object/second\n\n\n\n\nvarnish.n_ban_retire(gauge)\nOld bans deleted.shown as object/second\n\n\n\n\nvarnish.n_expired(gauge)\nObjects that expired from cache because of TTL.shown as object\n\n\n\n\nvarnish.n_gunzip(gauge)\nGunzip operations.shown as event/second\n\n\n\n\nvarnish.n_gzip(gauge)\nGzip operations.shown as event/second\n\n\n\n\nvarnish.n_lru_moved(gauge)\nMove operations done on the LRU list.shown as operation\n\n\n\n\nvarnish.n_lru_nuked(gauge)\nObjects forcefully evicted from storage to make room for new objects.shown as operation\n\n\n\n\nvarnish.n_obj_purged(gauge)\nPurged objects.shown as object\n\n\n\n\nvarnish.n_object(gauge)\nobject structs made.shown as object\n\n\n\n\nvarnish.n_objectcore(gauge)\nobjectcore structs made.shown as object\n\n\n\n\nvarnish.n_objecthead(gauge)\nobjecthead structs made.shown as object\n\n\n\n\nvarnish.n_objoverflow(gauge)\nObjects overflowing workspace.shown as object/second\n\n\n\n\nvarnish.n_objsendfile(gauge)\nObjects sent with sendfile.shown as object/second\n\n\n\n\nvarnish.n_objwrite(gauge)\nObjects sent with write.shown as object/second\n\n\n\n\nvarnish.n_purges(gauge)\nPurges executed.shown as event\n\n\n\n\nvarnish.n_sess(gauge)\nsess structs made.shown as object\n\n\n\n\nvarnish.n_sess_mem(gauge)\nsess_mem structs made.shown as object\n\n\n\n\nvarnish.n_vampireobject(gauge)\nUnresurrected objects.shown as object\n\n\n\n\nvarnish.n_vbc(gauge)\nvbc structs made.shown as object\n\n\n\n\nvarnish.n_vcl(gauge)\nTotal VCLs loaded.shown as object/second\n\n\n\n\nvarnish.n_vcl_avail(gauge)\nAvailable VCLs.shown as object/second\n\n\n\n\nvarnish.n_vcl_discard(gauge)\nDiscarded VCLs.shown as object/second\n\n\n\n\nvarnish.n_waitinglist(gauge)\nwaitinglist structs made.shown as object\n\n\n\n\nvarnish.n_wrk(gauge)\nWorker threads.shown as thread\n\n\n\n\nvarnish.n_wrk_create(gauge)\nWorker threads created.shown as event/second\n\n\n\n\nvarnish.n_wrk_drop(gauge)\nDropped work requests.shown as event/second\n\n\n\n\nvarnish.n_wrk_failed(gauge)\nWorker threads not created.shown as event/second\n\n\n\n\nvarnish.n_wrk_lqueue(gauge)\nWork request queue length.shown as event/second\n\n\n\n\nvarnish.n_wrk_max(gauge)\nWorker threads limited.shown as event/second\n\n\n\n\nvarnish.n_wrk_queued(gauge)\nQueued work requests.shown as event/second\n\n\n\n\nvarnish.pools(gauge)\nThread pools.\n\n\n\n\nvarnish.s_bodybytes(gauge)\nTotal body size.shown as byte/second\n\n\n\n\nvarnish.s_fetch(gauge)\nBackend fetches.shown as request/second\n\n\n\n\nvarnish.s_hdrbytes(gauge)\nTotal header size.shown as byte/second\n\n\n\n\nvarnish.s_pass(gauge)\nPassed requests.shown as request/second\n\n\n\n\nvarnish.s_pipe(gauge)\nPipe sessions seen.shown as connection/second\n\n\n\n\nvarnish.s_pipe_hdrbytes(gauge)\nTotal request bytes received for piped sessions.shown as byte/second\n\n\n\n\nvarnish.s_pipe_in(gauge)\nTotal number of bytes forwarded from clients in pipe sessions.shown as byte/second\n\n\n\n\nvarnish.s_pipe_out(gauge)\nTotal number of bytes forwarded to clients in pipe sessions.shown as byte/second\n\n\n\n\nvarnish.s_req(gauge)\nRequests.shown as request/second\n\n\n\n\nvarnish.s_req_bodybytes(gauge)\nTotal request body bytes received.shown as byte/second\n\n\n\n\nvarnish.s_req_hdrbytes(gauge)\nTotal request header bytes received.shown as byte/second\n\n\n\n\nvarnish.s_resp_bodybytes(gauge)\nTotal response body bytes transmitted.shown as byte/second\n\n\n\n\nvarnish.s_resp_hdrbytes(gauge)\nTotal response header bytes transmitted.shown as byte/second\n\n\n\n\nvarnish.s_sess(gauge)\nClient connections.shown as connection/second\n\n\n\n\nvarnish.s_synth(gauge)\nSynthetic responses made.shown as response/second\n\n\n\n\nvarnish.sess_closed(gauge)\nClient connections closed.shown as connection/second\n\n\n\n\nvarnish.sess_conn(gauge)\nClient connections accepted.shown as connection/second\n\n\n\n\nvarnish.sess_drop(gauge)\nClient connections dropped due to lack of worker thread.shown as connection/second\n\n\n\n\nvarnish.sess_dropped(gauge)\nClient connections dropped due to a full queue.shown as connection/second\n\n\n\n\nvarnish.sess_fail(gauge)\nFailures to accept a TCP connection. Either the client changed its mind, or the kernel ran out of some resource like file descriptors.shown as connection/second\n\n\n\n\nvarnish.sess_herd(gauge)\n\nshown as connection/second\n\n\n\n\nvarnish.sess_linger(gauge)\n\nshown as connection/second\n\n\n\n\nvarnish.sess_pipe_overflow(gauge)\n\nshown as connection/second\n\n\n\n\nvarnish.sess_pipeline(gauge)\n\nshown as connection/second\n\n\n\n\nvarnish.sess_queued(gauge)\nClient connections queued to wait for a thread.shown as connection/second\n\n\n\n\nvarnish.sess_readahead(gauge)\n\nshown as connection/second\n\n\n\n\nvarnish.shm_cont(gauge)\nSHM MTX contention.shown as event/second\n\n\n\n\nvarnish.shm_cycles(gauge)\nSHM cycles through buffer.shown as event/second\n\n\n\n\nvarnish.shm_flushes(gauge)\nSHM flushes due to overflow.shown as event/second\n\n\n\n\nvarnish.shm_records(gauge)\nSHM records.shown as event/second\n\n\n\n\nvarnish.shm_writes(gauge)\nSHM writes.shown as event/second\n\n\n\n\nvarnish.SMA.s0.c_bytes(gauge)\nTotal space allocated by this storage.shown as byte/second\n\n\n\n\nvarnish.SMA.s0.c_fail(gauge)\nTimes the storage has failed to provide a storage segment.shown as event/second\n\n\n\n\nvarnish.SMA.s0.c_freed(gauge)\nTotal space returned to this storage.shown as byte/second\n\n\n\n\nvarnish.SMA.s0.c_req(gauge)\nTimes the storage has been asked to provide a storage segment.shown as event/second\n\n\n\n\nvarnish.SMA.s0.g_alloc(gauge)\nStorage allocations outstanding.shown as event\n\n\n\n\nvarnish.SMA.s0.g_bytes(gauge)\nSpace allocated from the storage.shown as byte\n\n\n\n\nvarnish.SMA.s0.g_space(gauge)\nSpace left in the storage.shown as byte\n\n\n\n\nvarnish.SMA.Transient.c_bytes(gauge)\nTotal space allocated by this storage.shown as byte/second\n\n\n\n\nvarnish.SMA.Transient.c_fail(gauge)\nTimes the storage has failed to provide a storage segment.shown as event/second\n\n\n\n\nvarnish.SMA.Transient.c_freed(gauge)\nTotal space returned to this storage.shown as byte/second\n\n\n\n\nvarnish.SMA.Transient.c_req(gauge)\nTimes the storage has been asked to provide a storage segment.shown as event/second\n\n\n\n\nvarnish.SMA.Transient.g_alloc(gauge)\nStorage allocations outstanding.shown as event\n\n\n\n\nvarnish.SMA.Transient.g_bytes(gauge)\nSpace allocated from the storage.shown as byte\n\n\n\n\nvarnish.SMA.Transient.g_space(gauge)\nSpace left in the storage.shown as byte\n\n\n\n\nvarnish.sms_balloc(gauge)\nSMS space allocated.shown as byte\n\n\n\n\nvarnish.sms_bfree(gauge)\nSMS space freed.shown as byte\n\n\n\n\nvarnish.sms_nbytes(gauge)\nSMS outstanding space.shown as byte\n\n\n\n\nvarnish.sms_nobj(gauge)\nSMS outstanding allocations.shown as event\n\n\n\n\nvarnish.sms_nreq(gauge)\nSMS allocator requests.shown as event/second\n\n\n\n\nvarnish.thread_queue_len(gauge)\nLength of session queue waiting for threads.shown as connection\n\n\n\n\nvarnish.threads(gauge)\nNumber of threads.shown as thread\n\n\n\n\nvarnish.threads_created(gauge)\nThreads created.shown as thread/second\n\n\n\n\nvarnish.threads_destroyed(gauge)\nThreads destroyed.shown as thread/second\n\n\n\n\nvarnish.threads_failed(gauge)\nThreads that failed to get created.shown as thread/second\n\n\n\n\nvarnish.threads_limited(gauge)\nThreads that were needed but couldn't be created because of a thread pool limit.shown as thread/second\n\n\n\n\nvarnish.uptime(gauge)\n\n\n\n\nvarnish.vmods(gauge)\nLoaded VMODs.shown as object\n\n\n\n\nvarnish.vsm_cooling(gauge)\nSpace which will soon (max 1 minute) be freed in the shared memory used to communicate with tools like varnishstat, varnishlog etc.shown as byte\n\n\n\n\nvarnish.vsm_free(gauge)\nFree space in the shared memory used to communicate with tools like varnishstat, varnishlog etc.shown as byte\n\n\n\n\nvarnish.vsm_overflow(gauge)\nData which does not fit in the shared memory used to communicate with tools like varnishstat, varnishlog etc.shown as byte\n\n\n\n\nvarnish.vsm_overflowed(gauge)\nTotal data which did not fit in the shared memory used to communicate with tools like varnishstat, varnishlog etc.shown as byte/second\n\n\n\n\nvarnish.vsm_used(gauge)\nUsed space in the shared memory used to communicate with tools like varnishstat, varnishlog etc.shown as byte\n\n\n\n\nWhile the above list contains all possible metrics from our Varnish integration, your environment\nmay show only a subset of these metrics depending on which version of Varnish you have installed.\n\nA breakdown by Varnish version is available below.\n\n\nVarnish 3.x\n\nvarnish.accept_fail\nvarnish.backend_busy\nvarnish.backend_conn\nvarnish.backend_fail\nvarnish.backend_recycle\nvarnish.backend_req\nvarnish.backend_retry\nvarnish.backend_reuse\nvarnish.backend_toolate\nvarnish.backend_unhealthy\nvarnish.backend_unused\nvarnish.cache_hit\nvarnish.cache_hitpass\nvarnish.cache_miss\nvarnish.client_conn\nvarnish.client_drop\nvarnish.client_drop_late\nvarnish.client_req\nvarnish.dir_dns_cache_full\nvarnish.dir_dns_failed\nvarnish.dir_dns_hit\nvarnish.dir_dns_lookups\nvarnish.esi_errors\nvarnish.esi_parse\nvarnish.esi_warnings\nvarnish.fetch_1xx\nvarnish.fetch_204\nvarnish.fetch_304\nvarnish.fetch_bad\nvarnish.fetch_chunked\nvarnish.fetch_close\nvarnish.fetch_eof\nvarnish.fetch_failed\nvarnish.fetch_head\nvarnish.fetch_length\nvarnish.fetch_oldhttp\nvarnish.fetch_zero\nvarnish.hcb_insert\nvarnish.hcb_lock\nvarnish.hcb_nolock\nvarnish.LCK.backend.colls\nvarnish.LCK.backend.creat\nvarnish.LCK.backend.destroy\nvarnish.LCK.backend.locks\nvarnish.LCK.ban.colls\nvarnish.LCK.ban.creat\nvarnish.LCK.ban.destroy\nvarnish.LCK.ban.locks\nvarnish.LCK.cli.colls\nvarnish.LCK.cli.creat\nvarnish.LCK.cli.destroy\nvarnish.LCK.cli.locks\nvarnish.LCK.exp.colls\nvarnish.LCK.exp.creat\nvarnish.LCK.exp.destroy\nvarnish.LCK.exp.locks\nvarnish.LCK.hcb.colls\nvarnish.LCK.hcb.creat\nvarnish.LCK.hcb.destroy\nvarnish.LCK.hcb.locks\nvarnish.LCK.hcl.colls\nvarnish.LCK.hcl.creat\nvarnish.LCK.hcl.destroy\nvarnish.LCK.hcl.locks\nvarnish.LCK.herder.colls\nvarnish.LCK.herder.creat\nvarnish.LCK.herder.destroy\nvarnish.LCK.herder.locks\nvarnish.LCK.hsl.colls\nvarnish.LCK.hsl.creat\nvarnish.LCK.hsl.destroy\nvarnish.LCK.hsl.locks\nvarnish.LCK.lru.colls\nvarnish.LCK.lru.creat\nvarnish.LCK.lru.destroy\nvarnish.LCK.lru.locks\nvarnish.LCK.objhdr.colls\nvarnish.LCK.objhdr.creat\nvarnish.LCK.objhdr.destroy\nvarnish.LCK.objhdr.locks\nvarnish.LCK.sessmem.colls\nvarnish.LCK.sessmem.creat\nvarnish.LCK.sessmem.destroy\nvarnish.LCK.sessmem.locks\nvarnish.LCK.sma.colls\nvarnish.LCK.sma.creat\nvarnish.LCK.sma.destroy\nvarnish.LCK.sma.locks\nvarnish.LCK.smf.colls\nvarnish.LCK.smf.creat\nvarnish.LCK.smf.destroy\nvarnish.LCK.smf.locks\nvarnish.LCK.smp.colls\nvarnish.LCK.smp.creat\nvarnish.LCK.smp.destroy\nvarnish.LCK.smp.locks\nvarnish.LCK.sms.colls\nvarnish.LCK.sms.creat\nvarnish.LCK.sms.destroy\nvarnish.LCK.sms.locks\nvarnish.LCK.stat.colls\nvarnish.LCK.stat.creat\nvarnish.LCK.stat.destroy\nvarnish.LCK.stat.locks\nvarnish.LCK.vbe.colls\nvarnish.LCK.vbe.creat\nvarnish.LCK.vbe.destroy\nvarnish.LCK.vbe.locks\nvarnish.LCK.vbp.colls\nvarnish.LCK.vbp.creat\nvarnish.LCK.vbp.destroy\nvarnish.LCK.vbp.locks\nvarnish.LCK.vcl.colls\nvarnish.LCK.vcl.creat\nvarnish.LCK.vcl.destroy\nvarnish.LCK.vcl.locks\nvarnish.LCK.wq.colls\nvarnish.LCK.wq.creat\nvarnish.LCK.wq.destroy\nvarnish.LCK.wq.locks\nvarnish.LCK.wstat.colls\nvarnish.LCK.wstat.creat\nvarnish.LCK.wstat.destroy\nvarnish.LCK.wstat.locks\nvarnish.losthdr\nvarnish.n_backend\nvarnish.n_deathrow\nvarnish.n_ban\nvarnish.n_ban_add\nvarnish.n_ban_dups\nvarnish.n_ban_obj_test\nvarnish.n_ban_re_test\nvarnish.n_ban_retire\nvarnish.n_expired\nvarnish.n_gunzip\nvarnish.n_gzip\nvarnish.n_lru_moved\nvarnish.n_lru_nuked\nvarnish.n_lru_saved\nvarnish.n_object\nvarnish.n_objectcore\nvarnish.n_objecthead\nvarnish.n_objoverflow\nvarnish.n_objsendfile\nvarnish.n_objwrite\nvarnish.n_purge\nvarnish.n_purge_add\nvarnish.n_purge_dups\nvarnish.n_purge_obj_test\nvarnish.n_purge_re_test\nvarnish.n_purge_retire\nvarnish.n_sess\nvarnish.n_sess_mem\nvarnish.n_smf\nvarnish.n_smf_frag\nvarnish.n_smf_large\nvarnish.n_vampireobject\nvarnish.n_vbe_conn\nvarnish.n_vbc\nvarnish.n_vcl\nvarnish.n_vcl_avail\nvarnish.n_vcl_discard\nvarnish.n_waitinglist\nvarnish.n_wrk\nvarnish.n_wrk_create\nvarnish.n_wrk_drop\nvarnish.n_wrk_failed\nvarnish.n_wrk_lqueue\nvarnish.n_wrk_max\nvarnish.n_wrk_overflow\nvarnish.n_wrk_queue\nvarnish.n_wrk_queued\nvarnish.s_bodybytes\nvarnish.s_fetch\nvarnish.s_hdrbytes\nvarnish.s_pass\nvarnish.s_pipe\nvarnish.s_req\nvarnish.s_sess\nvarnish.sess_closed\nvarnish.sess_herd\nvarnish.sess_linger\nvarnish.sess_pipeline\nvarnish.sess_readahead\nvarnish.shm_cont\nvarnish.shm_cycles\nvarnish.shm_flushes\nvarnish.shm_records\nvarnish.shm_writes\nvarnish.sm_balloc\nvarnish.sm_bfree\nvarnish.sm_nobj\nvarnish.sm_nreq\nvarnish.sma_balloc\nvarnish.sma_bfree\nvarnish.sma_nbytes\nvarnish.sma_nobj\nvarnish.sma_nreq\nvarnish.SMA.s0.c_bytes\nvarnish.SMA.s0.c_fail\nvarnish.SMA.s0.c_freed\nvarnish.SMA.s0.c_req\nvarnish.SMA.s0.g_alloc\nvarnish.SMA.s0.g_bytes\nvarnish.SMA.s0.g_space\nvarnish.SMA.Transient.c_bytes\nvarnish.SMA.Transient.c_fail\nvarnish.SMA.Transient.c_freed\nvarnish.SMA.Transient.c_req\nvarnish.SMA.Transient.g_alloc\nvarnish.SMA.Transient.g_bytes\nvarnish.SMA.Transient.g_space\nvarnish.sms_balloc\nvarnish.sms_bfree\nvarnish.sms_nbytes\nvarnish.sms_nobj\nvarnish.sms_nreq\nvarnish.uptime\n\n\n\nVarnish 4.x\n\nvarnish.backend_busy\nvarnish.backend_conn\nvarnish.backend_fail\nvarnish.backend_recycle\nvarnish.backend_req\nvarnish.backend_retry\nvarnish.backend_reuse\nvarnish.backend_toolate\nvarnish.backend_unhealthy\nvarnish.bans\nvarnish.bans_added\nvarnish.bans_completed\nvarnish.bans_deleted\nvarnish.bans_dups\nvarnish.bans_lurker_contention\nvarnish.bans_lurker_obj_killed\nvarnish.bans_lurker_tested\nvarnish.bans_lurker_tests_tested\nvarnish.bans_obj\nvarnish.bans_obj_killed\nvarnish.bans_persisted_bytes\nvarnish.bans_persisted_fragmentation\nvarnish.bans_req\nvarnish.bans_tested\nvarnish.bans_tests_tested\nvarnish.busy_sleep\nvarnish.busy_wakeup\nvarnish.cache_hit\nvarnish.cache_hitpass\nvarnish.cache_miss\nvarnish.client_req\nvarnish.client_req_400\nvarnish.client_req_411\nvarnish.client_req_413\nvarnish.client_req_417\nvarnish.esi_errors\nvarnish.esi_warnings\nvarnish.exp_mailed\nvarnish.exp_received\nvarnish.fetch_1xx\nvarnish.fetch_204\nvarnish.fetch_304\nvarnish.fetch_bad\nvarnish.fetch_chunked\nvarnish.fetch_close\nvarnish.fetch_eof\nvarnish.fetch_failed\nvarnish.fetch_head\nvarnish.fetch_length\nvarnish.fetch_no_thread\nvarnish.fetch_oldhttp\nvarnish.fetch_zero\nvarnish.hcb_insert\nvarnish.hcb_lock\nvarnish.hcb_nolock\nvarnish.LCK.backend.creat\nvarnish.LCK.backend.destroy\nvarnish.LCK.backend.locks\nvarnish.LCK.ban.creat\nvarnish.LCK.ban.destroy\nvarnish.LCK.ban.locks\nvarnish.LCK.busyobj.creat\nvarnish.LCK.busyobj.destroy\nvarnish.LCK.busyobj.locks\nvarnish.LCK.cli.creat\nvarnish.LCK.cli.destroy\nvarnish.LCK.cli.locks\nvarnish.LCK.exp.creat\nvarnish.LCK.exp.destroy\nvarnish.LCK.exp.locks\nvarnish.LCK.hcb.creat\nvarnish.LCK.hcb.destroy\nvarnish.LCK.hcb.locks\nvarnish.LCK.hcl.creat\nvarnish.LCK.hcl.destroy\nvarnish.LCK.hcl.locks\nvarnish.LCK.herder.creat\nvarnish.LCK.herder.destroy\nvarnish.LCK.herder.locks\nvarnish.LCK.hsl.creat\nvarnish.LCK.hsl.destroy\nvarnish.LCK.hsl.locks\nvarnish.LCK.lru.creat\nvarnish.LCK.lru.destroy\nvarnish.LCK.lru.locks\nvarnish.LCK.mempool.creat\nvarnish.LCK.mempool.destroy\nvarnish.LCK.mempool.locks\nvarnish.LCK.nbusyobj.creat\nvarnish.LCK.nbusyobj.destroy\nvarnish.LCK.nbusyobj.locks\nvarnish.LCK.objhdr.creat\nvarnish.LCK.objhdr.destroy\nvarnish.LCK.objhdr.locks\nvarnish.LCK.pipestat.creat\nvarnish.LCK.pipestat.destroy\nvarnish.LCK.pipestat.locks\nvarnish.LCK.sess.creat\nvarnish.LCK.sess.destroy\nvarnish.LCK.sess.locks\nvarnish.LCK.sessmem.creat\nvarnish.LCK.sessmem.destroy\nvarnish.LCK.sessmem.locks\nvarnish.LCK.sma.creat\nvarnish.LCK.sma.destroy\nvarnish.LCK.sma.locks\nvarnish.LCK.smf.creat\nvarnish.LCK.smf.destroy\nvarnish.LCK.smf.locks\nvarnish.LCK.smp.creat\nvarnish.LCK.smp.destroy\nvarnish.LCK.smp.locks\nvarnish.LCK.sms.creat\nvarnish.LCK.sms.destroy\nvarnish.LCK.sms.locks\nvarnish.LCK.vbp.creat\nvarnish.LCK.vbp.destroy\nvarnish.LCK.vbp.locks\nvarnish.LCK.vcapace.creat\nvarnish.LCK.vcapace.destroy\nvarnish.LCK.vcapace.locks\nvarnish.LCK.vcl.creat\nvarnish.LCK.vcl.destroy\nvarnish.LCK.vcl.locks\nvarnish.LCK.vxid.creat\nvarnish.LCK.vxid.destroy\nvarnish.LCK.vxid.locks\nvarnish.LCK.wq.creat\nvarnish.LCK.wq.destroy\nvarnish.LCK.wq.locks\nvarnish.LCK.wstat.creat\nvarnish.LCK.wstat.destroy\nvarnish.LCK.wstat.locks\nvarnish.losthdr\nvarnish.MEMPOOL.busyobj.allocs\nvarnish.MEMPOOL.busyobj.frees\nvarnish.MEMPOOL.busyobj.live\nvarnish.MEMPOOL.busyobj.pool\nvarnish.MEMPOOL.busyobj.randry\nvarnish.MEMPOOL.busyobj.recycle\nvarnish.MEMPOOL.busyobj.surplus\nvarnish.MEMPOOL.busyobj.sz_needed\nvarnish.MEMPOOL.busyobj.sz_wanted\nvarnish.MEMPOOL.busyobj.timeout\nvarnish.MEMPOOL.busyobj.toosmall\nvarnish.MEMPOOL.req0.allocs\nvarnish.MEMPOOL.req0.frees\nvarnish.MEMPOOL.req0.live\nvarnish.MEMPOOL.req0.pool\nvarnish.MEMPOOL.req0.randry\nvarnish.MEMPOOL.req0.recycle\nvarnish.MEMPOOL.req0.surplus\nvarnish.MEMPOOL.req0.sz_needed\nvarnish.MEMPOOL.req0.sz_wanted\nvarnish.MEMPOOL.req0.timeout\nvarnish.MEMPOOL.req0.toosmall\nvarnish.MEMPOOL.req1.allocs\nvarnish.MEMPOOL.req1.frees\nvarnish.MEMPOOL.req1.live\nvarnish.MEMPOOL.req1.pool\nvarnish.MEMPOOL.req1.randry\nvarnish.MEMPOOL.req1.recycle\nvarnish.MEMPOOL.req1.surplus\nvarnish.MEMPOOL.req1.sz_needed\nvarnish.MEMPOOL.req1.sz_wanted\nvarnish.MEMPOOL.req1.timeout\nvarnish.MEMPOOL.req1.toosmall\nvarnish.MEMPOOL.sess0.allocs\nvarnish.MEMPOOL.sess0.frees\nvarnish.MEMPOOL.sess0.live\nvarnish.MEMPOOL.sess0.pool\nvarnish.MEMPOOL.sess0.randry\nvarnish.MEMPOOL.sess0.recycle\nvarnish.MEMPOOL.sess0.surplus\nvarnish.MEMPOOL.sess0.sz_needed\nvarnish.MEMPOOL.sess0.sz_wanted\nvarnish.MEMPOOL.sess0.timeout\nvarnish.MEMPOOL.sess0.toosmall\nvarnish.MEMPOOL.sess1.allocs\nvarnish.MEMPOOL.sess1.frees\nvarnish.MEMPOOL.sess1.live\nvarnish.MEMPOOL.sess1.pool\nvarnish.MEMPOOL.sess1.randry\nvarnish.MEMPOOL.sess1.recycle\nvarnish.MEMPOOL.sess1.surplus\nvarnish.MEMPOOL.sess1.sz_needed\nvarnish.MEMPOOL.sess1.sz_wanted\nvarnish.MEMPOOL.sess1.timeout\nvarnish.MEMPOOL.sess1.toosmall\nvarnish.MEMPOOL.vbc.allocs\nvarnish.MEMPOOL.vbc.frees\nvarnish.MEMPOOL.vbc.live\nvarnish.MEMPOOL.vbc.pool\nvarnish.MEMPOOL.vbc.randry\nvarnish.MEMPOOL.vbc.recycle\nvarnish.MEMPOOL.vbc.surplus\nvarnish.MEMPOOL.vbc.sz_needed\nvarnish.MEMPOOL.vbc.sz_wanted\nvarnish.MEMPOOL.vbc.timeout\nvarnish.MEMPOOL.vbc.toosmall\nvarnish.MGT.child_died\nvarnish.MGT.child_dump\nvarnish.MGT.child_exit\nvarnish.MGT.child_panic\nvarnish.MGT.child_start\nvarnish.MGT.child_stop\nvarnish.MGT.uptime\nvarnish.n_backend\nvarnish.n_expired\nvarnish.n_gunzip\nvarnish.n_gzip\nvarnish.n_lru_moved\nvarnish.n_lru_nuked\nvarnish.n_obj_purged\nvarnish.n_object\nvarnish.n_objectcore\nvarnish.n_objecthead\nvarnish.n_purges\nvarnish.n_vampireobject\nvarnish.n_vcl\nvarnish.n_vcl_avail\nvarnish.n_vcl_discard\nvarnish.n_waitinglist\nvarnish.pools\nvarnish.s_fetch\nvarnish.s_pass\nvarnish.s_pipe\nvarnish.s_pipe_hdrbytes\nvarnish.s_pipe_in\nvarnish.s_pipe_out\nvarnish.s_req\nvarnish.s_req_bodybytes\nvarnish.s_req_hdrbytes\nvarnish.s_resp_bodybytes\nvarnish.s_resp_hdrbytes\nvarnish.s_sess\nvarnish.s_synth\nvarnish.sess_closed\nvarnish.sess_conn\nvarnish.sess_drop\nvarnish.sess_dropped\nvarnish.sess_fail\nvarnish.sess_herd\nvarnish.sess_pipe_overflow\nvarnish.sess_pipeline\nvarnish.sess_queued\nvarnish.sess_readahead\nvarnish.shm_cont\nvarnish.shm_cycles\nvarnish.shm_flushes\nvarnish.shm_records\nvarnish.shm_writes\nvarnish.SMA.s0.c_bytes\nvarnish.SMA.s0.c_fail\nvarnish.SMA.s0.c_freed\nvarnish.SMA.s0.c_req\nvarnish.SMA.s0.g_alloc\nvarnish.SMA.s0.g_bytes\nvarnish.SMA.s0.g_space\nvarnish.SMA.Transient.c_bytes\nvarnish.SMA.Transient.c_fail\nvarnish.SMA.Transient.c_freed\nvarnish.SMA.Transient.c_req\nvarnish.SMA.Transient.g_alloc\nvarnish.SMA.Transient.g_bytes\nvarnish.SMA.Transient.g_space\nvarnish.sms_balloc\nvarnish.sms_bfree\nvarnish.sms_nbytes\nvarnish.sms_nobj\nvarnish.sms_nreq\nvarnish.thread_queue_len\nvarnish.threads\nvarnish.threads_created\nvarnish.threads_destroyed\nvarnish.threads_failed\nvarnish.threads_limited\nvarnish.uptime\nvarnish.VBE.default_127.0.0.1_80.bereq_bodybytes\nvarnish.VBE.default_127.0.0.1_80.bereq_hdrbytes\nvarnish.VBE.default_127.0.0.1_80.beresp_bodybytes\nvarnish.VBE.default_127.0.0.1_80.beresp_hdrbytes\nvarnish.VBE.default_127.0.0.1_80.pipe_hdrbytes\nvarnish.VBE.default_127.0.0.1_80.pipe_in\nvarnish.VBE.default_127.0.0.1_80.pipe_out\nvarnish.VBE.default_127.0.0.1_80.vcls\nvarnish.vmods\nvarnish.vsm_cooling\nvarnish.vsm_free\nvarnish.vsm_overflow\nvarnish.vsm_overflowed\nvarnish.vsm_used\n\n\n","tags":"","loc":"/integrations/varnish/"},{"title":"Datadog-VictorOps Integration","text":"\n\nEnable Datadog integration on VictorOps\n\n\n  On your VictorOps settings page, click “Integrations”\n  Click “Datadog”, then “Enable Integration”\n  Copy your key\n  Back to Datadog, paste the API key in the next section here\n\n\n\nVictorOps Routing Keys\n\nDirect alerts to certain VictorOps users\nPlease list all the routing keys to be used on Datadog (if none are set up here, VictorOps will send the alert to the default group).\n\nYou will then be able to choose which VictorOps endpoint should receive the alert by using @victorops\n\nSpecial characters are not allowed in the names. Upper/lower case letters, numbers, ‘_’ and ‘-‘ are allowed.\n\n\nChoose a custom endpoint\n\nIf this field is left empty, the default endpoint will be ‘https://alert.victorops.com/integrations/datadog/20140523/alert’\n","tags":"","loc":"/integrations/victorops/"},{"title":"Datadog-VMware Integration","text":"\n\nOverview\n\n\n\nInstall the Datadog VMware vSphere integration to:\n\n\n  Get your performance metrics from vSphere and see them all in Datadog.\n  Get vSphere events in Datadog and overlay them on top of your metrics (vMotion, configuration changes, on/off…).\n  Interact with your teams on dashboards and the event stream, showing all vSphere data at one glance.\n\n\nWe also have an awesome blog post on vSphere which can be seen here.\n\n\nInstallation\n\n\n  Install the Datadog windows agent on your vCenter server.\n  \n    Create a Datadog user in the Administration section of vCenter, you can use the default Read-Only access group.\n\n    \n  \n\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to your vCenter instance. Edit conf.d/vsphere.yaml:\n\n    init_config:\n\ninstances:\n  - name: main-vcenter\n    host: vcenter.domain.com\n    username: datadog-readonly@vsphere.local\n    password: mypassword\n\n  \n  \n    Restart the Agent\n  \n\n\n\nConfiguration Options\n\n\n  \nssl_verify (Optional) - Set to false to disable SSL verification, when connecting to vCenter optional\n  \nssl_capath (Optional) - Set to the absolute file path of a directory containing CA certificates in PEM format\n  \nhost_include_only_regex (Optional) - Use a regex like this if you want only the check to fetch metrics for these ESXi hosts and the VMs running on it\n  \nvm_include_only_regex (Optional) - Use a regex to include only the VMs that are matching this pattern.\n  \ninclude_only_marked (Optional) - Set to true if you’d like to only collect metrics on vSphere VMs which are marked by a custom field with the value ‘DatadogMonitored’. To set this custom field with PowerCLI, use the follow command: Get-VM <MyVMName> | Set-CustomField -Name \"DatadogMonitored\" -Value \"DatadogMonitored\"\n\n  \nall_metrics (Optional) - When set to true, this will collect EVERY metric from vCenter, which means a LOT of metrics you probably do not care about. We have selected a set of metrics that are interesting to monitor for you if false.\n  \nevent_config (Optional) - Event config is a dictionary. For now the only switch you can flip is collect_vcenter_alarms which will send as events the alarms set in vCenter.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nVMware YAML example\nVMware checks.d\n\n\n\nValidation\n\nExecute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  vsphere\n  -------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\nvsphere.cpu.extra(gauge)\nMilliseconds of extra CPU time.shown as millisecond\n\n\n\n\nvsphere.cpu.ready(gauge)\nMilliseconds of CPU time spent in ready state.shown as millisecond\n\n\n\n\nvsphere.cpu.usage(gauge)\nPercentage of CPU capacity being used.shown as percent\n\n\n\n\nvsphere.cpu.usagemhz(gauge)\nTotal megehertz of CPU being used.shown as megahertz\n\n\n\n\nvsphere.disk.commandsAborted(gauge)\nNumber of SCSI commands aborted.shown as occurrence\n\n\n\n\nvsphere.disk.deviceLatency(gauge)\nAverage amount of time it takes to complete an SCSI command from physical device.shown as millisecond\n\n\n\n\nvsphere.disk.deviceReadLatency(gauge)\nAverage amount of time it takes to complete read from physical device.shown as millisecond\n\n\n\n\nvsphere.disk.deviceWriteLatency(gauge)\nAverage amount of time it takes to complete write to the physical device (LUN).shown as millisecond\n\n\n\n\nvsphere.disk.queueLatency(gauge)\nAverage amount of time spent in VMkernel queue (per SCSI command).shown as millisecond\n\n\n\n\nvsphere.disk.totalLatency(gauge)\nSum of average amount of time (in kernel and device) to process an SCSI command issued by the Guest OS to the vm.shown as millisecond\n\n\n\n\nvsphere.mem.active(gauge)\nKilobytes of memory that the VMkernel estimates is being actively used based on recently touched memory pages.shown as kibibyte\n\n\n\n\nvsphere.mem.compressed(gauge)\nKilobytes of memory that have been compressed.shown as kibibyte\n\n\n\n\nvsphere.mem.consumed(gauge)\nKilobytes of used memory.shown as kibibyte\n\n\n\n\nvsphere.mem.overhead(gauge)\nKilobytes of memory allocated to a vm beyond its reserved amount.shown as kibibyte\n\n\n\n\nvsphere.mem.vmmemctl(gauge)\nKilobytes of memory allocated by the virtual machine memory control driver (vmmemctl).shown as kibibyte\n\n\n\n\nvsphere.network.received(rate)\nNumber of kilobytes received by the host.shown as kibibyte\n\n\n\n\nvsphere.network.transmitted(rate)\nNumber of kilobytes transmitted by the host.shown as kibibyte\n\n\n\n\n\nTroubleshooting\n\nHow should the Datadog Agent be set up with vCenter and ESX?\n\n\n\nHow will a VMware integration impact my monthly billing?\n\nThe base pricing is $15 per virtual machine per month. For general info on Datadog pricing, please visit our Billing FAQ page.\n\n","tags":"","loc":"/integrations/vmware/"},{"title":"Datadog-Webhooks Integration","text":"\n\nOverview\n\nWith Webhooks you’ll be able to:\n\n\n  Connect to your services.\n  Alert your services when a metric alert is triggered.\n\n\n\nConfiguration\n\nGo to the webhook integration tile and enter the URL and name of the webhook you want to use\n\n\nUsage\n\nTo use your webhook, add @webhook-name_of_the_webhook in the text of the metric alert you want to trigger the webhook. It will trigger a POST request to the URL you set with the following content in JSON format.\n\nYou can also specify your own payload in order to add your own custom fields to the request. Check the Use Custom Payload checkbox and specify your own custom payload, using the following variables. If you want your payload to be URL-encoded, check the Encode as form payload and specify your payload in a json format.\n\n\n  \n    \n      Variable\n      Meaning\n    \n  \n  \n    \n      $ID\n      ID of the event (ex: 1234567)\n\n    \n    \n      $EVENT_TITLE\n      Title of the event (ex: [Triggered] [Memory Alert])\n\n    \n    \n      $EVENT_MSG\n      Text of the event (ex: @webhook-url Sending to the webhook)\n\n    \n    \n      $EVENT_TYPE\n      Type of the event (values: metric_alert_monitor, event_alert, or service_check)\n\n    \n    \n      $LAST_UPDATED\n      Date when the event was last updated .\n    \n    \n      $DATE\n      Date (epoch) where the event happened (ex: 1406662672000)\n\n    \n    \n      $AGGREG_KEY\n      ID to aggregate events belonging together (ex: 9bd4ac313a4d1e8fae2482df7b77628)\n\n    \n    \n      $ORG_ID\n      ID of your organization (ex: 11023)\n\n    \n    \n      $ORG_NAME\n      Name of your organization (ex: Datadog)\n\n    \n    \n      $USER\n      User posting the event that triggered the webhook (ex: rudy)\n\n    \n    \n      $SNAPSHOT\n      Url of the image if the event contains a snapshot (ex: https://url.to.snpashot.com/)\n\n    \n    \n      $LINK\n      Url of the event (ex: https://app.datadoghq.com/event/jump_to?event_id=123456)\n\n    \n    \n      $PRIORITY\n      Priority of the event (values: normal or low)\n\n    \n    \n      $TAGS\n      Comma-separated list of the event tags (ex: monitor, name:myService, role:computing-node)\n\n    \n    \n      $ALERT_ID\n      ID of alert (ex: 1234)\n\n    \n    \n      $ALERT_TITLE\n      Title of the alert\n    \n    \n      $ALERT_METRIC\n      Name of the metric if it’s an alert (ex: system.load.1)\n\n    \n    \n      $ALERT_SCOPE\n      Comma-separated list of tags triggering the alert (ex: availability-zone:us-east-1a, role:computing-node)\n\n    \n    \n      $ALERT_QUERY\n      Query of the monitor that triggered the webhook\n    \n    \n      $ALERT_STATUS\n      Summary of the alert status (ex: system.load.1 over host:my-host was > 0 at least once during the last 1m)\n\n    \n    \n      $ALERT_TRANSITION\n      Type of alert notification (values: Triggered or Recovered)\n\n    \n  \n\n\nIf you want to post your webhooks to a service requiring authentication, you can Basic HTTP authentication my modifing your URL from https://my.service.com to https://username:password@my.service.com.\n\n\nExamples\n\n\nSending SMS through Twilio\n\nUse as URL:\nhttps://{Your-Account-id}:{Your-Auth-Token}@api.twilio.com/2010-04-01/Accounts/{Your-Account-id}/Messages.json\nand as payload\n\n{\n    \"To\":\"+1347XXXXXXX\",\n    \"From\":\"+1347XXXXXX\",\n    \"Body\":\"$EVENT_TITLE \\n Related Graph: $SNAPSHOT\"\n}\n\n\nreplacing To with your phone number and From with the one twilio attributed to you. Check the Encode as form checkbox.\n\n\nCreating an issue in Jira\n\nUse as URL:\nhttps://{Your-Jira-Username}:{Your-Jira-Password}@{Your-Domain}.atlassian.net/rest/api/2/issue\nand as payload\n\n{\n    \"fields\": {\n        \"project\": {\n            \"key\": \"YOUR-PROJECT-KEY\"\n            },\n        \"issuetype\": {\n            \"name\": \"Task\"\n        },\n        \"description\": \"There's an issue. See the graph: $SNAPSHOT and event: $LINK\",\n        \"summary\": \"$EVENT_TITLE\"\n    }\n}\n\nDon’t check the “Encode as form” checkbox.\n","tags":"","loc":"/integrations/webhooks/"},{"title":"Datadog-Windows Services Integration","text":"\n\nOverview\n\nMonitor the state of your Windows Services.\n\n\n\n\nConfiguration\n\nConfigure the Agent using the Agent Manager\n\n\n  \n    Edit the “Windows Service” configuration in the Agent Manager.\n\n    init_config:\n\ninstances:\n  # For each instance you define what host to connect to (defaulting to the\n  # current host) as well as a list of services you care about. The service\n  # names should match the Service name in the properties and NOT the display\n  # name in the services.msc list.\n  #\n  # If you want to check services on a remote host, you have to specify a\n  # hostname and (optional) credentials\n  #\n  #-  host: MYREMOTESERVER\n  #   username: MYREMOTESERVER\\fred\n  #   password: mysecretpassword\n  #   tags:\n  #     - fredserver\n  #\n  # The sample configuration will monitor the WMI Performance Adapter service,\n  # named \"wmiApSrv\" in the service properties.\n  #\n  - host: . # \".\" means the current host\n    services:\n      - wmiApSrv # service names are not case-sensitive\n\n  \n  \n    Restart the agent.\n  \n\n\n\nValidation\n\nAfter you restart the agent, check the info page in the Agent Manager and verify that the integration check has passed. It should display a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  windows_service\n  ---------------\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nWindows Services YAML example\nWindows Services checks.d\n\n\n","tags":"","loc":"/integrations/winservices/"},{"title":"Datadog-WMI Integration","text":"\n\nOverview\n\n\n\nGet metrics from your Windows applications/servers with Windows Management Instrumentation (WMI) in real time to\n\n\n  Visualize their performance.\n  Correlate their activity with the rest of your applications.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nWMI YAML example\nWMI checks.d\n\n\n\nInstallation\n\nIf you are only collecting standard metrics from Microsoft Windows and other packaged applications, there are no installation steps. If you need to define new metrics to collect from your application, then you have a few options:\n\n\n  Submit perfomance counters using System.Diagnostics in .NET, then access them via WMI.\n  Implement a COM-based WMI provider for your application. You would typically only do this if you are using a non-.NET language.\n\n\nTo learn more about using System.Diagnostics, refer to the MSDN documentation here. After adding your metric you should be able to find it in WMI. To browse the WMI namespaces you may find this tool useful: WMI Explorer. You can find the same information with Powershell here. Also review the information in the Datadog Knowledge Base article.\n\nIf you assign the new metric a category of My_New_Metric, the WMI path will be \n\\\\<ComputerName>\\ROOT\\CIMV2:Win32_PerfFormattedData_My_New_Metric\n\nIf the metric isn’t showing up in WMI, try running winmgmt /resyncperf to force the computer to reregister the performance libraries with WMI.\n\n\nConfiguration\n\n\n  Click the Install Integration button on the WMI Integration Tile. \n  Open the Datadog Agent Manager on the Windows server.\n  \n    Edit the Wmi Check configuration.\n\n    init_config:\n\ninstances:\n  - class: Win32_OperatingSystem\n    metrics:\n      - [NumberOfProcesses, system.proc.count, gauge]\n      - [NumberOfUsers, system.users.count, gauge]\n\n  - class: Win32_PerfFormattedData_PerfProc_Process\n    metrics:\n      - [ThreadCount, proc.threads.count, gauge]\n      - [VirtualBytes, proc.mem.virtual, gauge]\n      - [PercentProcessorTime, proc.cpu_pct, gauge]\n    tag_by: Name\n\n  - class: Win32_PerfFormattedData_PerfProc_Process\n    metrics:\n      - [IOReadBytesPerSec, proc.io.bytes_read, gauge]\n    tag_by: Name\n    tag_queries:\n      - [IDProcess, Win32_Process, Handle, CommandLine]\n\n\n    Note that the default configuration uses the filter clause to limit the metrics pulled. Either set the filters to valid values or remove them as shown above to collect the metrics.\n\n    The metrics definitions include three components: class property in WMI, metric name as it appears in Datadog, and the metric type. \n  \n  Restart the agent.\n\n\n\nConfiguration Options\n\nEach WMI query has 2 required options, class and metrics and six optional options, host, namespace, filters, provider, tag_by, constant_tags and tag_queries.\n\nclass is the name of the WMI class, for example Win32_OperatingSystem or Win32_PerfFormattedData_PerfProc_Process. You can find many of the standard class names on the MSDN docs. The Win32_FormattedData_* classes provide many useful performance counters by default.\n\nmetrics is a list of metrics you want to capture, with each item in the\nlist being a set of [WMI property name, metric name, metric type].\n\n\n  \n    The property name is something like NumberOfUsers or ThreadCount.\nThe standard properties are also available on the MSDN docs for each\nclass.\n  \n  \n    The metric name is the name you want to show up in Datadog.\n  \n  \n    The metric type is from the standard choices for all agent checks, such as gauge, rate, histogram or counter.\n  \n\n\nhost is the optional target of the WMI query, localhost is assumed by default. If you set this option, make sure that Remote Management is enabled on the target host see here for more information.\n\nnamespace is the optionnal WMI namespace to connect to (default to cimv2). \n\nfilters is a list of filters on the WMI query you may want. For example, for a process-based WMI class you may want metrics for only certain processes running on your machine, so you could add a filter for each process name. You can also use the ‘%’ character as a wildcard.\n\nprovider is the optional WMI provider (default to 32 on Datadog Agent 32-bit or 64). It is used to request WMI data from the non-default provider. Available options are: 32 or 64.\nSee MSDN for more information.\n\ntag_by optionally lets you tag each metric with a property from the WMI class you’re using. This is only useful when you will have multiple values for your WMI query. The examples below show how you can tag your process metrics with the process name (giving a tag of “name:app_name”).\n\nconstant_tags optionally lets you tag each metric with a set of fixed values.\n\ntag_queries optionally lets you specify a list of queries, to tag metrics with a target class property. Each item in the list is a set of [link source property, target class, link target class property, target property] where:\n\n\n  \n    ‘link source property’ contains the link value\n  \n  \n    ‘target class’ is the class to link to\n  \n  \n    ‘link target class property’ is the target class property to link to\n  \n  \n    ‘target property’ contains the value to tag with\n  \n\n\nIt translates to a WMI query:\n\nSELECT 'target property' FROM 'target class' WHERE 'link target class property' = 'link source property'\n\n\nNote: setting this will cause any instance number to be removed from tag_by values\n i.e. name:process#1 => name:process\n\nThis feature is available starting with version 5.3 of the agent\n\n\nValidation\n\nTo validate your installation and configuration, click the Agent Status menu from the Logs and Status button. The output should contain a section similar to the following:\n\n\n\n","tags":"","loc":"/integrations/wmi/"},{"title":"Datadog-Hadoop YARN Integration","text":"\n\nOverview\n\n\n\nCapture Yarn metrics to:\n\n\n  Visualize cluster health, performance, and utilization.\n  Analyze and inspect individual application performance.\n\n\n\nConfiguration\n\nInstall Datadog Agent on the ResourceManager\n\n\n  \n    Configure the agent to connect to the ResourceManager: Edit conf.d/yarn.yaml\n\n    init_config:\n\ninstances:\n    -   resourcemanager_address: localhost\n        resourcemanager_port: 8088\n\n  \n  \n    Restart the Agent\n  \n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nHadoop YARN YAML example\nHadoop YARN checks.d\n\n\n\nValidation\n\nExecute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  yarn\n  ----\n      - instance #0 [OK]\n      - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\nyarn.metrics.apps_submitted(gauge)\nThe number of submitted appsshown as task\n\n\n\n\nyarn.metrics.apps_completed(gauge)\nThe number of completed appsshown as task\n\n\n\n\nyarn.metrics.apps_pending(gauge)\nThe number of pending appsshown as task\n\n\n\n\nyarn.metrics.apps_running(gauge)\nThe number of running appsshown as task\n\n\n\n\nyarn.metrics.apps_failed(gauge)\nThe number of failed appsshown as task\n\n\n\n\nyarn.metrics.apps_killed(gauge)\nThe number of killed appsshown as task\n\n\n\n\nyarn.metrics.reserved_mb(gauge)\nThe size of reserved memoryshown as mebibyte\n\n\n\n\nyarn.metrics.available_mb(gauge)\nThe amount of available memoryshown as mebibyte\n\n\n\n\nyarn.metrics.allocated_mb(gauge)\nThe amount of allocated memoryshown as mebibyte\n\n\n\n\nyarn.metrics.total_mb(gauge)\nThe amount of total memoryshown as mebibyte\n\n\n\n\nyarn.metrics.reserved_virtual_cores(gauge)\nThe number of reserved virtual coresshown as core\n\n\n\n\nyarn.metrics.available_virtual_cores(gauge)\nThe number of available virtual coresshown as core\n\n\n\n\nyarn.metrics.allocated_virtual_cores(gauge)\nThe number of allocated virtual coresshown as core\n\n\n\n\nyarn.metrics.total_virtual_cores(gauge)\nThe total number of virtual coresshown as core\n\n\n\n\nyarn.metrics.containers_allocated(gauge)\nThe number of containers allocated\n\n\n\n\nyarn.metrics.containers_reserved(gauge)\nThe number of containers reserved\n\n\n\n\nyarn.metrics.containers_pending(gauge)\nThe number of containers pending\n\n\n\n\nyarn.metrics.total_nodes(gauge)\nThe total number of nodesshown as node\n\n\n\n\nyarn.metrics.active_nodes(gauge)\nThe number of active nodesshown as node\n\n\n\n\nyarn.metrics.lost_nodes(gauge)\nThe number of lost nodesshown as node\n\n\n\n\nyarn.metrics.unhealthy_nodes(gauge)\nThe number of unhealthy nodesshown as node\n\n\n\n\nyarn.metrics.decommissioned_nodes(gauge)\nThe number of decommissioned nodesshown as node\n\n\n\n\nyarn.metrics.rebooted_nodes(gauge)\nThe number of rebooted nodesshown as node\n\n\n\n\nyarn.apps.progress(rate)\nThe progress of the application as a percentshown as percent\n\n\n\n\nyarn.apps.started_time(rate)\nThe time in which application started (in ms since epoch)shown as second\n\n\n\n\nyarn.apps.finished_time(rate)\nThe time in which the application finished (in ms since epoch)shown as second\n\n\n\n\nyarn.apps.elapsed_time(rate)\nThe elapsed time since the application started (in ms)shown as second\n\n\n\n\nyarn.apps.allocated_mb(rate)\nThe sum of memory in MB allocated to the applications running containersshown as mebibyte\n\n\n\n\nyarn.apps.allocated_vcores(rate)\nThe sum of virtual cores allocated to the applications running containersshown as core\n\n\n\n\nyarn.apps.running_containers(rate)\nThe number of containers currently running for the application\n\n\n\n\nyarn.apps.memory_seconds(rate)\nThe amount of memory the application has allocated (megabyte-seconds)shown as second\n\n\n\n\nyarn.apps.vcore_seconds(rate)\nThe amount of CPU resources the application has allocated (virtual core-seconds)shown as second\n\n\n\n\nyarn.node.last_health_update(gauge)\nThe last time the node reported its health (in ms since epoch)shown as millisecond\n\n\n\n\nyarn.node.used_memory_mb(gauge)\nThe total amount of memory currently used on the node (in MB)shown as mebibyte\n\n\n\n\nyarn.node.avail_memory_mb(gauge)\nThe total amount of memory currently available on the node (in MB)shown as mebibyte\n\n\n\n\nyarn.node.used_virtual_cores(gauge)\nThe total number of vCores currently used on the nodeshown as core\n\n\n\n\nyarn.node.available_virtual_cores(gauge)\nThe total number of vCores available on the nodeshown as core\n\n\n\n\nyarn.node.num_containers(gauge)\nThe total number of containers currently running on the node\n\n\n\n\n","tags":"","loc":"/integrations/yarn/"},{"title":"Datadog-Zendesk Integration","text":"\n\nOverview\n\n\n\nZendesk is a customer service and support ticket platform that allows you to receive, track and respond to inquiries and requests from customers. Enable this integration to see ticket metrics in Datadog and to create and update tickets from Datadog.\n\nIntegrate with Zendesk to:\n\n\n  Monitor and graph ticket count metrics by status, user, and satisfaction rating\n  Receive a Datadog event each time a new Zendesk ticket is opened\n  Create and update tickets using @zendesk mentions\n\n\n\nInstallation\n\nTo install this integration, you will first need to generate a Zendesk API Token:\n\n\n  Navigate to the API settings page by clicking the Admin gear icon from the left menu, then selecting API from the Channels section of the menu item list.\n  Enable Token Access if it is not already enabled.\n  Click the plus symbol to create a new token.\n  Set the API Token description to something informative, e.g. “Datadog-Zendesk Integration”\n  Copy the API Token. Important: You will need to temporarily save this token, as it will be hidden once you click Save.\n  Click Save.\n\n\nTo complete the integration, enter your information in Datadog:\n\n\n  Visit the Zendesk integration tile or navigate to it by clicking Integrations in the left side menu, then clicking the Zendesk integration tile. Then click on the Configuration tab.\n  Enter your Zendesk domain. This is the text that appears before zendesk.com. e.g. If your Zendesk is located at https://my-company.zendesk.com, your domain will be my-company.\n  Enter your Zendesk username.\n  Paste the Zendesk API Token you received in step 5 above.\n  Click the Install Integration button.\n\n\n\nMetrics\n\n\n\n\nzendesk.ticket.count(gauge)\nThe number of tickets per status and assignee.\n\n\n\n\nzendesk.satisfaction.rating(gauge)\nThe number of satisfaction ratings submitted today per rating and assignee.\n\n\n\n\nzendesk.tickets_today(gauge)\nThe number of tickets opened and solved today (UTC).\n\n\n\n\nzendesk.recent_tickets(count every 300 seconds)\nThe rate of tickets opened and solved\n\n\n\n\n\nEvents\n\nThis integration will generate an event each time a new Zendesk ticket is opened.\n\n\nZendesk Tickets\n\nYou can create new Zendesk tickets and assign them to a a group. First add the group name in the Datadog Zendesk integration tile, then use @zendesk-group-name in your Datadog monitors and annotations. e.g. to create a ticket and assign it to the Zendesk group Support, you would add the group and use @zendesk-support.\n","tags":"","loc":"/integrations/zendesk/"},{"title":"Datadog-Zookeeper Integration","text":"\n\nOverview\n\nConnect ZooKeeper to Datadog in order to:\n\n\n  Visualize ZooKeeper performance and utilization.\n  Correlate the performance of ZooKeeper with the rest of your applications.\n\n\nFor more details about configuring this integration refer to the following file(s) on GitHub:\n\nZookeeper YAML example\nZookeeper checks.d\n\n\n\n\n\nConfiguration\n\n\n  \n    Configure the Agent to connect to ZooKeeper. Edit conf.d/zk.yaml\n\n    init_config:\n\ninstances:\n  - host: localhost\n    port: 2181\n    timeout: 3\n\n  \n  \n    Restart the Agent\n  \n\n\n\nValidation\n\nExecute the info command and verify that the integration check has passed. The output of the command should contain a section similar to the following:\n\nChecks\n======\n\n  [...]\n\n  zk\n  --\n    - instance #0 [OK]\n    - Collected 8 metrics & 0 events\n\n\n\nMetrics\n\n\n\n\nzookeeper.bytes_received(gauge)\n\n\n\n\nzookeeper.bytes_sent(gauge)\n\n\n\n\nzookeeper.packets_received(gauge)\nThe number of packets received.shown as packet/second\n\n\n\n\nzookeeper.packets_sent(gauge)\nThe number of packets sent.shown as packet/second\n\n\n\n\nzookeeper.connections(gauge)\nThe total count of client connections.shown as connection\n\n\n\n\nzookeeper.datadog_client_exception(rate)\nThe exception rate seen by the Datadog Agent when trying to collect stats.shown as error\n\n\n\n\nzookeeper.latency.avg(gauge)\nThe amount of time it takes for the server to respond to a client request.shown as millisecond\n\n\n\n\nzookeeper.latency.max(gauge)\nThe amount of time it takes for the server to respond to a client request.shown as millisecond\n\n\n\n\nzookeeper.latency.min(gauge)\nThe amount of time it takes for the server to respond to a client request.shown as millisecond\n\n\n\n\nzookeeper.nodes(gauge)\nThe number of znodes in the ZooKeeper namespace (the data).shown as node\n\n\n\n\nzookeeper.outstanding_requests(gauge)\nThe number of queued requests when the server is under load and is receiving more sustained requests than it can process.shown as request\n\n\n\n\nzookeeper.timeouts(rate)\nThe rate of timeouts the Datadog Agent received when trying to collect stats.shown as occurrence\n\n\n\n\nzookeeper.zxid.count(gauge)\n\n\n\n\nzookeeper.zxid.epoch(gauge)\n\n\n\n","tags":"","loc":"/integrations/zookeeper/"},{"title":"Libraries","text":"\nThere are many libraries available to help you interact with the Datadog API.\n\n\nC#\n\n\n  \ndogstatsd-csharp-client - A C# DogStatsD client.\n\n\n\nGo\n\n\n  \ndatadog-go - A Go DogStatsD client.\n\n\n\nJAVA\n\n  \njava-dogstatsd-client - a DogStatsD Client for Java written by Indeed and Datadog.\n\n\n\nPython\n\n\n  \ndatadogpy - A Python Datadog API wrapper and DogStatsD client.\n\n\n\nRuby\n\n\n  \nDogApi - A Ruby Datadog API wrapper.\n  \ndogstatsd-ruby - A Ruby DogStatsD client.\n\n\n\nPHP\n\n\n  \nphp-datadogstatsd - An extremely simple PHP DogStatsD client written by Alex Corley.\n\n\n\nCommunity Libraries\n\nSome great folks have written their own libraries to help interact with Datadog. Check them out:\n\n\nC#\n\n\n  \nmetrics.net-datadog - a .NET translation of the metrics-to-datadog java adapter\n\n\n\nCrystal\n\n\n  \nstatsd.cr - A statsd client library implemented in Crystal by Mike Fiedler\n\n\n\n\nDelphi\n\n\n  \ndatadog-delphi - A statsd client library implemented in Delphi.\n\n\n\nElixir\n\n\n  \nExStatsD - an Elixir DogStatsD library by CargoSense.\n  \ndogstatsd-elixir - a dogstatsd client in Elixir by Adam Kittelson.\n  \nmtx - an Elixir Datadog client by synrc.\n\n\n\nGo\n\n\n  \necsdog - a standalone Go application that scrapes metrics and events from ECS, and sends them to statsd by ejholmes\n\n  \ngodspeed - a feature-rich dogstatsd client written in Go by PagerDuty.\n  \ngo-datadog-api - a Go wrapper for our API by Mark Smith from Dropbox.\n  \ngo-dogstatsd - a dogstatsd client written in Go by Ooyala.\n  \nxstats - a generic client for service instrumentation using dogstatsd in Go by Olivier Poitrey.\n\n\n\nJava\n\n\n  \nmetrics-datadog - a backend to yammers’s metrics library written by Coursera.\n  \nLassie - a Java screenboard API client by Bazaarvoice.\n  \njava-dogstatsd-client - DogStatsD Client for Java to submit both Events and Metrics written by arnabk.\n\n\n\nNode.js\n\n  \nhotshots - a Node.js client for statsd, DogStatsD, and Telegraf written by Brightcove.\n  \nnode-datadog - a Node.js API client, contributed by HashGo.\n  \nnode-dogstatsd - a Node.js DogStatsD client, contributed by Young Han Lee.\n  \nnode-dogapi - a Node.js API client, contributed by Brett Langdon.\n  \ndatadog-metrics - Node.js API client, contributed by Daniel Bader.\n\n\n\nPerl\n\n\n  \nwebservice-datadog - a Perl API client, contributed by Jennifer Pinkham.\n  \ndogstatsd-perl - a Perl DogStatsD client, contributed by Stefan Goethals.\n\n\n\nPHP\n\n\n  \ndog-statsd - A fork of thephpleague/statsd with additional Datadog features by Graze.\n  \nplesk_metrics_datadog - a PHP script to collect metrics from Plesk by Israel Viana.\n\n\n\nPython\n\n\n  \nscales_datadog - a Datadog backend for the Scales library, written by Tommaso Barbugli.\n\n\n\nRuby\n\n\n  \nmetricks-dogstatsd - a backend for the popular Metriks gem, written by Mavenlink.\n  \nhotdog - A command-line interface contributed by Yuu Yamashita.\n\n\n\nR\n\n\n  \nrdog - an R package to analyze Datadog metrics into R.\n\n\n\nScala\n\n\n  \ndatadog-scala - a Scala API client, written by Cory Watson.\n\n\n\nCommunity APM (Tracing) Libraries\n\n\nC#\n\n\n  \nDatadogSharp - A C# Datadog client that supports DogStatsD and APM.\n\n\n\nElixir\n\n\n  \nspandex - A Datadog APM reporting library.\n\n\n\nJava\n\n\n  \napm-client - A Java client for Datadog APM.\n\n\n\nOpenTracing\n\n\n  \n    datadog-tracer-js - OpenTracing tracer implementation for Datadog in JavaScript.\n  \n  \n    dd-go-opentracing - OpenTracing tracer implementation for Datadog in Go.\n  \n\n\n\nPHP\n\n\n  \ndd-trace-php - A PHP tracing implementation for Datadog.\n\n\n\nZipkin\n\n\n  \ndd-zipkin-proxy - A simple Zipkin-to-Datadog proxy.\n\n\n\nCommunity Integration Libraries\n\n\nAnsible\n\n\n  In addition to our official integration, the monitoring section of the ansible-modules-extras repository contains modules that interact with Datadog.\n\n\n\nConsul\n\n\n  Publish consul service counts into Datadog via dogstatsd with this library.\n\n\n\nDogscaler\n\n\n  Scale up auto-scale groups based on the results of a datadog query with Dogscaler.\n\n\n\nFreeSwitch\n\n\n  This is for a FreeSwitch ESL  application to export statistics to DataDog using the dogstatsd API and is written by WiMacTel.\n\n\n\nGoogle Analytics\n\n\n  You can get data into Datadog from Google Analytics using our API with this library.\n\n\n\nLogstash Output\n\n\n  Logstash Output for Datadog\n  Logstash Output for Dogstatsd\n\n\n\nNGINX LUA\n\n\n  Emit custom metrics directly from NGINX configurations using the nginx_lua_datadog module in your LUA scripts.\n  \nlua-resty-dogstatsd is an extension developed by  mediba inc, which enables emiting metrics, events, and service checks to DogStatsD protocol. lua-resty-dogstatsd is released as GPLv3 and relies on the nginx cosocket API.\n\n\n\nPhusion Passenger\n\n\n  Send health metrics from Phusion’s Passenger server using the passenger-datadog-monitor written by Stevenson Jean-Pierre\n\n\n\n\nPid-stats\n\n\n  This library will allow you to generate process information from StatsD, given pid files. It was created by GitterHQ.\n\n\n\nSaltstack\n\n\n  Datadog Saltstack Formula\n  \nDatadog Saltstack written by Luca Cipriani.\n\n\nIf you’ve written a Datadog library, write us at code@datadoghq.com and we’ll be happy to add it to the list.\n\n","tags":"","loc":"/libraries/"},{"title":"Metric Types","text":"\nA metric’s Datadog in-app type affects how its data is interpreted in query results and graph visualizations across the app. The metric type visible on the metric summary page is the Datadog in-app type. You should only change the type if you have started submitting this metric with a new type, and should be aware that changing the type may render historical data nonsensical.\n\n\nHow do submission types relate to Datadog in-app types?\nDatadog accepts metrics submitted from a variety of sources, and as a result the submission type does not always map exactly to the Datadog in-app type:\n\n\n  \n    \n      Submission Source\n      Submission Method (python)\n      Submission Type\n      Datadog In-App Type\n    \n  \n  \n    \n      API\n      api.Metric.send(...)\n      gauge\n      gauge\n    \n    \n      dogstatsd\n      dog.gauge(...)\n      gauge\n      gauge\n    \n    \n      dogstatsd\n      dog.increment(...)\n      counter\n      rate\n    \n    \n      dogstatsd\n      dog.histogram(...)\n      histogram\n      gauge, rate\n    \n    \n      dogstatsd\n      dog.set(...)\n      set\n      gauge\n    \n    \n      agent check\n      self.gauge(...)\n      gauge\n      gauge\n    \n    \n      agent check\n      self.increment(...)\n      counter\n      rate\n    \n    \n      agent check\n      self.rate(...)\n      rate\n      gauge\n    \n    \n      agent check\n      self.count(...)\n      count\n      count\n    \n    \n      agent check\n      self.monotonic_count(...)\n      monotonic_count\n      count\n    \n    \n      agent check\n      self.histogram(...)\n      histogram\n      gauge, rate\n    \n    \n      agent check\n      self.set(...)\n      set\n      gauge\n    \n  \n\n\n\nWhat’s a use case for changing a metric’s type?\n\n\n  \n    A user has a metric app.requests.served that counts requests served, she accidently submits it via dogstatsd as a gauge. The metric’s Datadog type is therefore gauge.\n  \n  \n    She realizes she should have submitted it as a dogstatsd counter metric, that way she can do time aggregation to answer questions like “How many total requests were served in the past day?” by querying sum:app.requests.served{*} (this would not make sense for a gauge-type  metric.)\n  \n  \n    She likes the name app.requests.served so rather than submitting a new metric name with the more appropriate counter type, she’ll change the type of app.requests.served.\n\n    a. She updates her submission code, calling dogstatsd.increment('app.requests.served', N) after N requests are served.\n\n    b. She updates the Datadog in-app type via the metric summary page to rate.\n  \n\n\nThis will cause data submitted before the type change for app.requests.served to behave incorrectly because it\nwas stored in a format to be interpreted as an in-app gauge not a rate. Data submitted after steps 3a and 3b\nwill be interpreted properly. If she was not willing to lose the historical data submitted as a gauge she would\nhave created a new metric name with the new type, leaving the type of app.requests.served unchanged.\n","tags":"","loc":"/metrictypes/"},{"title":"Monitoring Reference","text":"\nMonitoring in Datadog refers to the ability to notify your team when conditions are met. If you are just starting with monitors in Datadog, please refer to our Guide to Monitors for an introduction.\n\n\nGlossary\n\nHere is a quick overview of the different terms used in this guide.\n\n\n  \nStatus: Each check run submits a status of OK, WARNING or CRITICAL.\n  \nCheck: Emits one or more statuses.\n  \nMonitor: Sends notifications based on a sequence of check statuses, metric\nthreshold or other alerting conditions.\n  \nMonitor type: host-, metric-, integration-, process-, network-, event-based, and custom. See side navigation to drill into a specific type.\n  \nTags: Configurable labels that can be applied to each metric and host. See the Tagging page for more details.\n\n\n\nCreating a Monitor\n\nNavigate to the Create Monitors\npage by highlighting the “Monitors” tab in the main menu and selecting the\n“Create Monitors” sub-tab (depending on your chosen theme, the main menu may be at the top or on the left).  You will be presented with a list of monitor types\non the left. This document will walk through the configuration of each type.\n\n\nHost Monitors\n\nRequires Datadog Agent version >= 5.0.0.\n\n\n\nEvery Datadog Agent collection reports a heartbeat called datadog.agent.up\nwith a status UP. You can monitor this heartbeat across one or more hosts.\n\n\n  \n    Select your host by name or tag(s). Providing a tag will monitor every\nhost that has that tag or tag combination.\n  \n  \n    Select the no-data timeframe. If the heartbeat stops reporting for more\nthan the number of minutes you have selected, then you will get notified.\n  \n  \n    Configure your notification options Refer to the\nNotifications section of this guide for a detailed\nwalkthrough of the common notification options.\n  \n\n\n\nMetric Monitors\n\n\n  \n    Select the metric and scope you want to monitor.\n  \n\n    You can create a monitor on any metrics that you are currently sending to\n Datadog. The standard scoping rules apply here. Please refer to the\n scope section of the graphing primer for\n further information.\n  \n  \n    Select the alert grouping.\n \n\n    A simple alert aggregates over all reporting sources. You will get one\n alert when the aggregated value meets the conditions set below. This works\n best to monitor a metric from a single host, like avg of\n system.cpu.iowait over host:bits, or for an aggregate metric across many\n hosts like sum of nginx.bytes.net over region:us-east.\n\n    A multi alert applies the alert to each source, according to your group\n parameters. E.g. to alert on disk space you might group by host and device,\n creating the query:\n\n     avg:system.disk.in_use{*} by {host,device}\n\n\n    This will trigger a separate alert for each device on each host that is\n running out of space.\n  \n  \n    Select the alert type.\n \n\n    A threshold alert will compare the value in the selected\n timeframe against a given threshold. There are additional options available\n in the alerting conditions section. This is the standard alert case where\n you know what sort values are unexpected.\n\n    A change alert will compare the change or % change of a value between\n now and some time ago against a given threshold.\n The compared data points will not be single points but are computed using\n the parameters in the alert conditions section.\n\n    This type of alert is useful to track fast spikes or drops as well as slow\n changes in a metric when you might not have an exact “unexpected” threshold.\n Note: the calculated value is not the absolute value - meaning it will be\n negative for a downward change.\n  \n  \n    Select the alert conditions\n\n    \n      \n        The threshold options vary slightly depending on what alert type you\nhave chosen. For either case, you input a threshold and comparison type\nbased on your metric. As you change your threshold, you will see the graph\nupdate with a marker showing the cutoff point.\n\n        \n\n        Note that you can use formatted values in this input based on the\nmetric itself. For example, if you are monitoring system.disk.used, you\ncan give a threshold of 20GB.\n\n        For a threshold alert you will be able to chose a time aggregation\nof the data. The alerting engine will generate a single series and perform\nselected aggregation.\n\n        Let’s look at the details of each option:\n\n        \n          \n            on average: The series will be averaged to produce a single\nvalue that will be checked against the threshold.\n          \n          \n            at least once: If any single value in the generated series crosses\nthe threshold then an alert will be triggered.\n          \n          \n            at all times: If every point in the generated series is outside the\nthreshold then an alert will be triggered.\n          \n          \n            in total: If the summation of every point in the series is outside\nthe threshold then an alert will be triggered.\n          \n        \n\n        Note the on average and at all times aggregations require a full\nwindow of data in the final series. This does not mean that each series\nmust be full but that there shouldn’t be a gap of more than 1 minute\nacross all aggregated series. In other words, we recommend using at least\nonce or in total for metrics with > 1 minute interval.\n      \n      \n        When you select the change alert option, you will have additional\n parameters you can adjust.\n        \n          \nchange is an absolute change of the value whereas % change is the\npercentage change of your value compared to its previous value (so if\nit was a value of 2 and now 4, the % change will be 100%).\n          You can compare the change of the value during a given timeframe by\nselecting the period you want to compare against. This can range from 5\nminutes to up to 2 days.\n          Like the threshold alert, you will need to select the\ntime aggregation and a time window on which the change will be\ncalculated.\n        \n      \n    \n  \n  \n    You can optionally notify on no data after a configurable timeframe. At\nthe minimum, your chosen timeframe must be greater than 2x the alerting\nwindow. For example, if you are alerting over the last 5 minutes then you\nwould need to wait at least 10 minutes before notifying on missing data.\n  \n  \n    You can opt to automatically resolve the monitor from a triggered\nstate. In general you’ll want to leave this option off as you only want\nan alert to be resolved when it’s fixed.\n\n    This most common use-case for this option is when you have very sparse\ncounters, e.g. for errors. When errors stop occuring the metric will stop\nreporting. This means the monitor will not resolve because there are not\nanymore values to trigger a resolution.\n  \n  \n    Configure your notification options Refer to the\nNotifications section of this guide for a detailed\nwalkthrough of the common notification options.\n  \n\n\n\nIntegration Monitors\n\n\n\nOn the integration tab you will see a list of your installed integrations. Upon\nselection, you can choose to monitor either a “Status” or a “Metric”.\n\n\n  \n    Choosing Integration Status will present you with one or more service\nchecks for each integration. Please refer to the\ncustom monitors section for details on the\navailable options.\n  \n  \n    Choosing Integration Metric will provide a familiar interface used for a\ninterface used for a Metric Monitor. You will be able to choose from any of\nthe metrics provided by this integration. Please refer to the\nalert conditions section for details on the available\noptions.\n  \n\n\n\nProcess Monitors\n\n\n\nA process monitor will watch the status produced by the process.up service\ncheck reported by the check in the Agent. At the Agent level you can configure\nthresholds based on the number of matching processes.\n\nRead more about configuration on the Process Check\npage.\n\nFor each process, a single service check status will be produced. Through this\ncreation interface, you can choose which of those checks to monitor and at what\npoint they should notify.\n\n\n  \n    Pick the process to monitor. You will see the names configured in any\nAgent with an active process check.\n  \n  \n    Pick the monitor scope. You will only see hosts or tags that\nare reporting a status for the selected process.\n  \n  \n    Select alerting options. Please refer to the\ncustom monitors section for details on the available options.\n  \n  \n    Configure your notification options Refer to the\nNotifications section of this guide for a detailed\nwalkthrough of the common notification options.\n  \n\n\n\nNetwork Monitors\n\n\n\nNetwork monitors cover the TCP and HTTP checks available in the Agent. Read\nthe guide to network checks for details on Agent\nconfiguration.\n\nNetwork Status\n\n\n  \n    Choose a network check. You will be able to choose from all HTTP and TCP\nchecks being submitted by your Agents.\n  \n  \n    Pick monitor scope. You will only see hosts or tags reporting\nthe check you have chosen.\n  \n  \n    Select alerting options. Please refer to the\ncustom monitors section for details on the available\noptions.\n  \n  \n    Configure your notification options Refer to the\nNotifications section of this guide for a detailed\nwalkthrough of the common notification options.\n  \n\n\nNetwork Metric\n\n\n  \n    Choose a network metric. You will be able to choose either the TCP or\nHTTP response time metric.\n  \n  \n    Pick monitor scope. You will only see hosts or tags reporting\nthe metric you have chosen.\n  \n  \n    Select alerting options. Please refer to the\nalert-conditions section for details on the available\noptions.\n  \n  \n    Configure your notification options Refer to the\nNotifications section of this guide for a detailed\nwalkthrough of the common notification options.\n  \n\n\n\nEvent Monitors\n\nEvent monitors allows you to alert when an event matching your query occurs.\n\n\n\n\n  \n    Select the query and parameters (status, priority, sources and tags) you want\n to monitor.\n  \n  \n    Select the alert gouping\n  \n  \n    Select the alerting conditions. The threshold value and timeframe\n options allows you to set the number of occurence of an event required during\n a timeframe before triggering the monitor.\n  \n  \n    Configure your notifcation options. Refer to the Notifications\n section of this guide for informations.\n  \n\n\n\nCustom Monitors\n\n\n\nCustom monitors encompass any service checks that are not reported by one of the\nout-of-the-box integrations included with the Agent.\n\nRefer to the Guide to Agent Checks for detailed\ninformation on writing your own checks that send metrics, events,\nor service checks.\n\n\n  \n    Select your custom check.\n  \n  \n    Select host or tags that you would like to monitor. The check will run\nfor every unique set of tags from all monitored hosts. For example, the\nNginx service check reports one status per {host,port}. So if you have\nmultiple servers running on a single host, then each one will alert separately\nin the case of failure.\n  \n  \n    Select your alert options.\n\n    While each check run will send a status of either CRITICAL, WARNING or OK,\nyou can choose at what consecutive conditions to cause a state change and a\nnotification. For example, you might want to know immediately when your check\nfails and only have it recover if it stays that way. In this case you might\nchoose to notify on 1 critical status, 1 warning status and 4 OK statuses.\n\n    You can optionally notify on no data after a configurable timeframe. You\nmust choose at least 2 minutes for your timeframe.\n  \n  \n    Configure your notification options. Refer to the\nNotifications section of this guide for a detailed\nwalkthrough of the common notification options.\n  \n\n\n\nMonitor Notifications\n\nNotifications are a key component of any monitor. You want to make sure the\nright people get notified so the problem can be resolved as soon as possible.\n\n\n\n\n  \n    Give your monitor a title. It is often useful to use a succinct\nexplanation of the monitor so a notified team member can quickly understand\nwhat is going on.\n  \n  \n    Enter a message for the monitor. This field allows standard\nmarkdown formatting\nas well as Datadog’s @-notification syntax. Note: you can notify any\nnon-Datadog users via email by simply adding @their-email to the\nmessage.\n\n    A common use-case for the monitor message is to include a step-by-step way\nto resolve the problem. For example if you are monitoring a database then you\nmight want to include steps for failing over to a standby node. All in all,\nyou should attempt to give as much context to the monitor as possible.\n  \n  \n    Optionally enable monitor renotification. This option is useful to remind\nyour team that a problem is not solved until the monitor is marked as\nresolved. If enabled, you can configure an escalation message to be sent\nanytime the monitor renotifies. The original message will be included as\nwell.\n  \n\n\n\nMessage template variables\n\nMessage template variables can be used to customize your monitor notifications.\nThis feature is supported in all monitor types. There are two primary use cases\nfor template variables: 1) displaying a different message depending on the\nnotification type (e.g. triggered, recovered, no data) and 2) incorporating the\ntriggering scope into the message of multi alerts.\n\n\n  \n    Conditional variables for different notification types: You can have a\n monitor event display a different message depending on whether the event is a\n trigger, warning, recovery, or no data notification. These variables use simple if-else\n logic with the following syntax:\n\n    \n\n    Here is an example of how you can set it up in the editor:\n\n    \n\n    The corresponding trigger event notification will look like this:\n\n    \n\n    and the recovery notification:\n\n    \n\n    The conditional variables available are is_alert, is_alert_recovery,\n is_warning, is_warning_recovery, is_recovery, and is_no_data.\n These can also be seen in the “Use message template variables” help box in\n Step 3 of the monitor editor.\n  \n  \n    Tag variables for multi alerts: When your monitor is a multi alert, instead\n of having a generic message (and finding the triggering tag scope in the alert\n query definition), a variable can be used in the message for explicitly\n identifying the triggering scope.\n\n    Here is an example of how you can use template variables for a multi alert:\n\n    \n\n    and the corresponding event notification:\n\n    \n\n    The tag template variables available depend on the tag group selected in Step 1\n of the monitor editor. The possible options will automatically populate at the\n bottom of the “Use message template variables” help box in Step 3 of the editor.\n These variables can also be used in the monitor titles (names), but note that\n the variables are only populated in the text of Datadog child events (not the\n parent, which displays an aggregation summary).\n\n    Some tags identifying your triggering scope will automatically be inserted into\n the title of your multi alert. If your scope is defined by a lot of tags, your\n alert title may end up being undesirably long. If you’ve used template tag variables\n to include this information in the body of your alert, you can uncheck\n Include triggering tags in notification title to save some space. This will make\n your notification title look like this:\n\n    \n\n    Note that template variable content is escaped by default. If your variable\n contains JSON or code that you would NOT like to be escaped, then use triple braces\n instead of double braces (e.g. {{{event.text}}}).\n  \n  \n    Conditional variables for different triggering scopes: You can have a\nmonitor event display a different message depending on the group that’s\ncausing a notification.\n\n    The {{is_match}} conditional lets you match the triggering context to some\nstring. For example, you might want to notify your db team if a triggering\nhost has role:db but notify your app team if the host has role:app.\n\n    You can use any of the available tag variables in your condition. A match\nwill be made if the comparison string is anywhere in the resolved variable.\n\n    The variable uses the following format:\n\n    {{#is_match \"tag_variable\" \"comparison_string\"}}\nThis will show if comparison_string is in tag_variable.\n{{/is_match}}\n\n\n    Here is an example of how you can give a different message depending on the\ntriggering context:\n\n    \n  \n\n\n\nVariable availability\n\nWe provide a number of different types of monitors and not all variables are available for each type of monitor. Integration monitor variables are largely dependent on the specific integration and monitor configuration.\n\n\n  \n    \n       \n      host\n      metric\n      integration\n      process\n      network\n      custom check\n      event\n    \n    \n      Conditionals\n       \n       \n       \n       \n       \n       \n       \n    \n    \n      is_alert\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n    \n    \n      is_alert_recovery\n       \n      Y\n      Y\n      Y\n      Y\n      Y\n       \n    \n    \n      is_warning\n       \n      Y\n      Y\n      Y\n      Y\n      Y\n       \n    \n    \n      is_warning_recovery\n       \n      Y\n      Y\n      Y\n      Y\n      Y\n       \n    \n    \n      is_recovery\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n    \n    \n      is_no_data\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n    \n    \n      is_match\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n    \n    \n      Variables\n       \n       \n       \n       \n       \n       \n       \n    \n    \n      {{value}}\n       \n      Y\n      Y\n       \n       \n       \n       \n    \n    \n      {{threshold}}\n      Y (cluster)\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n    \n    \n      {{warn_threshold}}\n      Y (cluster)\n      Y\n      Y\n      Y\n      Y\n      Y\n       \n    \n    \n      {{ok_threshold}}\n       \n       \n      Y\n      Y\n      Y\n      Y\n       \n    \n    \n      {{comparator}}\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n      Y\n    \n    \n      Additional variables\n      Contextual\n       \n      Contextual{{check_message}}\n\n      Contextual{{process.name}}\n\n      Contextual{{url.name}}{{instance.name}}\n\n      {{check_message}}\n       \n    \n  \n\n\n\n  .tpl-var-table tr td {\n    text-align: center;\n    border: 1px #9d6ebf solid;\n    padding: 5px;\n  }\n  .tpl-var-table tr td:first-child {\n    text-align: right;\n  }\n\n\nNote that some monitors offer addtional contextual variables based on what you are monitoring. For example, host monitors may provide variables for host.availability-zone and host.cloud_provider. You can see a complete list of contextual template variables available to your monitor by clicking the “Use message template variables” link or in the list of suggestions that appears when you type “{{“ to begin a template variable name.\n\n\nMonitor FAQs\n\n\n  \n    Can I manage my monitors programatically?\n\n    Yes. Refer to the Datadog API docs\nfor detailed information on managing monitors through the API using the\navailable libraries or cURL.\n  \n  \n    Can you alert on a function?\n\n    Yes, selecting the ‘Source’ tab of a monitor editor (Step 1) will allow you to\nalert on custom queries and functions, similar to the JSON editor for graphs.\n  \n\n","tags":"","loc":"/monitoring/"},{"title":"Tracing API","text":"Overview\n\nDatadog’s APM allows you to collect performance metrics by tracing your code to determine which parts of your application are slow or inefficient.\n\nTracing data is sent to the Datadog Agent via an HTTP API. We provide some official libraries that simplify sending metrics to the Datadog Agent, however you may want to interact directly with the API to instrument applications that cannot use the libraries or are written in languages that don’t yet have an official Datadog Tracing library.\n\nAPI\n\n\n\nTraces\n\n\n  \n    Arguments\n    \n          \n      traces [required]\n      A list of traces. Traces are a list of spans as JSON objects containing the span information:\n        \n          trace_id - Required. The unique integer (64-bit unsigned) ID of the trace containing this span.\n          span_id - Required. The span integer (64-bit unsigned) ID.\n          name - Required. The span name.\n          resource - Required. The resource you are tracing.\n          service - Required.The service name.\n          type - Required. The type of request.\n          start - Required. The start time of the request in nanoseconds from the unix epoch.\n          duration - Required. The duration of the request in nanoseconds.\n          parent_id - Optional. The span integer ID of the parent span.\n          error - Optional. Set this value to 1 to indicate if an error occured. If an error occurs, you should pass additional information, such as the error message, type and stack information in the meta property.\n          meta - Optional. A dictionary of key-value metadata. e.g. tags.\n        \n      \n    \n\n    \n\n    Note: You may send multiple spans within a trace array and each span within a trace should use the same trace_id. You may also send multiple traces.\n\n    Response\n\n    The Agent will return a 200 status code and the text \"OK\" if the traces were successfully delivered. If delivery fails, a 500 status code and an error message will be returned. Note that successful delivery does not mean the traces are accepted. Traces may be dropped after successful delivery. For more information about your traces, please refer to your agent log.\n\n  \n\n  \n    Signature\n    PUT /v0.3/traces\n\n    Example Request\n    \n      #!/bin/bash\n\n# Create IDs.\nTRACE_ID=($RANDOM % 1000000)\nSPAN_ID=($RANDOM % 1000000)\n\n# Start a timer.\nSTART=$(date +%s%N)\n\n# Do things...\nsleep 2\n\n# Stop the timer.\nDURATION=$(($(date +%s%N) - $START))\n\n# Send the traces.\ncurl -X PUT -H \"Content-type: application/json\" \\\n  -d \"[[{\n    \\\"trace_id\\\": $TRACE_ID,\n    \\\"span_id\\\": $SPAN_ID,\n    \\\"name\\\": \\\"span_name\\\",\n    \\\"resource\\\": \\\"/home\\\",\n    \\\"service\\\": \\\"service_name\\\",\n    \\\"type\\\": \\\"web\\\",\n    \\\"start\\\": $START,\n    \\\"duration\\\": $DURATION\n  }]]\" \\\n  http://localhost:8126/v0.3/traces\n\n    \n\n    Example Response\n    \n      OK\n\n    \n  \n\n\nServices\n\n\n  \n    Arguments\n    \n          \n      service [required]\n      A service as a JSON object containing the service name mapped to application and application type information:\n        \n          service - Required.The service name as a dictionary key.\n          app - Required. The name of the application.\n          app_type - Required. The type of application.\n        \n      \n    \n\n    \n\n    Response\n\n    The Agent will return a 200 status code and the text \"OK\" if the service was successfully delivered. If delivery fails, a 500 status code and an error message will be returned. For more information about your service, please refer to your agent log.\n\n  \n\n  \n    Signature\n    PUT /v0.3/services\n\n    Example Request\n    \n      #!/bin/bash\n\n# Send the service.\ncurl -X PUT -H \"Content-type: application/json\" \\\n  -d \"{\n    \\\"service_name\\\": {\n      \\\"app\\\": \\\"my-app\\\",\n      \\\"app_type\\\": \\\"web\\\"\n    }\n  }\" \\\n  http://localhost:8126/v0.3/services\n\n    \n\n    Example Response\n    \n      OK\n\n    \n  \n\n\n","tags":"","loc":"/tracing/api/"},{"title":"Metric Units","text":"\nThe following units may be associated with metrics submitted to datadog.\n\n\nbytes\nbit\nbyte\nkibibyte\nmebibyte\ngibibyte\ntebibyte\npebibyte\nexbibyte\n\ntime\nmicrosecond\nmillisecond\nsecond\nminute\nhour\nday\nweek\nnanosecond\n\npercentage\nfraction\npercent\npercent_nano\napdex\n\nnetwork\nconnection\nrequest\npacket\nsegment\nresponse\nmessage\npayload\ntimeout\ndatagram\nroute\nsession\n\nsystem\nprocess\ncore\nthread\nhost\nnode\nfault\nservice\ninstance\ncpu\n\ndisk\nfile\ninode\nsector\nblock\n\ngeneral\nbuffer\nerror\nread\nwrite\noccurrence\nevent\ntime\nunit\noperation\nitem\ntask\nworker\nresource\ngarbage collection\nemail\nsample\nstage\nmonitor\nlocation\ncheck\nattempt\ndevice\nupdate\nmethod\njob\ncontainer\n\ndb\ntable\nindex\nlock\ntransaction\nquery\nrow\nkey\ncommand\noffset\nrecord\nobject\ncursor\nassertion\nscan\ndocument\nshard\nflush\nmerge\nrefresh\nfetch\ncolumn\ncommit\nwait\nticket\nquestion\n\ncache\nhit\nmiss\neviction\nget\nset\n\nmoney\ndollar\ncent\n\nmemory\npage\nsplit\n\nfrequency\nhertz\nkilohertz\nmegahertz\ngigahertz\n\nlogging\nentry\n\n\n","tags":"","loc":"/units/"}]};

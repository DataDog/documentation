---
title: Archives sur AWS S3
kind: Documentation
description: Transférez tous vos logs Datadog sur S3 pour les conserver à long terme.
aliases:
  - /fr/logs/s3
---
## Archives S3

Configurez votre compte Datadog de manière à transférer tous les logs ingérés vers votre propre compartiment S3. Cela vous permet de stocker à long terme tous les logs que vous avez agrégés avec Datadog. Ce guide vous montre comment configurer cette fonctionnalité.

Remarque : Seuls les utilisateurs de Datadog bénéficiant des droits administrateur peuvent créer, modifier ou supprimer des configurations d'archivage des logs.

## Créer et configurer un compartiment S3

1. Accédez à votre [console AWS][1] et [créez un compartiment S3][2] vers lequel vos archives seront envoyées. Assurez-vous que votre compartiment n'est pas accessible au public.

2. Modifiez votre compartiment pour accorder un accès en écriture seulement à l'utilisateur Datadog AWS. Pour ce faire, modifiez les **autorisations** de votre compartiment et définissez la **politique du compartiment** à l'aide des informations suivantes (remplacez `<MY_BUCKET_NAME>` par le nom de votre compartiment) :

    ```
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Sid": "AllowDatadogArchivesUploader",
                "Effect": "Allow",
                "Principal": {
                    "AWS": "464622532012"
                },
                "Action": [
                    "s3:PutObject",
                    "s3:PutObjectAcl",
                    "s3:ListMultipartUploadParts",
                    "s3:AbortMultipartUpload"
                ],
                "Resource": "arn:aws:s3:::<MY_BUCKET_NAME>/*"
            }
        ]
    }
    ```

    {{< img src="logs/archives/log_archives_s3_iam_policy.png" alt="IAM Policy for S3 Archives" responsive="true" style="width:75%;">}}

3. Accédez à la [page des pipelines dans votre application Datadog][3], puis sélectionnez l'option **Add archive** en bas. Seuls les utilisateurs de Datadog bénéficiant des droits administrateur peuvent effectuer cette étape ainsi que la suivante.

4. Saisissez le nom de votre compartiment. Vous avez la possibilité d'ajouter un répertoire comme préfixe vers lequel l'ensemble de vos archives de logs seront envoyées. Pour terminer, enregistrez votre archive.

    {{< img src="logs/archives/log_archives_s3_datadog_settings.png" alt="Set your S3 bucket info in Datadog" responsive="true" style="width:75%;">}}

Dès que vos paramètres d'archivage ont été correctement configurés dans votre compte Datadog, tous les logs que Datadog ingère sont enrichis par vos Pipelines de processing avant d'être transférés vers votre compartiment S3 pour leur archivage.

Toutefois, après avoir créé ou modifié vos paramètres d'archivage, il est parfois nécessaire d'attendre quelques minutes avant la prochaine tentative d'importation des archives. Par conséquent, **attendez 15 minutes** avant de vérifier que les archives ont bien été importées vers votre compartiment S3 depuis votre compte Datadog.

## Format des archives S3

Les archives de logs que Datadog transmet à votre compartiment S3 sont au format JSON compressé (gzip). Au sein du préfixe que vous avez indiqué (ou dans `/` si aucun n'a été précisé), les archives sont stockées selon une structure de répertoire qui indique à quelle date et à quelle heure les fichiers d'archives ont été générés. La structure est la suivante :

`/my/s3/prefix/dt=20180515/hour=14/archive_143201.1234.7dq1a9mnSya3bFotoErfxl.json.gz`

Cette structure de répertoire vous permet de consulter plus facilement vos archives de logs en fonction de leur date.

À l'intérieur du fichier JSON compressé, le contenu de chaque événement est formaté comme suit :

```
{
    "_id": "123456789abcdefg",
    "date": "2018-05-15T14:31:16.003Z",
    "host": "i-12345abced6789efg",
    "source": "source_name",
    "service": "service_name",
    "status": "status_level",
    "message": " ... log message content ... ",
    "attributes": { ... log attributes content ... }
}
```

[1]: https://s3.console.aws.amazon.com/s3/
[2]: https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html
[3]: https://app.datadoghq.com/logs/pipelines
---
title: dbt Core
description: "Connect dbt Core to Datadog for job run metadata and model lineage."
further_reading:
  - link: '/data_observability/data_quality'
    tag: 'Documentation'
    text: 'Learn about Data Quality monitoring'
---

## Overview

Datadog can access your dbt Core metadata to extract information about job runs, including run durations, models generated by dbt, and lineage relationships between models. Datadog matches tables in your warehouse with dbt models to determine the causality and consequences of table failure.

**Note**: If you run dbt Core with an external orchestrator (such as Airflow) and want to correlate orchestrator tasks with dbt runs, follow the [Airflow integration instructions][1] first.

Follow the steps below to connect dbt Core to Datadog.

## Retrieve your Datadog API key

1. [Follow these instructions][2] to retrieve a Datadog API key.

## Install openlineage-dbt

1. Install the `openlineage-dbt` package. Reference [Using dbt with Amazon MWAA][3] for setting up this package in your virtual environment.

   ```shell
   pip3 install openlineage-dbt>=1.39.0
   ```

## Set the environment variables

1. Set the following environment variables. Replace `datadoghq.com` with the relevant [Datadog site][4] for your organization. For more information on predefined Datadog sites, see the [OpenLineage documentation][5].

   ```shell
   export DD_SITE=datadoghq.com
   export DD_API_KEY=<YOUR_DATADOG_API_KEY>
   export OPENLINEAGE__TRANSPORT__TYPE=datadog

   # OPENLINEAGE_NAMESPACE determines the Datadog tag value for the environment (similar to how the service tag identifies the application).
   # Typical values are dev, staging, or prod, but you can over ride it with any custom value.
   export OPENLINEAGE_NAMESPACE=<YOUR_ENV>

   # Optional, for debugging purposes
   export OPENLINEAGE_CLIENT_LOGGING=DEBUG
   ```

## Update the dbt invocation

1. Change the dbt invocation to use the OpenLineage wrapper (`dbt-ol`).
2. Add the `--consume-structured-logs` flag to view dbt jobs while the command is still running.

   ```shell
   dbt-ol run --consume-structured-logs --openlineage-dbt-job-name <YOUR_DBT_JOB_NAME>
   ```

## What's next

After your next dbt job run, you should start seeing job run and lineage data in [Datadog Data Observability][6], as shown below.

{{< img src="data_observability/data-obs-dbt-cloud-final.png" alt="Data Observability overview showing dbt job runs and model lineage." style="width:100%;" >}}

## Further reading

{{< partial name="whats-next/whats-next.html" >}}

[1]: /data_jobs/airflow/?tab=kubernetes
[2]: /account_management/api-app-keys/#add-an-api-key-or-client-token
[3]: https://docs.aws.amazon.com/mwaa/latest/userguide/samples-dbt.html
[4]: /getting_started/site/#access-the-datadog-site
[5]: https://openlineage.io/docs/client/python/#predefined-datadog-sites
[6]: https://app.datadoghq.com/datasets/catalog?integration=dbt

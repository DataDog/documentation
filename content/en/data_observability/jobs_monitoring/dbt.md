---
title: dbt
description: "Connect dbt Cloud or dbt Core to Datadog for job run metadata and model lineage."
aliases:
  - /data_observability/jobs_monitoring/dbtcore
  - /data_observability/jobs_monitoring/dbtcloud
further_reading:
  - link: '/data_observability/'
    tag: 'Documentation'
    text: 'Learn about Data Observability'
  - link: 'https://www.datadoghq.com/blog/understanding-dbt/'
    tag: 'Blog'
    text: 'Understanding dbt: basics and best practices'
---

<div class="alert alert-info">dbt integrations are in Preview.</div>

## Overview

Datadog can access your dbt Cloud or dbt Core metadata to extract information about job runs, including run durations, models generated by dbt, and lineage relationships between models. Datadog matches tables in your warehouse with dbt models to determine the causality and consequences of table failure.

{{< tabs >}}
{{% tab "dbt Cloud" %}}

Follow the steps below to connect dbt Cloud to Datadog.

## Generate an API token in dbt Cloud

Create a service token in dbt Cloud so Datadog can access your account's metadata.

1. In dbt Cloud, go to **User Profile > API Tokens > Service Tokens**.
2. Click on **+ Create Service Token**.
3. Provide a name for the token.
4. Set the token permissions:
   - For dbt Cloud Enterprise plan, ensure that the token has **Developer** permissions.
   - For dbt Cloud Team plan, ensure that the token has **Account Admin** permissions.
5. Click **Save** and copy the generated API token.

## Connect your dbt Cloud account to Datadog

Use the API token to configure the integration in Datadog.

1. Navigate to Datadog's [dbt Cloud integration tile][1].
2. If you have already created a dbt Cloud integration account, make sure you have updated it with the API token with permissions described above.
3. If not, create a new account. Fill in the **Account Name**, **Account Id**, **Account Url**, and **API Token** sections.
4. Click **Save** to save your settings.

## What's next

After your next dbt job run, you should start seeing job run and lineage data in [Datadog Data Observability][2], as shown below.

{{< img src="data_observability/data-obs-dbt-cloud-final.png" alt="Data Observability overview showing dbt job runs as a stacked bar chart over time and a table of connected dbt Cloud accounts with their status." style="width:100%;" >}}

[1]: https://app.datadoghq.com/integrations/dbt-cloud
[2]: https://app.datadoghq.com/datasets/catalog?integration=dbt

{{% /tab %}}

{{% tab "dbt Core" %}}

Follow the steps below to connect dbt Core to Datadog.

**Note**: If you run dbt Core with an external orchestrator (such as Airflow) and want to correlate orchestrator tasks with dbt runs, follow the [Airflow integration instructions][1] first.

## Retrieve your Datadog API key

1. [Follow these instructions][2] to create or retrieve a Datadog API key.

## Install openlineage-dbt

1. Install the `openlineage-dbt` package. Reference [Using dbt with Amazon MWAA][3] for setting up this package in your virtual environment.

   ```shell
   pip3 install openlineage-dbt>=1.39.0
   ```

## Set the environment variables

1. Set the following environment variables. Replace `datadoghq.com` with the relevant [Datadog site][4] for your organization. For more information on predefined Datadog sites, see the [OpenLineage documentation][5].

   ```shell
   export DD_SITE=datadoghq.com
   export DD_API_KEY=<YOUR_DATADOG_API_KEY>
   export OPENLINEAGE__TRANSPORT__TYPE=datadog

   # OPENLINEAGE_NAMESPACE determines the Datadog tag value for the environment (similar to how the service tag identifies the application).
   # Typical values are dev, staging, or prod, but you can over ride it with any custom value.
   export OPENLINEAGE_NAMESPACE=<YOUR_ENV>

   # Optional, for debugging purposes
   export OPENLINEAGE_CLIENT_LOGGING=DEBUG
   ```

## Update the dbt invocation

1. Change your dbt invocations to use the OpenLineage wrapper (`dbt-ol`) instead of calling `dbt` directly. This applies to any dbt command you want to track in Datadog, such as `run`, `build`, and `test`. For the full list of available commands, see the [dbt documentation][7].
2. Add the `--consume-structured-logs` flag to view dbt jobs while the command is still running.

   ```shell
   # Run models
   dbt-ol run --consume-structured-logs --openlineage-dbt-job-name <YOUR_DBT_JOB_NAME>

   # Run tests (required to see test failures in Datadog)
   dbt-ol test --consume-structured-logs --openlineage-dbt-job-name <YOUR_DBT_JOB_NAME>

   # Run build (runs models, tests, seeds, and snapshots)
   dbt-ol build --consume-structured-logs --openlineage-dbt-job-name <YOUR_DBT_JOB_NAME>
   ```

## What's next

After your next dbt job run, you should start seeing job run and lineage data in [Datadog Data Observability][6], as shown below.

{{< img src="data_observability/data-obs-dbt-cloud-final.png" alt="Data Observability overview showing dbt job runs and model lineage." style="width:100%;" >}}

[1]: /data_jobs/airflow/?tab=kubernetes
[2]: /account_management/api-app-keys/#add-an-api-key-or-client-token
[3]: https://docs.aws.amazon.com/mwaa/latest/userguide/samples-dbt.html
[4]: /getting_started/site/#access-the-datadog-site
[5]: https://openlineage.io/docs/client/python/#predefined-datadog-sites
[6]: https://app.datadoghq.com/datasets/catalog?integration=dbt
[7]: https://docs.getdbt.com/docs/running-a-dbt-project/run-your-dbt-projects

{{% /tab %}}
{{< /tabs >}}

## Further reading

{{< partial name="whats-next/whats-next.html" >}}


---
title: Logging without Limits
kind: documentation
description: Control the volume of logs indexed by Datadog
aliases:
  - /logs/dynamic_volume_control
further_reading:
- link: "logs/explorer/analytics"
  tag: "Documentation"
  text: "Perform Log Analytics"
- link: "logs/processing"
  tag: "Documentation"
  text: "Learn how to process your logs"
- link: "logs/processing/parsing"
  tag: "Documentation"
  text: "Learn more about parsing"
- link: "https://www.datadoghq.com/blog/logging-without-limits/"
  tag: "Blog"
  text: "Logging without limits blogpost"
---

{{< vimeo 293195142 >}}

## Overview

Sometimes the amount of log events generated by your infrastructure is too large and/or fluctuates a lot, raising the issue of choosing which logs should be sent to a Log Management solution and which should be sent to an archive. But filtering your logs before sending them inevitably leads to gaps in coverage, and often filters out valuable data.

Datadog log management removes these limitations by decoupling log ingestion from indexing, which makes it possible to cost-effectively collect, process, and archive all your logs.
Datadog Index Filters avoid complex Agent level configuration and control what you want to index dynamically.
You can now:

* Ingest all your log events without server side filtering
* [Process and enrich all of them][1]
* [Live Tail over the whole infrastructure][2]
* Dynamically decide what to include or exclude from your indexes to control your costs
* [Get alerted when volumes grows unexpectedly over an index][3]
* [Archive all enriched logs][4]

This flexibility is critical in some exceptional situations such as outages, when you can disable specific filters to send more data. The inverse is true as well; if you over-consume because of a seasonal reason (Black Friday, Christmas, etc...) you can decide to selectively reduce some volume to avoid overages.

## Index details

Indexes are located in the [pipeline page][5] within the Indexes section. Double click on them or click on the *edit* button to see more information about the number of logs that were indexed in the past 3 days, and the retention period for those logs:

{{< img src="logs/logging_without_limits/index_details.png" alt="" responsive="true" style="width:70%;">}}

Indexed logs can be used for [faceted searching][6], [Log Analytics][7], [dashboarding][8], and [monitoring][9].

It is also possible to have multiple indexes with different retention periods (**currently in private beta**).
Logs enter the first index whose filter they match on, so it is important to order your indexes carefully.

For example, if you create a first index filtered to the `status:notice` attribute and a second index filtered to the `status:error` attribute and a final one without any filter (the equivalent of `*`), all your notice logs would go to the first index, all your error logs to the second index and the rest would go to the final one.

{{< img src="logs/logging_without_limits/multi_indexes.png" alt="" responsive="true" style="width:70%;">}}

Multiple indexes also provide the ability to define access rules on the data contained in each index. [More information available in the role base access control documentation][10].

## Setup Log Monitors on volumes

Get notified at any moment if the volumes in any scope (`service`, `availibility-zone`, etc...) of your infrastructure is growing unexpectedly:

1. Go in the [Datadog Log Explorer][11] view
2. Build a [search query][12] that represents the volume to monitor.
3. Click on **Export to monitor**.
4. Define the rate you would like to set as *warning* or *error*.
5. Define an explicit notification: `The volume on this service just got too high. Define an additional exclusion filter or increase the sampling rate to put it back under control.`

{{< img src="logs/logging_without_limits/example_notification.png" alt="" responsive="true" style="width:70%;">}}

## Exclusion Filters

Index Filters give dynamic control over what goes into your indexes.

For example, if some logs were captured only for troubleshooting purposes, you may only care to index those logs with errors and warnings. This can easily be achieved with exclusion filters.

To define a new Index Filter click on the "add" button:

{{< img src="logs/logging_without_limits/index_filters.png" alt="" responsive="true" style="width:70%;">}}

To configure an exclusion filter:

1. Define the name of your filter
2. Define the query for logs to exclude from your index
    **Note**: It is possible to use any attribute or tag in the Index filter query, even those that are not facets. If you are filtering by non-faceted attributes or tags, be sure to hit "enter/return" from the query bar
3. Define the sampling rate
4. Save the filter

    {{< img src="logs/logging_without_limits/index_filter_details.png" alt="" responsive="true" style="width:80%;">}}

**Note**: If a log matches several exclusion filters, only the first exclusion filter rule is applied. A log is not sampled or excluded multiple times by different exclusion filters.

### Example

The following filter removes all logs that have a fast response time.
We use the `duration` attribute and filter all logs that have a value below *100ms*.

```json
{
    "http": {
        "url": "https://app.datadoghq.com/logs",
        "status_code": "200"
    },
    "duration":12,
    "metadata": {
        "version": 12,
        "release": "sept18"
    }
}
```

**Filter**: `@duration:<100`

### Container example

Container logs have a lot of metadata collected as tags. To exclude all logs coming from images that contains `httpd` in the `image_name` tag use the following filter:

**Filter**: `image_name:*httpd*`

## Reorder filters

Order matters for exclusion filters. And contrary to where several pipelines can process a log, if a log matches several exclusion filters, only the first exclusion filter rule is applied.

Reorder your pipeline to make sure the proper exclusion filters applies for your log. For instance, you probably want to set up the filters with the most inclusive queries after the others.

To reorder your exclusion filter, drag and drop them into your preferred order.


{{< img src="logs/logging_without_limits/reorder_index_filters.png" alt="" responsive="true" style="width:80%;">}}


## Enable/Disable filters

If all logs are not worth indexing on a daily basis, they might still be critical in some situations.
Debug logs, for instance, are not always useful but during a complex troubleshooting or during a production release they become very interesting to get better insight into what is going on.

Instead of changing your application logging level or using a complex internal filtering tool, it is now possible to change what is indexed directly with the Datadog index filters.

Enable or disable them in one click in the Pipeline page:

{{< img src="logs/logging_without_limits/enable_index_filters.png" alt="" responsive="true" style="width:80%;">}}

## Further Reading

{{< partial name="whats-next/whats-next.html" >}}

[1]: /logs/processing
[2]: /logs/live_tail
[3]: /monitors/monitor_types/log
[4]: /logs/archives
[5]: https://app.datadoghq.com/logs/pipelines/indexes
[6]: /logs/explorer/?tab=facets#setup
[7]: /logs/explorer/analytics
[8]: /logs/explorer/analytics/#dashboard
[9]: /monitors/monitor_types/log
[10]: /account_management/rbac
[11]: https://app.datadoghq.com/logs
[12]: /logs/explorer/search

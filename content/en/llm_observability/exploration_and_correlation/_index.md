---
title: Exploration and Correlation
description: Learn about how to explore more of your application in LLM Observability.
---

## Overview

Explore and analyze your LLM applications in production with tools for querying, visualizing, correlating, and investigating data across traces, clusters, and beyond.

Monitor performance, debug issues, evaluate quality, and secure your LLM-powered systems with unified visibility across traces, metrics, and online evaluations.

### Real-time Performance Monitoring

Monitor your LLM application's operational health with built-in metrics and dashboards:

{{< img src="llm_observability/index/llm_dashboard.png" alt=" This image shows a built‑in dashboard highlighting LLM Observability metrics." style="width:100%">}}

- Request volume and latency: Track requests per second, response times, and performance bottlenecks across different models, operations, and endpoints.
- Error tracking: Monitor HTTP errors, model timeouts, and failed requests with detailed error context.
- Token consumption: Track prompt tokens, cached tokens, completion tokens, and total usage to optimize costs.
- Model usage analytics: Monitor which models are being called, their frequency, and performance characteristics.

The out-of-the-box LLM Overview Dashboard provides consolidated views of trace-level and span-level metrics, error rates, latency breakdowns, token consumption trends, and triggered monitors.

### Production Debugging and Troubleshooting

Debug complex LLM workflows with detailed execution visibility:

- End-to-end trace analysis: Visualize complete request flows from user input through model calls, tool calls, and response generation.
- Span-level debugging: Examine individual operations within chains, including preprocessing steps, model calls, and post-processing logic.
- Identify root cause of errors: Pinpoint failure points in multi-step chains, workflows, or agentic operations with detailed error context and timing information.
- Performance bottleneck identification: Find slow operations and optimize based on latency breakdowns across workflow components.

### Quality and Safety Evaluations

{{< img src="llm_observability/index/llm_example_eval.png" alt=" This image shows a built‑in dashboard highlighting LLM Observability metrics." style="width:100%">}}

Ensure your LLM outputs meet quality standards with online evaluations. For comprehensive information about built-in quality checks, custom evaluation support, and safety monitoring capabilities, see the [Evaluations documentation][5].

### Query your LLM Application's Traces and Spans

{{< img src="llm_observability/index/llm_query_example.png" alt=" This image shows a built‑in dashboard highlighting LLM Observability metrics." style="width:100%">}}

Learn how to use Datadog's LLM Observability Query interface to search, filter, and analyze traces and spans generated by your LLM applications. The [Querying documentation][1] covers how to:

- Use the search bar to filter traces and spans by attributes such as model, user, or error status.
- Apply advanced filters to focus on specific LLM operations or timeframes.
- Visualize and inspect trace details to troubleshoot and optimize your LLM workflows.

This enables you to quickly identify issues, monitor performance, and gain insights into your LLM application's behavior in production.


### Correlate APM and LLM Observability

{{< img src="llm_observability/index/llm_apm_example.png" alt=" This image shows a built‑in dashboard highlighting LLM Observability metrics." style="width:100%">}}

You can also correlate applications instrumented by [Correlating APM and LLM Observability][2] through the SDK. Correlating with your broader app with APM enables full end-to-end visibility and seamless drill-downs from app issues into LLM-specific root causes.

### Cluster Map

{{< img src="llm_observability/index/llm_cluster_example.png" alt=" This image shows a built‑in dashboard highlighting LLM Observability metrics." style="width:100%">}}

The [Cluster Map][3] provides a visual overview of how your LLM application's requests are grouped and related. It helps you identify patterns, clusters of similar activity, and outliers in your LLM traces, making it easier to investigate issues and optimize performance.

### Monitor your Agentic Sytems 

Learn how to monitor agentic LLM applications, which use multiple tools or chains of reasoning, with Datadog's Agent Monitoring. This feature helps you track agent actions, tool usage, and reasoning steps, providing visibility into complex LLM workflows and enabling you to troubleshoot and optimize agentic systems effectively. See the [Agent Monitoring documentation][4] for details.


[1]: /llm_observability/monitoring/querying
[2]: /llm_observability/monitoring/llm_observability_and_apm
[3]: /llm_observability/monitoring/cluster_map/
[4]: /llm_observability/monitoring/agent_monitoring
[5]: /llm_observability/evaluations/
---
title: Dual Ship Logs
kind: Documentation
disable_toc: false
---

## Overview

As your infrastructure and your organization scales, so does your log volume, complexity of your data, and your observability architecture. To optimize how you manage your logs, you might need to experiment with different log management tools and routing workflows. Use Observability Pipelines to send your logs to different destinations, so that you can evaluate different tools and workflows with minimal disruption to your production environment.

Select a source to get started:

- [Datadog Agent][1]
- [Splunk HTTP Event Collector][2]
- [Splunk Heavy and Universal Forwarders (TCP)][3]
- [Sumo Logic][4]

[1]: /observability_pipelines/dual_ship_logs/datadog_agent
[2]: /observability_pipelines/dual_ship_logs/splunk_hec
[3]: /observability_pipelines/dual_ship_logs/splunk_tcp
[4]: /observability_pipelines/dual_ship_logs/sumo_logic_hosted_collector

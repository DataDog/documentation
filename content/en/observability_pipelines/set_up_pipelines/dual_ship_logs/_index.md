---
title: Dual Ship Logs
disable_toc: false
aliases:
    - /observability_pipelines/dual_ship_logs/
further_reading:
- link: "/observability_pipelines/set_up_pipelines/"
  tag: "Documentation"
  text: "Set up a pipeline"
---

## Overview

As your infrastructure and your organization scales, so does your log volume, the complexity of your data, and your observability architecture. To optimize how you manage your logs, you might need to experiment with different log management tools and routing workflows. Use Observability Pipelines to send your logs to different destinations, so you can evaluate different tools and workflows with minimal disruption to your production environment.

{{% observability_pipelines/use_case_images/dual_ship_logs %}}

## Further reading

{{< partial name="whats-next/whats-next.html" >}}

[1]: /observability_pipelines/dual_ship_logs/datadog_agent
[2]: /observability_pipelines/dual_ship_logs/fluent
[3]: /observability_pipelines/set_up_pipelines/dual_ship_logs/google_pubsub
[4]: /observability_pipelines/dual_ship_logs/http_client
[5]: /observability_pipelines/set_up_pipelines/dual_ship_logs/http_server
[6]: /observability_pipelines/set_up_pipelines/dual_ship_logs/logstash
[7]: /observability_pipelines/dual_ship_logs/splunk_hec
[8]: /observability_pipelines/dual_ship_logs/splunk_tcp
[9]: /observability_pipelines/dual_ship_logs/sumo_logic_hosted_collector
[10]: /observability_pipelines/dual_ship_logs/syslog
[11]: /observability_pipelines/set_up_pipelines/dual_ship_logs/amazon_s3
[12]: /observability_pipelines/set_up_pipelines/dual_ship_logs/amazon_data_firehose
[13]: /observability_pipelines/set_up_pipelines/dual_ship_logs/kafka
[14]: /observability_pipelines/set_up_pipelines/dual_ship_logs/socket
